{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SER1D_EMODB_AUGMENTATION.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jU1SgkWrX0Mi"
      },
      "source": [
        "# IMPORT NECESSARY LIBRARIES\n",
        "import librosa\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa.display\n",
        "from IPython.display import Audio\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras import backend as K\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import auc\n",
        "from sklearn.metrics import roc_curve\n",
        "import tensorflow as tf\n",
        "from matplotlib.pyplot import specgram\n",
        "import pandas as pd\n",
        "from sklearn import datasets, metrics, model_selection, svm\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import plot_roc_curve\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.inspection import permutation_importance\n",
        "import IPython.display as ipd  # To play sound in the notebook\n",
        "import os # interface with underlying OS that python is running on\n",
        "import sys\n",
        "import soundfile as sf\n",
        "import warnings\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import tensorflow.keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
        "from tensorflow.keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization, Dense, LSTM\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.regularizers import l2\n",
        "import seaborn as sns\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import classification_report\n",
        "seed=7\n",
        "np.random.seed(seed)\n",
        "from matplotlib.pyplot import specgram\n",
        "import glob \n",
        "import IPython.display as ipd  # To play sound in the notebook\n",
        "import pickle\n",
        "# ignore warnings \n",
        "if not sys.warnoptions:\n",
        "    warnings.simplefilter(\"ignore\")\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhSPfUfGx4aB",
        "outputId": "b60bea87-12e2-47bb-910f-39b7ae7628a8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ncafi9ylYGkn",
        "outputId": "11c4e953-352f-4dbc-ee1e-7f2af29e3511"
      },
      "source": [
        "EMO = \"/content/drive/MyDrive/Speech Emotion analysis/Emo-db/\"\n",
        "# Run one example \n",
        "dir_list = os.listdir(EMO)\n",
        "dir_list[0:5]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['08a01Ab.wav', '12a01Fb.wav', '03a01Fa.wav', '09a01Fa.wav', '08a01Na.wav']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMsD6PslZa4v",
        "outputId": "a01e58c0-3042-4682-8a0f-c0fc92366465"
      },
      "source": [
        "\n",
        "# Get the data location for EMO\n",
        "dir_list = os.listdir(EMO)\n",
        "\n",
        "# parse the filename to get the emotions\n",
        "emotion=[]\n",
        "path = []\n",
        "for i in dir_list:\n",
        "    if  (i[-6:-5]=='W') or (i[-6:-5]=='E') :\n",
        "        emotion.append('Angry')\n",
        "    elif i[-6:-5]=='F':\n",
        "        emotion.append('Happy')\n",
        "    elif (i[-6:-5]=='L') or (i[-6:-5]=='T'):\n",
        "        emotion.append('Sad')\n",
        "    elif i[-6:-5]=='A':\n",
        "        emotion.append('Fear')\n",
        "    elif i[-6:-5]=='N':\n",
        "        emotion.append('Neutral')\n",
        "    else:\n",
        "        emotion.append('Unknown') \n",
        "    path.append(EMO + i)\n",
        "\n",
        "# Now check out the label count distribution \n",
        "EMO_df = pd.DataFrame(emotion, columns = ['emotion'])\n",
        "EMO_df['source'] = 'EMO'\n",
        "EMO_df = pd.concat([EMO_df, pd.DataFrame(path, columns = ['path'])], axis = 1)\n",
        "EMO_df.emotion.value_counts()\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Angry      173\n",
              "Sad        143\n",
              "Neutral     79\n",
              "Happy       71\n",
              "Fear        69\n",
              "Name: emotion, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVMfDV66COwk",
        "outputId": "30d3421c-194b-45df-b2f4-823e636c8a7e"
      },
      "source": [
        "\n",
        "# Get the data location for EMO\n",
        "dir_list = os.listdir(EMO)\n",
        "\n",
        "# parse the filename to get the emotions\n",
        "emotion=[]\n",
        "path = []\n",
        "for i in dir_list:\n",
        "    if  (i[-6:-5]=='W') :\n",
        "        emotion.append('Angry')\n",
        "    elif (i[-6:-5]=='E') :\n",
        "        emotion.append('Disgust')    \n",
        "    elif i[-6:-5]=='F':\n",
        "        emotion.append('Happy')\n",
        "    elif (i[-6:-5]=='L') :\n",
        "        emotion.append('Boredom')\n",
        "    elif (i[-6:-5]=='T') :\n",
        "        emotion.append('Sadness') \n",
        "    elif i[-6:-5]=='A':\n",
        "        emotion.append('Fear')\n",
        "    elif i[-6:-5]=='N':\n",
        "        emotion.append('Neutral')\n",
        "    else:\n",
        "        emotion.append('Unknown') \n",
        "    path.append(EMO + i)\n",
        "\n",
        "# Now check out the label count distribution \n",
        "EMO_df = pd.DataFrame(emotion, columns = ['emotion'])\n",
        "EMO_df['source'] = 'EMO'\n",
        "EMO_df = pd.concat([EMO_df, pd.DataFrame(path, columns = ['path'])], axis = 1)\n",
        "EMO_df.emotion.value_counts()\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Angry      127\n",
              "Boredom     81\n",
              "Neutral     79\n",
              "Happy       71\n",
              "Fear        69\n",
              "Sadness     62\n",
              "Disgust     46\n",
              "Name: emotion, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5naKvXVfj8w",
        "outputId": "e6066a94-0249-439a-b4a2-14ab577235b4"
      },
      "source": [
        "df = pd.concat([EMO_df], axis = 0)\n",
        "print(df.emotion.value_counts())\n",
        "df.head()\n",
        "df.to_csv(\"Data_path.csv\",index=False)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Angry      127\n",
            "Boredom     81\n",
            "Neutral     79\n",
            "Happy       71\n",
            "Fear        69\n",
            "Sadness     62\n",
            "Disgust     46\n",
            "Name: emotion, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        },
        "id": "z5-ffVF_f1tT",
        "outputId": "a13f45ef-b0dc-431f-b87f-4ccef90548d6"
      },
      "source": [
        "# lets pick up the meta-data that we got from our first part of the Kernel\n",
        "ref = pd.read_csv(\"./Data_path.csv\")\n",
        "ref.head(30)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emotion</th>\n",
              "      <th>source</th>\n",
              "      <th>path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Fear</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Happy</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Happy</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Happy</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Neutral</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Angry</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Happy</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Neutral</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Angry</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Happy</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Boredom</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Angry</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Disgust</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Fear</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Boredom</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Happy</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Boredom</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Neutral</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Angry</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Angry</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Happy</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Angry</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Disgust</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Neutral</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Fear</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Neutral</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Fear</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>Neutral</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Angry</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Fear</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    emotion source                                               path\n",
              "0      Fear    EMO  /content/drive/MyDrive/Speech Emotion analysis...\n",
              "1     Happy    EMO  /content/drive/MyDrive/Speech Emotion analysis...\n",
              "2     Happy    EMO  /content/drive/MyDrive/Speech Emotion analysis...\n",
              "3     Happy    EMO  /content/drive/MyDrive/Speech Emotion analysis...\n",
              "4   Neutral    EMO  /content/drive/MyDrive/Speech Emotion analysis...\n",
              "5     Angry    EMO  /content/drive/MyDrive/Speech Emotion analysis...\n",
              "6     Happy    EMO  /content/drive/MyDrive/Speech Emotion analysis...\n",
              "7   Neutral    EMO  /content/drive/MyDrive/Speech Emotion analysis...\n",
              "8     Angry    EMO  /content/drive/MyDrive/Speech Emotion analysis...\n",
              "9     Happy    EMO  /content/drive/MyDrive/Speech Emotion analysis...\n",
              "10  Boredom    EMO  /content/drive/MyDrive/Speech Emotion analysis...\n",
              "11    Angry    EMO  /content/drive/MyDrive/Speech Emotion analysis...\n",
              "12  Disgust    EMO  /content/drive/MyDrive/Speech Emotion analysis...\n",
              "13     Fear    EMO  /content/drive/MyDrive/Speech Emotion analysis...\n",
              "14  Boredom    EMO  /content/drive/MyDrive/Speech Emotion analysis...\n",
              "15    Happy    EMO  /content/drive/MyDrive/Speech Emotion analysis...\n",
              "16  Boredom    EMO  /content/drive/MyDrive/Speech Emotion analysis...\n",
              "17  Neutral    EMO  /content/drive/MyDrive/Speech Emotion analysis...\n",
              "18    Angry    EMO  /content/drive/MyDrive/Speech Emotion analysis...\n",
              "19    Angry    EMO  /content/drive/MyDrive/Speech Emotion analysis...\n",
              "20    Happy    EMO  /content/drive/MyDrive/Speech Emotion analysis...\n",
              "21    Angry    EMO  /content/drive/MyDrive/Speech Emotion analysis...\n",
              "22  Disgust    EMO  /content/drive/MyDrive/Speech Emotion analysis...\n",
              "23  Neutral    EMO  /content/drive/MyDrive/Speech Emotion analysis...\n",
              "24     Fear    EMO  /content/drive/MyDrive/Speech Emotion analysis...\n",
              "25  Neutral    EMO  /content/drive/MyDrive/Speech Emotion analysis...\n",
              "26     Fear    EMO  /content/drive/MyDrive/Speech Emotion analysis...\n",
              "27  Neutral    EMO  /content/drive/MyDrive/Speech Emotion analysis...\n",
              "28    Angry    EMO  /content/drive/MyDrive/Speech Emotion analysis...\n",
              "29     Fear    EMO  /content/drive/MyDrive/Speech Emotion analysis..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "id": "q2uLMaTdf56b",
        "outputId": "c32126d9-45a3-46f2-8057-bbfaa4143b10"
      },
      "source": [
        "# ENSURE GENDER,EMOTION, AND ACTOR COLUMN VALUES ARE CORRECT\n",
        "pd.set_option('display.max_colwidth', -1)\n",
        "df.sample(100)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emotion</th>\n",
              "      <th>source</th>\n",
              "      <th>path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>458</th>\n",
              "      <td>Disgust</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis/Emo-db/13b10Ec.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>235</th>\n",
              "      <td>Fear</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis/Emo-db/10a07Ad.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>281</th>\n",
              "      <td>Sadness</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis/Emo-db/03b02Tb.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>Fear</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis/Emo-db/10a02Ab.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284</th>\n",
              "      <td>Sadness</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis/Emo-db/08b02Tc.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>Sadness</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis/Emo-db/08a02Tb.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>452</th>\n",
              "      <td>Angry</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis/Emo-db/10b10Wa.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>204</th>\n",
              "      <td>Boredom</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis/Emo-db/14a05Lb.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>371</th>\n",
              "      <td>Sadness</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis/Emo-db/15b03Tc.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>164</th>\n",
              "      <td>Angry</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis/Emo-db/03a05Wb.wav</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     emotion  ...                                                               path\n",
              "458  Disgust  ...  /content/drive/MyDrive/Speech Emotion analysis/Emo-db/13b10Ec.wav\n",
              "235  Fear     ...  /content/drive/MyDrive/Speech Emotion analysis/Emo-db/10a07Ad.wav\n",
              "281  Sadness  ...  /content/drive/MyDrive/Speech Emotion analysis/Emo-db/03b02Tb.wav\n",
              "55   Fear     ...  /content/drive/MyDrive/Speech Emotion analysis/Emo-db/10a02Ab.wav\n",
              "284  Sadness  ...  /content/drive/MyDrive/Speech Emotion analysis/Emo-db/08b02Tc.wav\n",
              "..       ...  ...                                                                ...\n",
              "60   Sadness  ...  /content/drive/MyDrive/Speech Emotion analysis/Emo-db/08a02Tb.wav\n",
              "452  Angry    ...  /content/drive/MyDrive/Speech Emotion analysis/Emo-db/10b10Wa.wav\n",
              "204  Boredom  ...  /content/drive/MyDrive/Speech Emotion analysis/Emo-db/14a05Lb.wav\n",
              "371  Sadness  ...  /content/drive/MyDrive/Speech Emotion analysis/Emo-db/15b03Tc.wav\n",
              "164  Angry    ...  /content/drive/MyDrive/Speech Emotion analysis/Emo-db/03a05Wb.wav\n",
              "\n",
              "[100 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "OjIoFKyegB13",
        "outputId": "5fa72841-ea30-4621-f535-4d8d64b29602"
      },
      "source": [
        "# LOOK AT DISTRIBUTION OF CLASSES\n",
        "df.emotion.value_counts().plot(kind='pie') "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fef5086d710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-PtNhdJKgG-D",
        "outputId": "b5a0e8d1-9a54-4b8c-f63a-eb4d02b7fddf"
      },
      "source": [
        "# Note this takes a couple of minutes (~10 mins) as we're iterating over 4 datasets \n",
        "df = pd.DataFrame(columns=['Features'])\n",
        "\n",
        "# loop feature extraction over the entire dataset\n",
        "counter=0\n",
        "for index,path in enumerate(ref.path):\n",
        "    X, sample_rate = librosa.load(path\n",
        "                                  ,res_type='kaiser_fast'\n",
        "                                  ,duration=3\n",
        "                                  ,sr=44100\n",
        "                                  ,offset=0.5\n",
        "                                 )\n",
        "    sample_rate = np.array(sample_rate)\n",
        "    result = np.array([])\n",
        "    \n",
        "    # mean as the feature. Could do min and max etc as well. \n",
        "    mfccs = np.mean(librosa.feature.mfcc(y=X, \n",
        "                                        sr=sample_rate, \n",
        "                                        n_mfcc=20),\n",
        "                    axis=0)\n",
        "    result=np.hstack((result, mfccs)) # stacking horizontally\n",
        "\n",
        "    #get the mel-scaled spectrogram (ransform both the y-axis (frequency) to log scale, and the “color” axis (amplitude) to Decibels, which is kinda the log scale of amplitudes.)\n",
        "    spectrogram = librosa.feature.melspectrogram(y=X, sr=sample_rate, n_mels=128,fmax=8000) \n",
        "    db_spec = librosa.power_to_db(spectrogram)\n",
        "    #temporally average spectrogram\n",
        "    log_spectrogram = np.mean(db_spec, axis = 0)\n",
        "    result=np.hstack((result, log_spectrogram)) # stacking horizontally\n",
        "\n",
        "    # Chroma_stft\n",
        "    stft = np.abs(librosa.stft(X))\n",
        "    chroma_stft = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T, axis=0)\n",
        "    result = np.hstack((result, chroma_stft)) # stacking horizontally\n",
        "\n",
        "    # Root Mean Square Value\n",
        "    rms = np.mean(librosa.feature.rms(y=X).T, axis=0)\n",
        "    result = np.hstack((result, rms)) # stacking horizontally\n",
        "\n",
        "    df.loc[counter] = [result]\n",
        "    counter=counter+1   \n",
        "\n",
        "# Check a few records to make sure its processed successfully\n",
        "print(len(df))\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "535\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Features</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[-3.020548105239868, -5.986682891845703, -17.65738296508789, -15.65730094909668, -15.12962818145752, -15.039176940917969, -15.331384658813477, -14.618766784667969, -14.647868156433105, -15.893167495727539, -16.321304321289062, -16.78694725036621, -15.868365287780762, -13.939315795898438, -12.105884552001953, -12.854204177856445, -13.878453254699707, -15.838191032409668, -17.212888717651367, -14.871292114257812, -12.63183879852295, -13.500885009765625, -15.568746566772461, -14.775090217590332, -16.93557357788086, -17.810428619384766, -8.799540519714355, -4.3315043449401855, -4.042933940887451, -8.786327362060547, -12.521449089050293, -14.641298294067383, -13.75732707977295, -12.103842735290527, -10.877647399902344, -11.437983512878418, -9.468372344970703, -9.869132041931152, -13.514001846313477, -9.438905715942383, -6.065412998199463, -6.006787300109863, -9.120977401733398, -12.805081367492676, -13.633074760437012, -14.039316177368164, -12.474197387695312, -14.707188606262207, -16.328716278076172, -13.983403205871582, -13.461906433105469, -14.290181159973145, -11.067129135131836, -9.4396390914917, -10.25782299041748, -12.832815170288086, -14.47233772277832, -15.180559158325195, -15.026118278503418, -16.440393447875977, -16.871919631958008, -16.227798461914062, -15.772287368774414, -15.051045417785645, -16.76930809020996, -15.759112358093262, -12.111649513244629, -11.299077987670898, -14.4454984664917, -13.920129776000977, -13.106307983398438, -13.9061918258667, -15.664796829223633, -16.918140411376953, -17.58910369873047, -15.499702453613281, -12.670782089233398, -8.358739852905273, -3.781482219696045, -4.170160293579102, -7.698156833648682, -9.289326667785645, -11.01113510131836, -9.088045120239258, -9.548360824584961, -10.905054092407227, -11.694174766540527, -11.663125991821289, -11.92285442352295, -11.218873023986816, -10.992666244506836, -10.715929985046387, -11.608819961547852, -12.646204948425293, -11.574254989624023, -11.507253646850586, -11.179191589355469, -9.480924606323242, -7.215013027191162, -7.65401554107666, ...]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[-7.918447017669678, -9.700054168701172, -13.931797981262207, -14.202247619628906, -15.660321235656738, -14.658056259155273, -14.20276165008545, -14.460031509399414, -14.984807968139648, -15.091924667358398, -14.54084587097168, -15.216166496276855, -15.255208015441895, -14.236157417297363, -14.092397689819336, -13.94226360321045, -13.650103569030762, -14.738187789916992, -14.968870162963867, -15.2593994140625, -15.638392448425293, -16.27830696105957, -16.53255844116211, -18.244434356689453, -15.061880111694336, -10.419013023376465, -9.546479225158691, -11.230467796325684, -10.435259819030762, -10.452363014221191, -11.54275894165039, -10.987311363220215, -10.832088470458984, -10.94855785369873, -11.137842178344727, -11.864161491394043, -11.051187515258789, -13.456280708312988, -21.57398796081543, -16.532928466796875, -12.666706085205078, -11.937260627746582, -13.08344554901123, -12.631006240844727, -11.728055953979492, -11.380725860595703, -11.213301658630371, -10.970061302185059, -11.192733764648438, -12.963197708129883, -13.101036071777344, -12.274778366088867, -12.584842681884766, -14.22430419921875, -18.949295043945312, -16.44747543334961, -13.400530815124512, -10.26575756072998, -9.083967208862305, -10.074304580688477, -9.411404609680176, -10.016633033752441, -11.534296035766602, -11.844507217407227, -11.385453224182129, -12.399581909179688, -14.147883415222168, -13.348068237304688, -14.118375778198242, -16.05929183959961, -15.032766342163086, -12.1964750289917, -12.244417190551758, -18.667207717895508, -20.615827560424805, -20.06505584716797, -17.07769775390625, -16.66744613647461, -12.243195533752441, -9.06714153289795, -7.628981113433838, -9.873872756958008, -12.670413970947266, -13.123285293579102, -12.164233207702637, -11.204316139221191, -11.197726249694824, -10.449433326721191, -10.412951469421387, -10.420699119567871, -10.261754989624023, -10.488927841186523, -10.787619590759277, -10.808159828186035, -10.991859436035156, -11.233869552612305, -11.053648948669434, -12.813728332519531, -13.740083694458008, -14.787927627563477, ...]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[-12.148096084594727, -10.61555290222168, -12.712873458862305, -14.446484565734863, -16.46312713623047, -16.694599151611328, -14.1416654586792, -13.675297737121582, -12.584769248962402, -11.681584358215332, -13.388961791992188, -12.183250427246094, -12.927635192871094, -12.010310173034668, -12.4882230758667, -12.281132698059082, -10.904417037963867, -7.701502799987793, -6.974416255950928, -9.76063060760498, -11.579658508300781, -14.750325202941895, -12.458921432495117, -12.58065414428711, -14.434855461120605, -11.5320405960083, -9.61296558380127, -13.763952255249023, -17.029312133789062, -10.605391502380371, -8.37590217590332, -10.09701156616211, -10.170818328857422, -9.595808029174805, -8.590011596679688, -8.381210327148438, -8.361083030700684, -8.691391944885254, -8.118986129760742, -9.72829532623291, -8.106839179992676, -5.053135395050049, -7.177920341491699, -15.152145385742188, -12.345412254333496, -6.090043544769287, -4.0788254737854, -7.156494140625, -10.011366844177246, -10.865019798278809, -10.529207229614258, -9.9502534866333, -11.891989707946777, -11.12156867980957, -9.95300579071045, -10.480453491210938, -12.62531852722168, -15.821905136108398, -15.221166610717773, -9.688528060913086, -7.173816680908203, -6.856049537658691, -8.619898796081543, -9.160311698913574, -10.182062149047852, -10.754276275634766, -12.167823791503906, -12.486286163330078, -13.857048034667969, -15.73656177520752, -16.07811737060547, -14.120733261108398, -14.323835372924805, -12.81370735168457, -12.475730895996094, -12.980400085449219, -12.63280963897705, -13.839816093444824, -14.24449348449707, -13.106870651245117, -13.065309524536133, -15.588595390319824, -13.275410652160645, -12.744037628173828, -12.254037857055664, -9.740470886230469, -10.31661319732666, -14.026432991027832, -14.73132610321045, -9.339259147644043, -6.41290283203125, -4.771424293518066, -3.5634491443634033, -3.2048332691192627, -3.493462324142456, -3.6207785606384277, -3.665897846221924, -4.447425842285156, -4.835511207580566, -4.947717189788818, ...]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[-21.099449157714844, -19.98943519592285, -18.420570373535156, -20.03567886352539, -23.943761825561523, -24.36056137084961, -25.801483154296875, -26.79062843322754, -27.18401527404785, -26.4794864654541, -25.002399444580078, -19.19887924194336, -19.33736228942871, -22.273345947265625, -23.26068115234375, -24.573001861572266, -22.738603591918945, -23.259601593017578, -21.463001251220703, -20.125492095947266, -18.720300674438477, -19.31197166442871, -21.306447982788086, -14.221975326538086, -12.133466720581055, -14.362260818481445, -18.78898811340332, -20.07866859436035, -20.371112823486328, -21.616430282592773, -22.374814987182617, -20.397584915161133, -18.411800384521484, -16.42764663696289, -17.536548614501953, -21.042783737182617, -24.957918167114258, -24.07847023010254, -14.119771957397461, -8.518667221069336, -9.407273292541504, -17.00771141052246, -22.32094955444336, -23.99687957763672, -24.0288028717041, -24.095115661621094, -23.434593200683594, -24.502885818481445, -24.605661392211914, -20.66512680053711, -19.774585723876953, -18.504119873046875, -15.8585786819458, -14.988615036010742, -14.511189460754395, -15.016743659973145, -15.950724601745605, -16.64797592163086, -14.728192329406738, -15.477429389953613, -15.675294876098633, -15.476374626159668, -15.049052238464355, -16.317157745361328, -16.789241790771484, -16.860139846801758, -19.024166107177734, -19.481103897094727, -18.929279327392578, -17.42547607421875, -16.5417537689209, -15.778729438781738, -16.6085147857666, -16.36345100402832, -13.54755687713623, -10.751996040344238, -10.026277542114258, -10.693559646606445, -12.983319282531738, -16.52169418334961, -16.469043731689453, -18.3940372467041, -22.160974502563477, -20.18037223815918, -20.777782440185547, -23.53042984008789, -20.919946670532227, -20.952674865722656, -22.96934700012207, -22.436052322387695, -22.128124237060547, -22.787853240966797, -22.294692993164062, -19.574132919311523, -16.46436882019043, -16.18743896484375, -18.711910247802734, -19.68351173400879, -19.422391891479492, -20.558881759643555, ...]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[-1.496551275253296, -3.419499158859253, -7.935415744781494, -7.3110857009887695, -7.160665988922119, -9.339265823364258, -12.268321990966797, -10.383132934570312, -5.322261810302734, -3.457881212234497, -4.181371688842773, -6.407264709472656, -8.701879501342773, -9.840286254882812, -9.872453689575195, -8.859932899475098, -6.9238600730896, -6.467466831207275, -9.949822425842285, -12.851659774780273, -7.610814571380615, -4.910651206970215, -4.581605911254883, -5.6799468994140625, -6.2015485763549805, -5.697085380554199, -6.098206520080566, -6.235016822814941, -5.90188455581665, -6.347792148590088, -6.3999714851379395, -5.966947078704834, -4.4266462326049805, -3.779510498046875, -4.354317665100098, -4.541447639465332, -3.5465590953826904, -2.9987897872924805, -3.186447858810425, -3.3374438285827637, -3.941516399383545, -4.259490013122559, -3.6124637126922607, -3.5606913566589355, -3.9880599975585938, -3.8204474449157715, -4.32437801361084, -6.624500274658203, -9.198064804077148, -7.8063154220581055, -7.189703464508057, -9.414762496948242, -10.143705368041992, -12.288909912109375, -11.620626449584961, -10.208653450012207, -9.673921585083008, -7.98199987411499, -7.8009748458862305, -7.461470603942871, -6.883126735687256, -4.4783124923706055, -5.054468631744385, -6.132120609283447, -7.624539375305176, -7.66168212890625, -7.659646034240723, -8.061732292175293, -7.630990505218506, -7.876167297363281, -7.877667427062988, -8.008142471313477, -8.770608901977539, -8.882316589355469, -9.489706039428711, -10.333707809448242, -10.420012474060059, -9.125871658325195, -8.222508430480957, -6.708151817321777, -4.865965843200684, -6.679470062255859, -8.738327026367188, -9.24110221862793, -10.687686920166016, -12.268397331237793, -12.425100326538086, -12.896965026855469, -12.529001235961914, -12.809347152709961, -13.654756546020508, -13.937894821166992, -14.52452564239502, -13.412470817565918, -12.206378936767578, -10.5975341796875, -9.756102561950684, -12.561323165893555, -13.027898788452148, -15.20246410369873, ...]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Features\n",
              "0  [-3.020548105239868, -5.986682891845703, -17.65738296508789, -15.65730094909668, -15.12962818145752, -15.039176940917969, -15.331384658813477, -14.618766784667969, -14.647868156433105, -15.893167495727539, -16.321304321289062, -16.78694725036621, -15.868365287780762, -13.939315795898438, -12.105884552001953, -12.854204177856445, -13.878453254699707, -15.838191032409668, -17.212888717651367, -14.871292114257812, -12.63183879852295, -13.500885009765625, -15.568746566772461, -14.775090217590332, -16.93557357788086, -17.810428619384766, -8.799540519714355, -4.3315043449401855, -4.042933940887451, -8.786327362060547, -12.521449089050293, -14.641298294067383, -13.75732707977295, -12.103842735290527, -10.877647399902344, -11.437983512878418, -9.468372344970703, -9.869132041931152, -13.514001846313477, -9.438905715942383, -6.065412998199463, -6.006787300109863, -9.120977401733398, -12.805081367492676, -13.633074760437012, -14.039316177368164, -12.474197387695312, -14.707188606262207, -16.328716278076172, -13.983403205871582, -13.461906433105469, -14.290181159973145, -11.067129135131836, -9.4396390914917, -10.25782299041748, -12.832815170288086, -14.47233772277832, -15.180559158325195, -15.026118278503418, -16.440393447875977, -16.871919631958008, -16.227798461914062, -15.772287368774414, -15.051045417785645, -16.76930809020996, -15.759112358093262, -12.111649513244629, -11.299077987670898, -14.4454984664917, -13.920129776000977, -13.106307983398438, -13.9061918258667, -15.664796829223633, -16.918140411376953, -17.58910369873047, -15.499702453613281, -12.670782089233398, -8.358739852905273, -3.781482219696045, -4.170160293579102, -7.698156833648682, -9.289326667785645, -11.01113510131836, -9.088045120239258, -9.548360824584961, -10.905054092407227, -11.694174766540527, -11.663125991821289, -11.92285442352295, -11.218873023986816, -10.992666244506836, -10.715929985046387, -11.608819961547852, -12.646204948425293, -11.574254989624023, -11.507253646850586, -11.179191589355469, -9.480924606323242, -7.215013027191162, -7.65401554107666, ...]             \n",
              "1  [-7.918447017669678, -9.700054168701172, -13.931797981262207, -14.202247619628906, -15.660321235656738, -14.658056259155273, -14.20276165008545, -14.460031509399414, -14.984807968139648, -15.091924667358398, -14.54084587097168, -15.216166496276855, -15.255208015441895, -14.236157417297363, -14.092397689819336, -13.94226360321045, -13.650103569030762, -14.738187789916992, -14.968870162963867, -15.2593994140625, -15.638392448425293, -16.27830696105957, -16.53255844116211, -18.244434356689453, -15.061880111694336, -10.419013023376465, -9.546479225158691, -11.230467796325684, -10.435259819030762, -10.452363014221191, -11.54275894165039, -10.987311363220215, -10.832088470458984, -10.94855785369873, -11.137842178344727, -11.864161491394043, -11.051187515258789, -13.456280708312988, -21.57398796081543, -16.532928466796875, -12.666706085205078, -11.937260627746582, -13.08344554901123, -12.631006240844727, -11.728055953979492, -11.380725860595703, -11.213301658630371, -10.970061302185059, -11.192733764648438, -12.963197708129883, -13.101036071777344, -12.274778366088867, -12.584842681884766, -14.22430419921875, -18.949295043945312, -16.44747543334961, -13.400530815124512, -10.26575756072998, -9.083967208862305, -10.074304580688477, -9.411404609680176, -10.016633033752441, -11.534296035766602, -11.844507217407227, -11.385453224182129, -12.399581909179688, -14.147883415222168, -13.348068237304688, -14.118375778198242, -16.05929183959961, -15.032766342163086, -12.1964750289917, -12.244417190551758, -18.667207717895508, -20.615827560424805, -20.06505584716797, -17.07769775390625, -16.66744613647461, -12.243195533752441, -9.06714153289795, -7.628981113433838, -9.873872756958008, -12.670413970947266, -13.123285293579102, -12.164233207702637, -11.204316139221191, -11.197726249694824, -10.449433326721191, -10.412951469421387, -10.420699119567871, -10.261754989624023, -10.488927841186523, -10.787619590759277, -10.808159828186035, -10.991859436035156, -11.233869552612305, -11.053648948669434, -12.813728332519531, -13.740083694458008, -14.787927627563477, ...]\n",
              "2  [-12.148096084594727, -10.61555290222168, -12.712873458862305, -14.446484565734863, -16.46312713623047, -16.694599151611328, -14.1416654586792, -13.675297737121582, -12.584769248962402, -11.681584358215332, -13.388961791992188, -12.183250427246094, -12.927635192871094, -12.010310173034668, -12.4882230758667, -12.281132698059082, -10.904417037963867, -7.701502799987793, -6.974416255950928, -9.76063060760498, -11.579658508300781, -14.750325202941895, -12.458921432495117, -12.58065414428711, -14.434855461120605, -11.5320405960083, -9.61296558380127, -13.763952255249023, -17.029312133789062, -10.605391502380371, -8.37590217590332, -10.09701156616211, -10.170818328857422, -9.595808029174805, -8.590011596679688, -8.381210327148438, -8.361083030700684, -8.691391944885254, -8.118986129760742, -9.72829532623291, -8.106839179992676, -5.053135395050049, -7.177920341491699, -15.152145385742188, -12.345412254333496, -6.090043544769287, -4.0788254737854, -7.156494140625, -10.011366844177246, -10.865019798278809, -10.529207229614258, -9.9502534866333, -11.891989707946777, -11.12156867980957, -9.95300579071045, -10.480453491210938, -12.62531852722168, -15.821905136108398, -15.221166610717773, -9.688528060913086, -7.173816680908203, -6.856049537658691, -8.619898796081543, -9.160311698913574, -10.182062149047852, -10.754276275634766, -12.167823791503906, -12.486286163330078, -13.857048034667969, -15.73656177520752, -16.07811737060547, -14.120733261108398, -14.323835372924805, -12.81370735168457, -12.475730895996094, -12.980400085449219, -12.63280963897705, -13.839816093444824, -14.24449348449707, -13.106870651245117, -13.065309524536133, -15.588595390319824, -13.275410652160645, -12.744037628173828, -12.254037857055664, -9.740470886230469, -10.31661319732666, -14.026432991027832, -14.73132610321045, -9.339259147644043, -6.41290283203125, -4.771424293518066, -3.5634491443634033, -3.2048332691192627, -3.493462324142456, -3.6207785606384277, -3.665897846221924, -4.447425842285156, -4.835511207580566, -4.947717189788818, ...]                                     \n",
              "3  [-21.099449157714844, -19.98943519592285, -18.420570373535156, -20.03567886352539, -23.943761825561523, -24.36056137084961, -25.801483154296875, -26.79062843322754, -27.18401527404785, -26.4794864654541, -25.002399444580078, -19.19887924194336, -19.33736228942871, -22.273345947265625, -23.26068115234375, -24.573001861572266, -22.738603591918945, -23.259601593017578, -21.463001251220703, -20.125492095947266, -18.720300674438477, -19.31197166442871, -21.306447982788086, -14.221975326538086, -12.133466720581055, -14.362260818481445, -18.78898811340332, -20.07866859436035, -20.371112823486328, -21.616430282592773, -22.374814987182617, -20.397584915161133, -18.411800384521484, -16.42764663696289, -17.536548614501953, -21.042783737182617, -24.957918167114258, -24.07847023010254, -14.119771957397461, -8.518667221069336, -9.407273292541504, -17.00771141052246, -22.32094955444336, -23.99687957763672, -24.0288028717041, -24.095115661621094, -23.434593200683594, -24.502885818481445, -24.605661392211914, -20.66512680053711, -19.774585723876953, -18.504119873046875, -15.8585786819458, -14.988615036010742, -14.511189460754395, -15.016743659973145, -15.950724601745605, -16.64797592163086, -14.728192329406738, -15.477429389953613, -15.675294876098633, -15.476374626159668, -15.049052238464355, -16.317157745361328, -16.789241790771484, -16.860139846801758, -19.024166107177734, -19.481103897094727, -18.929279327392578, -17.42547607421875, -16.5417537689209, -15.778729438781738, -16.6085147857666, -16.36345100402832, -13.54755687713623, -10.751996040344238, -10.026277542114258, -10.693559646606445, -12.983319282531738, -16.52169418334961, -16.469043731689453, -18.3940372467041, -22.160974502563477, -20.18037223815918, -20.777782440185547, -23.53042984008789, -20.919946670532227, -20.952674865722656, -22.96934700012207, -22.436052322387695, -22.128124237060547, -22.787853240966797, -22.294692993164062, -19.574132919311523, -16.46436882019043, -16.18743896484375, -18.711910247802734, -19.68351173400879, -19.422391891479492, -20.558881759643555, ...]             \n",
              "4  [-1.496551275253296, -3.419499158859253, -7.935415744781494, -7.3110857009887695, -7.160665988922119, -9.339265823364258, -12.268321990966797, -10.383132934570312, -5.322261810302734, -3.457881212234497, -4.181371688842773, -6.407264709472656, -8.701879501342773, -9.840286254882812, -9.872453689575195, -8.859932899475098, -6.9238600730896, -6.467466831207275, -9.949822425842285, -12.851659774780273, -7.610814571380615, -4.910651206970215, -4.581605911254883, -5.6799468994140625, -6.2015485763549805, -5.697085380554199, -6.098206520080566, -6.235016822814941, -5.90188455581665, -6.347792148590088, -6.3999714851379395, -5.966947078704834, -4.4266462326049805, -3.779510498046875, -4.354317665100098, -4.541447639465332, -3.5465590953826904, -2.9987897872924805, -3.186447858810425, -3.3374438285827637, -3.941516399383545, -4.259490013122559, -3.6124637126922607, -3.5606913566589355, -3.9880599975585938, -3.8204474449157715, -4.32437801361084, -6.624500274658203, -9.198064804077148, -7.8063154220581055, -7.189703464508057, -9.414762496948242, -10.143705368041992, -12.288909912109375, -11.620626449584961, -10.208653450012207, -9.673921585083008, -7.98199987411499, -7.8009748458862305, -7.461470603942871, -6.883126735687256, -4.4783124923706055, -5.054468631744385, -6.132120609283447, -7.624539375305176, -7.66168212890625, -7.659646034240723, -8.061732292175293, -7.630990505218506, -7.876167297363281, -7.877667427062988, -8.008142471313477, -8.770608901977539, -8.882316589355469, -9.489706039428711, -10.333707809448242, -10.420012474060059, -9.125871658325195, -8.222508430480957, -6.708151817321777, -4.865965843200684, -6.679470062255859, -8.738327026367188, -9.24110221862793, -10.687686920166016, -12.268397331237793, -12.425100326538086, -12.896965026855469, -12.529001235961914, -12.809347152709961, -13.654756546020508, -13.937894821166992, -14.52452564239502, -13.412470817565918, -12.206378936767578, -10.5975341796875, -9.756102561950684, -12.561323165893555, -13.027898788452148, -15.20246410369873, ...]                                           "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "id": "EsULzjOQh5So",
        "outputId": "e946f244-32a9-4119-fbe2-b76b99aac53e"
      },
      "source": [
        "# Now extract the mean bands to its own feature columns\n",
        "df = pd.concat([ref,pd.DataFrame(df['Features'].values.tolist())],axis=1)\n",
        "df[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emotion</th>\n",
              "      <th>source</th>\n",
              "      <th>path</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>...</th>\n",
              "      <th>491</th>\n",
              "      <th>492</th>\n",
              "      <th>493</th>\n",
              "      <th>494</th>\n",
              "      <th>495</th>\n",
              "      <th>496</th>\n",
              "      <th>497</th>\n",
              "      <th>498</th>\n",
              "      <th>499</th>\n",
              "      <th>500</th>\n",
              "      <th>501</th>\n",
              "      <th>502</th>\n",
              "      <th>503</th>\n",
              "      <th>504</th>\n",
              "      <th>505</th>\n",
              "      <th>506</th>\n",
              "      <th>507</th>\n",
              "      <th>508</th>\n",
              "      <th>509</th>\n",
              "      <th>510</th>\n",
              "      <th>511</th>\n",
              "      <th>512</th>\n",
              "      <th>513</th>\n",
              "      <th>514</th>\n",
              "      <th>515</th>\n",
              "      <th>516</th>\n",
              "      <th>517</th>\n",
              "      <th>518</th>\n",
              "      <th>519</th>\n",
              "      <th>520</th>\n",
              "      <th>521</th>\n",
              "      <th>522</th>\n",
              "      <th>523</th>\n",
              "      <th>524</th>\n",
              "      <th>525</th>\n",
              "      <th>526</th>\n",
              "      <th>527</th>\n",
              "      <th>528</th>\n",
              "      <th>529</th>\n",
              "      <th>530</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Fear</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis/Emo-db/08a01Ab.wav</td>\n",
              "      <td>-3.020548</td>\n",
              "      <td>-5.986683</td>\n",
              "      <td>-17.657383</td>\n",
              "      <td>-15.657301</td>\n",
              "      <td>-15.129628</td>\n",
              "      <td>-15.039177</td>\n",
              "      <td>-15.331385</td>\n",
              "      <td>-14.618767</td>\n",
              "      <td>-14.647868</td>\n",
              "      <td>-15.893167</td>\n",
              "      <td>-16.321304</td>\n",
              "      <td>-16.786947</td>\n",
              "      <td>-15.868365</td>\n",
              "      <td>-13.939316</td>\n",
              "      <td>-12.105885</td>\n",
              "      <td>-12.854204</td>\n",
              "      <td>-13.878453</td>\n",
              "      <td>-15.838191</td>\n",
              "      <td>-17.212889</td>\n",
              "      <td>-14.871292</td>\n",
              "      <td>-12.631839</td>\n",
              "      <td>-13.500885</td>\n",
              "      <td>-15.568747</td>\n",
              "      <td>-14.775090</td>\n",
              "      <td>-16.935574</td>\n",
              "      <td>-17.810429</td>\n",
              "      <td>-8.799541</td>\n",
              "      <td>-4.331504</td>\n",
              "      <td>-4.042934</td>\n",
              "      <td>-8.786327</td>\n",
              "      <td>-12.521449</td>\n",
              "      <td>-14.641298</td>\n",
              "      <td>-13.757327</td>\n",
              "      <td>-12.103843</td>\n",
              "      <td>-10.877647</td>\n",
              "      <td>-11.437984</td>\n",
              "      <td>-9.468372</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Happy</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis/Emo-db/12a01Fb.wav</td>\n",
              "      <td>-7.918447</td>\n",
              "      <td>-9.700054</td>\n",
              "      <td>-13.931798</td>\n",
              "      <td>-14.202248</td>\n",
              "      <td>-15.660321</td>\n",
              "      <td>-14.658056</td>\n",
              "      <td>-14.202762</td>\n",
              "      <td>-14.460032</td>\n",
              "      <td>-14.984808</td>\n",
              "      <td>-15.091925</td>\n",
              "      <td>-14.540846</td>\n",
              "      <td>-15.216166</td>\n",
              "      <td>-15.255208</td>\n",
              "      <td>-14.236157</td>\n",
              "      <td>-14.092398</td>\n",
              "      <td>-13.942264</td>\n",
              "      <td>-13.650104</td>\n",
              "      <td>-14.738188</td>\n",
              "      <td>-14.968870</td>\n",
              "      <td>-15.259399</td>\n",
              "      <td>-15.638392</td>\n",
              "      <td>-16.278307</td>\n",
              "      <td>-16.532558</td>\n",
              "      <td>-18.244434</td>\n",
              "      <td>-15.061880</td>\n",
              "      <td>-10.419013</td>\n",
              "      <td>-9.546479</td>\n",
              "      <td>-11.230468</td>\n",
              "      <td>-10.435260</td>\n",
              "      <td>-10.452363</td>\n",
              "      <td>-11.542759</td>\n",
              "      <td>-10.987311</td>\n",
              "      <td>-10.832088</td>\n",
              "      <td>-10.948558</td>\n",
              "      <td>-11.137842</td>\n",
              "      <td>-11.864161</td>\n",
              "      <td>-11.051188</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Happy</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis/Emo-db/03a01Fa.wav</td>\n",
              "      <td>-12.148096</td>\n",
              "      <td>-10.615553</td>\n",
              "      <td>-12.712873</td>\n",
              "      <td>-14.446485</td>\n",
              "      <td>-16.463127</td>\n",
              "      <td>-16.694599</td>\n",
              "      <td>-14.141665</td>\n",
              "      <td>-13.675298</td>\n",
              "      <td>-12.584769</td>\n",
              "      <td>-11.681584</td>\n",
              "      <td>-13.388962</td>\n",
              "      <td>-12.183250</td>\n",
              "      <td>-12.927635</td>\n",
              "      <td>-12.010310</td>\n",
              "      <td>-12.488223</td>\n",
              "      <td>-12.281133</td>\n",
              "      <td>-10.904417</td>\n",
              "      <td>-7.701503</td>\n",
              "      <td>-6.974416</td>\n",
              "      <td>-9.760631</td>\n",
              "      <td>-11.579659</td>\n",
              "      <td>-14.750325</td>\n",
              "      <td>-12.458921</td>\n",
              "      <td>-12.580654</td>\n",
              "      <td>-14.434855</td>\n",
              "      <td>-11.532041</td>\n",
              "      <td>-9.612966</td>\n",
              "      <td>-13.763952</td>\n",
              "      <td>-17.029312</td>\n",
              "      <td>-10.605392</td>\n",
              "      <td>-8.375902</td>\n",
              "      <td>-10.097012</td>\n",
              "      <td>-10.170818</td>\n",
              "      <td>-9.595808</td>\n",
              "      <td>-8.590012</td>\n",
              "      <td>-8.381210</td>\n",
              "      <td>-8.361083</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Happy</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis/Emo-db/09a01Fa.wav</td>\n",
              "      <td>-21.099449</td>\n",
              "      <td>-19.989435</td>\n",
              "      <td>-18.420570</td>\n",
              "      <td>-20.035679</td>\n",
              "      <td>-23.943762</td>\n",
              "      <td>-24.360561</td>\n",
              "      <td>-25.801483</td>\n",
              "      <td>-26.790628</td>\n",
              "      <td>-27.184015</td>\n",
              "      <td>-26.479486</td>\n",
              "      <td>-25.002399</td>\n",
              "      <td>-19.198879</td>\n",
              "      <td>-19.337362</td>\n",
              "      <td>-22.273346</td>\n",
              "      <td>-23.260681</td>\n",
              "      <td>-24.573002</td>\n",
              "      <td>-22.738604</td>\n",
              "      <td>-23.259602</td>\n",
              "      <td>-21.463001</td>\n",
              "      <td>-20.125492</td>\n",
              "      <td>-18.720301</td>\n",
              "      <td>-19.311972</td>\n",
              "      <td>-21.306448</td>\n",
              "      <td>-14.221975</td>\n",
              "      <td>-12.133467</td>\n",
              "      <td>-14.362261</td>\n",
              "      <td>-18.788988</td>\n",
              "      <td>-20.078669</td>\n",
              "      <td>-20.371113</td>\n",
              "      <td>-21.616430</td>\n",
              "      <td>-22.374815</td>\n",
              "      <td>-20.397585</td>\n",
              "      <td>-18.411800</td>\n",
              "      <td>-16.427647</td>\n",
              "      <td>-17.536549</td>\n",
              "      <td>-21.042784</td>\n",
              "      <td>-24.957918</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Neutral</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis/Emo-db/08a01Na.wav</td>\n",
              "      <td>-1.496551</td>\n",
              "      <td>-3.419499</td>\n",
              "      <td>-7.935416</td>\n",
              "      <td>-7.311086</td>\n",
              "      <td>-7.160666</td>\n",
              "      <td>-9.339266</td>\n",
              "      <td>-12.268322</td>\n",
              "      <td>-10.383133</td>\n",
              "      <td>-5.322262</td>\n",
              "      <td>-3.457881</td>\n",
              "      <td>-4.181372</td>\n",
              "      <td>-6.407265</td>\n",
              "      <td>-8.701880</td>\n",
              "      <td>-9.840286</td>\n",
              "      <td>-9.872454</td>\n",
              "      <td>-8.859933</td>\n",
              "      <td>-6.923860</td>\n",
              "      <td>-6.467467</td>\n",
              "      <td>-9.949822</td>\n",
              "      <td>-12.851660</td>\n",
              "      <td>-7.610815</td>\n",
              "      <td>-4.910651</td>\n",
              "      <td>-4.581606</td>\n",
              "      <td>-5.679947</td>\n",
              "      <td>-6.201549</td>\n",
              "      <td>-5.697085</td>\n",
              "      <td>-6.098207</td>\n",
              "      <td>-6.235017</td>\n",
              "      <td>-5.901885</td>\n",
              "      <td>-6.347792</td>\n",
              "      <td>-6.399971</td>\n",
              "      <td>-5.966947</td>\n",
              "      <td>-4.426646</td>\n",
              "      <td>-3.779510</td>\n",
              "      <td>-4.354318</td>\n",
              "      <td>-4.541448</td>\n",
              "      <td>-3.546559</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 534 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   emotion source  ... 529  530\n",
              "0  Fear     EMO    ... NaN NaN \n",
              "1  Happy    EMO    ... NaN NaN \n",
              "2  Happy    EMO    ... NaN NaN \n",
              "3  Happy    EMO    ... NaN NaN \n",
              "4  Neutral  EMO    ... NaN NaN \n",
              "\n",
              "[5 rows x 534 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "qxnTYKtAh6t6",
        "outputId": "fa59c609-f2dc-43f9-eb13-63a2e3a579b1"
      },
      "source": [
        "# replace NA with 0\n",
        "df=df.fillna(0)\n",
        "print(df.shape)\n",
        "df[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(535, 534)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emotion</th>\n",
              "      <th>source</th>\n",
              "      <th>path</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>...</th>\n",
              "      <th>491</th>\n",
              "      <th>492</th>\n",
              "      <th>493</th>\n",
              "      <th>494</th>\n",
              "      <th>495</th>\n",
              "      <th>496</th>\n",
              "      <th>497</th>\n",
              "      <th>498</th>\n",
              "      <th>499</th>\n",
              "      <th>500</th>\n",
              "      <th>501</th>\n",
              "      <th>502</th>\n",
              "      <th>503</th>\n",
              "      <th>504</th>\n",
              "      <th>505</th>\n",
              "      <th>506</th>\n",
              "      <th>507</th>\n",
              "      <th>508</th>\n",
              "      <th>509</th>\n",
              "      <th>510</th>\n",
              "      <th>511</th>\n",
              "      <th>512</th>\n",
              "      <th>513</th>\n",
              "      <th>514</th>\n",
              "      <th>515</th>\n",
              "      <th>516</th>\n",
              "      <th>517</th>\n",
              "      <th>518</th>\n",
              "      <th>519</th>\n",
              "      <th>520</th>\n",
              "      <th>521</th>\n",
              "      <th>522</th>\n",
              "      <th>523</th>\n",
              "      <th>524</th>\n",
              "      <th>525</th>\n",
              "      <th>526</th>\n",
              "      <th>527</th>\n",
              "      <th>528</th>\n",
              "      <th>529</th>\n",
              "      <th>530</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Fear</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis/Emo-db/08a01Ab.wav</td>\n",
              "      <td>-3.020548</td>\n",
              "      <td>-5.986683</td>\n",
              "      <td>-17.657383</td>\n",
              "      <td>-15.657301</td>\n",
              "      <td>-15.129628</td>\n",
              "      <td>-15.039177</td>\n",
              "      <td>-15.331385</td>\n",
              "      <td>-14.618767</td>\n",
              "      <td>-14.647868</td>\n",
              "      <td>-15.893167</td>\n",
              "      <td>-16.321304</td>\n",
              "      <td>-16.786947</td>\n",
              "      <td>-15.868365</td>\n",
              "      <td>-13.939316</td>\n",
              "      <td>-12.105885</td>\n",
              "      <td>-12.854204</td>\n",
              "      <td>-13.878453</td>\n",
              "      <td>-15.838191</td>\n",
              "      <td>-17.212889</td>\n",
              "      <td>-14.871292</td>\n",
              "      <td>-12.631839</td>\n",
              "      <td>-13.500885</td>\n",
              "      <td>-15.568747</td>\n",
              "      <td>-14.775090</td>\n",
              "      <td>-16.935574</td>\n",
              "      <td>-17.810429</td>\n",
              "      <td>-8.799541</td>\n",
              "      <td>-4.331504</td>\n",
              "      <td>-4.042934</td>\n",
              "      <td>-8.786327</td>\n",
              "      <td>-12.521449</td>\n",
              "      <td>-14.641298</td>\n",
              "      <td>-13.757327</td>\n",
              "      <td>-12.103843</td>\n",
              "      <td>-10.877647</td>\n",
              "      <td>-11.437984</td>\n",
              "      <td>-9.468372</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Happy</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis/Emo-db/12a01Fb.wav</td>\n",
              "      <td>-7.918447</td>\n",
              "      <td>-9.700054</td>\n",
              "      <td>-13.931798</td>\n",
              "      <td>-14.202248</td>\n",
              "      <td>-15.660321</td>\n",
              "      <td>-14.658056</td>\n",
              "      <td>-14.202762</td>\n",
              "      <td>-14.460032</td>\n",
              "      <td>-14.984808</td>\n",
              "      <td>-15.091925</td>\n",
              "      <td>-14.540846</td>\n",
              "      <td>-15.216166</td>\n",
              "      <td>-15.255208</td>\n",
              "      <td>-14.236157</td>\n",
              "      <td>-14.092398</td>\n",
              "      <td>-13.942264</td>\n",
              "      <td>-13.650104</td>\n",
              "      <td>-14.738188</td>\n",
              "      <td>-14.968870</td>\n",
              "      <td>-15.259399</td>\n",
              "      <td>-15.638392</td>\n",
              "      <td>-16.278307</td>\n",
              "      <td>-16.532558</td>\n",
              "      <td>-18.244434</td>\n",
              "      <td>-15.061880</td>\n",
              "      <td>-10.419013</td>\n",
              "      <td>-9.546479</td>\n",
              "      <td>-11.230468</td>\n",
              "      <td>-10.435260</td>\n",
              "      <td>-10.452363</td>\n",
              "      <td>-11.542759</td>\n",
              "      <td>-10.987311</td>\n",
              "      <td>-10.832088</td>\n",
              "      <td>-10.948558</td>\n",
              "      <td>-11.137842</td>\n",
              "      <td>-11.864161</td>\n",
              "      <td>-11.051188</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Happy</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis/Emo-db/03a01Fa.wav</td>\n",
              "      <td>-12.148096</td>\n",
              "      <td>-10.615553</td>\n",
              "      <td>-12.712873</td>\n",
              "      <td>-14.446485</td>\n",
              "      <td>-16.463127</td>\n",
              "      <td>-16.694599</td>\n",
              "      <td>-14.141665</td>\n",
              "      <td>-13.675298</td>\n",
              "      <td>-12.584769</td>\n",
              "      <td>-11.681584</td>\n",
              "      <td>-13.388962</td>\n",
              "      <td>-12.183250</td>\n",
              "      <td>-12.927635</td>\n",
              "      <td>-12.010310</td>\n",
              "      <td>-12.488223</td>\n",
              "      <td>-12.281133</td>\n",
              "      <td>-10.904417</td>\n",
              "      <td>-7.701503</td>\n",
              "      <td>-6.974416</td>\n",
              "      <td>-9.760631</td>\n",
              "      <td>-11.579659</td>\n",
              "      <td>-14.750325</td>\n",
              "      <td>-12.458921</td>\n",
              "      <td>-12.580654</td>\n",
              "      <td>-14.434855</td>\n",
              "      <td>-11.532041</td>\n",
              "      <td>-9.612966</td>\n",
              "      <td>-13.763952</td>\n",
              "      <td>-17.029312</td>\n",
              "      <td>-10.605392</td>\n",
              "      <td>-8.375902</td>\n",
              "      <td>-10.097012</td>\n",
              "      <td>-10.170818</td>\n",
              "      <td>-9.595808</td>\n",
              "      <td>-8.590012</td>\n",
              "      <td>-8.381210</td>\n",
              "      <td>-8.361083</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Happy</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis/Emo-db/09a01Fa.wav</td>\n",
              "      <td>-21.099449</td>\n",
              "      <td>-19.989435</td>\n",
              "      <td>-18.420570</td>\n",
              "      <td>-20.035679</td>\n",
              "      <td>-23.943762</td>\n",
              "      <td>-24.360561</td>\n",
              "      <td>-25.801483</td>\n",
              "      <td>-26.790628</td>\n",
              "      <td>-27.184015</td>\n",
              "      <td>-26.479486</td>\n",
              "      <td>-25.002399</td>\n",
              "      <td>-19.198879</td>\n",
              "      <td>-19.337362</td>\n",
              "      <td>-22.273346</td>\n",
              "      <td>-23.260681</td>\n",
              "      <td>-24.573002</td>\n",
              "      <td>-22.738604</td>\n",
              "      <td>-23.259602</td>\n",
              "      <td>-21.463001</td>\n",
              "      <td>-20.125492</td>\n",
              "      <td>-18.720301</td>\n",
              "      <td>-19.311972</td>\n",
              "      <td>-21.306448</td>\n",
              "      <td>-14.221975</td>\n",
              "      <td>-12.133467</td>\n",
              "      <td>-14.362261</td>\n",
              "      <td>-18.788988</td>\n",
              "      <td>-20.078669</td>\n",
              "      <td>-20.371113</td>\n",
              "      <td>-21.616430</td>\n",
              "      <td>-22.374815</td>\n",
              "      <td>-20.397585</td>\n",
              "      <td>-18.411800</td>\n",
              "      <td>-16.427647</td>\n",
              "      <td>-17.536549</td>\n",
              "      <td>-21.042784</td>\n",
              "      <td>-24.957918</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Neutral</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis/Emo-db/08a01Na.wav</td>\n",
              "      <td>-1.496551</td>\n",
              "      <td>-3.419499</td>\n",
              "      <td>-7.935416</td>\n",
              "      <td>-7.311086</td>\n",
              "      <td>-7.160666</td>\n",
              "      <td>-9.339266</td>\n",
              "      <td>-12.268322</td>\n",
              "      <td>-10.383133</td>\n",
              "      <td>-5.322262</td>\n",
              "      <td>-3.457881</td>\n",
              "      <td>-4.181372</td>\n",
              "      <td>-6.407265</td>\n",
              "      <td>-8.701880</td>\n",
              "      <td>-9.840286</td>\n",
              "      <td>-9.872454</td>\n",
              "      <td>-8.859933</td>\n",
              "      <td>-6.923860</td>\n",
              "      <td>-6.467467</td>\n",
              "      <td>-9.949822</td>\n",
              "      <td>-12.851660</td>\n",
              "      <td>-7.610815</td>\n",
              "      <td>-4.910651</td>\n",
              "      <td>-4.581606</td>\n",
              "      <td>-5.679947</td>\n",
              "      <td>-6.201549</td>\n",
              "      <td>-5.697085</td>\n",
              "      <td>-6.098207</td>\n",
              "      <td>-6.235017</td>\n",
              "      <td>-5.901885</td>\n",
              "      <td>-6.347792</td>\n",
              "      <td>-6.399971</td>\n",
              "      <td>-5.966947</td>\n",
              "      <td>-4.426646</td>\n",
              "      <td>-3.779510</td>\n",
              "      <td>-4.354318</td>\n",
              "      <td>-4.541448</td>\n",
              "      <td>-3.546559</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 534 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   emotion source  ...  529  530\n",
              "0  Fear     EMO    ...  0.0  0.0\n",
              "1  Happy    EMO    ...  0.0  0.0\n",
              "2  Happy    EMO    ...  0.0  0.0\n",
              "3  Happy    EMO    ...  0.0  0.0\n",
              "4  Neutral  EMO    ...  0.0  0.0\n",
              "\n",
              "[5 rows x 534 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "AkLfotB6h-4f",
        "outputId": "81007842-af97-42aa-c68a-6b9f6abbe51a"
      },
      "source": [
        "# Split between train and test \n",
        "X_train, X_test, y_train, y_test = train_test_split(df.drop(['path','emotion','source'],axis=1)\n",
        "                                                    , df.emotion\n",
        "                                                    , test_size=0.20\n",
        "                                                    , shuffle=True\n",
        "                                                    , random_state=42\n",
        "                                                   )\n",
        "\n",
        "# Lets see how the data present itself before normalisation \n",
        "X_train[150:160]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>491</th>\n",
              "      <th>492</th>\n",
              "      <th>493</th>\n",
              "      <th>494</th>\n",
              "      <th>495</th>\n",
              "      <th>496</th>\n",
              "      <th>497</th>\n",
              "      <th>498</th>\n",
              "      <th>499</th>\n",
              "      <th>500</th>\n",
              "      <th>501</th>\n",
              "      <th>502</th>\n",
              "      <th>503</th>\n",
              "      <th>504</th>\n",
              "      <th>505</th>\n",
              "      <th>506</th>\n",
              "      <th>507</th>\n",
              "      <th>508</th>\n",
              "      <th>509</th>\n",
              "      <th>510</th>\n",
              "      <th>511</th>\n",
              "      <th>512</th>\n",
              "      <th>513</th>\n",
              "      <th>514</th>\n",
              "      <th>515</th>\n",
              "      <th>516</th>\n",
              "      <th>517</th>\n",
              "      <th>518</th>\n",
              "      <th>519</th>\n",
              "      <th>520</th>\n",
              "      <th>521</th>\n",
              "      <th>522</th>\n",
              "      <th>523</th>\n",
              "      <th>524</th>\n",
              "      <th>525</th>\n",
              "      <th>526</th>\n",
              "      <th>527</th>\n",
              "      <th>528</th>\n",
              "      <th>529</th>\n",
              "      <th>530</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>441</th>\n",
              "      <td>2.554508</td>\n",
              "      <td>0.332811</td>\n",
              "      <td>-4.323872</td>\n",
              "      <td>-3.829839</td>\n",
              "      <td>-3.784656</td>\n",
              "      <td>-2.037540</td>\n",
              "      <td>-1.917794</td>\n",
              "      <td>-5.298573</td>\n",
              "      <td>-7.020211</td>\n",
              "      <td>-1.899866</td>\n",
              "      <td>-1.378309</td>\n",
              "      <td>-4.354558</td>\n",
              "      <td>-6.183126</td>\n",
              "      <td>-5.151677</td>\n",
              "      <td>-4.774991</td>\n",
              "      <td>-4.441161</td>\n",
              "      <td>-3.334033</td>\n",
              "      <td>-5.521398</td>\n",
              "      <td>-9.956796</td>\n",
              "      <td>-14.268373</td>\n",
              "      <td>-13.486684</td>\n",
              "      <td>-12.487345</td>\n",
              "      <td>-12.416306</td>\n",
              "      <td>-13.461077</td>\n",
              "      <td>-13.310376</td>\n",
              "      <td>-12.386252</td>\n",
              "      <td>-12.904840</td>\n",
              "      <td>-10.328028</td>\n",
              "      <td>-4.756080</td>\n",
              "      <td>-3.034296</td>\n",
              "      <td>-5.064128</td>\n",
              "      <td>-5.325008</td>\n",
              "      <td>-5.263274</td>\n",
              "      <td>-6.551642</td>\n",
              "      <td>-6.748463</td>\n",
              "      <td>-5.768163</td>\n",
              "      <td>-6.189312</td>\n",
              "      <td>-7.353658</td>\n",
              "      <td>-8.506231</td>\n",
              "      <td>-8.241019</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>321</th>\n",
              "      <td>2.089165</td>\n",
              "      <td>-0.869029</td>\n",
              "      <td>-9.188924</td>\n",
              "      <td>-8.600752</td>\n",
              "      <td>-7.945798</td>\n",
              "      <td>-8.212059</td>\n",
              "      <td>-9.180105</td>\n",
              "      <td>-11.523394</td>\n",
              "      <td>-12.272377</td>\n",
              "      <td>-11.079719</td>\n",
              "      <td>-11.026040</td>\n",
              "      <td>-11.491572</td>\n",
              "      <td>-12.772799</td>\n",
              "      <td>-10.767256</td>\n",
              "      <td>-10.109247</td>\n",
              "      <td>-10.814725</td>\n",
              "      <td>-11.614202</td>\n",
              "      <td>-11.155945</td>\n",
              "      <td>-11.057000</td>\n",
              "      <td>-11.005651</td>\n",
              "      <td>-9.620328</td>\n",
              "      <td>-8.054120</td>\n",
              "      <td>-9.059633</td>\n",
              "      <td>-9.709857</td>\n",
              "      <td>-9.671993</td>\n",
              "      <td>-11.193630</td>\n",
              "      <td>-12.564958</td>\n",
              "      <td>-10.200889</td>\n",
              "      <td>-5.718858</td>\n",
              "      <td>-5.431477</td>\n",
              "      <td>-11.441430</td>\n",
              "      <td>-15.691137</td>\n",
              "      <td>-11.800409</td>\n",
              "      <td>-6.749269</td>\n",
              "      <td>-5.857358</td>\n",
              "      <td>-7.483369</td>\n",
              "      <td>-9.553657</td>\n",
              "      <td>-8.959196</td>\n",
              "      <td>-9.383835</td>\n",
              "      <td>-7.423701</td>\n",
              "      <td>...</td>\n",
              "      <td>-16.412991</td>\n",
              "      <td>-14.946004</td>\n",
              "      <td>-14.428662</td>\n",
              "      <td>-13.675397</td>\n",
              "      <td>-11.212651</td>\n",
              "      <td>-8.197986</td>\n",
              "      <td>-6.278272</td>\n",
              "      <td>-5.903176</td>\n",
              "      <td>-5.845412</td>\n",
              "      <td>-5.876747</td>\n",
              "      <td>-7.46554</td>\n",
              "      <td>-8.890612</td>\n",
              "      <td>-9.864847</td>\n",
              "      <td>-10.185379</td>\n",
              "      <td>-10.732654</td>\n",
              "      <td>-11.958053</td>\n",
              "      <td>-12.402618</td>\n",
              "      <td>-14.549863</td>\n",
              "      <td>-18.085485</td>\n",
              "      <td>-20.594572</td>\n",
              "      <td>-20.117603</td>\n",
              "      <td>-18.629053</td>\n",
              "      <td>-19.049086</td>\n",
              "      <td>-19.125256</td>\n",
              "      <td>-17.715269</td>\n",
              "      <td>-15.240993</td>\n",
              "      <td>-13.151398</td>\n",
              "      <td>0.490659</td>\n",
              "      <td>0.462994</td>\n",
              "      <td>0.460401</td>\n",
              "      <td>0.469066</td>\n",
              "      <td>0.443637</td>\n",
              "      <td>0.466506</td>\n",
              "      <td>0.482066</td>\n",
              "      <td>0.562383</td>\n",
              "      <td>0.657408</td>\n",
              "      <td>0.619529</td>\n",
              "      <td>0.529884</td>\n",
              "      <td>0.498665</td>\n",
              "      <td>0.157187</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>417</th>\n",
              "      <td>-2.934747</td>\n",
              "      <td>-5.843897</td>\n",
              "      <td>-13.098154</td>\n",
              "      <td>-12.410578</td>\n",
              "      <td>-13.226273</td>\n",
              "      <td>-13.179068</td>\n",
              "      <td>-13.895154</td>\n",
              "      <td>-14.242437</td>\n",
              "      <td>-13.522264</td>\n",
              "      <td>-14.208282</td>\n",
              "      <td>-12.915482</td>\n",
              "      <td>-10.696589</td>\n",
              "      <td>-10.632620</td>\n",
              "      <td>-13.131693</td>\n",
              "      <td>-14.301102</td>\n",
              "      <td>-14.883982</td>\n",
              "      <td>-17.915287</td>\n",
              "      <td>-18.174442</td>\n",
              "      <td>-16.882879</td>\n",
              "      <td>-15.727458</td>\n",
              "      <td>-14.668940</td>\n",
              "      <td>-12.674065</td>\n",
              "      <td>-11.111204</td>\n",
              "      <td>-12.387131</td>\n",
              "      <td>-12.810652</td>\n",
              "      <td>-11.493021</td>\n",
              "      <td>-8.531486</td>\n",
              "      <td>-7.269910</td>\n",
              "      <td>-8.620557</td>\n",
              "      <td>-13.155832</td>\n",
              "      <td>-14.206990</td>\n",
              "      <td>-11.512987</td>\n",
              "      <td>-10.190485</td>\n",
              "      <td>-11.261065</td>\n",
              "      <td>-11.746965</td>\n",
              "      <td>-12.475977</td>\n",
              "      <td>-11.115122</td>\n",
              "      <td>-11.614677</td>\n",
              "      <td>-13.913315</td>\n",
              "      <td>-14.719620</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>297</th>\n",
              "      <td>-5.609528</td>\n",
              "      <td>-7.312801</td>\n",
              "      <td>-14.232816</td>\n",
              "      <td>-12.350847</td>\n",
              "      <td>-9.437327</td>\n",
              "      <td>-11.548978</td>\n",
              "      <td>-16.365490</td>\n",
              "      <td>-15.814787</td>\n",
              "      <td>-6.656770</td>\n",
              "      <td>-2.905777</td>\n",
              "      <td>-1.910529</td>\n",
              "      <td>-3.786168</td>\n",
              "      <td>-4.931828</td>\n",
              "      <td>-5.344381</td>\n",
              "      <td>-6.155732</td>\n",
              "      <td>-9.508997</td>\n",
              "      <td>-10.409574</td>\n",
              "      <td>-10.032432</td>\n",
              "      <td>-11.405154</td>\n",
              "      <td>-7.062002</td>\n",
              "      <td>-5.387671</td>\n",
              "      <td>-5.995267</td>\n",
              "      <td>-3.995456</td>\n",
              "      <td>-5.597924</td>\n",
              "      <td>-8.319826</td>\n",
              "      <td>-8.359507</td>\n",
              "      <td>-7.289312</td>\n",
              "      <td>-7.583453</td>\n",
              "      <td>-9.211688</td>\n",
              "      <td>-8.754756</td>\n",
              "      <td>-8.221228</td>\n",
              "      <td>-8.683862</td>\n",
              "      <td>-8.101833</td>\n",
              "      <td>-7.765058</td>\n",
              "      <td>-8.877947</td>\n",
              "      <td>-11.189970</td>\n",
              "      <td>-12.417665</td>\n",
              "      <td>-7.924088</td>\n",
              "      <td>-3.798265</td>\n",
              "      <td>-2.998463</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>2.553626</td>\n",
              "      <td>1.221201</td>\n",
              "      <td>-1.486665</td>\n",
              "      <td>-1.536955</td>\n",
              "      <td>-1.987045</td>\n",
              "      <td>-3.232414</td>\n",
              "      <td>-3.002240</td>\n",
              "      <td>-1.677164</td>\n",
              "      <td>-1.775365</td>\n",
              "      <td>-2.228956</td>\n",
              "      <td>-2.631836</td>\n",
              "      <td>-4.095840</td>\n",
              "      <td>-6.954472</td>\n",
              "      <td>-8.644269</td>\n",
              "      <td>-11.591863</td>\n",
              "      <td>-12.821909</td>\n",
              "      <td>-4.524427</td>\n",
              "      <td>0.459214</td>\n",
              "      <td>1.685982</td>\n",
              "      <td>0.372662</td>\n",
              "      <td>1.162376</td>\n",
              "      <td>0.491954</td>\n",
              "      <td>-0.590146</td>\n",
              "      <td>-0.620091</td>\n",
              "      <td>-2.833821</td>\n",
              "      <td>-6.261988</td>\n",
              "      <td>-3.090545</td>\n",
              "      <td>-4.259115</td>\n",
              "      <td>-7.180827</td>\n",
              "      <td>-2.304492</td>\n",
              "      <td>0.242583</td>\n",
              "      <td>1.484846</td>\n",
              "      <td>0.872554</td>\n",
              "      <td>-0.779518</td>\n",
              "      <td>-0.810547</td>\n",
              "      <td>-1.147877</td>\n",
              "      <td>-1.438065</td>\n",
              "      <td>-0.244389</td>\n",
              "      <td>0.842554</td>\n",
              "      <td>-0.495751</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>139</th>\n",
              "      <td>0.272326</td>\n",
              "      <td>0.731354</td>\n",
              "      <td>0.041833</td>\n",
              "      <td>1.000185</td>\n",
              "      <td>0.507669</td>\n",
              "      <td>0.850467</td>\n",
              "      <td>0.634702</td>\n",
              "      <td>0.636942</td>\n",
              "      <td>-0.681274</td>\n",
              "      <td>-0.720431</td>\n",
              "      <td>-0.704341</td>\n",
              "      <td>-1.785257</td>\n",
              "      <td>-1.075405</td>\n",
              "      <td>-0.049871</td>\n",
              "      <td>-0.354716</td>\n",
              "      <td>-1.609398</td>\n",
              "      <td>-1.948223</td>\n",
              "      <td>-2.211042</td>\n",
              "      <td>-0.815761</td>\n",
              "      <td>-0.857294</td>\n",
              "      <td>-2.440834</td>\n",
              "      <td>-3.126916</td>\n",
              "      <td>-5.523283</td>\n",
              "      <td>-5.497748</td>\n",
              "      <td>-5.412446</td>\n",
              "      <td>-5.119538</td>\n",
              "      <td>-5.909093</td>\n",
              "      <td>-6.123106</td>\n",
              "      <td>-6.904838</td>\n",
              "      <td>-6.206822</td>\n",
              "      <td>-5.805974</td>\n",
              "      <td>-7.174685</td>\n",
              "      <td>-4.767554</td>\n",
              "      <td>-3.173957</td>\n",
              "      <td>-4.671813</td>\n",
              "      <td>-9.419676</td>\n",
              "      <td>-13.269404</td>\n",
              "      <td>-11.718691</td>\n",
              "      <td>-6.149555</td>\n",
              "      <td>-3.441999</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>253</th>\n",
              "      <td>6.090459</td>\n",
              "      <td>3.884537</td>\n",
              "      <td>0.801549</td>\n",
              "      <td>0.438381</td>\n",
              "      <td>-0.306169</td>\n",
              "      <td>-0.915305</td>\n",
              "      <td>-1.265587</td>\n",
              "      <td>-0.118297</td>\n",
              "      <td>-0.322143</td>\n",
              "      <td>-0.112609</td>\n",
              "      <td>-0.151865</td>\n",
              "      <td>-1.513421</td>\n",
              "      <td>-1.640567</td>\n",
              "      <td>-0.456743</td>\n",
              "      <td>-1.108199</td>\n",
              "      <td>-1.970560</td>\n",
              "      <td>-2.365304</td>\n",
              "      <td>-3.155236</td>\n",
              "      <td>-3.464699</td>\n",
              "      <td>-3.126809</td>\n",
              "      <td>-4.171237</td>\n",
              "      <td>-5.265306</td>\n",
              "      <td>-5.001640</td>\n",
              "      <td>-5.525298</td>\n",
              "      <td>-5.715283</td>\n",
              "      <td>-4.933531</td>\n",
              "      <td>1.517018</td>\n",
              "      <td>4.048472</td>\n",
              "      <td>4.589006</td>\n",
              "      <td>2.716230</td>\n",
              "      <td>2.817100</td>\n",
              "      <td>2.394981</td>\n",
              "      <td>1.407574</td>\n",
              "      <td>0.200415</td>\n",
              "      <td>1.236074</td>\n",
              "      <td>1.222334</td>\n",
              "      <td>1.069934</td>\n",
              "      <td>1.333965</td>\n",
              "      <td>0.840172</td>\n",
              "      <td>0.479817</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>519</th>\n",
              "      <td>-0.872542</td>\n",
              "      <td>-3.909370</td>\n",
              "      <td>-8.832712</td>\n",
              "      <td>-2.042587</td>\n",
              "      <td>1.235164</td>\n",
              "      <td>-0.493668</td>\n",
              "      <td>-4.830809</td>\n",
              "      <td>-7.739091</td>\n",
              "      <td>-8.632672</td>\n",
              "      <td>-7.400367</td>\n",
              "      <td>-5.753065</td>\n",
              "      <td>-4.144580</td>\n",
              "      <td>-5.396810</td>\n",
              "      <td>-10.077927</td>\n",
              "      <td>-10.727814</td>\n",
              "      <td>-8.656397</td>\n",
              "      <td>-8.166205</td>\n",
              "      <td>-8.492960</td>\n",
              "      <td>-7.733726</td>\n",
              "      <td>-6.534441</td>\n",
              "      <td>-7.402528</td>\n",
              "      <td>-6.337470</td>\n",
              "      <td>-5.452537</td>\n",
              "      <td>-3.807028</td>\n",
              "      <td>-6.458733</td>\n",
              "      <td>-10.817782</td>\n",
              "      <td>-9.372019</td>\n",
              "      <td>-5.963171</td>\n",
              "      <td>-3.939339</td>\n",
              "      <td>-4.176764</td>\n",
              "      <td>-6.166430</td>\n",
              "      <td>-5.408847</td>\n",
              "      <td>-7.192540</td>\n",
              "      <td>-8.497079</td>\n",
              "      <td>-10.065838</td>\n",
              "      <td>-11.166520</td>\n",
              "      <td>-10.188119</td>\n",
              "      <td>-10.149967</td>\n",
              "      <td>-12.647802</td>\n",
              "      <td>-10.929187</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>0.303354</td>\n",
              "      <td>-1.409928</td>\n",
              "      <td>-2.298852</td>\n",
              "      <td>-2.931700</td>\n",
              "      <td>-4.773086</td>\n",
              "      <td>-4.725467</td>\n",
              "      <td>-3.676522</td>\n",
              "      <td>-3.552760</td>\n",
              "      <td>-3.458724</td>\n",
              "      <td>-3.074026</td>\n",
              "      <td>-5.961193</td>\n",
              "      <td>-7.632787</td>\n",
              "      <td>-5.444441</td>\n",
              "      <td>-4.877847</td>\n",
              "      <td>-8.310521</td>\n",
              "      <td>-9.272482</td>\n",
              "      <td>-7.313097</td>\n",
              "      <td>-2.627021</td>\n",
              "      <td>-1.948459</td>\n",
              "      <td>-2.245119</td>\n",
              "      <td>-2.262736</td>\n",
              "      <td>-1.854951</td>\n",
              "      <td>-1.809192</td>\n",
              "      <td>-3.741264</td>\n",
              "      <td>-6.701384</td>\n",
              "      <td>-6.343671</td>\n",
              "      <td>-5.031825</td>\n",
              "      <td>-4.596236</td>\n",
              "      <td>-6.135837</td>\n",
              "      <td>-3.520262</td>\n",
              "      <td>-2.110157</td>\n",
              "      <td>-0.712955</td>\n",
              "      <td>-0.049607</td>\n",
              "      <td>0.710414</td>\n",
              "      <td>-2.218029</td>\n",
              "      <td>-10.349459</td>\n",
              "      <td>-13.568151</td>\n",
              "      <td>-14.210398</td>\n",
              "      <td>-16.136425</td>\n",
              "      <td>-15.335768</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111</th>\n",
              "      <td>-21.578802</td>\n",
              "      <td>-16.321423</td>\n",
              "      <td>-14.244370</td>\n",
              "      <td>-14.318384</td>\n",
              "      <td>-18.616825</td>\n",
              "      <td>-21.092945</td>\n",
              "      <td>-20.047506</td>\n",
              "      <td>-20.306751</td>\n",
              "      <td>-20.717882</td>\n",
              "      <td>-18.070995</td>\n",
              "      <td>-16.980732</td>\n",
              "      <td>-16.860077</td>\n",
              "      <td>-19.762794</td>\n",
              "      <td>-16.371773</td>\n",
              "      <td>-15.346682</td>\n",
              "      <td>-20.262247</td>\n",
              "      <td>-25.317373</td>\n",
              "      <td>-25.535950</td>\n",
              "      <td>-26.705448</td>\n",
              "      <td>-24.184381</td>\n",
              "      <td>-21.440220</td>\n",
              "      <td>-20.959192</td>\n",
              "      <td>-22.461538</td>\n",
              "      <td>-24.164148</td>\n",
              "      <td>-22.807590</td>\n",
              "      <td>-22.290619</td>\n",
              "      <td>-19.393932</td>\n",
              "      <td>-17.703886</td>\n",
              "      <td>-20.333426</td>\n",
              "      <td>-25.701298</td>\n",
              "      <td>-23.747673</td>\n",
              "      <td>-20.088171</td>\n",
              "      <td>-20.734032</td>\n",
              "      <td>-24.077358</td>\n",
              "      <td>-23.431440</td>\n",
              "      <td>-22.744389</td>\n",
              "      <td>-22.518610</td>\n",
              "      <td>-22.289835</td>\n",
              "      <td>-22.395649</td>\n",
              "      <td>-22.951963</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 531 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             0          1          2  ...       528       529       530\n",
              "441  2.554508   0.332811  -4.323872   ...  0.000000  0.000000  0.000000\n",
              "321  2.089165  -0.869029  -9.188924   ...  0.529884  0.498665  0.157187\n",
              "417 -2.934747  -5.843897  -13.098154  ...  0.000000  0.000000  0.000000\n",
              "297 -5.609528  -7.312801  -14.232816  ...  0.000000  0.000000  0.000000\n",
              "36   2.553626   1.221201  -1.486665   ...  0.000000  0.000000  0.000000\n",
              "139  0.272326   0.731354   0.041833   ...  0.000000  0.000000  0.000000\n",
              "253  6.090459   3.884537   0.801549   ...  0.000000  0.000000  0.000000\n",
              "519 -0.872542  -3.909370  -8.832712   ...  0.000000  0.000000  0.000000\n",
              "59   0.303354  -1.409928  -2.298852   ...  0.000000  0.000000  0.000000\n",
              "111 -21.578802 -16.321423 -14.244370  ...  0.000000  0.000000  0.000000\n",
              "\n",
              "[10 rows x 531 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nU8as8XxiH8h",
        "outputId": "2970e7d0-4b1a-4b1f-b891-17fdde94e089"
      },
      "source": [
        "\n",
        "# NORMALIZE DATA\n",
        "mean = np.mean(X_train, axis=0)\n",
        "std = np.std(X_train, axis=0)\n",
        "X_train = (X_train - mean)/std\n",
        "X_test = (X_test - mean)/std\n",
        "# TURN DATA INTO ARRAYS FOR KERAS\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "X_test = np.array(X_test)\n",
        "y_test = np.array(y_test)\n",
        "# ONE HOT ENCODE THE TARGET\n",
        "# CNN REQUIRES INPUT AND OUTPUT ARE NUMBERS\n",
        "lb = LabelEncoder()\n",
        "y_train = to_categorical(lb.fit_transform(y_train))\n",
        "y_test = to_categorical(lb.fit_transform(y_test))\n",
        "print(y_test[0:10])\n",
        "# RESHAPE DATA TO INCLUDE 3D TENSOR \n",
        "X_train = X_train[:,:,np.newaxis]\n",
        "X_test = X_test[:,:,np.newaxis]\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]]\n",
            "(428, 531, 1)\n",
            "(107, 531, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lygqPtRRignn",
        "outputId": "108e914e-f322-403b-c947-c62bc9ccde3f"
      },
      "source": [
        "lb.classes_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Angry', 'Fear', 'Happy', 'Neutral', 'Sad'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHBZIwJ1iKxX",
        "outputId": "521b72f4-8b5f-432c-cbc1-274d976bb3c6"
      },
      "source": [
        "model = tf.keras.Sequential()\n",
        "model.add(layers.Conv1D(256, kernel_size=(8),strides=1,dilation_rate=1,padding=\"same\", activation='relu', input_shape=(X_train.shape[1],1)))\n",
        "model.add(layers.Conv1D(256, kernel_size=(8),strides=1,activation='relu',dilation_rate=1,kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
        "model.add(layers.MaxPooling1D(pool_size=(2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Conv1D(256, kernel_size=(8),strides=1,dilation_rate=1,padding=\"same\",activation='relu'))\n",
        "model.add(layers.MaxPooling1D(pool_size=(2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.Conv1D(128, kernel_size=(8),strides=1,dilation_rate=1,padding=\"same\",activation='relu'))\n",
        "model.add(layers.MaxPooling1D(pool_size=(2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Conv1D(128, kernel_size=(8),strides=1,dilation_rate=1,padding=\"same\",activation='relu'))\n",
        "model.add(layers.MaxPooling1D(pool_size=(2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Conv1D(128, kernel_size=(8),strides=1,dilation_rate=1,padding=\"same\",activation='relu'))\n",
        "model.add(layers.MaxPooling1D(pool_size=(2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Conv1D(256, kernel_size=(8),strides=1,dilation_rate=1,padding=\"same\",activation='relu'))\n",
        "model.add(layers.MaxPooling1D(pool_size=(2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(512, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(5, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='Adam',metrics=['accuracy'])\n",
        "model.summary()\n",
        "checkpoint = ModelCheckpoint(\"SER_best_initial_model.hdf5\", monitor='val_accuracy', verbose=1, save_best_only=True, mode='max', period=1, save_weights_only=True)\n",
        "model_history=model.fit(X_train,y_train, batch_size=32, epochs=1000, validation_data=(X_test, y_test),callbacks=[checkpoint])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 531, 256)          2304      \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 524, 256)          524544    \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 262, 256)          0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 262, 256)          1024      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 262, 256)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 262, 256)          524544    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 131, 256)          0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 131, 256)          1024      \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 131, 128)          262272    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 65, 128)           0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 65, 128)           512       \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 65, 128)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_4 (Conv1D)            (None, 65, 128)           131200    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_3 (MaxPooling1 (None, 32, 128)           0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 32, 128)           512       \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 32, 128)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_5 (Conv1D)            (None, 32, 128)           131200    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_4 (MaxPooling1 (None, 16, 128)           0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 16, 128)           512       \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 16, 128)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_6 (Conv1D)            (None, 16, 256)           262400    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_5 (MaxPooling1 (None, 8, 256)            0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 8, 256)            1024      \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 8, 256)            0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               1049088   \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 5)                 645       \n",
            "=================================================================\n",
            "Total params: 2,958,469\n",
            "Trainable params: 2,956,165\n",
            "Non-trainable params: 2,304\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/1000\n",
            "14/14 [==============================] - 36s 113ms/step - loss: 5.8600 - accuracy: 0.2292 - val_loss: 4.1089 - val_accuracy: 0.3738\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.37383, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 2/1000\n",
            "14/14 [==============================] - 0s 35ms/step - loss: 5.0059 - accuracy: 0.3309 - val_loss: 3.9554 - val_accuracy: 0.4860\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.37383 to 0.48598, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 3/1000\n",
            "14/14 [==============================] - 0s 36ms/step - loss: 4.4916 - accuracy: 0.4269 - val_loss: 3.8053 - val_accuracy: 0.5047\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.48598 to 0.50467, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 4/1000\n",
            "14/14 [==============================] - 0s 36ms/step - loss: 4.1454 - accuracy: 0.4396 - val_loss: 3.6354 - val_accuracy: 0.5327\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.50467 to 0.53271, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 5/1000\n",
            "14/14 [==============================] - 0s 35ms/step - loss: 3.7559 - accuracy: 0.4801 - val_loss: 3.5407 - val_accuracy: 0.4673\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.53271\n",
            "Epoch 6/1000\n",
            "14/14 [==============================] - 0s 35ms/step - loss: 3.5637 - accuracy: 0.4784 - val_loss: 3.4623 - val_accuracy: 0.4579\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.53271\n",
            "Epoch 7/1000\n",
            "14/14 [==============================] - 0s 35ms/step - loss: 3.5864 - accuracy: 0.4495 - val_loss: 3.4371 - val_accuracy: 0.4393\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.53271\n",
            "Epoch 8/1000\n",
            "14/14 [==============================] - 0s 35ms/step - loss: 3.3160 - accuracy: 0.5046 - val_loss: 3.3003 - val_accuracy: 0.4486\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.53271\n",
            "Epoch 9/1000\n",
            "14/14 [==============================] - 0s 35ms/step - loss: 3.1792 - accuracy: 0.5318 - val_loss: 3.2329 - val_accuracy: 0.3832\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.53271\n",
            "Epoch 10/1000\n",
            "14/14 [==============================] - 0s 36ms/step - loss: 2.9553 - accuracy: 0.5275 - val_loss: 3.1462 - val_accuracy: 0.3738\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.53271\n",
            "Epoch 11/1000\n",
            "14/14 [==============================] - 0s 35ms/step - loss: 2.9625 - accuracy: 0.4999 - val_loss: 3.0656 - val_accuracy: 0.3832\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.53271\n",
            "Epoch 12/1000\n",
            "14/14 [==============================] - 0s 35ms/step - loss: 2.8473 - accuracy: 0.5160 - val_loss: 2.9555 - val_accuracy: 0.3925\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.53271\n",
            "Epoch 13/1000\n",
            "14/14 [==============================] - 0s 35ms/step - loss: 2.8102 - accuracy: 0.4681 - val_loss: 2.8886 - val_accuracy: 0.3925\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.53271\n",
            "Epoch 14/1000\n",
            "14/14 [==============================] - 0s 35ms/step - loss: 2.5798 - accuracy: 0.5415 - val_loss: 2.7903 - val_accuracy: 0.3832\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.53271\n",
            "Epoch 15/1000\n",
            "14/14 [==============================] - 0s 36ms/step - loss: 2.4474 - accuracy: 0.6001 - val_loss: 2.7411 - val_accuracy: 0.3925\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.53271\n",
            "Epoch 16/1000\n",
            "14/14 [==============================] - 0s 36ms/step - loss: 2.3193 - accuracy: 0.5679 - val_loss: 2.6636 - val_accuracy: 0.3645\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.53271\n",
            "Epoch 17/1000\n",
            "14/14 [==============================] - 0s 36ms/step - loss: 2.2080 - accuracy: 0.5999 - val_loss: 2.6004 - val_accuracy: 0.3645\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.53271\n",
            "Epoch 18/1000\n",
            "14/14 [==============================] - 0s 35ms/step - loss: 2.1853 - accuracy: 0.5371 - val_loss: 2.5173 - val_accuracy: 0.3551\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.53271\n",
            "Epoch 19/1000\n",
            "14/14 [==============================] - 1s 36ms/step - loss: 2.0474 - accuracy: 0.5627 - val_loss: 2.4379 - val_accuracy: 0.3458\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.53271\n",
            "Epoch 20/1000\n",
            "14/14 [==============================] - 0s 35ms/step - loss: 2.1790 - accuracy: 0.4635 - val_loss: 2.3761 - val_accuracy: 0.3925\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.53271\n",
            "Epoch 21/1000\n",
            "14/14 [==============================] - 0s 35ms/step - loss: 1.9960 - accuracy: 0.5207 - val_loss: 2.4021 - val_accuracy: 0.3738\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.53271\n",
            "Epoch 22/1000\n",
            "14/14 [==============================] - 0s 35ms/step - loss: 2.0042 - accuracy: 0.5146 - val_loss: 2.3134 - val_accuracy: 0.3645\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.53271\n",
            "Epoch 23/1000\n",
            "14/14 [==============================] - 0s 36ms/step - loss: 1.7961 - accuracy: 0.5889 - val_loss: 2.2507 - val_accuracy: 0.3645\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.53271\n",
            "Epoch 24/1000\n",
            "14/14 [==============================] - 0s 35ms/step - loss: 1.6825 - accuracy: 0.5983 - val_loss: 2.2445 - val_accuracy: 0.3832\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.53271\n",
            "Epoch 25/1000\n",
            "14/14 [==============================] - 0s 35ms/step - loss: 1.7501 - accuracy: 0.5967 - val_loss: 2.2903 - val_accuracy: 0.3645\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.53271\n",
            "Epoch 26/1000\n",
            "14/14 [==============================] - 0s 35ms/step - loss: 1.6565 - accuracy: 0.5906 - val_loss: 2.2712 - val_accuracy: 0.3551\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.53271\n",
            "Epoch 27/1000\n",
            "14/14 [==============================] - 0s 35ms/step - loss: 1.6296 - accuracy: 0.5745 - val_loss: 2.3081 - val_accuracy: 0.3925\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.53271\n",
            "Epoch 28/1000\n",
            "14/14 [==============================] - 0s 36ms/step - loss: 1.5908 - accuracy: 0.5531 - val_loss: 2.3275 - val_accuracy: 0.2804\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.53271\n",
            "Epoch 29/1000\n",
            "14/14 [==============================] - 0s 36ms/step - loss: 1.5221 - accuracy: 0.6111 - val_loss: 2.0788 - val_accuracy: 0.3645\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.53271\n",
            "Epoch 30/1000\n",
            "14/14 [==============================] - 0s 36ms/step - loss: 1.4967 - accuracy: 0.6119 - val_loss: 1.9053 - val_accuracy: 0.3738\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.53271\n",
            "Epoch 31/1000\n",
            "14/14 [==============================] - 1s 36ms/step - loss: 1.4556 - accuracy: 0.5404 - val_loss: 1.8267 - val_accuracy: 0.3645\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.53271\n",
            "Epoch 32/1000\n",
            "14/14 [==============================] - 0s 35ms/step - loss: 1.4730 - accuracy: 0.5593 - val_loss: 1.7463 - val_accuracy: 0.4299\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.53271\n",
            "Epoch 33/1000\n",
            "14/14 [==============================] - 0s 36ms/step - loss: 1.3584 - accuracy: 0.6021 - val_loss: 1.7328 - val_accuracy: 0.4579\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.53271\n",
            "Epoch 34/1000\n",
            "14/14 [==============================] - 1s 36ms/step - loss: 1.3577 - accuracy: 0.6101 - val_loss: 1.7497 - val_accuracy: 0.4206\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.53271\n",
            "Epoch 35/1000\n",
            "14/14 [==============================] - 0s 36ms/step - loss: 1.3041 - accuracy: 0.6105 - val_loss: 1.7052 - val_accuracy: 0.5047\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.53271\n",
            "Epoch 36/1000\n",
            "14/14 [==============================] - 0s 36ms/step - loss: 1.3314 - accuracy: 0.6263 - val_loss: 1.7893 - val_accuracy: 0.4112\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.53271\n",
            "Epoch 37/1000\n",
            "14/14 [==============================] - 0s 35ms/step - loss: 1.2387 - accuracy: 0.6119 - val_loss: 1.7266 - val_accuracy: 0.3925\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.53271\n",
            "Epoch 38/1000\n",
            "14/14 [==============================] - 0s 36ms/step - loss: 1.2076 - accuracy: 0.6024 - val_loss: 2.0227 - val_accuracy: 0.3645\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.53271\n",
            "Epoch 39/1000\n",
            "14/14 [==============================] - 0s 36ms/step - loss: 1.2139 - accuracy: 0.6210 - val_loss: 2.1762 - val_accuracy: 0.3738\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.53271\n",
            "Epoch 40/1000\n",
            "14/14 [==============================] - 0s 35ms/step - loss: 1.1890 - accuracy: 0.5993 - val_loss: 1.9317 - val_accuracy: 0.3645\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.53271\n",
            "Epoch 41/1000\n",
            "14/14 [==============================] - 0s 36ms/step - loss: 1.2257 - accuracy: 0.5599 - val_loss: 1.6511 - val_accuracy: 0.3832\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.53271\n",
            "Epoch 42/1000\n",
            "14/14 [==============================] - 0s 36ms/step - loss: 1.2523 - accuracy: 0.5758 - val_loss: 1.6176 - val_accuracy: 0.4299\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.53271\n",
            "Epoch 43/1000\n",
            "14/14 [==============================] - 0s 36ms/step - loss: 1.1481 - accuracy: 0.5700 - val_loss: 1.5184 - val_accuracy: 0.4206\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.53271\n",
            "Epoch 44/1000\n",
            "14/14 [==============================] - 0s 35ms/step - loss: 1.1196 - accuracy: 0.6032 - val_loss: 1.5761 - val_accuracy: 0.3925\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.53271\n",
            "Epoch 45/1000\n",
            "14/14 [==============================] - 0s 36ms/step - loss: 1.1441 - accuracy: 0.5691 - val_loss: 1.4980 - val_accuracy: 0.4393\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.53271\n",
            "Epoch 46/1000\n",
            "14/14 [==============================] - 1s 36ms/step - loss: 1.1054 - accuracy: 0.6157 - val_loss: 1.4191 - val_accuracy: 0.4766\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.53271\n",
            "Epoch 47/1000\n",
            "14/14 [==============================] - 1s 36ms/step - loss: 1.0899 - accuracy: 0.5767 - val_loss: 1.3933 - val_accuracy: 0.4299\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.53271\n",
            "Epoch 48/1000\n",
            "14/14 [==============================] - 0s 35ms/step - loss: 1.0609 - accuracy: 0.6269 - val_loss: 1.4601 - val_accuracy: 0.4299\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.53271\n",
            "Epoch 49/1000\n",
            "14/14 [==============================] - 0s 36ms/step - loss: 0.9736 - accuracy: 0.6597 - val_loss: 1.5136 - val_accuracy: 0.4393\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.53271\n",
            "Epoch 50/1000\n",
            "14/14 [==============================] - 1s 36ms/step - loss: 0.9888 - accuracy: 0.6783 - val_loss: 1.3977 - val_accuracy: 0.4299\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.53271\n",
            "Epoch 51/1000\n",
            "14/14 [==============================] - 0s 36ms/step - loss: 0.9607 - accuracy: 0.6221 - val_loss: 1.5018 - val_accuracy: 0.4299\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.53271\n",
            "Epoch 52/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.9540 - accuracy: 0.6524 - val_loss: 1.3319 - val_accuracy: 0.4579\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.53271\n",
            "Epoch 53/1000\n",
            "14/14 [==============================] - 0s 36ms/step - loss: 0.9617 - accuracy: 0.6264 - val_loss: 1.4180 - val_accuracy: 0.3925\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.53271\n",
            "Epoch 54/1000\n",
            "14/14 [==============================] - 0s 36ms/step - loss: 0.9411 - accuracy: 0.6333 - val_loss: 1.4056 - val_accuracy: 0.4206\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.53271\n",
            "Epoch 55/1000\n",
            "14/14 [==============================] - 0s 36ms/step - loss: 0.9596 - accuracy: 0.5895 - val_loss: 1.3123 - val_accuracy: 0.4953\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.53271\n",
            "Epoch 56/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.9052 - accuracy: 0.6269 - val_loss: 1.2196 - val_accuracy: 0.4953\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.53271\n",
            "Epoch 57/1000\n",
            "14/14 [==============================] - 0s 36ms/step - loss: 0.8236 - accuracy: 0.6729 - val_loss: 1.2955 - val_accuracy: 0.4579\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.53271\n",
            "Epoch 58/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.8814 - accuracy: 0.6359 - val_loss: 1.2985 - val_accuracy: 0.4206\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.53271\n",
            "Epoch 59/1000\n",
            "14/14 [==============================] - 0s 36ms/step - loss: 0.8781 - accuracy: 0.6505 - val_loss: 1.3010 - val_accuracy: 0.4299\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.53271\n",
            "Epoch 60/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.8896 - accuracy: 0.6340 - val_loss: 1.2570 - val_accuracy: 0.4579\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.53271\n",
            "Epoch 61/1000\n",
            "14/14 [==============================] - 0s 36ms/step - loss: 0.8632 - accuracy: 0.6572 - val_loss: 1.2795 - val_accuracy: 0.4393\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.53271\n",
            "Epoch 62/1000\n",
            "14/14 [==============================] - 0s 36ms/step - loss: 0.8516 - accuracy: 0.6754 - val_loss: 1.2522 - val_accuracy: 0.5140\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.53271\n",
            "Epoch 63/1000\n",
            "14/14 [==============================] - 0s 36ms/step - loss: 0.8566 - accuracy: 0.6705 - val_loss: 1.1601 - val_accuracy: 0.5327\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.53271\n",
            "Epoch 64/1000\n",
            "14/14 [==============================] - 0s 36ms/step - loss: 0.8599 - accuracy: 0.6711 - val_loss: 1.1615 - val_accuracy: 0.5327\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.53271\n",
            "Epoch 65/1000\n",
            "14/14 [==============================] - 0s 36ms/step - loss: 0.8166 - accuracy: 0.6682 - val_loss: 1.2882 - val_accuracy: 0.4393\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.53271\n",
            "Epoch 66/1000\n",
            "14/14 [==============================] - 1s 36ms/step - loss: 0.8075 - accuracy: 0.7167 - val_loss: 1.1468 - val_accuracy: 0.4860\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.53271\n",
            "Epoch 67/1000\n",
            "14/14 [==============================] - 0s 36ms/step - loss: 0.8086 - accuracy: 0.6935 - val_loss: 1.2188 - val_accuracy: 0.5234\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.53271\n",
            "Epoch 68/1000\n",
            "14/14 [==============================] - 1s 36ms/step - loss: 0.8358 - accuracy: 0.6704 - val_loss: 1.0683 - val_accuracy: 0.5421\n",
            "\n",
            "Epoch 00068: val_accuracy improved from 0.53271 to 0.54206, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 69/1000\n",
            "14/14 [==============================] - 0s 36ms/step - loss: 0.8074 - accuracy: 0.6475 - val_loss: 1.2672 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00069: val_accuracy improved from 0.54206 to 0.58879, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 70/1000\n",
            "14/14 [==============================] - 1s 36ms/step - loss: 0.7810 - accuracy: 0.6760 - val_loss: 1.1252 - val_accuracy: 0.5327\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.58879\n",
            "Epoch 71/1000\n",
            "14/14 [==============================] - 0s 36ms/step - loss: 0.8283 - accuracy: 0.7093 - val_loss: 1.1034 - val_accuracy: 0.5234\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.58879\n",
            "Epoch 72/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.8089 - accuracy: 0.6818 - val_loss: 1.1907 - val_accuracy: 0.5701\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.58879\n",
            "Epoch 73/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.8554 - accuracy: 0.6480 - val_loss: 1.0740 - val_accuracy: 0.5140\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.58879\n",
            "Epoch 74/1000\n",
            "14/14 [==============================] - 1s 36ms/step - loss: 0.8015 - accuracy: 0.6910 - val_loss: 1.0686 - val_accuracy: 0.5327\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.58879\n",
            "Epoch 75/1000\n",
            "14/14 [==============================] - 0s 36ms/step - loss: 0.7573 - accuracy: 0.7225 - val_loss: 1.0943 - val_accuracy: 0.5327\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.58879\n",
            "Epoch 76/1000\n",
            "14/14 [==============================] - 1s 36ms/step - loss: 0.7965 - accuracy: 0.6841 - val_loss: 1.3338 - val_accuracy: 0.3925\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.58879\n",
            "Epoch 77/1000\n",
            "14/14 [==============================] - 0s 36ms/step - loss: 0.7798 - accuracy: 0.7126 - val_loss: 1.2173 - val_accuracy: 0.4393\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.58879\n",
            "Epoch 78/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.7766 - accuracy: 0.7096 - val_loss: 1.1377 - val_accuracy: 0.5140\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.58879\n",
            "Epoch 79/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.8357 - accuracy: 0.6771 - val_loss: 1.0878 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.58879\n",
            "Epoch 80/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.7322 - accuracy: 0.7300 - val_loss: 1.0220 - val_accuracy: 0.5421\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.58879\n",
            "Epoch 81/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.6569 - accuracy: 0.7560 - val_loss: 1.2216 - val_accuracy: 0.5140\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.58879\n",
            "Epoch 82/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.7244 - accuracy: 0.7026 - val_loss: 1.0998 - val_accuracy: 0.5047\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.58879\n",
            "Epoch 83/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.7468 - accuracy: 0.7128 - val_loss: 1.2703 - val_accuracy: 0.4673\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.58879\n",
            "Epoch 84/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.7134 - accuracy: 0.7117 - val_loss: 1.1554 - val_accuracy: 0.4673\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.58879\n",
            "Epoch 85/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.6656 - accuracy: 0.7070 - val_loss: 1.1354 - val_accuracy: 0.5327\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.58879\n",
            "Epoch 86/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.6602 - accuracy: 0.7342 - val_loss: 1.2874 - val_accuracy: 0.4579\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.58879\n",
            "Epoch 87/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.7517 - accuracy: 0.6977 - val_loss: 1.1338 - val_accuracy: 0.5140\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.58879\n",
            "Epoch 88/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.7170 - accuracy: 0.6950 - val_loss: 1.3352 - val_accuracy: 0.5234\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.58879\n",
            "Epoch 89/1000\n",
            "14/14 [==============================] - 1s 36ms/step - loss: 0.6841 - accuracy: 0.7378 - val_loss: 1.1754 - val_accuracy: 0.5607\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.58879\n",
            "Epoch 90/1000\n",
            "14/14 [==============================] - 1s 36ms/step - loss: 0.7125 - accuracy: 0.7186 - val_loss: 1.1836 - val_accuracy: 0.5327\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.58879\n",
            "Epoch 91/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.6462 - accuracy: 0.7302 - val_loss: 1.2436 - val_accuracy: 0.5234\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.58879\n",
            "Epoch 92/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.7397 - accuracy: 0.6773 - val_loss: 1.0890 - val_accuracy: 0.6262\n",
            "\n",
            "Epoch 00092: val_accuracy improved from 0.58879 to 0.62617, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 93/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.7646 - accuracy: 0.6980 - val_loss: 1.0724 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.62617\n",
            "Epoch 94/1000\n",
            "14/14 [==============================] - 1s 36ms/step - loss: 0.6488 - accuracy: 0.7558 - val_loss: 1.1852 - val_accuracy: 0.4766\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.62617\n",
            "Epoch 95/1000\n",
            "14/14 [==============================] - 0s 36ms/step - loss: 0.6417 - accuracy: 0.7132 - val_loss: 1.1335 - val_accuracy: 0.4673\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.62617\n",
            "Epoch 96/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.8415 - accuracy: 0.6778 - val_loss: 1.2076 - val_accuracy: 0.5607\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.62617\n",
            "Epoch 97/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.6280 - accuracy: 0.7756 - val_loss: 1.1645 - val_accuracy: 0.4953\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.62617\n",
            "Epoch 98/1000\n",
            "14/14 [==============================] - 1s 36ms/step - loss: 0.6569 - accuracy: 0.7283 - val_loss: 1.1787 - val_accuracy: 0.5140\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.62617\n",
            "Epoch 99/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.7159 - accuracy: 0.7612 - val_loss: 1.1934 - val_accuracy: 0.5234\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.62617\n",
            "Epoch 100/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.6089 - accuracy: 0.7657 - val_loss: 1.3756 - val_accuracy: 0.5421\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.62617\n",
            "Epoch 101/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.7804 - accuracy: 0.7205 - val_loss: 1.3447 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.62617\n",
            "Epoch 102/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.6441 - accuracy: 0.7192 - val_loss: 1.3467 - val_accuracy: 0.6168\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.62617\n",
            "Epoch 103/1000\n",
            "14/14 [==============================] - 1s 36ms/step - loss: 0.6908 - accuracy: 0.7395 - val_loss: 1.0327 - val_accuracy: 0.6636\n",
            "\n",
            "Epoch 00103: val_accuracy improved from 0.62617 to 0.66355, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 104/1000\n",
            "14/14 [==============================] - 0s 36ms/step - loss: 0.6571 - accuracy: 0.7421 - val_loss: 1.2756 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 0.66355\n",
            "Epoch 105/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.5882 - accuracy: 0.7858 - val_loss: 1.2270 - val_accuracy: 0.5047\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.66355\n",
            "Epoch 106/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.6711 - accuracy: 0.7142 - val_loss: 1.0540 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.66355\n",
            "Epoch 107/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.6637 - accuracy: 0.7458 - val_loss: 1.0665 - val_accuracy: 0.6355\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.66355\n",
            "Epoch 108/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.5818 - accuracy: 0.7606 - val_loss: 1.2209 - val_accuracy: 0.5421\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 0.66355\n",
            "Epoch 109/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.7281 - accuracy: 0.7471 - val_loss: 1.7532 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.66355\n",
            "Epoch 110/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.7033 - accuracy: 0.7455 - val_loss: 1.5358 - val_accuracy: 0.6355\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.66355\n",
            "Epoch 111/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.6281 - accuracy: 0.7396 - val_loss: 1.6666 - val_accuracy: 0.6449\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 0.66355\n",
            "Epoch 112/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.5708 - accuracy: 0.7612 - val_loss: 1.3429 - val_accuracy: 0.6262\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.66355\n",
            "Epoch 113/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.6261 - accuracy: 0.7527 - val_loss: 1.2250 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00113: val_accuracy did not improve from 0.66355\n",
            "Epoch 114/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.5730 - accuracy: 0.7857 - val_loss: 1.1862 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00114: val_accuracy did not improve from 0.66355\n",
            "Epoch 115/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.5783 - accuracy: 0.7732 - val_loss: 1.2159 - val_accuracy: 0.5514\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.66355\n",
            "Epoch 116/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.5293 - accuracy: 0.7997 - val_loss: 1.2171 - val_accuracy: 0.5514\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.66355\n",
            "Epoch 117/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.6753 - accuracy: 0.7287 - val_loss: 1.1130 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.66355\n",
            "Epoch 118/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.6210 - accuracy: 0.7280 - val_loss: 1.1411 - val_accuracy: 0.6168\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.66355\n",
            "Epoch 119/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.6025 - accuracy: 0.7568 - val_loss: 1.2375 - val_accuracy: 0.5514\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.66355\n",
            "Epoch 120/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.6207 - accuracy: 0.7899 - val_loss: 1.3808 - val_accuracy: 0.5327\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 0.66355\n",
            "Epoch 121/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.5489 - accuracy: 0.7779 - val_loss: 1.4141 - val_accuracy: 0.5421\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.66355\n",
            "Epoch 122/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.6165 - accuracy: 0.7458 - val_loss: 2.3186 - val_accuracy: 0.5327\n",
            "\n",
            "Epoch 00122: val_accuracy did not improve from 0.66355\n",
            "Epoch 123/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.5653 - accuracy: 0.7923 - val_loss: 1.5163 - val_accuracy: 0.5701\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.66355\n",
            "Epoch 124/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.5693 - accuracy: 0.7589 - val_loss: 1.4546 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00124: val_accuracy did not improve from 0.66355\n",
            "Epoch 125/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.5476 - accuracy: 0.7898 - val_loss: 1.2341 - val_accuracy: 0.5421\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.66355\n",
            "Epoch 126/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.5342 - accuracy: 0.7703 - val_loss: 1.1220 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.66355\n",
            "Epoch 127/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.5080 - accuracy: 0.8260 - val_loss: 1.3296 - val_accuracy: 0.6168\n",
            "\n",
            "Epoch 00127: val_accuracy did not improve from 0.66355\n",
            "Epoch 128/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.4604 - accuracy: 0.8282 - val_loss: 1.1761 - val_accuracy: 0.5701\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.66355\n",
            "Epoch 129/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.5019 - accuracy: 0.8046 - val_loss: 1.2232 - val_accuracy: 0.5421\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.66355\n",
            "Epoch 130/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.4949 - accuracy: 0.8214 - val_loss: 1.2750 - val_accuracy: 0.5047\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.66355\n",
            "Epoch 131/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.4654 - accuracy: 0.8140 - val_loss: 1.2664 - val_accuracy: 0.5421\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.66355\n",
            "Epoch 132/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.4839 - accuracy: 0.8235 - val_loss: 1.4368 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.66355\n",
            "Epoch 133/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.5039 - accuracy: 0.8115 - val_loss: 1.2675 - val_accuracy: 0.5047\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.66355\n",
            "Epoch 134/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.4584 - accuracy: 0.8264 - val_loss: 1.2818 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.66355\n",
            "Epoch 135/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.5740 - accuracy: 0.7503 - val_loss: 1.5564 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00135: val_accuracy did not improve from 0.66355\n",
            "Epoch 136/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.5757 - accuracy: 0.8008 - val_loss: 1.4058 - val_accuracy: 0.5701\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.66355\n",
            "Epoch 137/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.5066 - accuracy: 0.8101 - val_loss: 1.7115 - val_accuracy: 0.5234\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 0.66355\n",
            "Epoch 138/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.6124 - accuracy: 0.7810 - val_loss: 1.5286 - val_accuracy: 0.5327\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.66355\n",
            "Epoch 139/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.5131 - accuracy: 0.7832 - val_loss: 1.7426 - val_accuracy: 0.5514\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.66355\n",
            "Epoch 140/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.5270 - accuracy: 0.8235 - val_loss: 1.6264 - val_accuracy: 0.4766\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.66355\n",
            "Epoch 141/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.5436 - accuracy: 0.8031 - val_loss: 1.4695 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00141: val_accuracy did not improve from 0.66355\n",
            "Epoch 142/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.4962 - accuracy: 0.8189 - val_loss: 1.3230 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.66355\n",
            "Epoch 143/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.3941 - accuracy: 0.8593 - val_loss: 1.5086 - val_accuracy: 0.5421\n",
            "\n",
            "Epoch 00143: val_accuracy did not improve from 0.66355\n",
            "Epoch 144/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.4597 - accuracy: 0.8154 - val_loss: 1.9262 - val_accuracy: 0.4860\n",
            "\n",
            "Epoch 00144: val_accuracy did not improve from 0.66355\n",
            "Epoch 145/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.5393 - accuracy: 0.8046 - val_loss: 1.5909 - val_accuracy: 0.5234\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.66355\n",
            "Epoch 146/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.5305 - accuracy: 0.8416 - val_loss: 1.5028 - val_accuracy: 0.5607\n",
            "\n",
            "Epoch 00146: val_accuracy did not improve from 0.66355\n",
            "Epoch 147/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.5302 - accuracy: 0.8010 - val_loss: 1.2319 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.66355\n",
            "Epoch 148/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.4043 - accuracy: 0.8518 - val_loss: 1.2956 - val_accuracy: 0.5607\n",
            "\n",
            "Epoch 00148: val_accuracy did not improve from 0.66355\n",
            "Epoch 149/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.4786 - accuracy: 0.8347 - val_loss: 1.7944 - val_accuracy: 0.5234\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.66355\n",
            "Epoch 150/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.4529 - accuracy: 0.8437 - val_loss: 1.2592 - val_accuracy: 0.6168\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 0.66355\n",
            "Epoch 151/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.4856 - accuracy: 0.8015 - val_loss: 1.2005 - val_accuracy: 0.6449\n",
            "\n",
            "Epoch 00151: val_accuracy did not improve from 0.66355\n",
            "Epoch 152/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.4275 - accuracy: 0.8116 - val_loss: 1.7124 - val_accuracy: 0.5140\n",
            "\n",
            "Epoch 00152: val_accuracy did not improve from 0.66355\n",
            "Epoch 153/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.4057 - accuracy: 0.8280 - val_loss: 1.3426 - val_accuracy: 0.5140\n",
            "\n",
            "Epoch 00153: val_accuracy did not improve from 0.66355\n",
            "Epoch 154/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.4392 - accuracy: 0.8394 - val_loss: 1.3598 - val_accuracy: 0.5607\n",
            "\n",
            "Epoch 00154: val_accuracy did not improve from 0.66355\n",
            "Epoch 155/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.4353 - accuracy: 0.8569 - val_loss: 1.6428 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00155: val_accuracy did not improve from 0.66355\n",
            "Epoch 156/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.4600 - accuracy: 0.8372 - val_loss: 2.9647 - val_accuracy: 0.5514\n",
            "\n",
            "Epoch 00156: val_accuracy did not improve from 0.66355\n",
            "Epoch 157/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.4318 - accuracy: 0.8505 - val_loss: 1.3375 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00157: val_accuracy did not improve from 0.66355\n",
            "Epoch 158/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.4873 - accuracy: 0.8131 - val_loss: 1.4315 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00158: val_accuracy did not improve from 0.66355\n",
            "Epoch 159/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.4315 - accuracy: 0.8249 - val_loss: 1.5612 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00159: val_accuracy did not improve from 0.66355\n",
            "Epoch 160/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.4030 - accuracy: 0.8492 - val_loss: 1.2691 - val_accuracy: 0.6449\n",
            "\n",
            "Epoch 00160: val_accuracy did not improve from 0.66355\n",
            "Epoch 161/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.3566 - accuracy: 0.8813 - val_loss: 1.3941 - val_accuracy: 0.5701\n",
            "\n",
            "Epoch 00161: val_accuracy did not improve from 0.66355\n",
            "Epoch 162/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.4479 - accuracy: 0.8517 - val_loss: 1.5553 - val_accuracy: 0.5607\n",
            "\n",
            "Epoch 00162: val_accuracy did not improve from 0.66355\n",
            "Epoch 163/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.4085 - accuracy: 0.8400 - val_loss: 1.5946 - val_accuracy: 0.5421\n",
            "\n",
            "Epoch 00163: val_accuracy did not improve from 0.66355\n",
            "Epoch 164/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.4970 - accuracy: 0.8201 - val_loss: 1.4764 - val_accuracy: 0.6355\n",
            "\n",
            "Epoch 00164: val_accuracy did not improve from 0.66355\n",
            "Epoch 165/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.5662 - accuracy: 0.7501 - val_loss: 1.7255 - val_accuracy: 0.4953\n",
            "\n",
            "Epoch 00165: val_accuracy did not improve from 0.66355\n",
            "Epoch 166/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.4337 - accuracy: 0.8386 - val_loss: 2.4375 - val_accuracy: 0.5607\n",
            "\n",
            "Epoch 00166: val_accuracy did not improve from 0.66355\n",
            "Epoch 167/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.5058 - accuracy: 0.8229 - val_loss: 1.7987 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00167: val_accuracy did not improve from 0.66355\n",
            "Epoch 168/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.5235 - accuracy: 0.8252 - val_loss: 2.2498 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00168: val_accuracy did not improve from 0.66355\n",
            "Epoch 169/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.4732 - accuracy: 0.8327 - val_loss: 1.3501 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00169: val_accuracy did not improve from 0.66355\n",
            "Epoch 170/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.4026 - accuracy: 0.8830 - val_loss: 1.5037 - val_accuracy: 0.6168\n",
            "\n",
            "Epoch 00170: val_accuracy did not improve from 0.66355\n",
            "Epoch 171/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.4091 - accuracy: 0.8649 - val_loss: 1.3194 - val_accuracy: 0.5701\n",
            "\n",
            "Epoch 00171: val_accuracy did not improve from 0.66355\n",
            "Epoch 172/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.4057 - accuracy: 0.8577 - val_loss: 1.2966 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00172: val_accuracy did not improve from 0.66355\n",
            "Epoch 173/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.3675 - accuracy: 0.8585 - val_loss: 2.1206 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00173: val_accuracy did not improve from 0.66355\n",
            "Epoch 174/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.3375 - accuracy: 0.9012 - val_loss: 1.4370 - val_accuracy: 0.6262\n",
            "\n",
            "Epoch 00174: val_accuracy did not improve from 0.66355\n",
            "Epoch 175/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.3355 - accuracy: 0.8778 - val_loss: 1.4184 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00175: val_accuracy did not improve from 0.66355\n",
            "Epoch 176/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.3640 - accuracy: 0.8643 - val_loss: 1.2145 - val_accuracy: 0.6729\n",
            "\n",
            "Epoch 00176: val_accuracy improved from 0.66355 to 0.67290, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 177/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.4105 - accuracy: 0.8598 - val_loss: 1.5867 - val_accuracy: 0.5514\n",
            "\n",
            "Epoch 00177: val_accuracy did not improve from 0.67290\n",
            "Epoch 178/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.4172 - accuracy: 0.8635 - val_loss: 1.5361 - val_accuracy: 0.6355\n",
            "\n",
            "Epoch 00178: val_accuracy did not improve from 0.67290\n",
            "Epoch 179/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.3354 - accuracy: 0.8695 - val_loss: 1.4665 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00179: val_accuracy did not improve from 0.67290\n",
            "Epoch 180/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.3714 - accuracy: 0.8482 - val_loss: 1.4296 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00180: val_accuracy did not improve from 0.67290\n",
            "Epoch 181/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.3393 - accuracy: 0.8649 - val_loss: 2.0309 - val_accuracy: 0.4860\n",
            "\n",
            "Epoch 00181: val_accuracy did not improve from 0.67290\n",
            "Epoch 182/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.3260 - accuracy: 0.8925 - val_loss: 1.3908 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00182: val_accuracy did not improve from 0.67290\n",
            "Epoch 183/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.3571 - accuracy: 0.8738 - val_loss: 1.6049 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00183: val_accuracy did not improve from 0.67290\n",
            "Epoch 184/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.3595 - accuracy: 0.8824 - val_loss: 1.6283 - val_accuracy: 0.6449\n",
            "\n",
            "Epoch 00184: val_accuracy did not improve from 0.67290\n",
            "Epoch 185/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.3273 - accuracy: 0.8765 - val_loss: 1.5541 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00185: val_accuracy did not improve from 0.67290\n",
            "Epoch 186/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.3302 - accuracy: 0.8838 - val_loss: 1.6121 - val_accuracy: 0.5234\n",
            "\n",
            "Epoch 00186: val_accuracy did not improve from 0.67290\n",
            "Epoch 187/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.3498 - accuracy: 0.8714 - val_loss: 1.9214 - val_accuracy: 0.5327\n",
            "\n",
            "Epoch 00187: val_accuracy did not improve from 0.67290\n",
            "Epoch 188/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.4633 - accuracy: 0.8348 - val_loss: 1.3803 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00188: val_accuracy did not improve from 0.67290\n",
            "Epoch 189/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.3534 - accuracy: 0.9006 - val_loss: 1.6006 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00189: val_accuracy did not improve from 0.67290\n",
            "Epoch 190/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.2896 - accuracy: 0.8992 - val_loss: 1.7756 - val_accuracy: 0.5327\n",
            "\n",
            "Epoch 00190: val_accuracy did not improve from 0.67290\n",
            "Epoch 191/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.3573 - accuracy: 0.8808 - val_loss: 2.0220 - val_accuracy: 0.5514\n",
            "\n",
            "Epoch 00191: val_accuracy did not improve from 0.67290\n",
            "Epoch 192/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.3482 - accuracy: 0.8836 - val_loss: 1.8402 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00192: val_accuracy did not improve from 0.67290\n",
            "Epoch 193/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.4512 - accuracy: 0.8669 - val_loss: 1.7046 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00193: val_accuracy did not improve from 0.67290\n",
            "Epoch 194/1000\n",
            "14/14 [==============================] - 1s 40ms/step - loss: 0.3529 - accuracy: 0.8664 - val_loss: 1.5299 - val_accuracy: 0.6636\n",
            "\n",
            "Epoch 00194: val_accuracy did not improve from 0.67290\n",
            "Epoch 195/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.3238 - accuracy: 0.8928 - val_loss: 2.5019 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00195: val_accuracy did not improve from 0.67290\n",
            "Epoch 196/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.4096 - accuracy: 0.8889 - val_loss: 2.5608 - val_accuracy: 0.4579\n",
            "\n",
            "Epoch 00196: val_accuracy did not improve from 0.67290\n",
            "Epoch 197/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.3360 - accuracy: 0.8812 - val_loss: 1.2981 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00197: val_accuracy did not improve from 0.67290\n",
            "Epoch 198/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.3257 - accuracy: 0.8954 - val_loss: 1.4725 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00198: val_accuracy did not improve from 0.67290\n",
            "Epoch 199/1000\n",
            "14/14 [==============================] - 1s 40ms/step - loss: 0.3856 - accuracy: 0.8518 - val_loss: 1.4121 - val_accuracy: 0.6168\n",
            "\n",
            "Epoch 00199: val_accuracy did not improve from 0.67290\n",
            "Epoch 200/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.3335 - accuracy: 0.8772 - val_loss: 1.5038 - val_accuracy: 0.6168\n",
            "\n",
            "Epoch 00200: val_accuracy did not improve from 0.67290\n",
            "Epoch 201/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.2879 - accuracy: 0.8894 - val_loss: 1.4632 - val_accuracy: 0.5607\n",
            "\n",
            "Epoch 00201: val_accuracy did not improve from 0.67290\n",
            "Epoch 202/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.3345 - accuracy: 0.8803 - val_loss: 1.5425 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00202: val_accuracy did not improve from 0.67290\n",
            "Epoch 203/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.3005 - accuracy: 0.8805 - val_loss: 1.4461 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00203: val_accuracy did not improve from 0.67290\n",
            "Epoch 204/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.3420 - accuracy: 0.8682 - val_loss: 1.5743 - val_accuracy: 0.6449\n",
            "\n",
            "Epoch 00204: val_accuracy did not improve from 0.67290\n",
            "Epoch 205/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.2924 - accuracy: 0.9003 - val_loss: 1.5245 - val_accuracy: 0.6449\n",
            "\n",
            "Epoch 00205: val_accuracy did not improve from 0.67290\n",
            "Epoch 206/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.3540 - accuracy: 0.8659 - val_loss: 1.3909 - val_accuracy: 0.6449\n",
            "\n",
            "Epoch 00206: val_accuracy did not improve from 0.67290\n",
            "Epoch 207/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.3291 - accuracy: 0.8877 - val_loss: 1.5718 - val_accuracy: 0.6355\n",
            "\n",
            "Epoch 00207: val_accuracy did not improve from 0.67290\n",
            "Epoch 208/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.2890 - accuracy: 0.9008 - val_loss: 1.2284 - val_accuracy: 0.6355\n",
            "\n",
            "Epoch 00208: val_accuracy did not improve from 0.67290\n",
            "Epoch 209/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.2886 - accuracy: 0.8778 - val_loss: 1.2504 - val_accuracy: 0.6262\n",
            "\n",
            "Epoch 00209: val_accuracy did not improve from 0.67290\n",
            "Epoch 210/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.2789 - accuracy: 0.9057 - val_loss: 1.2985 - val_accuracy: 0.5701\n",
            "\n",
            "Epoch 00210: val_accuracy did not improve from 0.67290\n",
            "Epoch 211/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.2641 - accuracy: 0.9178 - val_loss: 1.4682 - val_accuracy: 0.5701\n",
            "\n",
            "Epoch 00211: val_accuracy did not improve from 0.67290\n",
            "Epoch 212/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.2637 - accuracy: 0.9012 - val_loss: 1.5979 - val_accuracy: 0.5140\n",
            "\n",
            "Epoch 00212: val_accuracy did not improve from 0.67290\n",
            "Epoch 213/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.2668 - accuracy: 0.9091 - val_loss: 1.7481 - val_accuracy: 0.5514\n",
            "\n",
            "Epoch 00213: val_accuracy did not improve from 0.67290\n",
            "Epoch 214/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.2753 - accuracy: 0.9000 - val_loss: 1.8458 - val_accuracy: 0.5701\n",
            "\n",
            "Epoch 00214: val_accuracy did not improve from 0.67290\n",
            "Epoch 215/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.3293 - accuracy: 0.8746 - val_loss: 1.8242 - val_accuracy: 0.4673\n",
            "\n",
            "Epoch 00215: val_accuracy did not improve from 0.67290\n",
            "Epoch 216/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.3100 - accuracy: 0.8905 - val_loss: 2.6011 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00216: val_accuracy did not improve from 0.67290\n",
            "Epoch 217/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.3403 - accuracy: 0.8899 - val_loss: 2.2783 - val_accuracy: 0.6355\n",
            "\n",
            "Epoch 00217: val_accuracy did not improve from 0.67290\n",
            "Epoch 218/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.2945 - accuracy: 0.9276 - val_loss: 2.1069 - val_accuracy: 0.6168\n",
            "\n",
            "Epoch 00218: val_accuracy did not improve from 0.67290\n",
            "Epoch 219/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.2669 - accuracy: 0.9190 - val_loss: 1.8984 - val_accuracy: 0.6262\n",
            "\n",
            "Epoch 00219: val_accuracy did not improve from 0.67290\n",
            "Epoch 220/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.3408 - accuracy: 0.8729 - val_loss: 2.4103 - val_accuracy: 0.5234\n",
            "\n",
            "Epoch 00220: val_accuracy did not improve from 0.67290\n",
            "Epoch 221/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.2789 - accuracy: 0.9060 - val_loss: 1.6621 - val_accuracy: 0.6262\n",
            "\n",
            "Epoch 00221: val_accuracy did not improve from 0.67290\n",
            "Epoch 222/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.3176 - accuracy: 0.8800 - val_loss: 1.6196 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00222: val_accuracy did not improve from 0.67290\n",
            "Epoch 223/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.2523 - accuracy: 0.9110 - val_loss: 1.6069 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00223: val_accuracy did not improve from 0.67290\n",
            "Epoch 224/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.2505 - accuracy: 0.9178 - val_loss: 1.9041 - val_accuracy: 0.6542\n",
            "\n",
            "Epoch 00224: val_accuracy did not improve from 0.67290\n",
            "Epoch 225/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.3353 - accuracy: 0.9049 - val_loss: 1.4485 - val_accuracy: 0.6262\n",
            "\n",
            "Epoch 00225: val_accuracy did not improve from 0.67290\n",
            "Epoch 226/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.2939 - accuracy: 0.8994 - val_loss: 1.8442 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00226: val_accuracy did not improve from 0.67290\n",
            "Epoch 227/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.2655 - accuracy: 0.9062 - val_loss: 1.7311 - val_accuracy: 0.6355\n",
            "\n",
            "Epoch 00227: val_accuracy did not improve from 0.67290\n",
            "Epoch 228/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.2959 - accuracy: 0.8969 - val_loss: 1.5640 - val_accuracy: 0.6168\n",
            "\n",
            "Epoch 00228: val_accuracy did not improve from 0.67290\n",
            "Epoch 229/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.2627 - accuracy: 0.9082 - val_loss: 1.6392 - val_accuracy: 0.6636\n",
            "\n",
            "Epoch 00229: val_accuracy did not improve from 0.67290\n",
            "Epoch 230/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.3101 - accuracy: 0.9048 - val_loss: 1.9088 - val_accuracy: 0.5701\n",
            "\n",
            "Epoch 00230: val_accuracy did not improve from 0.67290\n",
            "Epoch 231/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.2270 - accuracy: 0.9382 - val_loss: 1.5318 - val_accuracy: 0.7103\n",
            "\n",
            "Epoch 00231: val_accuracy improved from 0.67290 to 0.71028, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 232/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.2375 - accuracy: 0.9429 - val_loss: 1.7991 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00232: val_accuracy did not improve from 0.71028\n",
            "Epoch 233/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.2894 - accuracy: 0.9136 - val_loss: 1.7130 - val_accuracy: 0.6355\n",
            "\n",
            "Epoch 00233: val_accuracy did not improve from 0.71028\n",
            "Epoch 234/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.2770 - accuracy: 0.9105 - val_loss: 1.5944 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00234: val_accuracy did not improve from 0.71028\n",
            "Epoch 235/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.2056 - accuracy: 0.9431 - val_loss: 2.2464 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00235: val_accuracy did not improve from 0.71028\n",
            "Epoch 236/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.2743 - accuracy: 0.9058 - val_loss: 1.8897 - val_accuracy: 0.5607\n",
            "\n",
            "Epoch 00236: val_accuracy did not improve from 0.71028\n",
            "Epoch 237/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.2138 - accuracy: 0.9440 - val_loss: 2.1275 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00237: val_accuracy did not improve from 0.71028\n",
            "Epoch 238/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.2668 - accuracy: 0.9130 - val_loss: 1.4438 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00238: val_accuracy did not improve from 0.71028\n",
            "Epoch 239/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.3360 - accuracy: 0.8808 - val_loss: 1.7996 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00239: val_accuracy did not improve from 0.71028\n",
            "Epoch 240/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.2343 - accuracy: 0.9381 - val_loss: 1.6400 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00240: val_accuracy did not improve from 0.71028\n",
            "Epoch 241/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1917 - accuracy: 0.9486 - val_loss: 1.6758 - val_accuracy: 0.6355\n",
            "\n",
            "Epoch 00241: val_accuracy did not improve from 0.71028\n",
            "Epoch 242/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.2775 - accuracy: 0.9126 - val_loss: 1.7098 - val_accuracy: 0.6355\n",
            "\n",
            "Epoch 00242: val_accuracy did not improve from 0.71028\n",
            "Epoch 243/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.2814 - accuracy: 0.9074 - val_loss: 1.8803 - val_accuracy: 0.5514\n",
            "\n",
            "Epoch 00243: val_accuracy did not improve from 0.71028\n",
            "Epoch 244/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.2514 - accuracy: 0.9114 - val_loss: 1.8853 - val_accuracy: 0.6636\n",
            "\n",
            "Epoch 00244: val_accuracy did not improve from 0.71028\n",
            "Epoch 245/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.3021 - accuracy: 0.8825 - val_loss: 2.3416 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00245: val_accuracy did not improve from 0.71028\n",
            "Epoch 246/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.2167 - accuracy: 0.9263 - val_loss: 1.8837 - val_accuracy: 0.6262\n",
            "\n",
            "Epoch 00246: val_accuracy did not improve from 0.71028\n",
            "Epoch 247/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.3381 - accuracy: 0.9117 - val_loss: 2.2691 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00247: val_accuracy did not improve from 0.71028\n",
            "Epoch 248/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.2615 - accuracy: 0.9142 - val_loss: 1.8447 - val_accuracy: 0.5607\n",
            "\n",
            "Epoch 00248: val_accuracy did not improve from 0.71028\n",
            "Epoch 249/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.3006 - accuracy: 0.9084 - val_loss: 2.3168 - val_accuracy: 0.5701\n",
            "\n",
            "Epoch 00249: val_accuracy did not improve from 0.71028\n",
            "Epoch 250/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.2465 - accuracy: 0.9236 - val_loss: 2.4648 - val_accuracy: 0.5421\n",
            "\n",
            "Epoch 00250: val_accuracy did not improve from 0.71028\n",
            "Epoch 251/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.2440 - accuracy: 0.9310 - val_loss: 1.8421 - val_accuracy: 0.5421\n",
            "\n",
            "Epoch 00251: val_accuracy did not improve from 0.71028\n",
            "Epoch 252/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.2850 - accuracy: 0.9148 - val_loss: 1.7319 - val_accuracy: 0.6168\n",
            "\n",
            "Epoch 00252: val_accuracy did not improve from 0.71028\n",
            "Epoch 253/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.2531 - accuracy: 0.9240 - val_loss: 1.9929 - val_accuracy: 0.5421\n",
            "\n",
            "Epoch 00253: val_accuracy did not improve from 0.71028\n",
            "Epoch 254/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1687 - accuracy: 0.9511 - val_loss: 2.3214 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00254: val_accuracy did not improve from 0.71028\n",
            "Epoch 255/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1938 - accuracy: 0.9354 - val_loss: 1.9247 - val_accuracy: 0.6168\n",
            "\n",
            "Epoch 00255: val_accuracy did not improve from 0.71028\n",
            "Epoch 256/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1798 - accuracy: 0.9463 - val_loss: 2.1542 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00256: val_accuracy did not improve from 0.71028\n",
            "Epoch 257/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1857 - accuracy: 0.9579 - val_loss: 2.6002 - val_accuracy: 0.5607\n",
            "\n",
            "Epoch 00257: val_accuracy did not improve from 0.71028\n",
            "Epoch 258/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.2516 - accuracy: 0.9173 - val_loss: 2.3354 - val_accuracy: 0.5607\n",
            "\n",
            "Epoch 00258: val_accuracy did not improve from 0.71028\n",
            "Epoch 259/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.1825 - accuracy: 0.9448 - val_loss: 2.4869 - val_accuracy: 0.5514\n",
            "\n",
            "Epoch 00259: val_accuracy did not improve from 0.71028\n",
            "Epoch 260/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.3147 - accuracy: 0.9216 - val_loss: 3.5854 - val_accuracy: 0.5514\n",
            "\n",
            "Epoch 00260: val_accuracy did not improve from 0.71028\n",
            "Epoch 261/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.3613 - accuracy: 0.8906 - val_loss: 2.1115 - val_accuracy: 0.5607\n",
            "\n",
            "Epoch 00261: val_accuracy did not improve from 0.71028\n",
            "Epoch 262/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.4144 - accuracy: 0.8816 - val_loss: 1.8027 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00262: val_accuracy did not improve from 0.71028\n",
            "Epoch 263/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.3215 - accuracy: 0.9157 - val_loss: 1.5849 - val_accuracy: 0.6168\n",
            "\n",
            "Epoch 00263: val_accuracy did not improve from 0.71028\n",
            "Epoch 264/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.2796 - accuracy: 0.9344 - val_loss: 1.6019 - val_accuracy: 0.6542\n",
            "\n",
            "Epoch 00264: val_accuracy did not improve from 0.71028\n",
            "Epoch 265/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.2963 - accuracy: 0.9243 - val_loss: 1.7829 - val_accuracy: 0.6636\n",
            "\n",
            "Epoch 00265: val_accuracy did not improve from 0.71028\n",
            "Epoch 266/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.2205 - accuracy: 0.9131 - val_loss: 1.9465 - val_accuracy: 0.6262\n",
            "\n",
            "Epoch 00266: val_accuracy did not improve from 0.71028\n",
            "Epoch 267/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1939 - accuracy: 0.9401 - val_loss: 1.7141 - val_accuracy: 0.6355\n",
            "\n",
            "Epoch 00267: val_accuracy did not improve from 0.71028\n",
            "Epoch 268/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.2156 - accuracy: 0.9179 - val_loss: 1.7501 - val_accuracy: 0.5514\n",
            "\n",
            "Epoch 00268: val_accuracy did not improve from 0.71028\n",
            "Epoch 269/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1392 - accuracy: 0.9659 - val_loss: 1.7281 - val_accuracy: 0.5607\n",
            "\n",
            "Epoch 00269: val_accuracy did not improve from 0.71028\n",
            "Epoch 270/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.2242 - accuracy: 0.9351 - val_loss: 1.7612 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00270: val_accuracy did not improve from 0.71028\n",
            "Epoch 271/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.2040 - accuracy: 0.9318 - val_loss: 1.6066 - val_accuracy: 0.6168\n",
            "\n",
            "Epoch 00271: val_accuracy did not improve from 0.71028\n",
            "Epoch 272/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1467 - accuracy: 0.9652 - val_loss: 1.9378 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00272: val_accuracy did not improve from 0.71028\n",
            "Epoch 273/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.2499 - accuracy: 0.9245 - val_loss: 1.9694 - val_accuracy: 0.5421\n",
            "\n",
            "Epoch 00273: val_accuracy did not improve from 0.71028\n",
            "Epoch 274/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1586 - accuracy: 0.9406 - val_loss: 1.9108 - val_accuracy: 0.5421\n",
            "\n",
            "Epoch 00274: val_accuracy did not improve from 0.71028\n",
            "Epoch 275/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1890 - accuracy: 0.9475 - val_loss: 1.5925 - val_accuracy: 0.6168\n",
            "\n",
            "Epoch 00275: val_accuracy did not improve from 0.71028\n",
            "Epoch 276/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.1691 - accuracy: 0.9404 - val_loss: 1.6803 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00276: val_accuracy did not improve from 0.71028\n",
            "Epoch 277/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.2075 - accuracy: 0.9306 - val_loss: 1.9895 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00277: val_accuracy did not improve from 0.71028\n",
            "Epoch 278/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.2420 - accuracy: 0.9303 - val_loss: 1.8110 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00278: val_accuracy did not improve from 0.71028\n",
            "Epoch 279/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.2065 - accuracy: 0.9357 - val_loss: 1.7138 - val_accuracy: 0.6449\n",
            "\n",
            "Epoch 00279: val_accuracy did not improve from 0.71028\n",
            "Epoch 280/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1989 - accuracy: 0.9630 - val_loss: 1.8576 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00280: val_accuracy did not improve from 0.71028\n",
            "Epoch 281/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.1678 - accuracy: 0.9424 - val_loss: 1.4077 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00281: val_accuracy did not improve from 0.71028\n",
            "Epoch 282/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.2719 - accuracy: 0.9152 - val_loss: 2.0230 - val_accuracy: 0.5421\n",
            "\n",
            "Epoch 00282: val_accuracy did not improve from 0.71028\n",
            "Epoch 283/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.2007 - accuracy: 0.9466 - val_loss: 1.9304 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00283: val_accuracy did not improve from 0.71028\n",
            "Epoch 284/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.2119 - accuracy: 0.9501 - val_loss: 2.3174 - val_accuracy: 0.5701\n",
            "\n",
            "Epoch 00284: val_accuracy did not improve from 0.71028\n",
            "Epoch 285/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.2599 - accuracy: 0.9159 - val_loss: 1.8519 - val_accuracy: 0.6542\n",
            "\n",
            "Epoch 00285: val_accuracy did not improve from 0.71028\n",
            "Epoch 286/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.2608 - accuracy: 0.9322 - val_loss: 2.1485 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00286: val_accuracy did not improve from 0.71028\n",
            "Epoch 287/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.1641 - accuracy: 0.9489 - val_loss: 2.0306 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00287: val_accuracy did not improve from 0.71028\n",
            "Epoch 288/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1424 - accuracy: 0.9581 - val_loss: 1.9757 - val_accuracy: 0.6168\n",
            "\n",
            "Epoch 00288: val_accuracy did not improve from 0.71028\n",
            "Epoch 289/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.2056 - accuracy: 0.9299 - val_loss: 2.3651 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00289: val_accuracy did not improve from 0.71028\n",
            "Epoch 290/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1902 - accuracy: 0.9426 - val_loss: 2.0299 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00290: val_accuracy did not improve from 0.71028\n",
            "Epoch 291/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.2316 - accuracy: 0.9493 - val_loss: 2.0910 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00291: val_accuracy did not improve from 0.71028\n",
            "Epoch 292/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.2612 - accuracy: 0.9048 - val_loss: 1.7368 - val_accuracy: 0.5514\n",
            "\n",
            "Epoch 00292: val_accuracy did not improve from 0.71028\n",
            "Epoch 293/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.1772 - accuracy: 0.9366 - val_loss: 2.0576 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00293: val_accuracy did not improve from 0.71028\n",
            "Epoch 294/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1564 - accuracy: 0.9443 - val_loss: 2.2042 - val_accuracy: 0.5701\n",
            "\n",
            "Epoch 00294: val_accuracy did not improve from 0.71028\n",
            "Epoch 295/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.1466 - accuracy: 0.9432 - val_loss: 2.4462 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00295: val_accuracy did not improve from 0.71028\n",
            "Epoch 296/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.2292 - accuracy: 0.9296 - val_loss: 1.8860 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00296: val_accuracy did not improve from 0.71028\n",
            "Epoch 297/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1321 - accuracy: 0.9599 - val_loss: 2.0289 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00297: val_accuracy did not improve from 0.71028\n",
            "Epoch 298/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.2300 - accuracy: 0.9255 - val_loss: 1.9371 - val_accuracy: 0.6262\n",
            "\n",
            "Epoch 00298: val_accuracy did not improve from 0.71028\n",
            "Epoch 299/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1779 - accuracy: 0.9434 - val_loss: 1.9052 - val_accuracy: 0.6449\n",
            "\n",
            "Epoch 00299: val_accuracy did not improve from 0.71028\n",
            "Epoch 300/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.1695 - accuracy: 0.9594 - val_loss: 1.7341 - val_accuracy: 0.6449\n",
            "\n",
            "Epoch 00300: val_accuracy did not improve from 0.71028\n",
            "Epoch 301/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.2205 - accuracy: 0.9385 - val_loss: 2.1272 - val_accuracy: 0.6168\n",
            "\n",
            "Epoch 00301: val_accuracy did not improve from 0.71028\n",
            "Epoch 302/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1653 - accuracy: 0.9476 - val_loss: 1.9514 - val_accuracy: 0.6449\n",
            "\n",
            "Epoch 00302: val_accuracy did not improve from 0.71028\n",
            "Epoch 303/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1668 - accuracy: 0.9296 - val_loss: 1.8478 - val_accuracy: 0.6355\n",
            "\n",
            "Epoch 00303: val_accuracy did not improve from 0.71028\n",
            "Epoch 304/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1464 - accuracy: 0.9665 - val_loss: 1.9746 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00304: val_accuracy did not improve from 0.71028\n",
            "Epoch 305/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1566 - accuracy: 0.9541 - val_loss: 2.3664 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00305: val_accuracy did not improve from 0.71028\n",
            "Epoch 306/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1111 - accuracy: 0.9845 - val_loss: 2.0926 - val_accuracy: 0.6449\n",
            "\n",
            "Epoch 00306: val_accuracy did not improve from 0.71028\n",
            "Epoch 307/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.2088 - accuracy: 0.9242 - val_loss: 2.5850 - val_accuracy: 0.6542\n",
            "\n",
            "Epoch 00307: val_accuracy did not improve from 0.71028\n",
            "Epoch 308/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.2236 - accuracy: 0.9351 - val_loss: 1.9148 - val_accuracy: 0.6168\n",
            "\n",
            "Epoch 00308: val_accuracy did not improve from 0.71028\n",
            "Epoch 309/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1530 - accuracy: 0.9653 - val_loss: 2.1347 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00309: val_accuracy did not improve from 0.71028\n",
            "Epoch 310/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.2166 - accuracy: 0.9431 - val_loss: 1.7338 - val_accuracy: 0.6636\n",
            "\n",
            "Epoch 00310: val_accuracy did not improve from 0.71028\n",
            "Epoch 311/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1552 - accuracy: 0.9689 - val_loss: 2.0833 - val_accuracy: 0.6168\n",
            "\n",
            "Epoch 00311: val_accuracy did not improve from 0.71028\n",
            "Epoch 312/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1504 - accuracy: 0.9578 - val_loss: 1.9610 - val_accuracy: 0.6355\n",
            "\n",
            "Epoch 00312: val_accuracy did not improve from 0.71028\n",
            "Epoch 313/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.1453 - accuracy: 0.9440 - val_loss: 1.8541 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00313: val_accuracy did not improve from 0.71028\n",
            "Epoch 314/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1398 - accuracy: 0.9531 - val_loss: 1.9261 - val_accuracy: 0.6262\n",
            "\n",
            "Epoch 00314: val_accuracy did not improve from 0.71028\n",
            "Epoch 315/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1240 - accuracy: 0.9685 - val_loss: 2.0628 - val_accuracy: 0.6168\n",
            "\n",
            "Epoch 00315: val_accuracy did not improve from 0.71028\n",
            "Epoch 316/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1549 - accuracy: 0.9619 - val_loss: 2.0576 - val_accuracy: 0.6262\n",
            "\n",
            "Epoch 00316: val_accuracy did not improve from 0.71028\n",
            "Epoch 317/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0937 - accuracy: 0.9787 - val_loss: 2.4163 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00317: val_accuracy did not improve from 0.71028\n",
            "Epoch 318/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.1086 - accuracy: 0.9707 - val_loss: 2.4835 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00318: val_accuracy did not improve from 0.71028\n",
            "Epoch 319/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.1810 - accuracy: 0.9526 - val_loss: 2.5050 - val_accuracy: 0.5327\n",
            "\n",
            "Epoch 00319: val_accuracy did not improve from 0.71028\n",
            "Epoch 320/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1949 - accuracy: 0.9329 - val_loss: 2.9621 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00320: val_accuracy did not improve from 0.71028\n",
            "Epoch 321/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.2991 - accuracy: 0.9316 - val_loss: 3.0869 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00321: val_accuracy did not improve from 0.71028\n",
            "Epoch 322/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.2300 - accuracy: 0.9235 - val_loss: 3.8118 - val_accuracy: 0.5514\n",
            "\n",
            "Epoch 00322: val_accuracy did not improve from 0.71028\n",
            "Epoch 323/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.3084 - accuracy: 0.9297 - val_loss: 3.1331 - val_accuracy: 0.5701\n",
            "\n",
            "Epoch 00323: val_accuracy did not improve from 0.71028\n",
            "Epoch 324/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.2436 - accuracy: 0.9264 - val_loss: 3.0260 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00324: val_accuracy did not improve from 0.71028\n",
            "Epoch 325/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1920 - accuracy: 0.9340 - val_loss: 2.9300 - val_accuracy: 0.6542\n",
            "\n",
            "Epoch 00325: val_accuracy did not improve from 0.71028\n",
            "Epoch 326/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.1551 - accuracy: 0.9575 - val_loss: 3.3976 - val_accuracy: 0.6542\n",
            "\n",
            "Epoch 00326: val_accuracy did not improve from 0.71028\n",
            "Epoch 327/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1195 - accuracy: 0.9674 - val_loss: 2.8323 - val_accuracy: 0.6262\n",
            "\n",
            "Epoch 00327: val_accuracy did not improve from 0.71028\n",
            "Epoch 328/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.2398 - accuracy: 0.9522 - val_loss: 2.3525 - val_accuracy: 0.6355\n",
            "\n",
            "Epoch 00328: val_accuracy did not improve from 0.71028\n",
            "Epoch 329/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1402 - accuracy: 0.9496 - val_loss: 2.6236 - val_accuracy: 0.5327\n",
            "\n",
            "Epoch 00329: val_accuracy did not improve from 0.71028\n",
            "Epoch 330/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1575 - accuracy: 0.9516 - val_loss: 1.9529 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00330: val_accuracy did not improve from 0.71028\n",
            "Epoch 331/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1697 - accuracy: 0.9501 - val_loss: 1.7780 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00331: val_accuracy did not improve from 0.71028\n",
            "Epoch 332/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1403 - accuracy: 0.9755 - val_loss: 1.7771 - val_accuracy: 0.6168\n",
            "\n",
            "Epoch 00332: val_accuracy did not improve from 0.71028\n",
            "Epoch 333/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.1510 - accuracy: 0.9621 - val_loss: 1.8609 - val_accuracy: 0.6168\n",
            "\n",
            "Epoch 00333: val_accuracy did not improve from 0.71028\n",
            "Epoch 334/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1011 - accuracy: 0.9688 - val_loss: 2.0535 - val_accuracy: 0.6168\n",
            "\n",
            "Epoch 00334: val_accuracy did not improve from 0.71028\n",
            "Epoch 335/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.1276 - accuracy: 0.9575 - val_loss: 2.3360 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00335: val_accuracy did not improve from 0.71028\n",
            "Epoch 336/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1338 - accuracy: 0.9448 - val_loss: 2.1768 - val_accuracy: 0.6168\n",
            "\n",
            "Epoch 00336: val_accuracy did not improve from 0.71028\n",
            "Epoch 337/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1283 - accuracy: 0.9666 - val_loss: 2.2639 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00337: val_accuracy did not improve from 0.71028\n",
            "Epoch 338/1000\n",
            "14/14 [==============================] - 1s 40ms/step - loss: 0.2040 - accuracy: 0.9371 - val_loss: 2.2420 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00338: val_accuracy did not improve from 0.71028\n",
            "Epoch 339/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.1282 - accuracy: 0.9640 - val_loss: 1.8979 - val_accuracy: 0.6168\n",
            "\n",
            "Epoch 00339: val_accuracy did not improve from 0.71028\n",
            "Epoch 340/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1260 - accuracy: 0.9737 - val_loss: 1.7186 - val_accuracy: 0.6168\n",
            "\n",
            "Epoch 00340: val_accuracy did not improve from 0.71028\n",
            "Epoch 341/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1300 - accuracy: 0.9586 - val_loss: 1.7720 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00341: val_accuracy did not improve from 0.71028\n",
            "Epoch 342/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1603 - accuracy: 0.9523 - val_loss: 1.8995 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00342: val_accuracy did not improve from 0.71028\n",
            "Epoch 343/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1719 - accuracy: 0.9379 - val_loss: 1.9870 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00343: val_accuracy did not improve from 0.71028\n",
            "Epoch 344/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.1157 - accuracy: 0.9626 - val_loss: 2.5982 - val_accuracy: 0.5514\n",
            "\n",
            "Epoch 00344: val_accuracy did not improve from 0.71028\n",
            "Epoch 345/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.1440 - accuracy: 0.9554 - val_loss: 1.9946 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00345: val_accuracy did not improve from 0.71028\n",
            "Epoch 346/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1171 - accuracy: 0.9657 - val_loss: 1.8540 - val_accuracy: 0.6168\n",
            "\n",
            "Epoch 00346: val_accuracy did not improve from 0.71028\n",
            "Epoch 347/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.1570 - accuracy: 0.9479 - val_loss: 2.5324 - val_accuracy: 0.5607\n",
            "\n",
            "Epoch 00347: val_accuracy did not improve from 0.71028\n",
            "Epoch 348/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1332 - accuracy: 0.9662 - val_loss: 2.1019 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00348: val_accuracy did not improve from 0.71028\n",
            "Epoch 349/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.1336 - accuracy: 0.9710 - val_loss: 2.2177 - val_accuracy: 0.6262\n",
            "\n",
            "Epoch 00349: val_accuracy did not improve from 0.71028\n",
            "Epoch 350/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.1250 - accuracy: 0.9690 - val_loss: 2.3156 - val_accuracy: 0.6168\n",
            "\n",
            "Epoch 00350: val_accuracy did not improve from 0.71028\n",
            "Epoch 351/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.1064 - accuracy: 0.9636 - val_loss: 2.1814 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00351: val_accuracy did not improve from 0.71028\n",
            "Epoch 352/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1241 - accuracy: 0.9492 - val_loss: 2.5061 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00352: val_accuracy did not improve from 0.71028\n",
            "Epoch 353/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1699 - accuracy: 0.9647 - val_loss: 1.9717 - val_accuracy: 0.6636\n",
            "\n",
            "Epoch 00353: val_accuracy did not improve from 0.71028\n",
            "Epoch 354/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0747 - accuracy: 0.9843 - val_loss: 1.9194 - val_accuracy: 0.6262\n",
            "\n",
            "Epoch 00354: val_accuracy did not improve from 0.71028\n",
            "Epoch 355/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0987 - accuracy: 0.9728 - val_loss: 2.1237 - val_accuracy: 0.6355\n",
            "\n",
            "Epoch 00355: val_accuracy did not improve from 0.71028\n",
            "Epoch 356/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1159 - accuracy: 0.9624 - val_loss: 2.1834 - val_accuracy: 0.6636\n",
            "\n",
            "Epoch 00356: val_accuracy did not improve from 0.71028\n",
            "Epoch 357/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.1277 - accuracy: 0.9546 - val_loss: 2.2321 - val_accuracy: 0.6355\n",
            "\n",
            "Epoch 00357: val_accuracy did not improve from 0.71028\n",
            "Epoch 358/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.2009 - accuracy: 0.9582 - val_loss: 2.5636 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00358: val_accuracy did not improve from 0.71028\n",
            "Epoch 359/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1335 - accuracy: 0.9695 - val_loss: 2.4806 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00359: val_accuracy did not improve from 0.71028\n",
            "Epoch 360/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.1186 - accuracy: 0.9638 - val_loss: 2.1726 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00360: val_accuracy did not improve from 0.71028\n",
            "Epoch 361/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.1089 - accuracy: 0.9706 - val_loss: 2.2884 - val_accuracy: 0.6168\n",
            "\n",
            "Epoch 00361: val_accuracy did not improve from 0.71028\n",
            "Epoch 362/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1250 - accuracy: 0.9687 - val_loss: 2.1695 - val_accuracy: 0.5701\n",
            "\n",
            "Epoch 00362: val_accuracy did not improve from 0.71028\n",
            "Epoch 363/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1232 - accuracy: 0.9688 - val_loss: 2.6174 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00363: val_accuracy did not improve from 0.71028\n",
            "Epoch 364/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1793 - accuracy: 0.9596 - val_loss: 2.3905 - val_accuracy: 0.5701\n",
            "\n",
            "Epoch 00364: val_accuracy did not improve from 0.71028\n",
            "Epoch 365/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.2634 - accuracy: 0.9390 - val_loss: 2.2112 - val_accuracy: 0.5514\n",
            "\n",
            "Epoch 00365: val_accuracy did not improve from 0.71028\n",
            "Epoch 366/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.2814 - accuracy: 0.9202 - val_loss: 2.7864 - val_accuracy: 0.5047\n",
            "\n",
            "Epoch 00366: val_accuracy did not improve from 0.71028\n",
            "Epoch 367/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.1341 - accuracy: 0.9562 - val_loss: 2.5243 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00367: val_accuracy did not improve from 0.71028\n",
            "Epoch 368/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1683 - accuracy: 0.9663 - val_loss: 2.1749 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00368: val_accuracy did not improve from 0.71028\n",
            "Epoch 369/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1348 - accuracy: 0.9509 - val_loss: 2.3203 - val_accuracy: 0.5607\n",
            "\n",
            "Epoch 00369: val_accuracy did not improve from 0.71028\n",
            "Epoch 370/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.1511 - accuracy: 0.9645 - val_loss: 2.3250 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00370: val_accuracy did not improve from 0.71028\n",
            "Epoch 371/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.2514 - accuracy: 0.9474 - val_loss: 2.2725 - val_accuracy: 0.6168\n",
            "\n",
            "Epoch 00371: val_accuracy did not improve from 0.71028\n",
            "Epoch 372/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.1144 - accuracy: 0.9575 - val_loss: 2.2803 - val_accuracy: 0.6355\n",
            "\n",
            "Epoch 00372: val_accuracy did not improve from 0.71028\n",
            "Epoch 373/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0807 - accuracy: 0.9805 - val_loss: 2.4605 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00373: val_accuracy did not improve from 0.71028\n",
            "Epoch 374/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0794 - accuracy: 0.9827 - val_loss: 2.4494 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00374: val_accuracy did not improve from 0.71028\n",
            "Epoch 375/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1100 - accuracy: 0.9722 - val_loss: 2.3589 - val_accuracy: 0.5514\n",
            "\n",
            "Epoch 00375: val_accuracy did not improve from 0.71028\n",
            "Epoch 376/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.1108 - accuracy: 0.9518 - val_loss: 2.3814 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00376: val_accuracy did not improve from 0.71028\n",
            "Epoch 377/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1044 - accuracy: 0.9741 - val_loss: 2.2957 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00377: val_accuracy did not improve from 0.71028\n",
            "Epoch 378/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1426 - accuracy: 0.9612 - val_loss: 2.6346 - val_accuracy: 0.5701\n",
            "\n",
            "Epoch 00378: val_accuracy did not improve from 0.71028\n",
            "Epoch 379/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1609 - accuracy: 0.9390 - val_loss: 2.0794 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00379: val_accuracy did not improve from 0.71028\n",
            "Epoch 380/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.3015 - accuracy: 0.9366 - val_loss: 2.3881 - val_accuracy: 0.5607\n",
            "\n",
            "Epoch 00380: val_accuracy did not improve from 0.71028\n",
            "Epoch 381/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1214 - accuracy: 0.9766 - val_loss: 2.5712 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00381: val_accuracy did not improve from 0.71028\n",
            "Epoch 382/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1099 - accuracy: 0.9742 - val_loss: 2.6264 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00382: val_accuracy did not improve from 0.71028\n",
            "Epoch 383/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1319 - accuracy: 0.9691 - val_loss: 2.5389 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00383: val_accuracy did not improve from 0.71028\n",
            "Epoch 384/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1543 - accuracy: 0.9585 - val_loss: 2.4425 - val_accuracy: 0.5234\n",
            "\n",
            "Epoch 00384: val_accuracy did not improve from 0.71028\n",
            "Epoch 385/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1340 - accuracy: 0.9656 - val_loss: 3.0822 - val_accuracy: 0.5047\n",
            "\n",
            "Epoch 00385: val_accuracy did not improve from 0.71028\n",
            "Epoch 386/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1963 - accuracy: 0.9607 - val_loss: 2.6649 - val_accuracy: 0.5421\n",
            "\n",
            "Epoch 00386: val_accuracy did not improve from 0.71028\n",
            "Epoch 387/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1529 - accuracy: 0.9647 - val_loss: 2.3394 - val_accuracy: 0.5421\n",
            "\n",
            "Epoch 00387: val_accuracy did not improve from 0.71028\n",
            "Epoch 388/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.1262 - accuracy: 0.9687 - val_loss: 2.3494 - val_accuracy: 0.5514\n",
            "\n",
            "Epoch 00388: val_accuracy did not improve from 0.71028\n",
            "Epoch 389/1000\n",
            "14/14 [==============================] - 1s 40ms/step - loss: 0.0810 - accuracy: 0.9753 - val_loss: 2.2997 - val_accuracy: 0.5701\n",
            "\n",
            "Epoch 00389: val_accuracy did not improve from 0.71028\n",
            "Epoch 390/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.1474 - accuracy: 0.9533 - val_loss: 2.3861 - val_accuracy: 0.5701\n",
            "\n",
            "Epoch 00390: val_accuracy did not improve from 0.71028\n",
            "Epoch 391/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0978 - accuracy: 0.9616 - val_loss: 2.1448 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00391: val_accuracy did not improve from 0.71028\n",
            "Epoch 392/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0897 - accuracy: 0.9802 - val_loss: 2.4929 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00392: val_accuracy did not improve from 0.71028\n",
            "Epoch 393/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.1504 - accuracy: 0.9634 - val_loss: 2.5819 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00393: val_accuracy did not improve from 0.71028\n",
            "Epoch 394/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1167 - accuracy: 0.9592 - val_loss: 2.2171 - val_accuracy: 0.5607\n",
            "\n",
            "Epoch 00394: val_accuracy did not improve from 0.71028\n",
            "Epoch 395/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.2115 - accuracy: 0.9692 - val_loss: 3.2529 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00395: val_accuracy did not improve from 0.71028\n",
            "Epoch 396/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1086 - accuracy: 0.9679 - val_loss: 3.3656 - val_accuracy: 0.5514\n",
            "\n",
            "Epoch 00396: val_accuracy did not improve from 0.71028\n",
            "Epoch 397/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.1242 - accuracy: 0.9644 - val_loss: 3.4192 - val_accuracy: 0.5327\n",
            "\n",
            "Epoch 00397: val_accuracy did not improve from 0.71028\n",
            "Epoch 398/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1100 - accuracy: 0.9573 - val_loss: 3.3225 - val_accuracy: 0.5701\n",
            "\n",
            "Epoch 00398: val_accuracy did not improve from 0.71028\n",
            "Epoch 399/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0951 - accuracy: 0.9794 - val_loss: 2.7329 - val_accuracy: 0.6355\n",
            "\n",
            "Epoch 00399: val_accuracy did not improve from 0.71028\n",
            "Epoch 400/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0804 - accuracy: 0.9752 - val_loss: 3.1294 - val_accuracy: 0.5327\n",
            "\n",
            "Epoch 00400: val_accuracy did not improve from 0.71028\n",
            "Epoch 401/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1199 - accuracy: 0.9801 - val_loss: 3.3244 - val_accuracy: 0.4766\n",
            "\n",
            "Epoch 00401: val_accuracy did not improve from 0.71028\n",
            "Epoch 402/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1202 - accuracy: 0.9726 - val_loss: 2.8681 - val_accuracy: 0.4766\n",
            "\n",
            "Epoch 00402: val_accuracy did not improve from 0.71028\n",
            "Epoch 403/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.2339 - accuracy: 0.9406 - val_loss: 2.6021 - val_accuracy: 0.5234\n",
            "\n",
            "Epoch 00403: val_accuracy did not improve from 0.71028\n",
            "Epoch 404/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.1437 - accuracy: 0.9607 - val_loss: 2.4323 - val_accuracy: 0.5607\n",
            "\n",
            "Epoch 00404: val_accuracy did not improve from 0.71028\n",
            "Epoch 405/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.1286 - accuracy: 0.9624 - val_loss: 2.4597 - val_accuracy: 0.5421\n",
            "\n",
            "Epoch 00405: val_accuracy did not improve from 0.71028\n",
            "Epoch 406/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1205 - accuracy: 0.9819 - val_loss: 2.4094 - val_accuracy: 0.5234\n",
            "\n",
            "Epoch 00406: val_accuracy did not improve from 0.71028\n",
            "Epoch 407/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.1995 - accuracy: 0.9456 - val_loss: 3.1029 - val_accuracy: 0.5607\n",
            "\n",
            "Epoch 00407: val_accuracy did not improve from 0.71028\n",
            "Epoch 408/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.1348 - accuracy: 0.9524 - val_loss: 2.6254 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00408: val_accuracy did not improve from 0.71028\n",
            "Epoch 409/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0917 - accuracy: 0.9763 - val_loss: 2.6143 - val_accuracy: 0.5607\n",
            "\n",
            "Epoch 00409: val_accuracy did not improve from 0.71028\n",
            "Epoch 410/1000\n",
            "14/14 [==============================] - 1s 40ms/step - loss: 0.1358 - accuracy: 0.9499 - val_loss: 2.7752 - val_accuracy: 0.5701\n",
            "\n",
            "Epoch 00410: val_accuracy did not improve from 0.71028\n",
            "Epoch 411/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.1151 - accuracy: 0.9589 - val_loss: 2.2888 - val_accuracy: 0.6262\n",
            "\n",
            "Epoch 00411: val_accuracy did not improve from 0.71028\n",
            "Epoch 412/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1386 - accuracy: 0.9554 - val_loss: 2.5680 - val_accuracy: 0.5327\n",
            "\n",
            "Epoch 00412: val_accuracy did not improve from 0.71028\n",
            "Epoch 413/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.1522 - accuracy: 0.9543 - val_loss: 2.2799 - val_accuracy: 0.5701\n",
            "\n",
            "Epoch 00413: val_accuracy did not improve from 0.71028\n",
            "Epoch 414/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.1059 - accuracy: 0.9676 - val_loss: 2.5928 - val_accuracy: 0.5421\n",
            "\n",
            "Epoch 00414: val_accuracy did not improve from 0.71028\n",
            "Epoch 415/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1802 - accuracy: 0.9662 - val_loss: 2.4394 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00415: val_accuracy did not improve from 0.71028\n",
            "Epoch 416/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1376 - accuracy: 0.9555 - val_loss: 2.2830 - val_accuracy: 0.5701\n",
            "\n",
            "Epoch 00416: val_accuracy did not improve from 0.71028\n",
            "Epoch 417/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1847 - accuracy: 0.9582 - val_loss: 2.4776 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00417: val_accuracy did not improve from 0.71028\n",
            "Epoch 418/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1170 - accuracy: 0.9711 - val_loss: 2.6046 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00418: val_accuracy did not improve from 0.71028\n",
            "Epoch 419/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1023 - accuracy: 0.9851 - val_loss: 1.7880 - val_accuracy: 0.6355\n",
            "\n",
            "Epoch 00419: val_accuracy did not improve from 0.71028\n",
            "Epoch 420/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0885 - accuracy: 0.9815 - val_loss: 1.7157 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00420: val_accuracy did not improve from 0.71028\n",
            "Epoch 421/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1256 - accuracy: 0.9634 - val_loss: 1.5876 - val_accuracy: 0.6262\n",
            "\n",
            "Epoch 00421: val_accuracy did not improve from 0.71028\n",
            "Epoch 422/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.1081 - accuracy: 0.9692 - val_loss: 1.8658 - val_accuracy: 0.6355\n",
            "\n",
            "Epoch 00422: val_accuracy did not improve from 0.71028\n",
            "Epoch 423/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1038 - accuracy: 0.9669 - val_loss: 1.8886 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00423: val_accuracy did not improve from 0.71028\n",
            "Epoch 424/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1113 - accuracy: 0.9734 - val_loss: 1.8392 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00424: val_accuracy did not improve from 0.71028\n",
            "Epoch 425/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.1307 - accuracy: 0.9676 - val_loss: 2.0854 - val_accuracy: 0.5607\n",
            "\n",
            "Epoch 00425: val_accuracy did not improve from 0.71028\n",
            "Epoch 426/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0761 - accuracy: 0.9683 - val_loss: 2.1561 - val_accuracy: 0.5514\n",
            "\n",
            "Epoch 00426: val_accuracy did not improve from 0.71028\n",
            "Epoch 427/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1554 - accuracy: 0.9495 - val_loss: 2.2083 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00427: val_accuracy did not improve from 0.71028\n",
            "Epoch 428/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0999 - accuracy: 0.9661 - val_loss: 2.1945 - val_accuracy: 0.6168\n",
            "\n",
            "Epoch 00428: val_accuracy did not improve from 0.71028\n",
            "Epoch 429/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0578 - accuracy: 0.9871 - val_loss: 2.4242 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00429: val_accuracy did not improve from 0.71028\n",
            "Epoch 430/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0880 - accuracy: 0.9707 - val_loss: 2.3153 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00430: val_accuracy did not improve from 0.71028\n",
            "Epoch 431/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.1267 - accuracy: 0.9805 - val_loss: 2.2929 - val_accuracy: 0.5701\n",
            "\n",
            "Epoch 00431: val_accuracy did not improve from 0.71028\n",
            "Epoch 432/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1853 - accuracy: 0.9664 - val_loss: 2.5828 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00432: val_accuracy did not improve from 0.71028\n",
            "Epoch 433/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1196 - accuracy: 0.9676 - val_loss: 2.2178 - val_accuracy: 0.6262\n",
            "\n",
            "Epoch 00433: val_accuracy did not improve from 0.71028\n",
            "Epoch 434/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0765 - accuracy: 0.9804 - val_loss: 1.9990 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00434: val_accuracy did not improve from 0.71028\n",
            "Epoch 435/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0575 - accuracy: 0.9861 - val_loss: 2.0575 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00435: val_accuracy did not improve from 0.71028\n",
            "Epoch 436/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.1374 - accuracy: 0.9550 - val_loss: 2.4029 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00436: val_accuracy did not improve from 0.71028\n",
            "Epoch 437/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0684 - accuracy: 0.9819 - val_loss: 2.6021 - val_accuracy: 0.6262\n",
            "\n",
            "Epoch 00437: val_accuracy did not improve from 0.71028\n",
            "Epoch 438/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1016 - accuracy: 0.9761 - val_loss: 2.6274 - val_accuracy: 0.6168\n",
            "\n",
            "Epoch 00438: val_accuracy did not improve from 0.71028\n",
            "Epoch 439/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0608 - accuracy: 0.9805 - val_loss: 3.0891 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00439: val_accuracy did not improve from 0.71028\n",
            "Epoch 440/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1940 - accuracy: 0.9586 - val_loss: 2.8880 - val_accuracy: 0.5701\n",
            "\n",
            "Epoch 00440: val_accuracy did not improve from 0.71028\n",
            "Epoch 441/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0739 - accuracy: 0.9821 - val_loss: 2.8582 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00441: val_accuracy did not improve from 0.71028\n",
            "Epoch 442/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0805 - accuracy: 0.9818 - val_loss: 2.6721 - val_accuracy: 0.6262\n",
            "\n",
            "Epoch 00442: val_accuracy did not improve from 0.71028\n",
            "Epoch 443/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0691 - accuracy: 0.9841 - val_loss: 2.5637 - val_accuracy: 0.5421\n",
            "\n",
            "Epoch 00443: val_accuracy did not improve from 0.71028\n",
            "Epoch 444/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1221 - accuracy: 0.9829 - val_loss: 2.7036 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00444: val_accuracy did not improve from 0.71028\n",
            "Epoch 445/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0770 - accuracy: 0.9806 - val_loss: 2.5544 - val_accuracy: 0.5701\n",
            "\n",
            "Epoch 00445: val_accuracy did not improve from 0.71028\n",
            "Epoch 446/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0949 - accuracy: 0.9712 - val_loss: 2.5679 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00446: val_accuracy did not improve from 0.71028\n",
            "Epoch 447/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0764 - accuracy: 0.9802 - val_loss: 2.8158 - val_accuracy: 0.5701\n",
            "\n",
            "Epoch 00447: val_accuracy did not improve from 0.71028\n",
            "Epoch 448/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1298 - accuracy: 0.9665 - val_loss: 3.3339 - val_accuracy: 0.5234\n",
            "\n",
            "Epoch 00448: val_accuracy did not improve from 0.71028\n",
            "Epoch 449/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0888 - accuracy: 0.9760 - val_loss: 2.6698 - val_accuracy: 0.5701\n",
            "\n",
            "Epoch 00449: val_accuracy did not improve from 0.71028\n",
            "Epoch 450/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0851 - accuracy: 0.9832 - val_loss: 2.9061 - val_accuracy: 0.5421\n",
            "\n",
            "Epoch 00450: val_accuracy did not improve from 0.71028\n",
            "Epoch 451/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1770 - accuracy: 0.9622 - val_loss: 2.5382 - val_accuracy: 0.5514\n",
            "\n",
            "Epoch 00451: val_accuracy did not improve from 0.71028\n",
            "Epoch 452/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1665 - accuracy: 0.9480 - val_loss: 2.5325 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00452: val_accuracy did not improve from 0.71028\n",
            "Epoch 453/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0679 - accuracy: 0.9764 - val_loss: 2.6137 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00453: val_accuracy did not improve from 0.71028\n",
            "Epoch 454/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0720 - accuracy: 0.9813 - val_loss: 2.6059 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00454: val_accuracy did not improve from 0.71028\n",
            "Epoch 455/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0610 - accuracy: 0.9838 - val_loss: 2.8199 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00455: val_accuracy did not improve from 0.71028\n",
            "Epoch 456/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0681 - accuracy: 0.9870 - val_loss: 2.8947 - val_accuracy: 0.6168\n",
            "\n",
            "Epoch 00456: val_accuracy did not improve from 0.71028\n",
            "Epoch 457/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1053 - accuracy: 0.9818 - val_loss: 3.2492 - val_accuracy: 0.5607\n",
            "\n",
            "Epoch 00457: val_accuracy did not improve from 0.71028\n",
            "Epoch 458/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.1559 - accuracy: 0.9690 - val_loss: 2.6889 - val_accuracy: 0.5607\n",
            "\n",
            "Epoch 00458: val_accuracy did not improve from 0.71028\n",
            "Epoch 459/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0603 - accuracy: 0.9830 - val_loss: 2.5248 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00459: val_accuracy did not improve from 0.71028\n",
            "Epoch 460/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.1120 - accuracy: 0.9625 - val_loss: 2.9149 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00460: val_accuracy did not improve from 0.71028\n",
            "Epoch 461/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0489 - accuracy: 0.9854 - val_loss: 3.0243 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00461: val_accuracy did not improve from 0.71028\n",
            "Epoch 462/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0563 - accuracy: 0.9752 - val_loss: 2.8111 - val_accuracy: 0.5701\n",
            "\n",
            "Epoch 00462: val_accuracy did not improve from 0.71028\n",
            "Epoch 463/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1179 - accuracy: 0.9683 - val_loss: 2.7666 - val_accuracy: 0.5701\n",
            "\n",
            "Epoch 00463: val_accuracy did not improve from 0.71028\n",
            "Epoch 464/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0772 - accuracy: 0.9810 - val_loss: 2.4163 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00464: val_accuracy did not improve from 0.71028\n",
            "Epoch 465/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1358 - accuracy: 0.9645 - val_loss: 2.8757 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00465: val_accuracy did not improve from 0.71028\n",
            "Epoch 466/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1286 - accuracy: 0.9707 - val_loss: 2.4851 - val_accuracy: 0.5327\n",
            "\n",
            "Epoch 00466: val_accuracy did not improve from 0.71028\n",
            "Epoch 467/1000\n",
            "14/14 [==============================] - 1s 41ms/step - loss: 0.0669 - accuracy: 0.9887 - val_loss: 2.1341 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00467: val_accuracy did not improve from 0.71028\n",
            "Epoch 468/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0845 - accuracy: 0.9726 - val_loss: 2.1428 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00468: val_accuracy did not improve from 0.71028\n",
            "Epoch 469/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0929 - accuracy: 0.9761 - val_loss: 2.3718 - val_accuracy: 0.6168\n",
            "\n",
            "Epoch 00469: val_accuracy did not improve from 0.71028\n",
            "Epoch 470/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0657 - accuracy: 0.9808 - val_loss: 3.0136 - val_accuracy: 0.6168\n",
            "\n",
            "Epoch 00470: val_accuracy did not improve from 0.71028\n",
            "Epoch 471/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0701 - accuracy: 0.9816 - val_loss: 2.4790 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00471: val_accuracy did not improve from 0.71028\n",
            "Epoch 472/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0672 - accuracy: 0.9816 - val_loss: 2.3356 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00472: val_accuracy did not improve from 0.71028\n",
            "Epoch 473/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1732 - accuracy: 0.9627 - val_loss: 2.4534 - val_accuracy: 0.5701\n",
            "\n",
            "Epoch 00473: val_accuracy did not improve from 0.71028\n",
            "Epoch 474/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0568 - accuracy: 0.9863 - val_loss: 2.5356 - val_accuracy: 0.6262\n",
            "\n",
            "Epoch 00474: val_accuracy did not improve from 0.71028\n",
            "Epoch 475/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.1001 - accuracy: 0.9718 - val_loss: 2.6945 - val_accuracy: 0.5607\n",
            "\n",
            "Epoch 00475: val_accuracy did not improve from 0.71028\n",
            "Epoch 476/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1368 - accuracy: 0.9676 - val_loss: 3.4996 - val_accuracy: 0.5514\n",
            "\n",
            "Epoch 00476: val_accuracy did not improve from 0.71028\n",
            "Epoch 477/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.2113 - accuracy: 0.9568 - val_loss: 3.2738 - val_accuracy: 0.5140\n",
            "\n",
            "Epoch 00477: val_accuracy did not improve from 0.71028\n",
            "Epoch 478/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1120 - accuracy: 0.9742 - val_loss: 2.9703 - val_accuracy: 0.5701\n",
            "\n",
            "Epoch 00478: val_accuracy did not improve from 0.71028\n",
            "Epoch 479/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1750 - accuracy: 0.9457 - val_loss: 2.7052 - val_accuracy: 0.5701\n",
            "\n",
            "Epoch 00479: val_accuracy did not improve from 0.71028\n",
            "Epoch 480/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0994 - accuracy: 0.9767 - val_loss: 2.6408 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00480: val_accuracy did not improve from 0.71028\n",
            "Epoch 481/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0648 - accuracy: 0.9848 - val_loss: 2.7008 - val_accuracy: 0.5701\n",
            "\n",
            "Epoch 00481: val_accuracy did not improve from 0.71028\n",
            "Epoch 482/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0700 - accuracy: 0.9823 - val_loss: 3.2977 - val_accuracy: 0.4766\n",
            "\n",
            "Epoch 00482: val_accuracy did not improve from 0.71028\n",
            "Epoch 483/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.1501 - accuracy: 0.9760 - val_loss: 2.4350 - val_accuracy: 0.5514\n",
            "\n",
            "Epoch 00483: val_accuracy did not improve from 0.71028\n",
            "Epoch 484/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1116 - accuracy: 0.9738 - val_loss: 2.4660 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00484: val_accuracy did not improve from 0.71028\n",
            "Epoch 485/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0644 - accuracy: 0.9842 - val_loss: 2.4665 - val_accuracy: 0.5701\n",
            "\n",
            "Epoch 00485: val_accuracy did not improve from 0.71028\n",
            "Epoch 486/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0749 - accuracy: 0.9853 - val_loss: 2.7963 - val_accuracy: 0.5514\n",
            "\n",
            "Epoch 00486: val_accuracy did not improve from 0.71028\n",
            "Epoch 487/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1606 - accuracy: 0.9601 - val_loss: 2.6404 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00487: val_accuracy did not improve from 0.71028\n",
            "Epoch 488/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1340 - accuracy: 0.9640 - val_loss: 2.8086 - val_accuracy: 0.6168\n",
            "\n",
            "Epoch 00488: val_accuracy did not improve from 0.71028\n",
            "Epoch 489/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1319 - accuracy: 0.9377 - val_loss: 2.5868 - val_accuracy: 0.6262\n",
            "\n",
            "Epoch 00489: val_accuracy did not improve from 0.71028\n",
            "Epoch 490/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.1503 - accuracy: 0.9665 - val_loss: 2.7035 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00490: val_accuracy did not improve from 0.71028\n",
            "Epoch 491/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.1290 - accuracy: 0.9734 - val_loss: 2.5051 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00491: val_accuracy did not improve from 0.71028\n",
            "Epoch 492/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0598 - accuracy: 0.9904 - val_loss: 2.3958 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00492: val_accuracy did not improve from 0.71028\n",
            "Epoch 493/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1305 - accuracy: 0.9704 - val_loss: 2.6766 - val_accuracy: 0.5047\n",
            "\n",
            "Epoch 00493: val_accuracy did not improve from 0.71028\n",
            "Epoch 494/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0939 - accuracy: 0.9874 - val_loss: 2.5581 - val_accuracy: 0.5514\n",
            "\n",
            "Epoch 00494: val_accuracy did not improve from 0.71028\n",
            "Epoch 495/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1163 - accuracy: 0.9742 - val_loss: 2.2784 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00495: val_accuracy did not improve from 0.71028\n",
            "Epoch 496/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0535 - accuracy: 0.9826 - val_loss: 2.4850 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00496: val_accuracy did not improve from 0.71028\n",
            "Epoch 497/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0517 - accuracy: 0.9877 - val_loss: 2.2782 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00497: val_accuracy did not improve from 0.71028\n",
            "Epoch 498/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1262 - accuracy: 0.9591 - val_loss: 2.1399 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00498: val_accuracy did not improve from 0.71028\n",
            "Epoch 499/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0976 - accuracy: 0.9869 - val_loss: 2.2737 - val_accuracy: 0.6449\n",
            "\n",
            "Epoch 00499: val_accuracy did not improve from 0.71028\n",
            "Epoch 500/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0947 - accuracy: 0.9740 - val_loss: 2.2693 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00500: val_accuracy did not improve from 0.71028\n",
            "Epoch 501/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0676 - accuracy: 0.9883 - val_loss: 2.7672 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00501: val_accuracy did not improve from 0.71028\n",
            "Epoch 502/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1568 - accuracy: 0.9506 - val_loss: 4.3713 - val_accuracy: 0.5421\n",
            "\n",
            "Epoch 00502: val_accuracy did not improve from 0.71028\n",
            "Epoch 503/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1416 - accuracy: 0.9627 - val_loss: 2.6306 - val_accuracy: 0.5701\n",
            "\n",
            "Epoch 00503: val_accuracy did not improve from 0.71028\n",
            "Epoch 504/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1140 - accuracy: 0.9608 - val_loss: 2.8457 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00504: val_accuracy did not improve from 0.71028\n",
            "Epoch 505/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.1039 - accuracy: 0.9785 - val_loss: 2.7011 - val_accuracy: 0.6168\n",
            "\n",
            "Epoch 00505: val_accuracy did not improve from 0.71028\n",
            "Epoch 506/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0899 - accuracy: 0.9763 - val_loss: 2.4716 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00506: val_accuracy did not improve from 0.71028\n",
            "Epoch 507/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1305 - accuracy: 0.9740 - val_loss: 2.5114 - val_accuracy: 0.6262\n",
            "\n",
            "Epoch 00507: val_accuracy did not improve from 0.71028\n",
            "Epoch 508/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0769 - accuracy: 0.9727 - val_loss: 2.5831 - val_accuracy: 0.5607\n",
            "\n",
            "Epoch 00508: val_accuracy did not improve from 0.71028\n",
            "Epoch 509/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.1237 - accuracy: 0.9696 - val_loss: 2.5347 - val_accuracy: 0.5701\n",
            "\n",
            "Epoch 00509: val_accuracy did not improve from 0.71028\n",
            "Epoch 510/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.1046 - accuracy: 0.9692 - val_loss: 2.4560 - val_accuracy: 0.6449\n",
            "\n",
            "Epoch 00510: val_accuracy did not improve from 0.71028\n",
            "Epoch 511/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.1067 - accuracy: 0.9772 - val_loss: 2.5915 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00511: val_accuracy did not improve from 0.71028\n",
            "Epoch 512/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1084 - accuracy: 0.9698 - val_loss: 2.6540 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00512: val_accuracy did not improve from 0.71028\n",
            "Epoch 513/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0936 - accuracy: 0.9813 - val_loss: 3.2637 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00513: val_accuracy did not improve from 0.71028\n",
            "Epoch 514/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1737 - accuracy: 0.9630 - val_loss: 2.9405 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00514: val_accuracy did not improve from 0.71028\n",
            "Epoch 515/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1179 - accuracy: 0.9853 - val_loss: 3.0152 - val_accuracy: 0.5421\n",
            "\n",
            "Epoch 00515: val_accuracy did not improve from 0.71028\n",
            "Epoch 516/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0862 - accuracy: 0.9851 - val_loss: 3.3299 - val_accuracy: 0.5514\n",
            "\n",
            "Epoch 00516: val_accuracy did not improve from 0.71028\n",
            "Epoch 517/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.2253 - accuracy: 0.9424 - val_loss: 2.4802 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00517: val_accuracy did not improve from 0.71028\n",
            "Epoch 518/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1363 - accuracy: 0.9659 - val_loss: 2.2097 - val_accuracy: 0.6355\n",
            "\n",
            "Epoch 00518: val_accuracy did not improve from 0.71028\n",
            "Epoch 519/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.1014 - accuracy: 0.9820 - val_loss: 2.2527 - val_accuracy: 0.6542\n",
            "\n",
            "Epoch 00519: val_accuracy did not improve from 0.71028\n",
            "Epoch 520/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.0821 - accuracy: 0.9824 - val_loss: 2.7800 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00520: val_accuracy did not improve from 0.71028\n",
            "Epoch 521/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.1990 - accuracy: 0.9526 - val_loss: 2.8495 - val_accuracy: 0.6262\n",
            "\n",
            "Epoch 00521: val_accuracy did not improve from 0.71028\n",
            "Epoch 522/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0822 - accuracy: 0.9802 - val_loss: 3.1590 - val_accuracy: 0.6262\n",
            "\n",
            "Epoch 00522: val_accuracy did not improve from 0.71028\n",
            "Epoch 523/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1174 - accuracy: 0.9715 - val_loss: 2.9063 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00523: val_accuracy did not improve from 0.71028\n",
            "Epoch 524/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.1220 - accuracy: 0.9656 - val_loss: 2.8404 - val_accuracy: 0.6355\n",
            "\n",
            "Epoch 00524: val_accuracy did not improve from 0.71028\n",
            "Epoch 525/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.0602 - accuracy: 0.9903 - val_loss: 2.5089 - val_accuracy: 0.6262\n",
            "\n",
            "Epoch 00525: val_accuracy did not improve from 0.71028\n",
            "Epoch 526/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0900 - accuracy: 0.9819 - val_loss: 2.9944 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00526: val_accuracy did not improve from 0.71028\n",
            "Epoch 527/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1609 - accuracy: 0.9618 - val_loss: 2.9925 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00527: val_accuracy did not improve from 0.71028\n",
            "Epoch 528/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1296 - accuracy: 0.9655 - val_loss: 3.3072 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00528: val_accuracy did not improve from 0.71028\n",
            "Epoch 529/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1237 - accuracy: 0.9736 - val_loss: 3.0581 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00529: val_accuracy did not improve from 0.71028\n",
            "Epoch 530/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.1203 - accuracy: 0.9884 - val_loss: 3.0406 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00530: val_accuracy did not improve from 0.71028\n",
            "Epoch 531/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.1319 - accuracy: 0.9730 - val_loss: 3.2071 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00531: val_accuracy did not improve from 0.71028\n",
            "Epoch 532/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0672 - accuracy: 0.9837 - val_loss: 3.5255 - val_accuracy: 0.5421\n",
            "\n",
            "Epoch 00532: val_accuracy did not improve from 0.71028\n",
            "Epoch 533/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0900 - accuracy: 0.9777 - val_loss: 2.7396 - val_accuracy: 0.5701\n",
            "\n",
            "Epoch 00533: val_accuracy did not improve from 0.71028\n",
            "Epoch 534/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0600 - accuracy: 0.9899 - val_loss: 2.5352 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00534: val_accuracy did not improve from 0.71028\n",
            "Epoch 535/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.0899 - accuracy: 0.9764 - val_loss: 2.3839 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00535: val_accuracy did not improve from 0.71028\n",
            "Epoch 536/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.1087 - accuracy: 0.9654 - val_loss: 3.2285 - val_accuracy: 0.5607\n",
            "\n",
            "Epoch 00536: val_accuracy did not improve from 0.71028\n",
            "Epoch 537/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0463 - accuracy: 0.9885 - val_loss: 3.5268 - val_accuracy: 0.5421\n",
            "\n",
            "Epoch 00537: val_accuracy did not improve from 0.71028\n",
            "Epoch 538/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0569 - accuracy: 0.9869 - val_loss: 2.6327 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00538: val_accuracy did not improve from 0.71028\n",
            "Epoch 539/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.1057 - accuracy: 0.9756 - val_loss: 3.0458 - val_accuracy: 0.5327\n",
            "\n",
            "Epoch 00539: val_accuracy did not improve from 0.71028\n",
            "Epoch 540/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1936 - accuracy: 0.9607 - val_loss: 2.9481 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00540: val_accuracy did not improve from 0.71028\n",
            "Epoch 541/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.2687 - accuracy: 0.9574 - val_loss: 2.3657 - val_accuracy: 0.5607\n",
            "\n",
            "Epoch 00541: val_accuracy did not improve from 0.71028\n",
            "Epoch 542/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1562 - accuracy: 0.9690 - val_loss: 2.5686 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00542: val_accuracy did not improve from 0.71028\n",
            "Epoch 543/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1012 - accuracy: 0.9760 - val_loss: 3.2955 - val_accuracy: 0.6449\n",
            "\n",
            "Epoch 00543: val_accuracy did not improve from 0.71028\n",
            "Epoch 544/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.1287 - accuracy: 0.9760 - val_loss: 2.6722 - val_accuracy: 0.6355\n",
            "\n",
            "Epoch 00544: val_accuracy did not improve from 0.71028\n",
            "Epoch 545/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0941 - accuracy: 0.9910 - val_loss: 2.7194 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00545: val_accuracy did not improve from 0.71028\n",
            "Epoch 546/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1543 - accuracy: 0.9595 - val_loss: 3.0867 - val_accuracy: 0.5701\n",
            "\n",
            "Epoch 00546: val_accuracy did not improve from 0.71028\n",
            "Epoch 547/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1229 - accuracy: 0.9601 - val_loss: 2.8912 - val_accuracy: 0.5607\n",
            "\n",
            "Epoch 00547: val_accuracy did not improve from 0.71028\n",
            "Epoch 548/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0772 - accuracy: 0.9848 - val_loss: 2.6049 - val_accuracy: 0.5607\n",
            "\n",
            "Epoch 00548: val_accuracy did not improve from 0.71028\n",
            "Epoch 549/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.1223 - accuracy: 0.9744 - val_loss: 2.8501 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00549: val_accuracy did not improve from 0.71028\n",
            "Epoch 550/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1474 - accuracy: 0.9774 - val_loss: 3.8952 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00550: val_accuracy did not improve from 0.71028\n",
            "Epoch 551/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0963 - accuracy: 0.9831 - val_loss: 2.5002 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00551: val_accuracy did not improve from 0.71028\n",
            "Epoch 552/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1196 - accuracy: 0.9830 - val_loss: 1.9752 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00552: val_accuracy did not improve from 0.71028\n",
            "Epoch 553/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0829 - accuracy: 0.9898 - val_loss: 2.3712 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00553: val_accuracy did not improve from 0.71028\n",
            "Epoch 554/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.1492 - accuracy: 0.9571 - val_loss: 2.3050 - val_accuracy: 0.6262\n",
            "\n",
            "Epoch 00554: val_accuracy did not improve from 0.71028\n",
            "Epoch 555/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0643 - accuracy: 0.9849 - val_loss: 2.4149 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00555: val_accuracy did not improve from 0.71028\n",
            "Epoch 556/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0916 - accuracy: 0.9738 - val_loss: 2.6791 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00556: val_accuracy did not improve from 0.71028\n",
            "Epoch 557/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0893 - accuracy: 0.9896 - val_loss: 3.0510 - val_accuracy: 0.5514\n",
            "\n",
            "Epoch 00557: val_accuracy did not improve from 0.71028\n",
            "Epoch 558/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1044 - accuracy: 0.9838 - val_loss: 2.9400 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00558: val_accuracy did not improve from 0.71028\n",
            "Epoch 559/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0690 - accuracy: 0.9749 - val_loss: 2.8098 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00559: val_accuracy did not improve from 0.71028\n",
            "Epoch 560/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0659 - accuracy: 0.9789 - val_loss: 2.6659 - val_accuracy: 0.6168\n",
            "\n",
            "Epoch 00560: val_accuracy did not improve from 0.71028\n",
            "Epoch 561/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0555 - accuracy: 0.9828 - val_loss: 2.3512 - val_accuracy: 0.6262\n",
            "\n",
            "Epoch 00561: val_accuracy did not improve from 0.71028\n",
            "Epoch 562/1000\n",
            "14/14 [==============================] - 1s 40ms/step - loss: 0.0581 - accuracy: 0.9845 - val_loss: 2.6441 - val_accuracy: 0.6168\n",
            "\n",
            "Epoch 00562: val_accuracy did not improve from 0.71028\n",
            "Epoch 563/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0964 - accuracy: 0.9732 - val_loss: 2.1284 - val_accuracy: 0.6355\n",
            "\n",
            "Epoch 00563: val_accuracy did not improve from 0.71028\n",
            "Epoch 564/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0719 - accuracy: 0.9844 - val_loss: 2.4376 - val_accuracy: 0.6542\n",
            "\n",
            "Epoch 00564: val_accuracy did not improve from 0.71028\n",
            "Epoch 565/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.0759 - accuracy: 0.9842 - val_loss: 2.2753 - val_accuracy: 0.6262\n",
            "\n",
            "Epoch 00565: val_accuracy did not improve from 0.71028\n",
            "Epoch 566/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0664 - accuracy: 0.9866 - val_loss: 2.2617 - val_accuracy: 0.6355\n",
            "\n",
            "Epoch 00566: val_accuracy did not improve from 0.71028\n",
            "Epoch 567/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0416 - accuracy: 0.9896 - val_loss: 2.0073 - val_accuracy: 0.6449\n",
            "\n",
            "Epoch 00567: val_accuracy did not improve from 0.71028\n",
            "Epoch 568/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0536 - accuracy: 0.9836 - val_loss: 2.0501 - val_accuracy: 0.6449\n",
            "\n",
            "Epoch 00568: val_accuracy did not improve from 0.71028\n",
            "Epoch 569/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0621 - accuracy: 0.9942 - val_loss: 2.3404 - val_accuracy: 0.6262\n",
            "\n",
            "Epoch 00569: val_accuracy did not improve from 0.71028\n",
            "Epoch 570/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0846 - accuracy: 0.9850 - val_loss: 2.6321 - val_accuracy: 0.6262\n",
            "\n",
            "Epoch 00570: val_accuracy did not improve from 0.71028\n",
            "Epoch 571/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0424 - accuracy: 0.9964 - val_loss: 2.3918 - val_accuracy: 0.6262\n",
            "\n",
            "Epoch 00571: val_accuracy did not improve from 0.71028\n",
            "Epoch 572/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0478 - accuracy: 0.9869 - val_loss: 2.1038 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00572: val_accuracy did not improve from 0.71028\n",
            "Epoch 573/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0470 - accuracy: 0.9885 - val_loss: 2.1447 - val_accuracy: 0.6355\n",
            "\n",
            "Epoch 00573: val_accuracy did not improve from 0.71028\n",
            "Epoch 574/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0518 - accuracy: 0.9945 - val_loss: 2.3264 - val_accuracy: 0.6542\n",
            "\n",
            "Epoch 00574: val_accuracy did not improve from 0.71028\n",
            "Epoch 575/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0779 - accuracy: 0.9875 - val_loss: 2.6028 - val_accuracy: 0.6168\n",
            "\n",
            "Epoch 00575: val_accuracy did not improve from 0.71028\n",
            "Epoch 576/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0533 - accuracy: 0.9844 - val_loss: 2.9163 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00576: val_accuracy did not improve from 0.71028\n",
            "Epoch 577/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.1088 - accuracy: 0.9796 - val_loss: 3.4085 - val_accuracy: 0.4953\n",
            "\n",
            "Epoch 00577: val_accuracy did not improve from 0.71028\n",
            "Epoch 578/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.1140 - accuracy: 0.9697 - val_loss: 2.3690 - val_accuracy: 0.6449\n",
            "\n",
            "Epoch 00578: val_accuracy did not improve from 0.71028\n",
            "Epoch 579/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1153 - accuracy: 0.9805 - val_loss: 2.2772 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00579: val_accuracy did not improve from 0.71028\n",
            "Epoch 580/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.2196 - accuracy: 0.9583 - val_loss: 2.3309 - val_accuracy: 0.6262\n",
            "\n",
            "Epoch 00580: val_accuracy did not improve from 0.71028\n",
            "Epoch 581/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0542 - accuracy: 0.9914 - val_loss: 2.4587 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00581: val_accuracy did not improve from 0.71028\n",
            "Epoch 582/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0673 - accuracy: 0.9886 - val_loss: 2.7440 - val_accuracy: 0.5701\n",
            "\n",
            "Epoch 00582: val_accuracy did not improve from 0.71028\n",
            "Epoch 583/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0544 - accuracy: 0.9919 - val_loss: 2.6930 - val_accuracy: 0.5607\n",
            "\n",
            "Epoch 00583: val_accuracy did not improve from 0.71028\n",
            "Epoch 584/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0643 - accuracy: 0.9871 - val_loss: 2.8169 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00584: val_accuracy did not improve from 0.71028\n",
            "Epoch 585/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0489 - accuracy: 0.9853 - val_loss: 2.7102 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00585: val_accuracy did not improve from 0.71028\n",
            "Epoch 586/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0602 - accuracy: 0.9932 - val_loss: 2.4518 - val_accuracy: 0.5607\n",
            "\n",
            "Epoch 00586: val_accuracy did not improve from 0.71028\n",
            "Epoch 587/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0564 - accuracy: 0.9837 - val_loss: 2.2819 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00587: val_accuracy did not improve from 0.71028\n",
            "Epoch 588/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.1162 - accuracy: 0.9855 - val_loss: 2.1039 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00588: val_accuracy did not improve from 0.71028\n",
            "Epoch 589/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0553 - accuracy: 0.9885 - val_loss: 2.2708 - val_accuracy: 0.6262\n",
            "\n",
            "Epoch 00589: val_accuracy did not improve from 0.71028\n",
            "Epoch 590/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0775 - accuracy: 0.9848 - val_loss: 2.5295 - val_accuracy: 0.5234\n",
            "\n",
            "Epoch 00590: val_accuracy did not improve from 0.71028\n",
            "Epoch 591/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0725 - accuracy: 0.9786 - val_loss: 2.6715 - val_accuracy: 0.5514\n",
            "\n",
            "Epoch 00591: val_accuracy did not improve from 0.71028\n",
            "Epoch 592/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0538 - accuracy: 0.9873 - val_loss: 3.0400 - val_accuracy: 0.5607\n",
            "\n",
            "Epoch 00592: val_accuracy did not improve from 0.71028\n",
            "Epoch 593/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0744 - accuracy: 0.9768 - val_loss: 2.7128 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00593: val_accuracy did not improve from 0.71028\n",
            "Epoch 594/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0793 - accuracy: 0.9827 - val_loss: 2.4512 - val_accuracy: 0.6168\n",
            "\n",
            "Epoch 00594: val_accuracy did not improve from 0.71028\n",
            "Epoch 595/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0565 - accuracy: 0.9845 - val_loss: 2.5236 - val_accuracy: 0.5607\n",
            "\n",
            "Epoch 00595: val_accuracy did not improve from 0.71028\n",
            "Epoch 596/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0390 - accuracy: 0.9952 - val_loss: 2.5055 - val_accuracy: 0.5701\n",
            "\n",
            "Epoch 00596: val_accuracy did not improve from 0.71028\n",
            "Epoch 597/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0382 - accuracy: 0.9920 - val_loss: 2.6232 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00597: val_accuracy did not improve from 0.71028\n",
            "Epoch 598/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1119 - accuracy: 0.9810 - val_loss: 2.4438 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00598: val_accuracy did not improve from 0.71028\n",
            "Epoch 599/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0699 - accuracy: 0.9816 - val_loss: 2.3714 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00599: val_accuracy did not improve from 0.71028\n",
            "Epoch 600/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0531 - accuracy: 0.9947 - val_loss: 2.2991 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00600: val_accuracy did not improve from 0.71028\n",
            "Epoch 601/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0788 - accuracy: 0.9823 - val_loss: 2.4032 - val_accuracy: 0.6168\n",
            "\n",
            "Epoch 00601: val_accuracy did not improve from 0.71028\n",
            "Epoch 602/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0838 - accuracy: 0.9765 - val_loss: 2.3229 - val_accuracy: 0.5607\n",
            "\n",
            "Epoch 00602: val_accuracy did not improve from 0.71028\n",
            "Epoch 603/1000\n",
            "14/14 [==============================] - 1s 40ms/step - loss: 0.0707 - accuracy: 0.9890 - val_loss: 2.6394 - val_accuracy: 0.5514\n",
            "\n",
            "Epoch 00603: val_accuracy did not improve from 0.71028\n",
            "Epoch 604/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0872 - accuracy: 0.9757 - val_loss: 2.7304 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00604: val_accuracy did not improve from 0.71028\n",
            "Epoch 605/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0609 - accuracy: 0.9899 - val_loss: 2.4592 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00605: val_accuracy did not improve from 0.71028\n",
            "Epoch 606/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0882 - accuracy: 0.9848 - val_loss: 2.7916 - val_accuracy: 0.5607\n",
            "\n",
            "Epoch 00606: val_accuracy did not improve from 0.71028\n",
            "Epoch 607/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.0598 - accuracy: 0.9895 - val_loss: 2.4972 - val_accuracy: 0.6355\n",
            "\n",
            "Epoch 00607: val_accuracy did not improve from 0.71028\n",
            "Epoch 608/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0921 - accuracy: 0.9825 - val_loss: 3.9083 - val_accuracy: 0.6636\n",
            "\n",
            "Epoch 00608: val_accuracy did not improve from 0.71028\n",
            "Epoch 609/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0911 - accuracy: 0.9777 - val_loss: 3.9176 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00609: val_accuracy did not improve from 0.71028\n",
            "Epoch 610/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.0851 - accuracy: 0.9777 - val_loss: 3.2029 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00610: val_accuracy did not improve from 0.71028\n",
            "Epoch 611/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0729 - accuracy: 0.9787 - val_loss: 3.2208 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00611: val_accuracy did not improve from 0.71028\n",
            "Epoch 612/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.0683 - accuracy: 0.9881 - val_loss: 3.2493 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00612: val_accuracy did not improve from 0.71028\n",
            "Epoch 613/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0617 - accuracy: 0.9861 - val_loss: 2.9334 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00613: val_accuracy did not improve from 0.71028\n",
            "Epoch 614/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0652 - accuracy: 0.9830 - val_loss: 2.9139 - val_accuracy: 0.6355\n",
            "\n",
            "Epoch 00614: val_accuracy did not improve from 0.71028\n",
            "Epoch 615/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0473 - accuracy: 0.9889 - val_loss: 2.8287 - val_accuracy: 0.6168\n",
            "\n",
            "Epoch 00615: val_accuracy did not improve from 0.71028\n",
            "Epoch 616/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0450 - accuracy: 0.9889 - val_loss: 2.6541 - val_accuracy: 0.6449\n",
            "\n",
            "Epoch 00616: val_accuracy did not improve from 0.71028\n",
            "Epoch 617/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0747 - accuracy: 0.9764 - val_loss: 2.8904 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00617: val_accuracy did not improve from 0.71028\n",
            "Epoch 618/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1023 - accuracy: 0.9792 - val_loss: 4.0857 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00618: val_accuracy did not improve from 0.71028\n",
            "Epoch 619/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0749 - accuracy: 0.9887 - val_loss: 4.1429 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00619: val_accuracy did not improve from 0.71028\n",
            "Epoch 620/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0720 - accuracy: 0.9839 - val_loss: 3.5995 - val_accuracy: 0.5701\n",
            "\n",
            "Epoch 00620: val_accuracy did not improve from 0.71028\n",
            "Epoch 621/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1002 - accuracy: 0.9839 - val_loss: 3.1473 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00621: val_accuracy did not improve from 0.71028\n",
            "Epoch 622/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.1414 - accuracy: 0.9588 - val_loss: 3.1170 - val_accuracy: 0.6168\n",
            "\n",
            "Epoch 00622: val_accuracy did not improve from 0.71028\n",
            "Epoch 623/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1023 - accuracy: 0.9739 - val_loss: 2.6649 - val_accuracy: 0.6262\n",
            "\n",
            "Epoch 00623: val_accuracy did not improve from 0.71028\n",
            "Epoch 624/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0845 - accuracy: 0.9851 - val_loss: 2.8769 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00624: val_accuracy did not improve from 0.71028\n",
            "Epoch 625/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.1884 - accuracy: 0.9487 - val_loss: 3.3026 - val_accuracy: 0.6262\n",
            "\n",
            "Epoch 00625: val_accuracy did not improve from 0.71028\n",
            "Epoch 626/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1809 - accuracy: 0.9696 - val_loss: 2.7045 - val_accuracy: 0.5701\n",
            "\n",
            "Epoch 00626: val_accuracy did not improve from 0.71028\n",
            "Epoch 627/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1928 - accuracy: 0.9648 - val_loss: 3.0005 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00627: val_accuracy did not improve from 0.71028\n",
            "Epoch 628/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.1348 - accuracy: 0.9747 - val_loss: 2.8215 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00628: val_accuracy did not improve from 0.71028\n",
            "Epoch 629/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1094 - accuracy: 0.9744 - val_loss: 2.7956 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00629: val_accuracy did not improve from 0.71028\n",
            "Epoch 630/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1376 - accuracy: 0.9864 - val_loss: 3.1207 - val_accuracy: 0.5327\n",
            "\n",
            "Epoch 00630: val_accuracy did not improve from 0.71028\n",
            "Epoch 631/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.1092 - accuracy: 0.9905 - val_loss: 2.8236 - val_accuracy: 0.5421\n",
            "\n",
            "Epoch 00631: val_accuracy did not improve from 0.71028\n",
            "Epoch 632/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.1713 - accuracy: 0.9720 - val_loss: 2.5947 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00632: val_accuracy did not improve from 0.71028\n",
            "Epoch 633/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1030 - accuracy: 0.9753 - val_loss: 2.2472 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00633: val_accuracy did not improve from 0.71028\n",
            "Epoch 634/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0782 - accuracy: 0.9870 - val_loss: 2.0070 - val_accuracy: 0.5514\n",
            "\n",
            "Epoch 00634: val_accuracy did not improve from 0.71028\n",
            "Epoch 635/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1179 - accuracy: 0.9714 - val_loss: 2.5561 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00635: val_accuracy did not improve from 0.71028\n",
            "Epoch 636/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1221 - accuracy: 0.9838 - val_loss: 3.2210 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00636: val_accuracy did not improve from 0.71028\n",
            "Epoch 637/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1673 - accuracy: 0.9683 - val_loss: 3.6079 - val_accuracy: 0.5421\n",
            "\n",
            "Epoch 00637: val_accuracy did not improve from 0.71028\n",
            "Epoch 638/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.1784 - accuracy: 0.9678 - val_loss: 2.8217 - val_accuracy: 0.4953\n",
            "\n",
            "Epoch 00638: val_accuracy did not improve from 0.71028\n",
            "Epoch 639/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.1243 - accuracy: 0.9848 - val_loss: 2.4616 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00639: val_accuracy did not improve from 0.71028\n",
            "Epoch 640/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0591 - accuracy: 0.9935 - val_loss: 3.0905 - val_accuracy: 0.6355\n",
            "\n",
            "Epoch 00640: val_accuracy did not improve from 0.71028\n",
            "Epoch 641/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0896 - accuracy: 0.9796 - val_loss: 2.4756 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00641: val_accuracy did not improve from 0.71028\n",
            "Epoch 642/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.1172 - accuracy: 0.9866 - val_loss: 2.6734 - val_accuracy: 0.5607\n",
            "\n",
            "Epoch 00642: val_accuracy did not improve from 0.71028\n",
            "Epoch 643/1000\n",
            "14/14 [==============================] - 1s 40ms/step - loss: 0.1094 - accuracy: 0.9824 - val_loss: 2.3209 - val_accuracy: 0.6168\n",
            "\n",
            "Epoch 00643: val_accuracy did not improve from 0.71028\n",
            "Epoch 644/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.1341 - accuracy: 0.9761 - val_loss: 2.2508 - val_accuracy: 0.6636\n",
            "\n",
            "Epoch 00644: val_accuracy did not improve from 0.71028\n",
            "Epoch 645/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0517 - accuracy: 0.9963 - val_loss: 2.2320 - val_accuracy: 0.6822\n",
            "\n",
            "Epoch 00645: val_accuracy did not improve from 0.71028\n",
            "Epoch 646/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0755 - accuracy: 0.9869 - val_loss: 2.1845 - val_accuracy: 0.6542\n",
            "\n",
            "Epoch 00646: val_accuracy did not improve from 0.71028\n",
            "Epoch 647/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0914 - accuracy: 0.9786 - val_loss: 2.5688 - val_accuracy: 0.6355\n",
            "\n",
            "Epoch 00647: val_accuracy did not improve from 0.71028\n",
            "Epoch 648/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0624 - accuracy: 0.9782 - val_loss: 2.2558 - val_accuracy: 0.5514\n",
            "\n",
            "Epoch 00648: val_accuracy did not improve from 0.71028\n",
            "Epoch 649/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0862 - accuracy: 0.9753 - val_loss: 2.0887 - val_accuracy: 0.5701\n",
            "\n",
            "Epoch 00649: val_accuracy did not improve from 0.71028\n",
            "Epoch 650/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0698 - accuracy: 0.9905 - val_loss: 2.3367 - val_accuracy: 0.5514\n",
            "\n",
            "Epoch 00650: val_accuracy did not improve from 0.71028\n",
            "Epoch 651/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.2156 - accuracy: 0.9853 - val_loss: 2.5260 - val_accuracy: 0.5607\n",
            "\n",
            "Epoch 00651: val_accuracy did not improve from 0.71028\n",
            "Epoch 652/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0961 - accuracy: 0.9759 - val_loss: 2.5099 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00652: val_accuracy did not improve from 0.71028\n",
            "Epoch 653/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0795 - accuracy: 0.9692 - val_loss: 2.5330 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00653: val_accuracy did not improve from 0.71028\n",
            "Epoch 654/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0492 - accuracy: 0.9950 - val_loss: 2.9681 - val_accuracy: 0.6636\n",
            "\n",
            "Epoch 00654: val_accuracy did not improve from 0.71028\n",
            "Epoch 655/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0887 - accuracy: 0.9850 - val_loss: 3.2523 - val_accuracy: 0.6542\n",
            "\n",
            "Epoch 00655: val_accuracy did not improve from 0.71028\n",
            "Epoch 656/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0852 - accuracy: 0.9828 - val_loss: 2.3102 - val_accuracy: 0.6542\n",
            "\n",
            "Epoch 00656: val_accuracy did not improve from 0.71028\n",
            "Epoch 657/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0670 - accuracy: 0.9899 - val_loss: 2.1204 - val_accuracy: 0.6355\n",
            "\n",
            "Epoch 00657: val_accuracy did not improve from 0.71028\n",
            "Epoch 658/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0485 - accuracy: 0.9878 - val_loss: 2.2589 - val_accuracy: 0.5607\n",
            "\n",
            "Epoch 00658: val_accuracy did not improve from 0.71028\n",
            "Epoch 659/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1146 - accuracy: 0.9779 - val_loss: 2.9970 - val_accuracy: 0.5701\n",
            "\n",
            "Epoch 00659: val_accuracy did not improve from 0.71028\n",
            "Epoch 660/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0596 - accuracy: 0.9836 - val_loss: 2.2491 - val_accuracy: 0.6168\n",
            "\n",
            "Epoch 00660: val_accuracy did not improve from 0.71028\n",
            "Epoch 661/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.0670 - accuracy: 0.9865 - val_loss: 2.3253 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00661: val_accuracy did not improve from 0.71028\n",
            "Epoch 662/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0660 - accuracy: 0.9907 - val_loss: 2.2953 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00662: val_accuracy did not improve from 0.71028\n",
            "Epoch 663/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.1078 - accuracy: 0.9764 - val_loss: 2.4102 - val_accuracy: 0.6168\n",
            "\n",
            "Epoch 00663: val_accuracy did not improve from 0.71028\n",
            "Epoch 664/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0531 - accuracy: 0.9929 - val_loss: 2.4250 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00664: val_accuracy did not improve from 0.71028\n",
            "Epoch 665/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0630 - accuracy: 0.9904 - val_loss: 2.7579 - val_accuracy: 0.5607\n",
            "\n",
            "Epoch 00665: val_accuracy did not improve from 0.71028\n",
            "Epoch 666/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0412 - accuracy: 0.9877 - val_loss: 3.4289 - val_accuracy: 0.5701\n",
            "\n",
            "Epoch 00666: val_accuracy did not improve from 0.71028\n",
            "Epoch 667/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0591 - accuracy: 0.9882 - val_loss: 2.5485 - val_accuracy: 0.6168\n",
            "\n",
            "Epoch 00667: val_accuracy did not improve from 0.71028\n",
            "Epoch 668/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0561 - accuracy: 0.9955 - val_loss: 1.9987 - val_accuracy: 0.6168\n",
            "\n",
            "Epoch 00668: val_accuracy did not improve from 0.71028\n",
            "Epoch 669/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0516 - accuracy: 0.9963 - val_loss: 2.2448 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00669: val_accuracy did not improve from 0.71028\n",
            "Epoch 670/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0724 - accuracy: 0.9843 - val_loss: 1.8378 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00670: val_accuracy did not improve from 0.71028\n",
            "Epoch 671/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0859 - accuracy: 0.9832 - val_loss: 3.8743 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00671: val_accuracy did not improve from 0.71028\n",
            "Epoch 672/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0559 - accuracy: 0.9915 - val_loss: 2.7588 - val_accuracy: 0.5701\n",
            "\n",
            "Epoch 00672: val_accuracy did not improve from 0.71028\n",
            "Epoch 673/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0925 - accuracy: 0.9881 - val_loss: 2.7143 - val_accuracy: 0.5327\n",
            "\n",
            "Epoch 00673: val_accuracy did not improve from 0.71028\n",
            "Epoch 674/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0494 - accuracy: 0.9934 - val_loss: 2.6595 - val_accuracy: 0.5701\n",
            "\n",
            "Epoch 00674: val_accuracy did not improve from 0.71028\n",
            "Epoch 675/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.1166 - accuracy: 0.9816 - val_loss: 3.2999 - val_accuracy: 0.6168\n",
            "\n",
            "Epoch 00675: val_accuracy did not improve from 0.71028\n",
            "Epoch 676/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0651 - accuracy: 0.9913 - val_loss: 3.1482 - val_accuracy: 0.6262\n",
            "\n",
            "Epoch 00676: val_accuracy did not improve from 0.71028\n",
            "Epoch 677/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0654 - accuracy: 0.9827 - val_loss: 2.7656 - val_accuracy: 0.6449\n",
            "\n",
            "Epoch 00677: val_accuracy did not improve from 0.71028\n",
            "Epoch 678/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0505 - accuracy: 0.9902 - val_loss: 2.4091 - val_accuracy: 0.6449\n",
            "\n",
            "Epoch 00678: val_accuracy did not improve from 0.71028\n",
            "Epoch 679/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0636 - accuracy: 0.9897 - val_loss: 3.0422 - val_accuracy: 0.6262\n",
            "\n",
            "Epoch 00679: val_accuracy did not improve from 0.71028\n",
            "Epoch 680/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0476 - accuracy: 0.9935 - val_loss: 3.1158 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00680: val_accuracy did not improve from 0.71028\n",
            "Epoch 681/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0548 - accuracy: 0.9843 - val_loss: 2.7791 - val_accuracy: 0.6449\n",
            "\n",
            "Epoch 00681: val_accuracy did not improve from 0.71028\n",
            "Epoch 682/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0483 - accuracy: 0.9876 - val_loss: 3.1795 - val_accuracy: 0.6168\n",
            "\n",
            "Epoch 00682: val_accuracy did not improve from 0.71028\n",
            "Epoch 683/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0581 - accuracy: 0.9874 - val_loss: 2.6520 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00683: val_accuracy did not improve from 0.71028\n",
            "Epoch 684/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0699 - accuracy: 0.9893 - val_loss: 3.0676 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00684: val_accuracy did not improve from 0.71028\n",
            "Epoch 685/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0801 - accuracy: 0.9804 - val_loss: 3.6779 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00685: val_accuracy did not improve from 0.71028\n",
            "Epoch 686/1000\n",
            "14/14 [==============================] - 1s 40ms/step - loss: 0.0716 - accuracy: 0.9840 - val_loss: 2.8481 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00686: val_accuracy did not improve from 0.71028\n",
            "Epoch 687/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0467 - accuracy: 0.9951 - val_loss: 2.8521 - val_accuracy: 0.5607\n",
            "\n",
            "Epoch 00687: val_accuracy did not improve from 0.71028\n",
            "Epoch 688/1000\n",
            "14/14 [==============================] - 1s 40ms/step - loss: 0.1146 - accuracy: 0.9657 - val_loss: 3.2438 - val_accuracy: 0.6262\n",
            "\n",
            "Epoch 00688: val_accuracy did not improve from 0.71028\n",
            "Epoch 689/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.0828 - accuracy: 0.9853 - val_loss: 2.5953 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00689: val_accuracy did not improve from 0.71028\n",
            "Epoch 690/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0531 - accuracy: 0.9915 - val_loss: 2.9788 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00690: val_accuracy did not improve from 0.71028\n",
            "Epoch 691/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.1373 - accuracy: 0.9717 - val_loss: 3.1709 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00691: val_accuracy did not improve from 0.71028\n",
            "Epoch 692/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.0961 - accuracy: 0.9702 - val_loss: 3.0591 - val_accuracy: 0.6262\n",
            "\n",
            "Epoch 00692: val_accuracy did not improve from 0.71028\n",
            "Epoch 693/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0718 - accuracy: 0.9923 - val_loss: 2.6413 - val_accuracy: 0.6262\n",
            "\n",
            "Epoch 00693: val_accuracy did not improve from 0.71028\n",
            "Epoch 694/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1157 - accuracy: 0.9852 - val_loss: 2.7422 - val_accuracy: 0.5607\n",
            "\n",
            "Epoch 00694: val_accuracy did not improve from 0.71028\n",
            "Epoch 695/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.1229 - accuracy: 0.9850 - val_loss: 3.1072 - val_accuracy: 0.6449\n",
            "\n",
            "Epoch 00695: val_accuracy did not improve from 0.71028\n",
            "Epoch 696/1000\n",
            "14/14 [==============================] - 1s 40ms/step - loss: 0.1100 - accuracy: 0.9864 - val_loss: 3.2117 - val_accuracy: 0.6168\n",
            "\n",
            "Epoch 00696: val_accuracy did not improve from 0.71028\n",
            "Epoch 697/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1081 - accuracy: 0.9847 - val_loss: 2.7533 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00697: val_accuracy did not improve from 0.71028\n",
            "Epoch 698/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1046 - accuracy: 0.9816 - val_loss: 3.3965 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00698: val_accuracy did not improve from 0.71028\n",
            "Epoch 699/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0854 - accuracy: 0.9831 - val_loss: 3.3032 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00699: val_accuracy did not improve from 0.71028\n",
            "Epoch 700/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0698 - accuracy: 0.9855 - val_loss: 2.9395 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00700: val_accuracy did not improve from 0.71028\n",
            "Epoch 701/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0736 - accuracy: 0.9861 - val_loss: 3.0865 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00701: val_accuracy did not improve from 0.71028\n",
            "Epoch 702/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0825 - accuracy: 0.9851 - val_loss: 3.2690 - val_accuracy: 0.5327\n",
            "\n",
            "Epoch 00702: val_accuracy did not improve from 0.71028\n",
            "Epoch 703/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0644 - accuracy: 0.9874 - val_loss: 2.3706 - val_accuracy: 0.5514\n",
            "\n",
            "Epoch 00703: val_accuracy did not improve from 0.71028\n",
            "Epoch 704/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0936 - accuracy: 0.9796 - val_loss: 2.0289 - val_accuracy: 0.5421\n",
            "\n",
            "Epoch 00704: val_accuracy did not improve from 0.71028\n",
            "Epoch 705/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0715 - accuracy: 0.9827 - val_loss: 1.8780 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00705: val_accuracy did not improve from 0.71028\n",
            "Epoch 706/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0637 - accuracy: 0.9848 - val_loss: 2.5473 - val_accuracy: 0.6168\n",
            "\n",
            "Epoch 00706: val_accuracy did not improve from 0.71028\n",
            "Epoch 707/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.1165 - accuracy: 0.9699 - val_loss: 2.3549 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00707: val_accuracy did not improve from 0.71028\n",
            "Epoch 708/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0849 - accuracy: 0.9871 - val_loss: 2.5496 - val_accuracy: 0.6262\n",
            "\n",
            "Epoch 00708: val_accuracy did not improve from 0.71028\n",
            "Epoch 709/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.1253 - accuracy: 0.9874 - val_loss: 2.4982 - val_accuracy: 0.6355\n",
            "\n",
            "Epoch 00709: val_accuracy did not improve from 0.71028\n",
            "Epoch 710/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1239 - accuracy: 0.9727 - val_loss: 2.7129 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00710: val_accuracy did not improve from 0.71028\n",
            "Epoch 711/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1407 - accuracy: 0.9788 - val_loss: 2.3569 - val_accuracy: 0.5514\n",
            "\n",
            "Epoch 00711: val_accuracy did not improve from 0.71028\n",
            "Epoch 712/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.1428 - accuracy: 0.9784 - val_loss: 2.4315 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00712: val_accuracy did not improve from 0.71028\n",
            "Epoch 713/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1239 - accuracy: 0.9865 - val_loss: 2.9909 - val_accuracy: 0.6636\n",
            "\n",
            "Epoch 00713: val_accuracy did not improve from 0.71028\n",
            "Epoch 714/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1033 - accuracy: 0.9823 - val_loss: 1.8498 - val_accuracy: 0.6355\n",
            "\n",
            "Epoch 00714: val_accuracy did not improve from 0.71028\n",
            "Epoch 715/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.1286 - accuracy: 0.9748 - val_loss: 2.3219 - val_accuracy: 0.5607\n",
            "\n",
            "Epoch 00715: val_accuracy did not improve from 0.71028\n",
            "Epoch 716/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0919 - accuracy: 0.9831 - val_loss: 3.2368 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00716: val_accuracy did not improve from 0.71028\n",
            "Epoch 717/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0816 - accuracy: 0.9875 - val_loss: 2.9282 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00717: val_accuracy did not improve from 0.71028\n",
            "Epoch 718/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1194 - accuracy: 0.9804 - val_loss: 2.3688 - val_accuracy: 0.5514\n",
            "\n",
            "Epoch 00718: val_accuracy did not improve from 0.71028\n",
            "Epoch 719/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0737 - accuracy: 0.9886 - val_loss: 2.2320 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00719: val_accuracy did not improve from 0.71028\n",
            "Epoch 720/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1925 - accuracy: 0.9711 - val_loss: 2.2481 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00720: val_accuracy did not improve from 0.71028\n",
            "Epoch 721/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0498 - accuracy: 0.9922 - val_loss: 2.6694 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00721: val_accuracy did not improve from 0.71028\n",
            "Epoch 722/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0450 - accuracy: 0.9910 - val_loss: 2.8386 - val_accuracy: 0.6168\n",
            "\n",
            "Epoch 00722: val_accuracy did not improve from 0.71028\n",
            "Epoch 723/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0470 - accuracy: 0.9954 - val_loss: 2.6879 - val_accuracy: 0.6542\n",
            "\n",
            "Epoch 00723: val_accuracy did not improve from 0.71028\n",
            "Epoch 724/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0710 - accuracy: 0.9866 - val_loss: 2.9567 - val_accuracy: 0.6542\n",
            "\n",
            "Epoch 00724: val_accuracy did not improve from 0.71028\n",
            "Epoch 725/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0416 - accuracy: 0.9961 - val_loss: 3.3254 - val_accuracy: 0.6262\n",
            "\n",
            "Epoch 00725: val_accuracy did not improve from 0.71028\n",
            "Epoch 726/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0976 - accuracy: 0.9834 - val_loss: 2.7101 - val_accuracy: 0.6449\n",
            "\n",
            "Epoch 00726: val_accuracy did not improve from 0.71028\n",
            "Epoch 727/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1029 - accuracy: 0.9732 - val_loss: 3.1277 - val_accuracy: 0.5607\n",
            "\n",
            "Epoch 00727: val_accuracy did not improve from 0.71028\n",
            "Epoch 728/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0755 - accuracy: 0.9909 - val_loss: 3.1488 - val_accuracy: 0.5607\n",
            "\n",
            "Epoch 00728: val_accuracy did not improve from 0.71028\n",
            "Epoch 729/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.1427 - accuracy: 0.9741 - val_loss: 2.8927 - val_accuracy: 0.5327\n",
            "\n",
            "Epoch 00729: val_accuracy did not improve from 0.71028\n",
            "Epoch 730/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0856 - accuracy: 0.9780 - val_loss: 2.5561 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00730: val_accuracy did not improve from 0.71028\n",
            "Epoch 731/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.1222 - accuracy: 0.9805 - val_loss: 2.7187 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00731: val_accuracy did not improve from 0.71028\n",
            "Epoch 732/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0689 - accuracy: 0.9928 - val_loss: 3.0692 - val_accuracy: 0.6542\n",
            "\n",
            "Epoch 00732: val_accuracy did not improve from 0.71028\n",
            "Epoch 733/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0664 - accuracy: 0.9917 - val_loss: 2.4956 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00733: val_accuracy did not improve from 0.71028\n",
            "Epoch 734/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0428 - accuracy: 0.9970 - val_loss: 2.7478 - val_accuracy: 0.5607\n",
            "\n",
            "Epoch 00734: val_accuracy did not improve from 0.71028\n",
            "Epoch 735/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0348 - accuracy: 0.9989 - val_loss: 2.8141 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00735: val_accuracy did not improve from 0.71028\n",
            "Epoch 736/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0739 - accuracy: 0.9908 - val_loss: 2.9755 - val_accuracy: 0.6168\n",
            "\n",
            "Epoch 00736: val_accuracy did not improve from 0.71028\n",
            "Epoch 737/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1777 - accuracy: 0.9841 - val_loss: 3.5012 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00737: val_accuracy did not improve from 0.71028\n",
            "Epoch 738/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0935 - accuracy: 0.9830 - val_loss: 3.2808 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00738: val_accuracy did not improve from 0.71028\n",
            "Epoch 739/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0870 - accuracy: 0.9905 - val_loss: 2.8669 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00739: val_accuracy did not improve from 0.71028\n",
            "Epoch 740/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.1412 - accuracy: 0.9753 - val_loss: 2.9068 - val_accuracy: 0.6355\n",
            "\n",
            "Epoch 00740: val_accuracy did not improve from 0.71028\n",
            "Epoch 741/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.0955 - accuracy: 0.9788 - val_loss: 3.0396 - val_accuracy: 0.6262\n",
            "\n",
            "Epoch 00741: val_accuracy did not improve from 0.71028\n",
            "Epoch 742/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0730 - accuracy: 0.9899 - val_loss: 3.2350 - val_accuracy: 0.6355\n",
            "\n",
            "Epoch 00742: val_accuracy did not improve from 0.71028\n",
            "Epoch 743/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.0648 - accuracy: 0.9851 - val_loss: 2.9085 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00743: val_accuracy did not improve from 0.71028\n",
            "Epoch 744/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0999 - accuracy: 0.9876 - val_loss: 2.8283 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00744: val_accuracy did not improve from 0.71028\n",
            "Epoch 745/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.1111 - accuracy: 0.9804 - val_loss: 3.2779 - val_accuracy: 0.6262\n",
            "\n",
            "Epoch 00745: val_accuracy did not improve from 0.71028\n",
            "Epoch 746/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0732 - accuracy: 0.9906 - val_loss: 2.2986 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00746: val_accuracy did not improve from 0.71028\n",
            "Epoch 747/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0447 - accuracy: 0.9935 - val_loss: 2.2219 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00747: val_accuracy did not improve from 0.71028\n",
            "Epoch 748/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0951 - accuracy: 0.9723 - val_loss: 2.4649 - val_accuracy: 0.5701\n",
            "\n",
            "Epoch 00748: val_accuracy did not improve from 0.71028\n",
            "Epoch 749/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0902 - accuracy: 0.9752 - val_loss: 2.2418 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00749: val_accuracy did not improve from 0.71028\n",
            "Epoch 750/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0430 - accuracy: 0.9949 - val_loss: 2.1848 - val_accuracy: 0.5514\n",
            "\n",
            "Epoch 00750: val_accuracy did not improve from 0.71028\n",
            "Epoch 751/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.0555 - accuracy: 0.9972 - val_loss: 2.2037 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00751: val_accuracy did not improve from 0.71028\n",
            "Epoch 752/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0789 - accuracy: 0.9829 - val_loss: 2.1732 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00752: val_accuracy did not improve from 0.71028\n",
            "Epoch 753/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.1065 - accuracy: 0.9741 - val_loss: 2.4697 - val_accuracy: 0.5421\n",
            "\n",
            "Epoch 00753: val_accuracy did not improve from 0.71028\n",
            "Epoch 754/1000\n",
            "14/14 [==============================] - 1s 40ms/step - loss: 0.0730 - accuracy: 0.9831 - val_loss: 3.2959 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00754: val_accuracy did not improve from 0.71028\n",
            "Epoch 755/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0831 - accuracy: 0.9871 - val_loss: 2.6305 - val_accuracy: 0.6168\n",
            "\n",
            "Epoch 00755: val_accuracy did not improve from 0.71028\n",
            "Epoch 756/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1702 - accuracy: 0.9714 - val_loss: 2.8278 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00756: val_accuracy did not improve from 0.71028\n",
            "Epoch 757/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1426 - accuracy: 0.9783 - val_loss: 3.3172 - val_accuracy: 0.6262\n",
            "\n",
            "Epoch 00757: val_accuracy did not improve from 0.71028\n",
            "Epoch 758/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0932 - accuracy: 0.9778 - val_loss: 3.2481 - val_accuracy: 0.6262\n",
            "\n",
            "Epoch 00758: val_accuracy did not improve from 0.71028\n",
            "Epoch 759/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.1325 - accuracy: 0.9695 - val_loss: 3.0495 - val_accuracy: 0.6355\n",
            "\n",
            "Epoch 00759: val_accuracy did not improve from 0.71028\n",
            "Epoch 760/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0845 - accuracy: 0.9790 - val_loss: 3.3589 - val_accuracy: 0.6168\n",
            "\n",
            "Epoch 00760: val_accuracy did not improve from 0.71028\n",
            "Epoch 761/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0870 - accuracy: 0.9870 - val_loss: 3.1178 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00761: val_accuracy did not improve from 0.71028\n",
            "Epoch 762/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0884 - accuracy: 0.9892 - val_loss: 3.0973 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00762: val_accuracy did not improve from 0.71028\n",
            "Epoch 763/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1110 - accuracy: 0.9735 - val_loss: 3.3973 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00763: val_accuracy did not improve from 0.71028\n",
            "Epoch 764/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0666 - accuracy: 0.9943 - val_loss: 3.5982 - val_accuracy: 0.5514\n",
            "\n",
            "Epoch 00764: val_accuracy did not improve from 0.71028\n",
            "Epoch 765/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0749 - accuracy: 0.9885 - val_loss: 3.1536 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00765: val_accuracy did not improve from 0.71028\n",
            "Epoch 766/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0558 - accuracy: 0.9897 - val_loss: 3.0125 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00766: val_accuracy did not improve from 0.71028\n",
            "Epoch 767/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0545 - accuracy: 0.9902 - val_loss: 2.9428 - val_accuracy: 0.5607\n",
            "\n",
            "Epoch 00767: val_accuracy did not improve from 0.71028\n",
            "Epoch 768/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.0452 - accuracy: 0.9909 - val_loss: 2.9010 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00768: val_accuracy did not improve from 0.71028\n",
            "Epoch 769/1000\n",
            "14/14 [==============================] - 1s 40ms/step - loss: 0.0429 - accuracy: 0.9936 - val_loss: 2.8639 - val_accuracy: 0.5607\n",
            "\n",
            "Epoch 00769: val_accuracy did not improve from 0.71028\n",
            "Epoch 770/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0823 - accuracy: 0.9829 - val_loss: 2.7558 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00770: val_accuracy did not improve from 0.71028\n",
            "Epoch 771/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.1413 - accuracy: 0.9708 - val_loss: 2.6276 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00771: val_accuracy did not improve from 0.71028\n",
            "Epoch 772/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0647 - accuracy: 0.9935 - val_loss: 2.9312 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00772: val_accuracy did not improve from 0.71028\n",
            "Epoch 773/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0893 - accuracy: 0.9874 - val_loss: 2.9211 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00773: val_accuracy did not improve from 0.71028\n",
            "Epoch 774/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0566 - accuracy: 0.9861 - val_loss: 2.4960 - val_accuracy: 0.5701\n",
            "\n",
            "Epoch 00774: val_accuracy did not improve from 0.71028\n",
            "Epoch 775/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1099 - accuracy: 0.9863 - val_loss: 3.3149 - val_accuracy: 0.6449\n",
            "\n",
            "Epoch 00775: val_accuracy did not improve from 0.71028\n",
            "Epoch 776/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0503 - accuracy: 0.9969 - val_loss: 2.8980 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00776: val_accuracy did not improve from 0.71028\n",
            "Epoch 777/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0428 - accuracy: 0.9958 - val_loss: 3.0523 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00777: val_accuracy did not improve from 0.71028\n",
            "Epoch 778/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0660 - accuracy: 0.9833 - val_loss: 3.0200 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00778: val_accuracy did not improve from 0.71028\n",
            "Epoch 779/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0913 - accuracy: 0.9835 - val_loss: 3.0963 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00779: val_accuracy did not improve from 0.71028\n",
            "Epoch 780/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0658 - accuracy: 0.9913 - val_loss: 2.9389 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00780: val_accuracy did not improve from 0.71028\n",
            "Epoch 781/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0973 - accuracy: 0.9757 - val_loss: 2.8399 - val_accuracy: 0.5514\n",
            "\n",
            "Epoch 00781: val_accuracy did not improve from 0.71028\n",
            "Epoch 782/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0490 - accuracy: 0.9960 - val_loss: 3.2253 - val_accuracy: 0.6262\n",
            "\n",
            "Epoch 00782: val_accuracy did not improve from 0.71028\n",
            "Epoch 783/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0517 - accuracy: 0.9952 - val_loss: 3.3117 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00783: val_accuracy did not improve from 0.71028\n",
            "Epoch 784/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1086 - accuracy: 0.9845 - val_loss: 3.3031 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00784: val_accuracy did not improve from 0.71028\n",
            "Epoch 785/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0614 - accuracy: 0.9924 - val_loss: 3.1574 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00785: val_accuracy did not improve from 0.71028\n",
            "Epoch 786/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0584 - accuracy: 0.9925 - val_loss: 3.0307 - val_accuracy: 0.5701\n",
            "\n",
            "Epoch 00786: val_accuracy did not improve from 0.71028\n",
            "Epoch 787/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.1367 - accuracy: 0.9754 - val_loss: 3.0367 - val_accuracy: 0.5421\n",
            "\n",
            "Epoch 00787: val_accuracy did not improve from 0.71028\n",
            "Epoch 788/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.0746 - accuracy: 0.9878 - val_loss: 3.0279 - val_accuracy: 0.5327\n",
            "\n",
            "Epoch 00788: val_accuracy did not improve from 0.71028\n",
            "Epoch 789/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1251 - accuracy: 0.9841 - val_loss: 2.6276 - val_accuracy: 0.5234\n",
            "\n",
            "Epoch 00789: val_accuracy did not improve from 0.71028\n",
            "Epoch 790/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0685 - accuracy: 0.9910 - val_loss: 2.6492 - val_accuracy: 0.5140\n",
            "\n",
            "Epoch 00790: val_accuracy did not improve from 0.71028\n",
            "Epoch 791/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0576 - accuracy: 0.9874 - val_loss: 2.6427 - val_accuracy: 0.5140\n",
            "\n",
            "Epoch 00791: val_accuracy did not improve from 0.71028\n",
            "Epoch 792/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.0525 - accuracy: 0.9924 - val_loss: 2.7271 - val_accuracy: 0.5234\n",
            "\n",
            "Epoch 00792: val_accuracy did not improve from 0.71028\n",
            "Epoch 793/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0770 - accuracy: 0.9759 - val_loss: 2.8921 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00793: val_accuracy did not improve from 0.71028\n",
            "Epoch 794/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0719 - accuracy: 0.9818 - val_loss: 2.8568 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00794: val_accuracy did not improve from 0.71028\n",
            "Epoch 795/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1034 - accuracy: 0.9766 - val_loss: 2.9784 - val_accuracy: 0.5701\n",
            "\n",
            "Epoch 00795: val_accuracy did not improve from 0.71028\n",
            "Epoch 796/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0496 - accuracy: 0.9904 - val_loss: 3.0522 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00796: val_accuracy did not improve from 0.71028\n",
            "Epoch 797/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0871 - accuracy: 0.9834 - val_loss: 3.2139 - val_accuracy: 0.5514\n",
            "\n",
            "Epoch 00797: val_accuracy did not improve from 0.71028\n",
            "Epoch 798/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0616 - accuracy: 0.9897 - val_loss: 2.8941 - val_accuracy: 0.5607\n",
            "\n",
            "Epoch 00798: val_accuracy did not improve from 0.71028\n",
            "Epoch 799/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0335 - accuracy: 0.9963 - val_loss: 2.5825 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00799: val_accuracy did not improve from 0.71028\n",
            "Epoch 800/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0425 - accuracy: 0.9955 - val_loss: 2.3425 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00800: val_accuracy did not improve from 0.71028\n",
            "Epoch 801/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0406 - accuracy: 0.9929 - val_loss: 2.3460 - val_accuracy: 0.5607\n",
            "\n",
            "Epoch 00801: val_accuracy did not improve from 0.71028\n",
            "Epoch 802/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0349 - accuracy: 0.9958 - val_loss: 2.2169 - val_accuracy: 0.5607\n",
            "\n",
            "Epoch 00802: val_accuracy did not improve from 0.71028\n",
            "Epoch 803/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0325 - accuracy: 0.9953 - val_loss: 2.1580 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00803: val_accuracy did not improve from 0.71028\n",
            "Epoch 804/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0401 - accuracy: 0.9916 - val_loss: 2.2885 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00804: val_accuracy did not improve from 0.71028\n",
            "Epoch 805/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0293 - accuracy: 0.9933 - val_loss: 2.4133 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00805: val_accuracy did not improve from 0.71028\n",
            "Epoch 806/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0459 - accuracy: 0.9858 - val_loss: 2.5797 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00806: val_accuracy did not improve from 0.71028\n",
            "Epoch 807/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0227 - accuracy: 0.9985 - val_loss: 2.8965 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00807: val_accuracy did not improve from 0.71028\n",
            "Epoch 808/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0593 - accuracy: 0.9853 - val_loss: 3.2525 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00808: val_accuracy did not improve from 0.71028\n",
            "Epoch 809/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0405 - accuracy: 0.9893 - val_loss: 3.0236 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00809: val_accuracy did not improve from 0.71028\n",
            "Epoch 810/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0698 - accuracy: 0.9897 - val_loss: 3.0913 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00810: val_accuracy did not improve from 0.71028\n",
            "Epoch 811/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0797 - accuracy: 0.9867 - val_loss: 3.0499 - val_accuracy: 0.5514\n",
            "\n",
            "Epoch 00811: val_accuracy did not improve from 0.71028\n",
            "Epoch 812/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.0539 - accuracy: 0.9781 - val_loss: 3.9711 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00812: val_accuracy did not improve from 0.71028\n",
            "Epoch 813/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0539 - accuracy: 0.9922 - val_loss: 3.3802 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00813: val_accuracy did not improve from 0.71028\n",
            "Epoch 814/1000\n",
            "14/14 [==============================] - 1s 40ms/step - loss: 0.0884 - accuracy: 0.9815 - val_loss: 2.8825 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00814: val_accuracy did not improve from 0.71028\n",
            "Epoch 815/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.1188 - accuracy: 0.9667 - val_loss: 3.1887 - val_accuracy: 0.5607\n",
            "\n",
            "Epoch 00815: val_accuracy did not improve from 0.71028\n",
            "Epoch 816/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1040 - accuracy: 0.9814 - val_loss: 3.0973 - val_accuracy: 0.5607\n",
            "\n",
            "Epoch 00816: val_accuracy did not improve from 0.71028\n",
            "Epoch 817/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1907 - accuracy: 0.9791 - val_loss: 3.0055 - val_accuracy: 0.5607\n",
            "\n",
            "Epoch 00817: val_accuracy did not improve from 0.71028\n",
            "Epoch 818/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0526 - accuracy: 0.9918 - val_loss: 2.6191 - val_accuracy: 0.5514\n",
            "\n",
            "Epoch 00818: val_accuracy did not improve from 0.71028\n",
            "Epoch 819/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0789 - accuracy: 0.9892 - val_loss: 2.3331 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00819: val_accuracy did not improve from 0.71028\n",
            "Epoch 820/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0558 - accuracy: 0.9886 - val_loss: 2.0807 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00820: val_accuracy did not improve from 0.71028\n",
            "Epoch 821/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0719 - accuracy: 0.9835 - val_loss: 2.6258 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00821: val_accuracy did not improve from 0.71028\n",
            "Epoch 822/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0403 - accuracy: 0.9949 - val_loss: 2.6432 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00822: val_accuracy did not improve from 0.71028\n",
            "Epoch 823/1000\n",
            "14/14 [==============================] - 1s 40ms/step - loss: 0.0803 - accuracy: 0.9875 - val_loss: 2.5092 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00823: val_accuracy did not improve from 0.71028\n",
            "Epoch 824/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0550 - accuracy: 0.9898 - val_loss: 2.4374 - val_accuracy: 0.6168\n",
            "\n",
            "Epoch 00824: val_accuracy did not improve from 0.71028\n",
            "Epoch 825/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0723 - accuracy: 0.9827 - val_loss: 2.3675 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00825: val_accuracy did not improve from 0.71028\n",
            "Epoch 826/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0889 - accuracy: 0.9799 - val_loss: 2.6668 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00826: val_accuracy did not improve from 0.71028\n",
            "Epoch 827/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0868 - accuracy: 0.9893 - val_loss: 3.4417 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00827: val_accuracy did not improve from 0.71028\n",
            "Epoch 828/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.1326 - accuracy: 0.9684 - val_loss: 4.2452 - val_accuracy: 0.6262\n",
            "\n",
            "Epoch 00828: val_accuracy did not improve from 0.71028\n",
            "Epoch 829/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.1760 - accuracy: 0.9646 - val_loss: 3.8623 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00829: val_accuracy did not improve from 0.71028\n",
            "Epoch 830/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0869 - accuracy: 0.9779 - val_loss: 3.6431 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00830: val_accuracy did not improve from 0.71028\n",
            "Epoch 831/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0786 - accuracy: 0.9930 - val_loss: 2.9429 - val_accuracy: 0.6168\n",
            "\n",
            "Epoch 00831: val_accuracy did not improve from 0.71028\n",
            "Epoch 832/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0870 - accuracy: 0.9849 - val_loss: 2.5700 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00832: val_accuracy did not improve from 0.71028\n",
            "Epoch 833/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1086 - accuracy: 0.9877 - val_loss: 2.6174 - val_accuracy: 0.6449\n",
            "\n",
            "Epoch 00833: val_accuracy did not improve from 0.71028\n",
            "Epoch 834/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0389 - accuracy: 0.9928 - val_loss: 2.5629 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00834: val_accuracy did not improve from 0.71028\n",
            "Epoch 835/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0692 - accuracy: 0.9858 - val_loss: 2.5723 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00835: val_accuracy did not improve from 0.71028\n",
            "Epoch 836/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0813 - accuracy: 0.9843 - val_loss: 2.5719 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00836: val_accuracy did not improve from 0.71028\n",
            "Epoch 837/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0564 - accuracy: 0.9920 - val_loss: 2.1865 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00837: val_accuracy did not improve from 0.71028\n",
            "Epoch 838/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0312 - accuracy: 0.9982 - val_loss: 2.2390 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00838: val_accuracy did not improve from 0.71028\n",
            "Epoch 839/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1139 - accuracy: 0.9872 - val_loss: 2.5809 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00839: val_accuracy did not improve from 0.71028\n",
            "Epoch 840/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.1382 - accuracy: 0.9736 - val_loss: 2.6056 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00840: val_accuracy did not improve from 0.71028\n",
            "Epoch 841/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.1984 - accuracy: 0.9824 - val_loss: 3.0131 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00841: val_accuracy did not improve from 0.71028\n",
            "Epoch 842/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.2345 - accuracy: 0.9801 - val_loss: 2.7406 - val_accuracy: 0.5701\n",
            "\n",
            "Epoch 00842: val_accuracy did not improve from 0.71028\n",
            "Epoch 843/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1064 - accuracy: 0.9650 - val_loss: 2.6409 - val_accuracy: 0.5327\n",
            "\n",
            "Epoch 00843: val_accuracy did not improve from 0.71028\n",
            "Epoch 844/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0514 - accuracy: 0.9950 - val_loss: 2.6142 - val_accuracy: 0.5327\n",
            "\n",
            "Epoch 00844: val_accuracy did not improve from 0.71028\n",
            "Epoch 845/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0709 - accuracy: 0.9785 - val_loss: 2.6956 - val_accuracy: 0.5607\n",
            "\n",
            "Epoch 00845: val_accuracy did not improve from 0.71028\n",
            "Epoch 846/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0555 - accuracy: 0.9932 - val_loss: 2.5561 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00846: val_accuracy did not improve from 0.71028\n",
            "Epoch 847/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0695 - accuracy: 0.9752 - val_loss: 2.4635 - val_accuracy: 0.5701\n",
            "\n",
            "Epoch 00847: val_accuracy did not improve from 0.71028\n",
            "Epoch 848/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0385 - accuracy: 0.9966 - val_loss: 2.4956 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00848: val_accuracy did not improve from 0.71028\n",
            "Epoch 849/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0335 - accuracy: 0.9990 - val_loss: 2.4638 - val_accuracy: 0.6262\n",
            "\n",
            "Epoch 00849: val_accuracy did not improve from 0.71028\n",
            "Epoch 850/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0807 - accuracy: 0.9899 - val_loss: 2.5244 - val_accuracy: 0.6168\n",
            "\n",
            "Epoch 00850: val_accuracy did not improve from 0.71028\n",
            "Epoch 851/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0466 - accuracy: 0.9935 - val_loss: 2.5465 - val_accuracy: 0.6355\n",
            "\n",
            "Epoch 00851: val_accuracy did not improve from 0.71028\n",
            "Epoch 852/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0502 - accuracy: 0.9832 - val_loss: 2.8388 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00852: val_accuracy did not improve from 0.71028\n",
            "Epoch 853/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0546 - accuracy: 0.9897 - val_loss: 2.9750 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00853: val_accuracy did not improve from 0.71028\n",
            "Epoch 854/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0302 - accuracy: 0.9915 - val_loss: 2.8042 - val_accuracy: 0.5607\n",
            "\n",
            "Epoch 00854: val_accuracy did not improve from 0.71028\n",
            "Epoch 855/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0706 - accuracy: 0.9852 - val_loss: 2.8631 - val_accuracy: 0.4953\n",
            "\n",
            "Epoch 00855: val_accuracy did not improve from 0.71028\n",
            "Epoch 856/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0451 - accuracy: 0.9892 - val_loss: 3.0273 - val_accuracy: 0.5327\n",
            "\n",
            "Epoch 00856: val_accuracy did not improve from 0.71028\n",
            "Epoch 857/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0933 - accuracy: 0.9729 - val_loss: 2.8482 - val_accuracy: 0.5140\n",
            "\n",
            "Epoch 00857: val_accuracy did not improve from 0.71028\n",
            "Epoch 858/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0613 - accuracy: 0.9866 - val_loss: 2.8757 - val_accuracy: 0.5421\n",
            "\n",
            "Epoch 00858: val_accuracy did not improve from 0.71028\n",
            "Epoch 859/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0501 - accuracy: 0.9935 - val_loss: 3.0282 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00859: val_accuracy did not improve from 0.71028\n",
            "Epoch 860/1000\n",
            "14/14 [==============================] - 1s 40ms/step - loss: 0.0556 - accuracy: 0.9886 - val_loss: 2.9586 - val_accuracy: 0.5327\n",
            "\n",
            "Epoch 00860: val_accuracy did not improve from 0.71028\n",
            "Epoch 861/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0279 - accuracy: 0.9964 - val_loss: 3.0275 - val_accuracy: 0.5234\n",
            "\n",
            "Epoch 00861: val_accuracy did not improve from 0.71028\n",
            "Epoch 862/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0309 - accuracy: 0.9986 - val_loss: 3.1025 - val_accuracy: 0.5514\n",
            "\n",
            "Epoch 00862: val_accuracy did not improve from 0.71028\n",
            "Epoch 863/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.0378 - accuracy: 0.9931 - val_loss: 3.2158 - val_accuracy: 0.5701\n",
            "\n",
            "Epoch 00863: val_accuracy did not improve from 0.71028\n",
            "Epoch 864/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0754 - accuracy: 0.9839 - val_loss: 3.0048 - val_accuracy: 0.5607\n",
            "\n",
            "Epoch 00864: val_accuracy did not improve from 0.71028\n",
            "Epoch 865/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0721 - accuracy: 0.9867 - val_loss: 3.1912 - val_accuracy: 0.5701\n",
            "\n",
            "Epoch 00865: val_accuracy did not improve from 0.71028\n",
            "Epoch 866/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0975 - accuracy: 0.9865 - val_loss: 3.4873 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00866: val_accuracy did not improve from 0.71028\n",
            "Epoch 867/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0574 - accuracy: 0.9984 - val_loss: 3.9599 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00867: val_accuracy did not improve from 0.71028\n",
            "Epoch 868/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1291 - accuracy: 0.9769 - val_loss: 4.3439 - val_accuracy: 0.5701\n",
            "\n",
            "Epoch 00868: val_accuracy did not improve from 0.71028\n",
            "Epoch 869/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.1346 - accuracy: 0.9828 - val_loss: 3.9121 - val_accuracy: 0.5514\n",
            "\n",
            "Epoch 00869: val_accuracy did not improve from 0.71028\n",
            "Epoch 870/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0818 - accuracy: 0.9895 - val_loss: 3.8713 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00870: val_accuracy did not improve from 0.71028\n",
            "Epoch 871/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1095 - accuracy: 0.9881 - val_loss: 3.3559 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00871: val_accuracy did not improve from 0.71028\n",
            "Epoch 872/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1123 - accuracy: 0.9845 - val_loss: 3.4761 - val_accuracy: 0.5327\n",
            "\n",
            "Epoch 00872: val_accuracy did not improve from 0.71028\n",
            "Epoch 873/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1340 - accuracy: 0.9790 - val_loss: 3.5819 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00873: val_accuracy did not improve from 0.71028\n",
            "Epoch 874/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1414 - accuracy: 0.9821 - val_loss: 3.2194 - val_accuracy: 0.5421\n",
            "\n",
            "Epoch 00874: val_accuracy did not improve from 0.71028\n",
            "Epoch 875/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.1001 - accuracy: 0.9845 - val_loss: 3.0603 - val_accuracy: 0.5607\n",
            "\n",
            "Epoch 00875: val_accuracy did not improve from 0.71028\n",
            "Epoch 876/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0791 - accuracy: 0.9853 - val_loss: 2.6945 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00876: val_accuracy did not improve from 0.71028\n",
            "Epoch 877/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0577 - accuracy: 0.9949 - val_loss: 2.6494 - val_accuracy: 0.6262\n",
            "\n",
            "Epoch 00877: val_accuracy did not improve from 0.71028\n",
            "Epoch 878/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0921 - accuracy: 0.9840 - val_loss: 2.6003 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00878: val_accuracy did not improve from 0.71028\n",
            "Epoch 879/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0716 - accuracy: 0.9858 - val_loss: 2.3146 - val_accuracy: 0.5607\n",
            "\n",
            "Epoch 00879: val_accuracy did not improve from 0.71028\n",
            "Epoch 880/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0620 - accuracy: 0.9892 - val_loss: 2.2554 - val_accuracy: 0.5701\n",
            "\n",
            "Epoch 00880: val_accuracy did not improve from 0.71028\n",
            "Epoch 881/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0730 - accuracy: 0.9814 - val_loss: 2.4320 - val_accuracy: 0.5701\n",
            "\n",
            "Epoch 00881: val_accuracy did not improve from 0.71028\n",
            "Epoch 882/1000\n",
            "14/14 [==============================] - 1s 40ms/step - loss: 0.0517 - accuracy: 0.9951 - val_loss: 2.6103 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00882: val_accuracy did not improve from 0.71028\n",
            "Epoch 883/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0578 - accuracy: 0.9900 - val_loss: 2.7278 - val_accuracy: 0.5514\n",
            "\n",
            "Epoch 00883: val_accuracy did not improve from 0.71028\n",
            "Epoch 884/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0680 - accuracy: 0.9887 - val_loss: 2.7895 - val_accuracy: 0.5607\n",
            "\n",
            "Epoch 00884: val_accuracy did not improve from 0.71028\n",
            "Epoch 885/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.0449 - accuracy: 0.9931 - val_loss: 2.9191 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00885: val_accuracy did not improve from 0.71028\n",
            "Epoch 886/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0498 - accuracy: 0.9856 - val_loss: 2.8706 - val_accuracy: 0.6168\n",
            "\n",
            "Epoch 00886: val_accuracy did not improve from 0.71028\n",
            "Epoch 887/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0529 - accuracy: 0.9917 - val_loss: 2.8264 - val_accuracy: 0.5607\n",
            "\n",
            "Epoch 00887: val_accuracy did not improve from 0.71028\n",
            "Epoch 888/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0504 - accuracy: 0.9904 - val_loss: 3.1080 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00888: val_accuracy did not improve from 0.71028\n",
            "Epoch 889/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0244 - accuracy: 1.0000 - val_loss: 3.0557 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00889: val_accuracy did not improve from 0.71028\n",
            "Epoch 890/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0615 - accuracy: 0.9911 - val_loss: 2.7641 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00890: val_accuracy did not improve from 0.71028\n",
            "Epoch 891/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0424 - accuracy: 0.9902 - val_loss: 2.8912 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00891: val_accuracy did not improve from 0.71028\n",
            "Epoch 892/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0226 - accuracy: 1.0000 - val_loss: 2.9954 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00892: val_accuracy did not improve from 0.71028\n",
            "Epoch 893/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0308 - accuracy: 0.9948 - val_loss: 2.7892 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00893: val_accuracy did not improve from 0.71028\n",
            "Epoch 894/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0720 - accuracy: 0.9788 - val_loss: 3.3877 - val_accuracy: 0.5701\n",
            "\n",
            "Epoch 00894: val_accuracy did not improve from 0.71028\n",
            "Epoch 895/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0345 - accuracy: 0.9973 - val_loss: 3.4847 - val_accuracy: 0.5421\n",
            "\n",
            "Epoch 00895: val_accuracy did not improve from 0.71028\n",
            "Epoch 896/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0364 - accuracy: 0.9924 - val_loss: 2.9940 - val_accuracy: 0.5514\n",
            "\n",
            "Epoch 00896: val_accuracy did not improve from 0.71028\n",
            "Epoch 897/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0469 - accuracy: 0.9944 - val_loss: 2.6117 - val_accuracy: 0.5514\n",
            "\n",
            "Epoch 00897: val_accuracy did not improve from 0.71028\n",
            "Epoch 898/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0729 - accuracy: 0.9875 - val_loss: 3.2366 - val_accuracy: 0.5514\n",
            "\n",
            "Epoch 00898: val_accuracy did not improve from 0.71028\n",
            "Epoch 899/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0454 - accuracy: 0.9944 - val_loss: 3.1360 - val_accuracy: 0.5514\n",
            "\n",
            "Epoch 00899: val_accuracy did not improve from 0.71028\n",
            "Epoch 900/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0582 - accuracy: 0.9842 - val_loss: 2.9982 - val_accuracy: 0.5607\n",
            "\n",
            "Epoch 00900: val_accuracy did not improve from 0.71028\n",
            "Epoch 901/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0764 - accuracy: 0.9855 - val_loss: 2.7472 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00901: val_accuracy did not improve from 0.71028\n",
            "Epoch 902/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0455 - accuracy: 0.9871 - val_loss: 2.7174 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00902: val_accuracy did not improve from 0.71028\n",
            "Epoch 903/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0444 - accuracy: 0.9969 - val_loss: 3.7072 - val_accuracy: 0.5514\n",
            "\n",
            "Epoch 00903: val_accuracy did not improve from 0.71028\n",
            "Epoch 904/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1254 - accuracy: 0.9701 - val_loss: 4.1980 - val_accuracy: 0.5140\n",
            "\n",
            "Epoch 00904: val_accuracy did not improve from 0.71028\n",
            "Epoch 905/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0552 - accuracy: 0.9908 - val_loss: 3.1755 - val_accuracy: 0.5701\n",
            "\n",
            "Epoch 00905: val_accuracy did not improve from 0.71028\n",
            "Epoch 906/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0486 - accuracy: 0.9850 - val_loss: 2.8947 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00906: val_accuracy did not improve from 0.71028\n",
            "Epoch 907/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0694 - accuracy: 0.9891 - val_loss: 3.2171 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00907: val_accuracy did not improve from 0.71028\n",
            "Epoch 908/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0653 - accuracy: 0.9815 - val_loss: 2.9773 - val_accuracy: 0.5607\n",
            "\n",
            "Epoch 00908: val_accuracy did not improve from 0.71028\n",
            "Epoch 909/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0547 - accuracy: 0.9889 - val_loss: 3.2113 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00909: val_accuracy did not improve from 0.71028\n",
            "Epoch 910/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0687 - accuracy: 0.9867 - val_loss: 3.6425 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00910: val_accuracy did not improve from 0.71028\n",
            "Epoch 911/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0349 - accuracy: 0.9961 - val_loss: 3.3493 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00911: val_accuracy did not improve from 0.71028\n",
            "Epoch 912/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0322 - accuracy: 0.9951 - val_loss: 3.1057 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00912: val_accuracy did not improve from 0.71028\n",
            "Epoch 913/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0527 - accuracy: 0.9934 - val_loss: 3.4283 - val_accuracy: 0.4953\n",
            "\n",
            "Epoch 00913: val_accuracy did not improve from 0.71028\n",
            "Epoch 914/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0864 - accuracy: 0.9736 - val_loss: 3.2075 - val_accuracy: 0.5234\n",
            "\n",
            "Epoch 00914: val_accuracy did not improve from 0.71028\n",
            "Epoch 915/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.1183 - accuracy: 0.9746 - val_loss: 3.1318 - val_accuracy: 0.5701\n",
            "\n",
            "Epoch 00915: val_accuracy did not improve from 0.71028\n",
            "Epoch 916/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0570 - accuracy: 0.9914 - val_loss: 2.9738 - val_accuracy: 0.5421\n",
            "\n",
            "Epoch 00916: val_accuracy did not improve from 0.71028\n",
            "Epoch 917/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0840 - accuracy: 0.9866 - val_loss: 2.7836 - val_accuracy: 0.5421\n",
            "\n",
            "Epoch 00917: val_accuracy did not improve from 0.71028\n",
            "Epoch 918/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0430 - accuracy: 0.9915 - val_loss: 3.5092 - val_accuracy: 0.5047\n",
            "\n",
            "Epoch 00918: val_accuracy did not improve from 0.71028\n",
            "Epoch 919/1000\n",
            "14/14 [==============================] - 1s 40ms/step - loss: 0.0433 - accuracy: 0.9939 - val_loss: 3.6845 - val_accuracy: 0.5140\n",
            "\n",
            "Epoch 00919: val_accuracy did not improve from 0.71028\n",
            "Epoch 920/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0388 - accuracy: 0.9969 - val_loss: 3.4496 - val_accuracy: 0.5701\n",
            "\n",
            "Epoch 00920: val_accuracy did not improve from 0.71028\n",
            "Epoch 921/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0630 - accuracy: 0.9902 - val_loss: 4.0726 - val_accuracy: 0.5327\n",
            "\n",
            "Epoch 00921: val_accuracy did not improve from 0.71028\n",
            "Epoch 922/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0540 - accuracy: 0.9919 - val_loss: 4.1450 - val_accuracy: 0.5607\n",
            "\n",
            "Epoch 00922: val_accuracy did not improve from 0.71028\n",
            "Epoch 923/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0782 - accuracy: 0.9934 - val_loss: 4.3567 - val_accuracy: 0.5701\n",
            "\n",
            "Epoch 00923: val_accuracy did not improve from 0.71028\n",
            "Epoch 924/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0798 - accuracy: 0.9804 - val_loss: 3.8413 - val_accuracy: 0.5701\n",
            "\n",
            "Epoch 00924: val_accuracy did not improve from 0.71028\n",
            "Epoch 925/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1172 - accuracy: 0.9795 - val_loss: 4.0716 - val_accuracy: 0.5607\n",
            "\n",
            "Epoch 00925: val_accuracy did not improve from 0.71028\n",
            "Epoch 926/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0642 - accuracy: 0.9914 - val_loss: 5.0315 - val_accuracy: 0.5607\n",
            "\n",
            "Epoch 00926: val_accuracy did not improve from 0.71028\n",
            "Epoch 927/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0638 - accuracy: 0.9871 - val_loss: 4.1904 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00927: val_accuracy did not improve from 0.71028\n",
            "Epoch 928/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0637 - accuracy: 0.9946 - val_loss: 3.9866 - val_accuracy: 0.5514\n",
            "\n",
            "Epoch 00928: val_accuracy did not improve from 0.71028\n",
            "Epoch 929/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0972 - accuracy: 0.9861 - val_loss: 3.8159 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00929: val_accuracy did not improve from 0.71028\n",
            "Epoch 930/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0422 - accuracy: 0.9951 - val_loss: 3.4460 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00930: val_accuracy did not improve from 0.71028\n",
            "Epoch 931/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0575 - accuracy: 0.9876 - val_loss: 3.5055 - val_accuracy: 0.5701\n",
            "\n",
            "Epoch 00931: val_accuracy did not improve from 0.71028\n",
            "Epoch 932/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.1054 - accuracy: 0.9720 - val_loss: 3.7184 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00932: val_accuracy did not improve from 0.71028\n",
            "Epoch 933/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.1464 - accuracy: 0.9796 - val_loss: 3.6026 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00933: val_accuracy did not improve from 0.71028\n",
            "Epoch 934/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0595 - accuracy: 0.9905 - val_loss: 3.0408 - val_accuracy: 0.6262\n",
            "\n",
            "Epoch 00934: val_accuracy did not improve from 0.71028\n",
            "Epoch 935/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0395 - accuracy: 0.9968 - val_loss: 3.4300 - val_accuracy: 0.6168\n",
            "\n",
            "Epoch 00935: val_accuracy did not improve from 0.71028\n",
            "Epoch 936/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0498 - accuracy: 0.9934 - val_loss: 3.9023 - val_accuracy: 0.6168\n",
            "\n",
            "Epoch 00936: val_accuracy did not improve from 0.71028\n",
            "Epoch 937/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1323 - accuracy: 0.9787 - val_loss: 4.1983 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00937: val_accuracy did not improve from 0.71028\n",
            "Epoch 938/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0478 - accuracy: 0.9850 - val_loss: 3.4076 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00938: val_accuracy did not improve from 0.71028\n",
            "Epoch 939/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0306 - accuracy: 0.9974 - val_loss: 3.6829 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00939: val_accuracy did not improve from 0.71028\n",
            "Epoch 940/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0355 - accuracy: 0.9974 - val_loss: 3.2519 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00940: val_accuracy did not improve from 0.71028\n",
            "Epoch 941/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0588 - accuracy: 0.9914 - val_loss: 3.4675 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00941: val_accuracy did not improve from 0.71028\n",
            "Epoch 942/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0564 - accuracy: 0.9854 - val_loss: 3.9302 - val_accuracy: 0.5701\n",
            "\n",
            "Epoch 00942: val_accuracy did not improve from 0.71028\n",
            "Epoch 943/1000\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 0.0438 - accuracy: 0.9966 - val_loss: 3.7172 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00943: val_accuracy did not improve from 0.71028\n",
            "Epoch 944/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.1092 - accuracy: 0.9855 - val_loss: 3.5174 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00944: val_accuracy did not improve from 0.71028\n",
            "Epoch 945/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0839 - accuracy: 0.9847 - val_loss: 3.5080 - val_accuracy: 0.5701\n",
            "\n",
            "Epoch 00945: val_accuracy did not improve from 0.71028\n",
            "Epoch 946/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0641 - accuracy: 0.9934 - val_loss: 2.8648 - val_accuracy: 0.5421\n",
            "\n",
            "Epoch 00946: val_accuracy did not improve from 0.71028\n",
            "Epoch 947/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0750 - accuracy: 0.9884 - val_loss: 3.5651 - val_accuracy: 0.5421\n",
            "\n",
            "Epoch 00947: val_accuracy did not improve from 0.71028\n",
            "Epoch 948/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0554 - accuracy: 0.9861 - val_loss: 3.7026 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00948: val_accuracy did not improve from 0.71028\n",
            "Epoch 949/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0463 - accuracy: 0.9978 - val_loss: 3.2104 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00949: val_accuracy did not improve from 0.71028\n",
            "Epoch 950/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0646 - accuracy: 0.9931 - val_loss: 3.5235 - val_accuracy: 0.5327\n",
            "\n",
            "Epoch 00950: val_accuracy did not improve from 0.71028\n",
            "Epoch 951/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0523 - accuracy: 0.9908 - val_loss: 3.5046 - val_accuracy: 0.4953\n",
            "\n",
            "Epoch 00951: val_accuracy did not improve from 0.71028\n",
            "Epoch 952/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0554 - accuracy: 0.9819 - val_loss: 3.3632 - val_accuracy: 0.5514\n",
            "\n",
            "Epoch 00952: val_accuracy did not improve from 0.71028\n",
            "Epoch 953/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0708 - accuracy: 0.9946 - val_loss: 3.6780 - val_accuracy: 0.5607\n",
            "\n",
            "Epoch 00953: val_accuracy did not improve from 0.71028\n",
            "Epoch 954/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0858 - accuracy: 0.9879 - val_loss: 4.5141 - val_accuracy: 0.5514\n",
            "\n",
            "Epoch 00954: val_accuracy did not improve from 0.71028\n",
            "Epoch 955/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0550 - accuracy: 0.9974 - val_loss: 4.7208 - val_accuracy: 0.5514\n",
            "\n",
            "Epoch 00955: val_accuracy did not improve from 0.71028\n",
            "Epoch 956/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0978 - accuracy: 0.9758 - val_loss: 4.1224 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00956: val_accuracy did not improve from 0.71028\n",
            "Epoch 957/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0440 - accuracy: 0.9962 - val_loss: 3.3350 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00957: val_accuracy did not improve from 0.71028\n",
            "Epoch 958/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0804 - accuracy: 0.9767 - val_loss: 3.1813 - val_accuracy: 0.5701\n",
            "\n",
            "Epoch 00958: val_accuracy did not improve from 0.71028\n",
            "Epoch 959/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0440 - accuracy: 0.9969 - val_loss: 3.0396 - val_accuracy: 0.5514\n",
            "\n",
            "Epoch 00959: val_accuracy did not improve from 0.71028\n",
            "Epoch 960/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0566 - accuracy: 0.9881 - val_loss: 3.1325 - val_accuracy: 0.5234\n",
            "\n",
            "Epoch 00960: val_accuracy did not improve from 0.71028\n",
            "Epoch 961/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0676 - accuracy: 0.9856 - val_loss: 3.1362 - val_accuracy: 0.5140\n",
            "\n",
            "Epoch 00961: val_accuracy did not improve from 0.71028\n",
            "Epoch 962/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0635 - accuracy: 0.9811 - val_loss: 3.3618 - val_accuracy: 0.5514\n",
            "\n",
            "Epoch 00962: val_accuracy did not improve from 0.71028\n",
            "Epoch 963/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0540 - accuracy: 0.9966 - val_loss: 3.0994 - val_accuracy: 0.5514\n",
            "\n",
            "Epoch 00963: val_accuracy did not improve from 0.71028\n",
            "Epoch 964/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0899 - accuracy: 0.9860 - val_loss: 2.8999 - val_accuracy: 0.5607\n",
            "\n",
            "Epoch 00964: val_accuracy did not improve from 0.71028\n",
            "Epoch 965/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0561 - accuracy: 0.9913 - val_loss: 3.5489 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00965: val_accuracy did not improve from 0.71028\n",
            "Epoch 966/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0682 - accuracy: 0.9940 - val_loss: 4.2551 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00966: val_accuracy did not improve from 0.71028\n",
            "Epoch 967/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0446 - accuracy: 0.9958 - val_loss: 3.7817 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00967: val_accuracy did not improve from 0.71028\n",
            "Epoch 968/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0594 - accuracy: 0.9857 - val_loss: 3.4208 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00968: val_accuracy did not improve from 0.71028\n",
            "Epoch 969/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0433 - accuracy: 0.9853 - val_loss: 3.4554 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00969: val_accuracy did not improve from 0.71028\n",
            "Epoch 970/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0432 - accuracy: 0.9939 - val_loss: 3.3539 - val_accuracy: 0.5701\n",
            "\n",
            "Epoch 00970: val_accuracy did not improve from 0.71028\n",
            "Epoch 971/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0474 - accuracy: 0.9877 - val_loss: 3.8390 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00971: val_accuracy did not improve from 0.71028\n",
            "Epoch 972/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0374 - accuracy: 0.9898 - val_loss: 5.1476 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00972: val_accuracy did not improve from 0.71028\n",
            "Epoch 973/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0629 - accuracy: 0.9821 - val_loss: 4.6028 - val_accuracy: 0.5607\n",
            "\n",
            "Epoch 00973: val_accuracy did not improve from 0.71028\n",
            "Epoch 974/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0518 - accuracy: 0.9932 - val_loss: 3.3159 - val_accuracy: 0.5514\n",
            "\n",
            "Epoch 00974: val_accuracy did not improve from 0.71028\n",
            "Epoch 975/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0434 - accuracy: 0.9929 - val_loss: 3.2697 - val_accuracy: 0.5701\n",
            "\n",
            "Epoch 00975: val_accuracy did not improve from 0.71028\n",
            "Epoch 976/1000\n",
            "14/14 [==============================] - 1s 40ms/step - loss: 0.0438 - accuracy: 0.9921 - val_loss: 3.1905 - val_accuracy: 0.5701\n",
            "\n",
            "Epoch 00976: val_accuracy did not improve from 0.71028\n",
            "Epoch 977/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0344 - accuracy: 0.9951 - val_loss: 2.8835 - val_accuracy: 0.5607\n",
            "\n",
            "Epoch 00977: val_accuracy did not improve from 0.71028\n",
            "Epoch 978/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0347 - accuracy: 0.9958 - val_loss: 2.9797 - val_accuracy: 0.5514\n",
            "\n",
            "Epoch 00978: val_accuracy did not improve from 0.71028\n",
            "Epoch 979/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0273 - accuracy: 0.9952 - val_loss: 2.7904 - val_accuracy: 0.5234\n",
            "\n",
            "Epoch 00979: val_accuracy did not improve from 0.71028\n",
            "Epoch 980/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0440 - accuracy: 0.9959 - val_loss: 2.5552 - val_accuracy: 0.5421\n",
            "\n",
            "Epoch 00980: val_accuracy did not improve from 0.71028\n",
            "Epoch 981/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0431 - accuracy: 0.9943 - val_loss: 2.7800 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00981: val_accuracy did not improve from 0.71028\n",
            "Epoch 982/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0481 - accuracy: 0.9841 - val_loss: 3.0772 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00982: val_accuracy did not improve from 0.71028\n",
            "Epoch 983/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0263 - accuracy: 0.9921 - val_loss: 3.0807 - val_accuracy: 0.6262\n",
            "\n",
            "Epoch 00983: val_accuracy did not improve from 0.71028\n",
            "Epoch 984/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0659 - accuracy: 0.9828 - val_loss: 2.9587 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00984: val_accuracy did not improve from 0.71028\n",
            "Epoch 985/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0905 - accuracy: 0.9890 - val_loss: 3.4351 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00985: val_accuracy did not improve from 0.71028\n",
            "Epoch 986/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0954 - accuracy: 0.9891 - val_loss: 2.9780 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00986: val_accuracy did not improve from 0.71028\n",
            "Epoch 987/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.1120 - accuracy: 0.9860 - val_loss: 3.5711 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00987: val_accuracy did not improve from 0.71028\n",
            "Epoch 988/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0688 - accuracy: 0.9895 - val_loss: 4.4601 - val_accuracy: 0.5327\n",
            "\n",
            "Epoch 00988: val_accuracy did not improve from 0.71028\n",
            "Epoch 989/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0590 - accuracy: 0.9921 - val_loss: 3.2076 - val_accuracy: 0.5607\n",
            "\n",
            "Epoch 00989: val_accuracy did not improve from 0.71028\n",
            "Epoch 990/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0540 - accuracy: 0.9957 - val_loss: 3.1777 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00990: val_accuracy did not improve from 0.71028\n",
            "Epoch 991/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0413 - accuracy: 0.9987 - val_loss: 4.7335 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00991: val_accuracy did not improve from 0.71028\n",
            "Epoch 992/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.2342 - accuracy: 0.9753 - val_loss: 2.9556 - val_accuracy: 0.5514\n",
            "\n",
            "Epoch 00992: val_accuracy did not improve from 0.71028\n",
            "Epoch 993/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0484 - accuracy: 0.9961 - val_loss: 2.6586 - val_accuracy: 0.5514\n",
            "\n",
            "Epoch 00993: val_accuracy did not improve from 0.71028\n",
            "Epoch 994/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0432 - accuracy: 0.9950 - val_loss: 2.5174 - val_accuracy: 0.5607\n",
            "\n",
            "Epoch 00994: val_accuracy did not improve from 0.71028\n",
            "Epoch 995/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0446 - accuracy: 0.9961 - val_loss: 3.0294 - val_accuracy: 0.5607\n",
            "\n",
            "Epoch 00995: val_accuracy did not improve from 0.71028\n",
            "Epoch 996/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0443 - accuracy: 0.9987 - val_loss: 2.9802 - val_accuracy: 0.5607\n",
            "\n",
            "Epoch 00996: val_accuracy did not improve from 0.71028\n",
            "Epoch 997/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0508 - accuracy: 0.9902 - val_loss: 2.7430 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00997: val_accuracy did not improve from 0.71028\n",
            "Epoch 998/1000\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.0410 - accuracy: 0.9930 - val_loss: 2.8040 - val_accuracy: 0.5234\n",
            "\n",
            "Epoch 00998: val_accuracy did not improve from 0.71028\n",
            "Epoch 999/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0944 - accuracy: 0.9768 - val_loss: 4.0523 - val_accuracy: 0.5234\n",
            "\n",
            "Epoch 00999: val_accuracy did not improve from 0.71028\n",
            "Epoch 1000/1000\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0770 - accuracy: 0.9876 - val_loss: 3.4769 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 01000: val_accuracy did not improve from 0.71028\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "E4fIIIUsiwAQ",
        "outputId": "c3cdd9bb-342b-45b8-d7f3-4b2d5ea81799"
      },
      "source": [
        "# PLOT MODEL HISTORY OF ACCURACY AND LOSS OVER EPOCHS\n",
        "# Plot the results\n",
        "train_loss=model_history.history['loss']\n",
        "val_loss=model_history.history['val_loss']\n",
        "train_acc=model_history.history['accuracy']\n",
        "val_acc=model_history.history['val_accuracy']\n",
        "plt.rcParams['figure.dpi'] = 150 \n",
        "plt.figure(1,figsize=(6,5))\n",
        "plt.plot(train_loss)\n",
        "plt.plot(val_loss)\n",
        "plt.xlabel('Number of epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training loss vs Validation loss')\n",
        "plt.grid(True)\n",
        "plt.legend(['Training','Validation'], loc=1)\n",
        "plt.style.use(['seaborn-darkgrid'])\n",
        "\n",
        "plt.rcParams['figure.dpi'] = 150 \n",
        "plt.figure(2,figsize=(6,5))\n",
        "plt.plot(train_acc)\n",
        "plt.plot(val_acc)\n",
        "plt.xlabel('Number of epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training accuracy vs Validation accuracy')\n",
        "plt.grid(True)\n",
        "plt.legend(['Training','Validation'],loc=4)\n",
        "plt.style.use(['seaborn-darkgrid'])     \n",
        "# PRINT LOSS AND ACCURACY PERCENTAGE ON TEST SET\n",
        "print(\"Loss of the model is - \" , model.evaluate(X_test,y_test)[0])\n",
        "print(\"Accuracy of the model is - \" , model.evaluate(X_test,y_test)[1]*100 , \"%\") \n",
        "\n",
        "# PREDICTION LABELS\n",
        "predictions = model.predict(X_test, batch_size=32)\n",
        "predictions=predictions.argmax(axis=1)\n",
        "predictions\n",
        "predictions = predictions.astype(int).flatten()\n",
        "predictions = (lb.inverse_transform((predictions)))\n",
        "predictions = pd.DataFrame({'Predicted Values': predictions}) \n",
        "\n",
        "# ACTUAL LABELS\n",
        "TRUE = y_test.argmax(axis=1)\n",
        "TRUE = TRUE.astype(int).flatten()\n",
        "TRUE = (lb.inverse_transform((TRUE)))\n",
        "TRUE = pd.DataFrame({'TRUE Values': TRUE})\n",
        "\n",
        "# COMBINE PREDICTION AND ACTUAL LABELS\n",
        "finaldf = TRUE.join(predictions)\n",
        "finaldf[40:50] \n",
        "# CREATE CONFUSION MATRIX OF ACTUAL VS. PREDICTION -SGD-MFCC\n",
        "cm = confusion_matrix(TRUE, predictions)\n",
        "plt.figure(figsize = (9, 7))\n",
        "plt.rcParams['figure.dpi'] = 150 \n",
        "cm = pd.DataFrame(cm , index = [i for i in lb.classes_] , columns = [i for i in lb.classes_])\n",
        "ax = sns.heatmap(cm, linecolor='white', cmap='Accent', linewidth=1, annot=True, fmt='')\n",
        "bottom, top = ax.get_ylim()\n",
        "ax.set_ylim(bottom + 0.6, top - 0.6)\n",
        "plt.title('Confusion Matrix', size=20)\n",
        "plt.xlabel('Predicted Classes', size=15)\n",
        "plt.ylabel('True Classes', size=15)\n",
        "plt.savefig('Initial_Model_Confusion_Matrix.png')\n",
        "plt.show()   \n",
        "print(classification_report(TRUE, predictions, target_names = ['Angry', 'Fear', 'Happy', 'Neutral', 'Sad']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 0s 14ms/step - loss: 3.4769 - accuracy: 0.5794\n",
            "Loss of the model is -  3.4769375324249268\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 3.4769 - accuracy: 0.5794\n",
            "Accuracy of the model is -  57.94392228126526 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 900x750 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 900x750 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1350x1050 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Angry       0.60      0.62      0.61        39\n",
            "        Fear       0.50      0.53      0.52        15\n",
            "       Happy       0.58      0.35      0.44        20\n",
            "     Neutral       0.46      0.55      0.50        11\n",
            "         Sad       0.65      0.77      0.71        22\n",
            "\n",
            "    accuracy                           0.58       107\n",
            "   macro avg       0.56      0.56      0.55       107\n",
            "weighted avg       0.58      0.58      0.57       107\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "id": "_7pBLwdi9ZuN",
        "outputId": "1b07ac56-6fec-45ce-f648-92e053058fe5"
      },
      "source": [
        "# ITERATE OVER ALL AUDIO FILES AND EXTRACT LOG MEL SPECTROGRAM MEAN VALUES INTO DF FOR MODELING\n",
        "import pandas as pd \n",
        "df_mel = pd.DataFrame(columns=['mel_spectrogram'])\n",
        "\n",
        "counter=0\n",
        "\n",
        "for index,path in enumerate(ref.path):\n",
        "    X, sample_rate = librosa.load(path, res_type='kaiser_fast',duration=3,sr=44100,offset=0.5)\n",
        "    \n",
        "    #get the mel-scaled spectrogram (ransform both the y-axis (frequency) to log scale, and the “color” axis (amplitude) to Decibels, which is kinda the log scale of amplitudes.)\n",
        "    spectrogram = librosa.feature.melspectrogram(y=X, sr=sample_rate, n_mels=128,fmax=8000) \n",
        "    db_spec = librosa.power_to_db(spectrogram)\n",
        "    #temporally average spectrogram\n",
        "    log_spectrogram = np.mean(db_spec, axis = 0)\n",
        "        \n",
        "    # Mel-frequency cepstral coefficients (MFCCs)\n",
        "#     mfcc = librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=13)\n",
        "#     mfcc=np.mean(mfcc,axis=0)\n",
        "    \n",
        "    # compute chroma energy (pertains to 12 different pitch classes)\n",
        "#     chroma = librosa.feature.chroma_stft(y=X, sr=sample_rate)\n",
        "#     chroma = np.mean(chroma, axis = 0)\n",
        "\n",
        "    # compute spectral contrast\n",
        "#     contrast = librosa.feature.spectral_contrast(y=X, sr=sample_rate)\n",
        "#     contrast = np.mean(contrast, axis= 0)\n",
        "\n",
        "    # compute zero-crossing-rate (zcr:the zcr is the rate of sign changes along a signal i.e.m the rate at \n",
        "#     which the signal changes from positive to negative or back - separation of voiced andunvoiced speech.)\n",
        "#     zcr = librosa.feature.zero_crossing_rate(y=X)\n",
        "#     zcr = np.mean(zcr, axis= 0)\n",
        "    \n",
        "    df_mel.loc[counter] = [log_spectrogram]\n",
        "    counter=counter+1   \n",
        "\n",
        "print(len(df_mel))\n",
        "df_mel.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "535\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mel_spectrogram</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[-18.804665, -21.521597, -27.88592, -24.218561...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[-32.407764, -32.98968, -31.687258, -31.718386...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[-36.368206, -32.799015, -33.12451, -35.60933,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[-46.121796, -42.230083, -31.603167, -25.71852...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[-14.672596, -17.095194, -24.047354, -28.71509...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     mel_spectrogram\n",
              "0  [-18.804665, -21.521597, -27.88592, -24.218561...\n",
              "1  [-32.407764, -32.98968, -31.687258, -31.718386...\n",
              "2  [-36.368206, -32.799015, -33.12451, -35.60933,...\n",
              "3  [-46.121796, -42.230083, -31.603167, -25.71852...\n",
              "4  [-14.672596, -17.095194, -24.047354, -28.71509..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "xss_GUsk9knK",
        "outputId": "cf4435ad-d469-4fad-c416-eb16c88ef3fa"
      },
      "source": [
        "# Now extract the mean bands to its own feature columns\n",
        "df = pd.concat([ref,pd.DataFrame(df_mel['mel_spectrogram'].values.tolist())],axis=1)\n",
        "df[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>labels</th>\n",
              "      <th>source</th>\n",
              "      <th>path</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>...</th>\n",
              "      <th>219</th>\n",
              "      <th>220</th>\n",
              "      <th>221</th>\n",
              "      <th>222</th>\n",
              "      <th>223</th>\n",
              "      <th>224</th>\n",
              "      <th>225</th>\n",
              "      <th>226</th>\n",
              "      <th>227</th>\n",
              "      <th>228</th>\n",
              "      <th>229</th>\n",
              "      <th>230</th>\n",
              "      <th>231</th>\n",
              "      <th>232</th>\n",
              "      <th>233</th>\n",
              "      <th>234</th>\n",
              "      <th>235</th>\n",
              "      <th>236</th>\n",
              "      <th>237</th>\n",
              "      <th>238</th>\n",
              "      <th>239</th>\n",
              "      <th>240</th>\n",
              "      <th>241</th>\n",
              "      <th>242</th>\n",
              "      <th>243</th>\n",
              "      <th>244</th>\n",
              "      <th>245</th>\n",
              "      <th>246</th>\n",
              "      <th>247</th>\n",
              "      <th>248</th>\n",
              "      <th>249</th>\n",
              "      <th>250</th>\n",
              "      <th>251</th>\n",
              "      <th>252</th>\n",
              "      <th>253</th>\n",
              "      <th>254</th>\n",
              "      <th>255</th>\n",
              "      <th>256</th>\n",
              "      <th>257</th>\n",
              "      <th>258</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Fear</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis...</td>\n",
              "      <td>-18.804665</td>\n",
              "      <td>-21.521597</td>\n",
              "      <td>-27.885920</td>\n",
              "      <td>-24.218561</td>\n",
              "      <td>-22.943007</td>\n",
              "      <td>-25.174477</td>\n",
              "      <td>-26.425821</td>\n",
              "      <td>-27.606398</td>\n",
              "      <td>-29.549362</td>\n",
              "      <td>-31.485579</td>\n",
              "      <td>-32.047272</td>\n",
              "      <td>-30.873663</td>\n",
              "      <td>-28.708744</td>\n",
              "      <td>-23.172752</td>\n",
              "      <td>-14.614209</td>\n",
              "      <td>-11.226435</td>\n",
              "      <td>-12.470586</td>\n",
              "      <td>-16.853674</td>\n",
              "      <td>-18.633949</td>\n",
              "      <td>-21.549841</td>\n",
              "      <td>-28.700449</td>\n",
              "      <td>-35.497490</td>\n",
              "      <td>-37.798492</td>\n",
              "      <td>-38.668697</td>\n",
              "      <td>-44.132996</td>\n",
              "      <td>-47.179703</td>\n",
              "      <td>-24.534758</td>\n",
              "      <td>-14.004228</td>\n",
              "      <td>-12.125667</td>\n",
              "      <td>-14.669782</td>\n",
              "      <td>-16.068775</td>\n",
              "      <td>-14.983406</td>\n",
              "      <td>-13.359447</td>\n",
              "      <td>-13.777181</td>\n",
              "      <td>-16.891363</td>\n",
              "      <td>-22.120945</td>\n",
              "      <td>-22.772476</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Happy</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis...</td>\n",
              "      <td>-32.407764</td>\n",
              "      <td>-32.989681</td>\n",
              "      <td>-31.687258</td>\n",
              "      <td>-31.718386</td>\n",
              "      <td>-27.894558</td>\n",
              "      <td>-21.176987</td>\n",
              "      <td>-18.267330</td>\n",
              "      <td>-19.207891</td>\n",
              "      <td>-20.612478</td>\n",
              "      <td>-22.750566</td>\n",
              "      <td>-24.493120</td>\n",
              "      <td>-23.486425</td>\n",
              "      <td>-19.540703</td>\n",
              "      <td>-18.870535</td>\n",
              "      <td>-20.576288</td>\n",
              "      <td>-22.270704</td>\n",
              "      <td>-20.765713</td>\n",
              "      <td>-21.762819</td>\n",
              "      <td>-27.541477</td>\n",
              "      <td>-40.208279</td>\n",
              "      <td>-46.904926</td>\n",
              "      <td>-47.860714</td>\n",
              "      <td>-47.553806</td>\n",
              "      <td>-50.302410</td>\n",
              "      <td>-32.184231</td>\n",
              "      <td>-18.020641</td>\n",
              "      <td>-10.971907</td>\n",
              "      <td>-8.587826</td>\n",
              "      <td>-8.391054</td>\n",
              "      <td>-8.129248</td>\n",
              "      <td>-8.916072</td>\n",
              "      <td>-10.246510</td>\n",
              "      <td>-12.216118</td>\n",
              "      <td>-17.439548</td>\n",
              "      <td>-25.416601</td>\n",
              "      <td>-29.751011</td>\n",
              "      <td>-32.402962</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Happy</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis...</td>\n",
              "      <td>-36.368206</td>\n",
              "      <td>-32.799015</td>\n",
              "      <td>-33.124512</td>\n",
              "      <td>-35.609329</td>\n",
              "      <td>-37.013054</td>\n",
              "      <td>-36.065643</td>\n",
              "      <td>-30.478870</td>\n",
              "      <td>-25.162720</td>\n",
              "      <td>-24.200771</td>\n",
              "      <td>-25.609528</td>\n",
              "      <td>-27.598541</td>\n",
              "      <td>-29.231234</td>\n",
              "      <td>-28.609461</td>\n",
              "      <td>-27.733837</td>\n",
              "      <td>-26.992952</td>\n",
              "      <td>-25.937771</td>\n",
              "      <td>-24.892262</td>\n",
              "      <td>-19.700335</td>\n",
              "      <td>-18.812206</td>\n",
              "      <td>-19.070112</td>\n",
              "      <td>-19.379847</td>\n",
              "      <td>-21.385183</td>\n",
              "      <td>-24.153214</td>\n",
              "      <td>-27.070450</td>\n",
              "      <td>-29.167181</td>\n",
              "      <td>-29.226816</td>\n",
              "      <td>-32.317734</td>\n",
              "      <td>-42.996925</td>\n",
              "      <td>-49.439175</td>\n",
              "      <td>-24.559893</td>\n",
              "      <td>-18.466587</td>\n",
              "      <td>-19.343744</td>\n",
              "      <td>-17.820953</td>\n",
              "      <td>-15.435842</td>\n",
              "      <td>-12.484180</td>\n",
              "      <td>-9.015182</td>\n",
              "      <td>-9.040695</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Happy</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis...</td>\n",
              "      <td>-46.121796</td>\n",
              "      <td>-42.230083</td>\n",
              "      <td>-31.603167</td>\n",
              "      <td>-25.718521</td>\n",
              "      <td>-25.146307</td>\n",
              "      <td>-27.747725</td>\n",
              "      <td>-30.559526</td>\n",
              "      <td>-32.077904</td>\n",
              "      <td>-33.075161</td>\n",
              "      <td>-34.002197</td>\n",
              "      <td>-33.009682</td>\n",
              "      <td>-24.742752</td>\n",
              "      <td>-20.337015</td>\n",
              "      <td>-22.896070</td>\n",
              "      <td>-27.084166</td>\n",
              "      <td>-24.767179</td>\n",
              "      <td>-21.932322</td>\n",
              "      <td>-26.415136</td>\n",
              "      <td>-36.652470</td>\n",
              "      <td>-38.335716</td>\n",
              "      <td>-36.294380</td>\n",
              "      <td>-39.304523</td>\n",
              "      <td>-47.361305</td>\n",
              "      <td>-25.687342</td>\n",
              "      <td>-14.328912</td>\n",
              "      <td>-9.082014</td>\n",
              "      <td>-10.017227</td>\n",
              "      <td>-12.665390</td>\n",
              "      <td>-12.624085</td>\n",
              "      <td>-13.286325</td>\n",
              "      <td>-11.966488</td>\n",
              "      <td>-12.537272</td>\n",
              "      <td>-18.323147</td>\n",
              "      <td>-25.694345</td>\n",
              "      <td>-31.400402</td>\n",
              "      <td>-37.693184</td>\n",
              "      <td>-47.064201</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Neutral</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis...</td>\n",
              "      <td>-14.672596</td>\n",
              "      <td>-17.095194</td>\n",
              "      <td>-24.047354</td>\n",
              "      <td>-28.715092</td>\n",
              "      <td>-29.135523</td>\n",
              "      <td>-33.275944</td>\n",
              "      <td>-44.504860</td>\n",
              "      <td>-27.663935</td>\n",
              "      <td>-13.682248</td>\n",
              "      <td>-9.503767</td>\n",
              "      <td>-10.787056</td>\n",
              "      <td>-12.582223</td>\n",
              "      <td>-15.174791</td>\n",
              "      <td>-18.706068</td>\n",
              "      <td>-20.964104</td>\n",
              "      <td>-23.312185</td>\n",
              "      <td>-22.561010</td>\n",
              "      <td>-25.565147</td>\n",
              "      <td>-38.795200</td>\n",
              "      <td>-48.254826</td>\n",
              "      <td>-23.067911</td>\n",
              "      <td>-13.832280</td>\n",
              "      <td>-13.614727</td>\n",
              "      <td>-18.464849</td>\n",
              "      <td>-20.866573</td>\n",
              "      <td>-21.200768</td>\n",
              "      <td>-25.261509</td>\n",
              "      <td>-29.797005</td>\n",
              "      <td>-30.029488</td>\n",
              "      <td>-28.760075</td>\n",
              "      <td>-25.979498</td>\n",
              "      <td>-21.505941</td>\n",
              "      <td>-16.722641</td>\n",
              "      <td>-13.732438</td>\n",
              "      <td>-14.346529</td>\n",
              "      <td>-13.335444</td>\n",
              "      <td>-11.233666</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 262 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    labels source  ... 257  258\n",
              "0     Fear    EMO  ... NaN  NaN\n",
              "1    Happy    EMO  ... NaN  NaN\n",
              "2    Happy    EMO  ... NaN  NaN\n",
              "3    Happy    EMO  ... NaN  NaN\n",
              "4  Neutral    EMO  ... NaN  NaN\n",
              "\n",
              "[5 rows x 262 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "EJmPbe9p9zav",
        "outputId": "af702e2a-b9a7-429f-b687-6cd4588921b8"
      },
      "source": [
        "# Split between train and test \n",
        "X_train, X_test, y_train, y_test = train_test_split(df.drop(['path','labels','source'],axis=1)\n",
        "                                                    , df.labels\n",
        "                                                    , test_size=0.20\n",
        "                                                    , shuffle=True\n",
        "                                                    , random_state=42\n",
        "                                                   )\n",
        "\n",
        "# Lets see how the data present itself before normalisation \n",
        "X_train[150:160]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>219</th>\n",
              "      <th>220</th>\n",
              "      <th>221</th>\n",
              "      <th>222</th>\n",
              "      <th>223</th>\n",
              "      <th>224</th>\n",
              "      <th>225</th>\n",
              "      <th>226</th>\n",
              "      <th>227</th>\n",
              "      <th>228</th>\n",
              "      <th>229</th>\n",
              "      <th>230</th>\n",
              "      <th>231</th>\n",
              "      <th>232</th>\n",
              "      <th>233</th>\n",
              "      <th>234</th>\n",
              "      <th>235</th>\n",
              "      <th>236</th>\n",
              "      <th>237</th>\n",
              "      <th>238</th>\n",
              "      <th>239</th>\n",
              "      <th>240</th>\n",
              "      <th>241</th>\n",
              "      <th>242</th>\n",
              "      <th>243</th>\n",
              "      <th>244</th>\n",
              "      <th>245</th>\n",
              "      <th>246</th>\n",
              "      <th>247</th>\n",
              "      <th>248</th>\n",
              "      <th>249</th>\n",
              "      <th>250</th>\n",
              "      <th>251</th>\n",
              "      <th>252</th>\n",
              "      <th>253</th>\n",
              "      <th>254</th>\n",
              "      <th>255</th>\n",
              "      <th>256</th>\n",
              "      <th>257</th>\n",
              "      <th>258</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>441</th>\n",
              "      <td>-13.191162</td>\n",
              "      <td>-17.412943</td>\n",
              "      <td>-24.742369</td>\n",
              "      <td>-25.107763</td>\n",
              "      <td>-17.959257</td>\n",
              "      <td>-12.717484</td>\n",
              "      <td>-12.783646</td>\n",
              "      <td>-15.346880</td>\n",
              "      <td>-15.822100</td>\n",
              "      <td>-10.258445</td>\n",
              "      <td>-7.173550</td>\n",
              "      <td>-7.117704</td>\n",
              "      <td>-8.526874</td>\n",
              "      <td>-8.349070</td>\n",
              "      <td>-8.227021</td>\n",
              "      <td>-8.822204</td>\n",
              "      <td>-11.211225</td>\n",
              "      <td>-20.789053</td>\n",
              "      <td>-34.036331</td>\n",
              "      <td>-42.310688</td>\n",
              "      <td>-44.034744</td>\n",
              "      <td>-39.574261</td>\n",
              "      <td>-36.159142</td>\n",
              "      <td>-33.453831</td>\n",
              "      <td>-29.980265</td>\n",
              "      <td>-26.202166</td>\n",
              "      <td>-24.087250</td>\n",
              "      <td>-22.496914</td>\n",
              "      <td>-15.548408</td>\n",
              "      <td>-10.719373</td>\n",
              "      <td>-10.887609</td>\n",
              "      <td>-11.767865</td>\n",
              "      <td>-11.220654</td>\n",
              "      <td>-11.309484</td>\n",
              "      <td>-11.972555</td>\n",
              "      <td>-14.048397</td>\n",
              "      <td>-13.898256</td>\n",
              "      <td>-13.996491</td>\n",
              "      <td>-14.898280</td>\n",
              "      <td>-17.143282</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>321</th>\n",
              "      <td>-1.592765</td>\n",
              "      <td>-2.214412</td>\n",
              "      <td>-4.411089</td>\n",
              "      <td>-4.603294</td>\n",
              "      <td>-8.027392</td>\n",
              "      <td>-15.837214</td>\n",
              "      <td>-19.350735</td>\n",
              "      <td>-19.892469</td>\n",
              "      <td>-21.878798</td>\n",
              "      <td>-21.020311</td>\n",
              "      <td>-19.273434</td>\n",
              "      <td>-18.574322</td>\n",
              "      <td>-19.740133</td>\n",
              "      <td>-15.958378</td>\n",
              "      <td>-12.353106</td>\n",
              "      <td>-10.549204</td>\n",
              "      <td>-10.782230</td>\n",
              "      <td>-12.114081</td>\n",
              "      <td>-11.630973</td>\n",
              "      <td>-10.334807</td>\n",
              "      <td>-10.133203</td>\n",
              "      <td>-10.327623</td>\n",
              "      <td>-10.550451</td>\n",
              "      <td>-11.779170</td>\n",
              "      <td>-13.768473</td>\n",
              "      <td>-15.215566</td>\n",
              "      <td>-15.886226</td>\n",
              "      <td>-14.640537</td>\n",
              "      <td>-13.317152</td>\n",
              "      <td>-19.360727</td>\n",
              "      <td>-39.222324</td>\n",
              "      <td>-44.826099</td>\n",
              "      <td>-20.196547</td>\n",
              "      <td>-9.857969</td>\n",
              "      <td>-8.191421</td>\n",
              "      <td>-8.862311</td>\n",
              "      <td>-6.713652</td>\n",
              "      <td>-5.551036</td>\n",
              "      <td>-5.385560</td>\n",
              "      <td>-6.958497</td>\n",
              "      <td>...</td>\n",
              "      <td>-12.014832</td>\n",
              "      <td>-12.266513</td>\n",
              "      <td>-12.751473</td>\n",
              "      <td>-16.449165</td>\n",
              "      <td>-21.407909</td>\n",
              "      <td>-22.443647</td>\n",
              "      <td>-18.847073</td>\n",
              "      <td>-15.85805</td>\n",
              "      <td>-14.654199</td>\n",
              "      <td>-14.714111</td>\n",
              "      <td>-16.135056</td>\n",
              "      <td>-17.128801</td>\n",
              "      <td>-17.32538</td>\n",
              "      <td>-16.412991</td>\n",
              "      <td>-14.946004</td>\n",
              "      <td>-14.428662</td>\n",
              "      <td>-13.675397</td>\n",
              "      <td>-11.212651</td>\n",
              "      <td>-8.197986</td>\n",
              "      <td>-6.278272</td>\n",
              "      <td>-5.903176</td>\n",
              "      <td>-5.845412</td>\n",
              "      <td>-5.876747</td>\n",
              "      <td>-7.46554</td>\n",
              "      <td>-8.890612</td>\n",
              "      <td>-9.864847</td>\n",
              "      <td>-10.185379</td>\n",
              "      <td>-10.732654</td>\n",
              "      <td>-11.958053</td>\n",
              "      <td>-12.402618</td>\n",
              "      <td>-14.549863</td>\n",
              "      <td>-18.085485</td>\n",
              "      <td>-20.594572</td>\n",
              "      <td>-20.117603</td>\n",
              "      <td>-18.629053</td>\n",
              "      <td>-19.049086</td>\n",
              "      <td>-19.125256</td>\n",
              "      <td>-17.715269</td>\n",
              "      <td>-15.240993</td>\n",
              "      <td>-13.151398</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>417</th>\n",
              "      <td>-12.716684</td>\n",
              "      <td>-15.351578</td>\n",
              "      <td>-24.829851</td>\n",
              "      <td>-27.959824</td>\n",
              "      <td>-30.245256</td>\n",
              "      <td>-30.974468</td>\n",
              "      <td>-31.381561</td>\n",
              "      <td>-32.478737</td>\n",
              "      <td>-31.918455</td>\n",
              "      <td>-29.376293</td>\n",
              "      <td>-19.700954</td>\n",
              "      <td>-10.590706</td>\n",
              "      <td>-6.740655</td>\n",
              "      <td>-6.866120</td>\n",
              "      <td>-7.246089</td>\n",
              "      <td>-9.357801</td>\n",
              "      <td>-13.327457</td>\n",
              "      <td>-16.531403</td>\n",
              "      <td>-20.591827</td>\n",
              "      <td>-26.780699</td>\n",
              "      <td>-30.512318</td>\n",
              "      <td>-27.093277</td>\n",
              "      <td>-25.889893</td>\n",
              "      <td>-32.716293</td>\n",
              "      <td>-29.014315</td>\n",
              "      <td>-27.540586</td>\n",
              "      <td>-19.247074</td>\n",
              "      <td>-13.761534</td>\n",
              "      <td>-14.754523</td>\n",
              "      <td>-17.918625</td>\n",
              "      <td>-16.688475</td>\n",
              "      <td>-14.447861</td>\n",
              "      <td>-14.255684</td>\n",
              "      <td>-13.435139</td>\n",
              "      <td>-14.392236</td>\n",
              "      <td>-19.530188</td>\n",
              "      <td>-22.415804</td>\n",
              "      <td>-26.156948</td>\n",
              "      <td>-29.989460</td>\n",
              "      <td>-28.223837</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>297</th>\n",
              "      <td>-20.364967</td>\n",
              "      <td>-18.610880</td>\n",
              "      <td>-17.983961</td>\n",
              "      <td>-16.277058</td>\n",
              "      <td>-16.297949</td>\n",
              "      <td>-23.436283</td>\n",
              "      <td>-39.288864</td>\n",
              "      <td>-29.974766</td>\n",
              "      <td>-10.909477</td>\n",
              "      <td>-5.081419</td>\n",
              "      <td>-3.588921</td>\n",
              "      <td>-4.342592</td>\n",
              "      <td>-5.321337</td>\n",
              "      <td>-5.092302</td>\n",
              "      <td>-5.843002</td>\n",
              "      <td>-7.711974</td>\n",
              "      <td>-7.439525</td>\n",
              "      <td>-6.974631</td>\n",
              "      <td>-6.682263</td>\n",
              "      <td>-7.361845</td>\n",
              "      <td>-9.800033</td>\n",
              "      <td>-14.259489</td>\n",
              "      <td>-14.091470</td>\n",
              "      <td>-14.954602</td>\n",
              "      <td>-16.044760</td>\n",
              "      <td>-16.780210</td>\n",
              "      <td>-18.428871</td>\n",
              "      <td>-20.193651</td>\n",
              "      <td>-22.561422</td>\n",
              "      <td>-23.766926</td>\n",
              "      <td>-24.323439</td>\n",
              "      <td>-25.028746</td>\n",
              "      <td>-25.630993</td>\n",
              "      <td>-26.376675</td>\n",
              "      <td>-26.852791</td>\n",
              "      <td>-28.205006</td>\n",
              "      <td>-29.845743</td>\n",
              "      <td>-22.047607</td>\n",
              "      <td>-13.895200</td>\n",
              "      <td>-10.148205</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>-11.744615</td>\n",
              "      <td>-12.375156</td>\n",
              "      <td>-14.608455</td>\n",
              "      <td>-12.468637</td>\n",
              "      <td>-13.061885</td>\n",
              "      <td>-15.994761</td>\n",
              "      <td>-15.004396</td>\n",
              "      <td>-10.737443</td>\n",
              "      <td>-9.621335</td>\n",
              "      <td>-11.533262</td>\n",
              "      <td>-14.864107</td>\n",
              "      <td>-23.529078</td>\n",
              "      <td>-30.127514</td>\n",
              "      <td>-30.514605</td>\n",
              "      <td>-39.144562</td>\n",
              "      <td>-37.796673</td>\n",
              "      <td>-14.742793</td>\n",
              "      <td>-6.934121</td>\n",
              "      <td>-4.546621</td>\n",
              "      <td>-3.727728</td>\n",
              "      <td>-3.766431</td>\n",
              "      <td>-4.492877</td>\n",
              "      <td>-8.329901</td>\n",
              "      <td>-12.593942</td>\n",
              "      <td>-13.873358</td>\n",
              "      <td>-15.047528</td>\n",
              "      <td>-16.209633</td>\n",
              "      <td>-21.268467</td>\n",
              "      <td>-22.781462</td>\n",
              "      <td>-12.642288</td>\n",
              "      <td>-11.019477</td>\n",
              "      <td>-9.739347</td>\n",
              "      <td>-10.113716</td>\n",
              "      <td>-12.386333</td>\n",
              "      <td>-12.380766</td>\n",
              "      <td>-11.005539</td>\n",
              "      <td>-10.920540</td>\n",
              "      <td>-10.363463</td>\n",
              "      <td>-9.074458</td>\n",
              "      <td>-12.389512</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>139</th>\n",
              "      <td>-6.723027</td>\n",
              "      <td>-8.061245</td>\n",
              "      <td>-10.093167</td>\n",
              "      <td>-9.288959</td>\n",
              "      <td>-8.547454</td>\n",
              "      <td>-9.199635</td>\n",
              "      <td>-10.364801</td>\n",
              "      <td>-11.329092</td>\n",
              "      <td>-11.611039</td>\n",
              "      <td>-13.349246</td>\n",
              "      <td>-16.629868</td>\n",
              "      <td>-21.148609</td>\n",
              "      <td>-21.104485</td>\n",
              "      <td>-21.864082</td>\n",
              "      <td>-21.262508</td>\n",
              "      <td>-20.508434</td>\n",
              "      <td>-20.684471</td>\n",
              "      <td>-20.639248</td>\n",
              "      <td>-20.511265</td>\n",
              "      <td>-21.299202</td>\n",
              "      <td>-23.469700</td>\n",
              "      <td>-24.914646</td>\n",
              "      <td>-26.326927</td>\n",
              "      <td>-28.141773</td>\n",
              "      <td>-29.240009</td>\n",
              "      <td>-30.610973</td>\n",
              "      <td>-31.570023</td>\n",
              "      <td>-31.505951</td>\n",
              "      <td>-29.737614</td>\n",
              "      <td>-28.254139</td>\n",
              "      <td>-28.847733</td>\n",
              "      <td>-30.905777</td>\n",
              "      <td>-29.305676</td>\n",
              "      <td>-27.477634</td>\n",
              "      <td>-30.214500</td>\n",
              "      <td>-36.489941</td>\n",
              "      <td>-43.652676</td>\n",
              "      <td>-44.198139</td>\n",
              "      <td>-20.398396</td>\n",
              "      <td>-14.406167</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>253</th>\n",
              "      <td>-9.062586</td>\n",
              "      <td>-12.493947</td>\n",
              "      <td>-18.453823</td>\n",
              "      <td>-18.643307</td>\n",
              "      <td>-19.676199</td>\n",
              "      <td>-18.623291</td>\n",
              "      <td>-16.728733</td>\n",
              "      <td>-15.175091</td>\n",
              "      <td>-13.898046</td>\n",
              "      <td>-12.602225</td>\n",
              "      <td>-11.733054</td>\n",
              "      <td>-10.440107</td>\n",
              "      <td>-7.737149</td>\n",
              "      <td>-5.261915</td>\n",
              "      <td>-5.180425</td>\n",
              "      <td>-5.974023</td>\n",
              "      <td>-6.440972</td>\n",
              "      <td>-7.397505</td>\n",
              "      <td>-8.871618</td>\n",
              "      <td>-11.678663</td>\n",
              "      <td>-17.928761</td>\n",
              "      <td>-29.826679</td>\n",
              "      <td>-34.315067</td>\n",
              "      <td>-34.776920</td>\n",
              "      <td>-35.035599</td>\n",
              "      <td>-32.437084</td>\n",
              "      <td>-6.758660</td>\n",
              "      <td>-1.117421</td>\n",
              "      <td>-3.910645</td>\n",
              "      <td>-9.474134</td>\n",
              "      <td>-10.930087</td>\n",
              "      <td>-12.543316</td>\n",
              "      <td>-13.856678</td>\n",
              "      <td>-13.891170</td>\n",
              "      <td>-13.896376</td>\n",
              "      <td>-15.678681</td>\n",
              "      <td>-16.468050</td>\n",
              "      <td>-16.087189</td>\n",
              "      <td>-18.656738</td>\n",
              "      <td>-20.402750</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>519</th>\n",
              "      <td>-10.904872</td>\n",
              "      <td>-13.345657</td>\n",
              "      <td>-17.893707</td>\n",
              "      <td>-8.954350</td>\n",
              "      <td>-3.736981</td>\n",
              "      <td>-3.968898</td>\n",
              "      <td>-5.677609</td>\n",
              "      <td>-6.533086</td>\n",
              "      <td>-7.110573</td>\n",
              "      <td>-6.474252</td>\n",
              "      <td>-6.516115</td>\n",
              "      <td>-10.071259</td>\n",
              "      <td>-15.569845</td>\n",
              "      <td>-17.227894</td>\n",
              "      <td>-17.126108</td>\n",
              "      <td>-15.262486</td>\n",
              "      <td>-13.145551</td>\n",
              "      <td>-11.090733</td>\n",
              "      <td>-9.915433</td>\n",
              "      <td>-10.253722</td>\n",
              "      <td>-10.777203</td>\n",
              "      <td>-10.689022</td>\n",
              "      <td>-9.520943</td>\n",
              "      <td>-10.446859</td>\n",
              "      <td>-17.070415</td>\n",
              "      <td>-31.984196</td>\n",
              "      <td>-26.976128</td>\n",
              "      <td>-12.169219</td>\n",
              "      <td>-7.878785</td>\n",
              "      <td>-6.722538</td>\n",
              "      <td>-7.256309</td>\n",
              "      <td>-8.623678</td>\n",
              "      <td>-10.392920</td>\n",
              "      <td>-11.561788</td>\n",
              "      <td>-13.332427</td>\n",
              "      <td>-14.229749</td>\n",
              "      <td>-13.402295</td>\n",
              "      <td>-17.169683</td>\n",
              "      <td>-30.243141</td>\n",
              "      <td>-36.138199</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>-14.477571</td>\n",
              "      <td>-16.002350</td>\n",
              "      <td>-18.644583</td>\n",
              "      <td>-19.097099</td>\n",
              "      <td>-19.534760</td>\n",
              "      <td>-14.113576</td>\n",
              "      <td>-9.339128</td>\n",
              "      <td>-9.666578</td>\n",
              "      <td>-10.024021</td>\n",
              "      <td>-15.637214</td>\n",
              "      <td>-33.303665</td>\n",
              "      <td>-24.102058</td>\n",
              "      <td>-15.282808</td>\n",
              "      <td>-15.501317</td>\n",
              "      <td>-19.367413</td>\n",
              "      <td>-21.333887</td>\n",
              "      <td>-20.817957</td>\n",
              "      <td>-14.358315</td>\n",
              "      <td>-9.350145</td>\n",
              "      <td>-7.803526</td>\n",
              "      <td>-6.898863</td>\n",
              "      <td>-8.562400</td>\n",
              "      <td>-12.566275</td>\n",
              "      <td>-17.399834</td>\n",
              "      <td>-18.361633</td>\n",
              "      <td>-16.646349</td>\n",
              "      <td>-18.609779</td>\n",
              "      <td>-16.992348</td>\n",
              "      <td>-16.065023</td>\n",
              "      <td>-10.960831</td>\n",
              "      <td>-6.963970</td>\n",
              "      <td>-4.731878</td>\n",
              "      <td>-3.955044</td>\n",
              "      <td>-6.422872</td>\n",
              "      <td>-16.365011</td>\n",
              "      <td>-36.515907</td>\n",
              "      <td>-41.909306</td>\n",
              "      <td>-43.934185</td>\n",
              "      <td>-45.404251</td>\n",
              "      <td>-41.009636</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111</th>\n",
              "      <td>-42.475464</td>\n",
              "      <td>-28.780304</td>\n",
              "      <td>-22.017761</td>\n",
              "      <td>-19.465897</td>\n",
              "      <td>-18.146711</td>\n",
              "      <td>-16.872749</td>\n",
              "      <td>-17.951916</td>\n",
              "      <td>-15.767006</td>\n",
              "      <td>-14.827606</td>\n",
              "      <td>-18.375690</td>\n",
              "      <td>-23.734240</td>\n",
              "      <td>-30.592152</td>\n",
              "      <td>-31.148943</td>\n",
              "      <td>-26.365679</td>\n",
              "      <td>-22.968023</td>\n",
              "      <td>-24.485415</td>\n",
              "      <td>-28.024675</td>\n",
              "      <td>-29.613668</td>\n",
              "      <td>-29.518122</td>\n",
              "      <td>-29.036875</td>\n",
              "      <td>-28.559492</td>\n",
              "      <td>-30.039312</td>\n",
              "      <td>-35.218796</td>\n",
              "      <td>-37.541721</td>\n",
              "      <td>-37.104164</td>\n",
              "      <td>-35.100357</td>\n",
              "      <td>-30.735695</td>\n",
              "      <td>-28.897301</td>\n",
              "      <td>-29.733597</td>\n",
              "      <td>-30.054611</td>\n",
              "      <td>-27.733130</td>\n",
              "      <td>-24.325466</td>\n",
              "      <td>-25.864487</td>\n",
              "      <td>-30.892752</td>\n",
              "      <td>-30.871346</td>\n",
              "      <td>-31.664890</td>\n",
              "      <td>-30.176968</td>\n",
              "      <td>-29.012527</td>\n",
              "      <td>-30.759102</td>\n",
              "      <td>-31.307381</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 259 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           0          1          2    ...        256        257        258\n",
              "441 -13.191162 -17.412943 -24.742369  ...        NaN        NaN        NaN\n",
              "321  -1.592765  -2.214412  -4.411089  ... -17.715269 -15.240993 -13.151398\n",
              "417 -12.716684 -15.351578 -24.829851  ...        NaN        NaN        NaN\n",
              "297 -20.364967 -18.610880 -17.983961  ...        NaN        NaN        NaN\n",
              "36  -11.744615 -12.375156 -14.608455  ...        NaN        NaN        NaN\n",
              "139  -6.723027  -8.061245 -10.093167  ...        NaN        NaN        NaN\n",
              "253  -9.062586 -12.493947 -18.453823  ...        NaN        NaN        NaN\n",
              "519 -10.904872 -13.345657 -17.893707  ...        NaN        NaN        NaN\n",
              "59  -14.477571 -16.002350 -18.644583  ...        NaN        NaN        NaN\n",
              "111 -42.475464 -28.780304 -22.017761  ...        NaN        NaN        NaN\n",
              "\n",
              "[10 rows x 259 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "df1Jo_oZ92WR",
        "outputId": "e343e5be-beb0-4a15-aa51-0b2f0e177e49"
      },
      "source": [
        "\n",
        "# NORMALIZE DATA\n",
        "mean = np.mean(X_train, axis=0)\n",
        "std = np.std(X_train, axis=0)\n",
        "X_train = (X_train - mean)/std\n",
        "X_test = (X_test - mean)/std\n",
        "# TURN DATA INTO ARRAYS FOR KERAS\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "X_test = np.array(X_test)\n",
        "y_test = np.array(y_test)\n",
        "# ONE HOT ENCODE THE TARGET\n",
        "# CNN REQUIRES INPUT AND OUTPUT ARE NUMBERS\n",
        "lb = LabelEncoder()\n",
        "y_train = to_categorical(lb.fit_transform(y_train))\n",
        "y_test = to_categorical(lb.fit_transform(y_test))\n",
        "print(y_test[0:10])\n",
        "# RESHAPE DATA TO INCLUDE 3D TENSOR \n",
        "X_train = X_train[:,:,np.newaxis]\n",
        "X_test = X_test[:,:,np.newaxis]\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0.]]\n",
            "(428, 259, 1)\n",
            "(107, 259, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cAufx5aw96KQ",
        "outputId": "d6c68350-dd24-4ad6-de41-0300c722b77f"
      },
      "source": [
        "model = tf.keras.Sequential()\n",
        "model.add(layers.Conv1D(256, kernel_size=(8),strides=1,dilation_rate=1,padding=\"same\", activation='relu', input_shape=(X_train.shape[1],1)))\n",
        "model.add(layers.Conv1D(256, kernel_size=(8),strides=1,activation='relu',dilation_rate=1,kernel_regularizer=l2(0.001), bias_regularizer=l2(0.001)))\n",
        "model.add(layers.MaxPooling1D(pool_size=(2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Conv1D(256, kernel_size=(8),strides=1,dilation_rate=1,padding=\"same\",activation='relu'))\n",
        "model.add(layers.MaxPooling1D(pool_size=(2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.Conv1D(128, kernel_size=(8),strides=1,dilation_rate=1,padding=\"same\",activation='relu'))\n",
        "model.add(layers.MaxPooling1D(pool_size=(2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Conv1D(128, kernel_size=(8),strides=1,dilation_rate=1,padding=\"same\",activation='relu'))\n",
        "model.add(layers.MaxPooling1D(pool_size=(2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Conv1D(128, kernel_size=(8),strides=1,dilation_rate=1,padding=\"same\",activation='relu'))\n",
        "model.add(layers.MaxPooling1D(pool_size=(2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Conv1D(256, kernel_size=(8),strides=1,dilation_rate=1,padding=\"same\",activation='relu'))\n",
        "model.add(layers.MaxPooling1D(pool_size=(2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(512, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(5, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='Adam',metrics=['accuracy'])\n",
        "model.summary()\n",
        "checkpoint = ModelCheckpoint(\"SER_best_initial_model.hdf5\", monitor='val_accuracy', verbose=1, save_best_only=True, mode='max', period=1, save_weights_only=True)\n",
        "model_history=model.fit(X_train,y_train, batch_size=32, epochs=1000, validation_data=(X_test, y_test),callbacks=[checkpoint])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 345, 256)          2304      \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 338, 256)          524544    \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 169, 256)          0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 169, 256)          1024      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 169, 256)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 169, 256)          524544    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 84, 256)           0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 84, 256)           1024      \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 84, 128)           262272    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 42, 128)           0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 42, 128)           512       \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 42, 128)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_4 (Conv1D)            (None, 42, 128)           131200    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_3 (MaxPooling1 (None, 21, 128)           0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 21, 128)           512       \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 21, 128)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_5 (Conv1D)            (None, 21, 128)           131200    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_4 (MaxPooling1 (None, 10, 128)           0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 10, 128)           512       \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 10, 128)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_6 (Conv1D)            (None, 10, 256)           262400    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_5 (MaxPooling1 (None, 5, 256)            0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 5, 256)            1024      \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 5, 256)            0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 5, 256)            0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1280)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               655872    \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 5)                 645       \n",
            "=================================================================\n",
            "Total params: 2,565,253\n",
            "Trainable params: 2,562,949\n",
            "Non-trainable params: 2,304\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/1000\n",
            "14/14 [==============================] - 21s 1s/step - loss: 4.8560 - accuracy: 0.2130 - val_loss: 1.8313 - val_accuracy: 0.4206\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.42056, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 2/1000\n",
            "14/14 [==============================] - 18s 1s/step - loss: 3.0736 - accuracy: 0.2918 - val_loss: 1.8599 - val_accuracy: 0.4953\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.42056 to 0.49533, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 3/1000\n",
            "14/14 [==============================] - 18s 1s/step - loss: 2.5057 - accuracy: 0.3164 - val_loss: 1.9659 - val_accuracy: 0.4673\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.49533\n",
            "Epoch 4/1000\n",
            "14/14 [==============================] - 18s 1s/step - loss: 2.1141 - accuracy: 0.4026 - val_loss: 1.9566 - val_accuracy: 0.4579\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.49533\n",
            "Epoch 5/1000\n",
            "14/14 [==============================] - 17s 1s/step - loss: 2.0043 - accuracy: 0.4105 - val_loss: 1.8013 - val_accuracy: 0.4766\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.49533\n",
            "Epoch 6/1000\n",
            "14/14 [==============================] - 17s 1s/step - loss: 1.9539 - accuracy: 0.3563 - val_loss: 1.7383 - val_accuracy: 0.4766\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.49533\n",
            "Epoch 7/1000\n",
            "14/14 [==============================] - 18s 1s/step - loss: 2.0008 - accuracy: 0.3762 - val_loss: 1.7071 - val_accuracy: 0.4579\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.49533\n",
            "Epoch 8/1000\n",
            "14/14 [==============================] - 18s 1s/step - loss: 1.6399 - accuracy: 0.4653 - val_loss: 1.6949 - val_accuracy: 0.4673\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.49533\n",
            "Epoch 9/1000\n",
            "14/14 [==============================] - 17s 1s/step - loss: 1.7380 - accuracy: 0.4487 - val_loss: 1.6812 - val_accuracy: 0.4860\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.49533\n",
            "Epoch 10/1000\n",
            "14/14 [==============================] - 18s 1s/step - loss: 1.6094 - accuracy: 0.5017 - val_loss: 1.6816 - val_accuracy: 0.4579\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.49533\n",
            "Epoch 11/1000\n",
            "14/14 [==============================] - 18s 1s/step - loss: 1.5838 - accuracy: 0.4745 - val_loss: 1.6765 - val_accuracy: 0.4299\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.49533\n",
            "Epoch 12/1000\n",
            "14/14 [==============================] - 18s 1s/step - loss: 1.5713 - accuracy: 0.4509 - val_loss: 1.6306 - val_accuracy: 0.5047\n",
            "\n",
            "Epoch 00012: val_accuracy improved from 0.49533 to 0.50467, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 13/1000\n",
            "14/14 [==============================] - 18s 1s/step - loss: 1.5418 - accuracy: 0.4913 - val_loss: 1.6253 - val_accuracy: 0.5047\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.50467\n",
            "Epoch 14/1000\n",
            "14/14 [==============================] - 18s 1s/step - loss: 1.5467 - accuracy: 0.4339 - val_loss: 1.6491 - val_accuracy: 0.4953\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.50467\n",
            "Epoch 15/1000\n",
            "14/14 [==============================] - 18s 1s/step - loss: 1.4863 - accuracy: 0.4540 - val_loss: 1.6333 - val_accuracy: 0.4579\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.50467\n",
            "Epoch 16/1000\n",
            "14/14 [==============================] - 18s 1s/step - loss: 1.3785 - accuracy: 0.5008 - val_loss: 1.6083 - val_accuracy: 0.4486\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.50467\n",
            "Epoch 17/1000\n",
            "14/14 [==============================] - 18s 1s/step - loss: 1.4925 - accuracy: 0.4725 - val_loss: 1.5870 - val_accuracy: 0.4673\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.50467\n",
            "Epoch 18/1000\n",
            "14/14 [==============================] - 18s 1s/step - loss: 1.4239 - accuracy: 0.5053 - val_loss: 1.5724 - val_accuracy: 0.5421\n",
            "\n",
            "Epoch 00018: val_accuracy improved from 0.50467 to 0.54206, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 19/1000\n",
            "14/14 [==============================] - 18s 1s/step - loss: 1.5056 - accuracy: 0.5098 - val_loss: 1.5598 - val_accuracy: 0.5514\n",
            "\n",
            "Epoch 00019: val_accuracy improved from 0.54206 to 0.55140, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 20/1000\n",
            "14/14 [==============================] - 18s 1s/step - loss: 1.4852 - accuracy: 0.4458 - val_loss: 1.5495 - val_accuracy: 0.5514\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.55140\n",
            "Epoch 21/1000\n",
            "14/14 [==============================] - 17s 1s/step - loss: 1.4386 - accuracy: 0.5060 - val_loss: 1.5331 - val_accuracy: 0.5234\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.55140\n",
            "Epoch 22/1000\n",
            "14/14 [==============================] - 17s 1s/step - loss: 1.4190 - accuracy: 0.5345 - val_loss: 1.5077 - val_accuracy: 0.5047\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.55140\n",
            "Epoch 23/1000\n",
            "14/14 [==============================] - 18s 1s/step - loss: 1.4607 - accuracy: 0.5023 - val_loss: 1.4965 - val_accuracy: 0.5234\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.55140\n",
            "Epoch 24/1000\n",
            "14/14 [==============================] - 18s 1s/step - loss: 1.4142 - accuracy: 0.4898 - val_loss: 1.5032 - val_accuracy: 0.5234\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.55140\n",
            "Epoch 25/1000\n",
            "14/14 [==============================] - 18s 1s/step - loss: 1.3386 - accuracy: 0.5101 - val_loss: 1.4915 - val_accuracy: 0.5234\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.55140\n",
            "Epoch 26/1000\n",
            "14/14 [==============================] - 18s 1s/step - loss: 1.3582 - accuracy: 0.5407 - val_loss: 1.4606 - val_accuracy: 0.5140\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.55140\n",
            "Epoch 27/1000\n",
            "14/14 [==============================] - 18s 1s/step - loss: 1.3978 - accuracy: 0.5034 - val_loss: 1.4757 - val_accuracy: 0.5514\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.55140\n",
            "Epoch 28/1000\n",
            "14/14 [==============================] - 17s 1s/step - loss: 1.4172 - accuracy: 0.4936 - val_loss: 1.4412 - val_accuracy: 0.5327\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.55140\n",
            "Epoch 29/1000\n",
            "14/14 [==============================] - 18s 1s/step - loss: 1.3080 - accuracy: 0.5360 - val_loss: 1.4409 - val_accuracy: 0.5514\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.55140\n",
            "Epoch 30/1000\n",
            "14/14 [==============================] - 18s 1s/step - loss: 1.3395 - accuracy: 0.5016 - val_loss: 1.4585 - val_accuracy: 0.4860\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.55140\n",
            "Epoch 31/1000\n",
            "14/14 [==============================] - 18s 1s/step - loss: 1.3255 - accuracy: 0.5628 - val_loss: 1.4446 - val_accuracy: 0.4953\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.55140\n",
            "Epoch 32/1000\n",
            "14/14 [==============================] - 18s 1s/step - loss: 1.2718 - accuracy: 0.5381 - val_loss: 1.4321 - val_accuracy: 0.5140\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.55140\n",
            "Epoch 33/1000\n",
            "14/14 [==============================] - 18s 1s/step - loss: 1.3302 - accuracy: 0.5319 - val_loss: 1.4189 - val_accuracy: 0.5047\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.55140\n",
            "Epoch 34/1000\n",
            "14/14 [==============================] - 18s 1s/step - loss: 1.3098 - accuracy: 0.5508 - val_loss: 1.4152 - val_accuracy: 0.4953\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.55140\n",
            "Epoch 35/1000\n",
            "14/14 [==============================] - 18s 1s/step - loss: 1.2956 - accuracy: 0.5349 - val_loss: 1.4381 - val_accuracy: 0.5327\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.55140\n",
            "Epoch 36/1000\n",
            "14/14 [==============================] - 18s 1s/step - loss: 1.2918 - accuracy: 0.5405 - val_loss: 1.4152 - val_accuracy: 0.4860\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.55140\n",
            "Epoch 37/1000\n",
            "14/14 [==============================] - 18s 1s/step - loss: 1.3155 - accuracy: 0.5282 - val_loss: 1.4003 - val_accuracy: 0.4766\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.55140\n",
            "Epoch 38/1000\n",
            "14/14 [==============================] - 18s 1s/step - loss: 1.2829 - accuracy: 0.5273 - val_loss: 1.4218 - val_accuracy: 0.4766\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.55140\n",
            "Epoch 39/1000\n",
            "14/14 [==============================] - 18s 1s/step - loss: 1.2734 - accuracy: 0.5396 - val_loss: 1.4761 - val_accuracy: 0.5047\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.55140\n",
            "Epoch 40/1000\n",
            "14/14 [==============================] - 18s 1s/step - loss: 1.3039 - accuracy: 0.5138 - val_loss: 1.4266 - val_accuracy: 0.5514\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.55140\n",
            "Epoch 41/1000\n",
            "14/14 [==============================] - 18s 1s/step - loss: 1.2873 - accuracy: 0.5531 - val_loss: 1.4257 - val_accuracy: 0.5327\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.55140\n",
            "Epoch 42/1000\n",
            "14/14 [==============================] - 18s 1s/step - loss: 1.2811 - accuracy: 0.5191 - val_loss: 1.4107 - val_accuracy: 0.4953\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.55140\n",
            "Epoch 43/1000\n",
            "14/14 [==============================] - 18s 1s/step - loss: 1.2446 - accuracy: 0.5621 - val_loss: 1.3928 - val_accuracy: 0.4673\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.55140\n",
            "Epoch 44/1000\n",
            "14/14 [==============================] - 18s 1s/step - loss: 1.2826 - accuracy: 0.5514 - val_loss: 1.4207 - val_accuracy: 0.5047\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.55140\n",
            "Epoch 45/1000\n",
            "14/14 [==============================] - 18s 1s/step - loss: 1.2170 - accuracy: 0.5153 - val_loss: 1.4251 - val_accuracy: 0.5140\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.55140\n",
            "Epoch 46/1000\n",
            "14/14 [==============================] - 18s 1s/step - loss: 1.2609 - accuracy: 0.5387 - val_loss: 1.4232 - val_accuracy: 0.4953\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.55140\n",
            "Epoch 47/1000\n",
            "14/14 [==============================] - 18s 1s/step - loss: 1.3491 - accuracy: 0.5484 - val_loss: 1.3663 - val_accuracy: 0.5234\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.55140\n",
            "Epoch 48/1000\n",
            "14/14 [==============================] - 18s 1s/step - loss: 1.2524 - accuracy: 0.5440 - val_loss: 1.4037 - val_accuracy: 0.4953\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.55140\n",
            "Epoch 49/1000\n",
            "14/14 [==============================] - 18s 1s/step - loss: 1.2443 - accuracy: 0.4939 - val_loss: 1.3870 - val_accuracy: 0.4953\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.55140\n",
            "Epoch 50/1000\n",
            "14/14 [==============================] - 18s 1s/step - loss: 1.3083 - accuracy: 0.5277 - val_loss: 1.3902 - val_accuracy: 0.5047\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.55140\n",
            "Epoch 51/1000\n",
            "14/14 [==============================] - 18s 1s/step - loss: 1.2055 - accuracy: 0.5563 - val_loss: 1.4311 - val_accuracy: 0.5234\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.55140\n",
            "Epoch 52/1000\n",
            "14/14 [==============================] - 18s 1s/step - loss: 1.2182 - accuracy: 0.4859 - val_loss: 1.4393 - val_accuracy: 0.5421\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.55140\n",
            "Epoch 53/1000\n",
            "14/14 [==============================] - 18s 1s/step - loss: 1.1822 - accuracy: 0.5550 - val_loss: 1.3810 - val_accuracy: 0.4860\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.55140\n",
            "Epoch 54/1000\n",
            "14/14 [==============================] - 18s 1s/step - loss: 1.1966 - accuracy: 0.5585 - val_loss: 1.4407 - val_accuracy: 0.4860\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.55140\n",
            "Epoch 55/1000\n",
            "14/14 [==============================] - 18s 1s/step - loss: 1.2547 - accuracy: 0.5548 - val_loss: 1.4396 - val_accuracy: 0.4579\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.55140\n",
            "Epoch 56/1000\n",
            "14/14 [==============================] - 18s 1s/step - loss: 1.2479 - accuracy: 0.5108 - val_loss: 1.3882 - val_accuracy: 0.4953\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.55140\n",
            "Epoch 57/1000\n",
            "14/14 [==============================] - 18s 1s/step - loss: 1.2326 - accuracy: 0.4997 - val_loss: 1.3796 - val_accuracy: 0.4953\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.55140\n",
            "Epoch 58/1000\n",
            "14/14 [==============================] - 18s 1s/step - loss: 1.2595 - accuracy: 0.5410 - val_loss: 1.4163 - val_accuracy: 0.5327\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.55140\n",
            "Epoch 59/1000\n",
            "14/14 [==============================] - 18s 1s/step - loss: 1.2292 - accuracy: 0.5393 - val_loss: 1.3854 - val_accuracy: 0.5234\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.55140\n",
            "Epoch 60/1000\n",
            "14/14 [==============================] - 18s 1s/step - loss: 1.2204 - accuracy: 0.5421 - val_loss: 1.3788 - val_accuracy: 0.5514\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.55140\n",
            "Epoch 61/1000\n",
            "14/14 [==============================] - 18s 1s/step - loss: 1.2049 - accuracy: 0.5578 - val_loss: 1.3930 - val_accuracy: 0.4860\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.55140\n",
            "Epoch 62/1000\n",
            "14/14 [==============================] - 18s 1s/step - loss: 1.1611 - accuracy: 0.5641 - val_loss: 1.4142 - val_accuracy: 0.4860\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.55140\n",
            "Epoch 63/1000\n",
            "14/14 [==============================] - 18s 1s/step - loss: 1.2419 - accuracy: 0.5186 - val_loss: 1.3661 - val_accuracy: 0.4673\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.55140\n",
            "Epoch 64/1000\n",
            "14/14 [==============================] - 18s 1s/step - loss: 1.1780 - accuracy: 0.5542 - val_loss: 1.4061 - val_accuracy: 0.4953\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.55140\n",
            "Epoch 65/1000\n",
            "14/14 [==============================] - 18s 1s/step - loss: 1.1958 - accuracy: 0.5304 - val_loss: 1.3460 - val_accuracy: 0.5140\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.55140\n",
            "Epoch 66/1000\n",
            "14/14 [==============================] - 18s 1s/step - loss: 1.1558 - accuracy: 0.5989 - val_loss: 1.3295 - val_accuracy: 0.5514\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.55140\n",
            "Epoch 67/1000\n",
            "14/14 [==============================] - 18s 1s/step - loss: 1.1365 - accuracy: 0.5492 - val_loss: 1.3658 - val_accuracy: 0.4860\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.55140\n",
            "Epoch 68/1000\n",
            "14/14 [==============================] - 18s 1s/step - loss: 1.1611 - accuracy: 0.5410 - val_loss: 1.3458 - val_accuracy: 0.5140\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.55140\n",
            "Epoch 69/1000\n",
            "14/14 [==============================] - 18s 1s/step - loss: 1.1331 - accuracy: 0.5746 - val_loss: 1.3713 - val_accuracy: 0.5607\n",
            "\n",
            "Epoch 00069: val_accuracy improved from 0.55140 to 0.56075, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 70/1000\n",
            "14/14 [==============================] - 18s 1s/step - loss: 1.1761 - accuracy: 0.5582 - val_loss: 1.3678 - val_accuracy: 0.4579\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.56075\n",
            "Epoch 71/1000\n",
            "14/14 [==============================] - 18s 1s/step - loss: 1.1553 - accuracy: 0.5547 - val_loss: 1.3668 - val_accuracy: 0.5047\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.56075\n",
            "Epoch 72/1000\n",
            "14/14 [==============================] - 18s 1s/step - loss: 1.1896 - accuracy: 0.5276 - val_loss: 1.3761 - val_accuracy: 0.4860\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.56075\n",
            "Epoch 73/1000\n",
            "14/14 [==============================] - ETA: 0s - loss: 1.1846 - accuracy: 0.5363"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "ocQQdgp98rFT",
        "outputId": "b574f5c1-7e2f-4c94-94a4-45a9aafb01ed"
      },
      "source": [
        "data_path = pd.concat([df], axis = 0)\n",
        "data_path.to_csv(\"data_path.csv\",index=False)\n",
        "data_path.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emotion</th>\n",
              "      <th>source</th>\n",
              "      <th>path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Fear</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis/Emo-db/08a01Ab.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Happy</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis/Emo-db/12a01Fb.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Happy</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis/Emo-db/03a01Fa.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Happy</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis/Emo-db/09a01Fa.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Neutral</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis/Emo-db/08a01Na.wav</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   emotion  ...                                                               path\n",
              "0  Fear     ...  /content/drive/MyDrive/Speech Emotion analysis/Emo-db/08a01Ab.wav\n",
              "1  Happy    ...  /content/drive/MyDrive/Speech Emotion analysis/Emo-db/12a01Fb.wav\n",
              "2  Happy    ...  /content/drive/MyDrive/Speech Emotion analysis/Emo-db/03a01Fa.wav\n",
              "3  Happy    ...  /content/drive/MyDrive/Speech Emotion analysis/Emo-db/09a01Fa.wav\n",
              "4  Neutral  ...  /content/drive/MyDrive/Speech Emotion analysis/Emo-db/08a01Na.wav\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "0HZwAllJ95CX",
        "outputId": "0efc4d0b-c81e-429a-ba19-5434e26289ed"
      },
      "source": [
        "plt.title('Count of Emotions', size=16)\n",
        "sns.countplot(data_path.emotion)\n",
        "plt.ylabel('Count', size=12)\n",
        "plt.xlabel('Emotions', size=12)\n",
        "sns.despine(top=True, right=True, left=False, bottom=False)\n",
        "plt.show() "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1ZA_ApD-AdE"
      },
      "source": [
        "def create_waveplot(data, sr, e):\n",
        "    plt.figure(figsize=(10, 3))\n",
        "    plt.title('Waveplot for audio with {} emotion'.format(e), size=15)\n",
        "    librosa.display.waveplot(data, sr=sr)\n",
        "    plt.show()\n",
        "\n",
        "def create_spectrogram(data, sr, e):\n",
        "    # stft function converts the data into short term fourier transform\n",
        "    X = librosa.stft(data)\n",
        "    Xdb = librosa.amplitude_to_db(abs(X))\n",
        "    plt.figure(figsize=(12, 3))\n",
        "    plt.title('Spectrogram for audio with {} emotion'.format(e), size=15)\n",
        "    librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='hz')   \n",
        "    #librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='log')\n",
        "    plt.colorbar()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNIbTx1U-B5f"
      },
      "source": [
        "def noise(data):\n",
        "    noise_amp = 0.015*np.random.uniform()*np.amax(data)\n",
        "    data = data + noise_amp*np.random.normal(size=data.shape[0])\n",
        "    return data\n",
        "\n",
        "def stretch(data, rate=0.8):\n",
        "    return librosa.effects.time_stretch(data, rate)\n",
        "\n",
        "def shift(data):\n",
        "    shift_range = int(np.random.uniform(low=-5, high = 5)*1000)\n",
        "    return np.roll(data, shift_range)\n",
        "\n",
        "def pitch(data, sampling_rate, pitch_factor=0.7):\n",
        "    return librosa.effects.pitch_shift(data, sampling_rate, pitch_factor)\n",
        "\n",
        "# taking any example and checking for techniques.\n",
        "path = np.array(data_path.path)[1]\n",
        "data, sample_rate = librosa.load(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvi9LEWJ-E0V"
      },
      "source": [
        "def extract_features(data):\n",
        "    # ZCR\n",
        "    result = np.array([])\n",
        "    zcr = np.mean(librosa.feature.zero_crossing_rate(y=data).T, axis=0)\n",
        "    result=np.hstack((result, zcr)) # stacking horizontally\n",
        "\n",
        "    # Chroma_stft\n",
        "    stft = np.abs(librosa.stft(data))\n",
        "    chroma_stft = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T, axis=0)\n",
        "    result = np.hstack((result, chroma_stft)) # stacking horizontally\n",
        "\n",
        "    # MFCC\n",
        "    mfcc = np.mean(librosa.feature.mfcc(y=data, sr=sample_rate,n_mfcc=13).T, axis=0)\n",
        "    result = np.hstack((result, mfcc)) # stacking horizontally\n",
        "\n",
        "    # Root Mean Square Value\n",
        "    rms = np.mean(librosa.feature.rms(y=data).T, axis=0)\n",
        "    result = np.hstack((result, rms)) # stacking horizontally\n",
        "\n",
        "    # MelSpectogram\n",
        "    mel = np.mean(librosa.feature.melspectrogram(y=data, sr=sample_rate).T, axis=0)\n",
        "    result = np.hstack((result, mel)) # stacking horizontally\n",
        "       \n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMWqKERR-GgI"
      },
      "source": [
        "def get_features(path):\n",
        "    # duration and offset are used to take care of the no audio in start and the ending of each audio files as seen above.\n",
        "    data, sample_rate = librosa.load(path, duration=2.5, offset=0.6)\n",
        "    result = np.array([])\n",
        "    \n",
        "    # without augmentation\n",
        "    res1 = extract_features(data)\n",
        "    result = np.array(res1)\n",
        "    \n",
        "    # data with noise\n",
        "    noise_data = noise(data)\n",
        "    res2 = extract_features(noise_data)\n",
        "    result = np.vstack((result, res2)) # stacking vertically\n",
        "    \n",
        "    # data with stretching and pitching\n",
        "    new_data = stretch(data)\n",
        "    data_stretch_pitch = pitch(new_data, sample_rate)\n",
        "    res3 = extract_features(data_stretch_pitch)\n",
        "    result = np.vstack((result, res3)) # stacking vertically\n",
        "    \n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wnbkMK9-IVa"
      },
      "source": [
        "X, Y = [], []\n",
        "for path, emotion in zip(df.path, df.emotion):\n",
        "    feature = get_features(path)\n",
        "    for ele in feature:\n",
        "        X.append(ele)\n",
        "        # appending emotion 3 times as we have made 3 augmentation techniques on each audio file.\n",
        "        Y.append(emotion)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydvwo5nB-PJs",
        "outputId": "93bad065-4637-4825-c111-b5174a6b70c2"
      },
      "source": [
        "len(X), len(Y), data_path.path.shape"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2140, 2140, (535,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "mW1eJnVu-QBI",
        "outputId": "b573cfe0-c122-448d-e2d9-42d554d1d7cc"
      },
      "source": [
        "Features = pd.DataFrame(X)\n",
        "Features['labels'] = Y\n",
        "Features.to_csv('features.csv', index=False)\n",
        "Features.head()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>116</th>\n",
              "      <th>117</th>\n",
              "      <th>118</th>\n",
              "      <th>119</th>\n",
              "      <th>120</th>\n",
              "      <th>121</th>\n",
              "      <th>122</th>\n",
              "      <th>123</th>\n",
              "      <th>124</th>\n",
              "      <th>125</th>\n",
              "      <th>126</th>\n",
              "      <th>127</th>\n",
              "      <th>128</th>\n",
              "      <th>129</th>\n",
              "      <th>130</th>\n",
              "      <th>131</th>\n",
              "      <th>132</th>\n",
              "      <th>133</th>\n",
              "      <th>134</th>\n",
              "      <th>135</th>\n",
              "      <th>136</th>\n",
              "      <th>137</th>\n",
              "      <th>138</th>\n",
              "      <th>139</th>\n",
              "      <th>140</th>\n",
              "      <th>141</th>\n",
              "      <th>142</th>\n",
              "      <th>143</th>\n",
              "      <th>144</th>\n",
              "      <th>145</th>\n",
              "      <th>146</th>\n",
              "      <th>147</th>\n",
              "      <th>148</th>\n",
              "      <th>149</th>\n",
              "      <th>150</th>\n",
              "      <th>151</th>\n",
              "      <th>152</th>\n",
              "      <th>153</th>\n",
              "      <th>154</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.118058</td>\n",
              "      <td>0.565005</td>\n",
              "      <td>0.608090</td>\n",
              "      <td>0.683121</td>\n",
              "      <td>0.617558</td>\n",
              "      <td>0.536719</td>\n",
              "      <td>0.544609</td>\n",
              "      <td>0.565097</td>\n",
              "      <td>0.586288</td>\n",
              "      <td>0.556638</td>\n",
              "      <td>0.535788</td>\n",
              "      <td>0.521537</td>\n",
              "      <td>0.521607</td>\n",
              "      <td>-239.242264</td>\n",
              "      <td>93.311470</td>\n",
              "      <td>-47.721405</td>\n",
              "      <td>36.792530</td>\n",
              "      <td>-29.406725</td>\n",
              "      <td>30.540400</td>\n",
              "      <td>-26.404978</td>\n",
              "      <td>-2.567815</td>\n",
              "      <td>-6.565616</td>\n",
              "      <td>-9.454045</td>\n",
              "      <td>-2.605035</td>\n",
              "      <td>-2.645095</td>\n",
              "      <td>-1.123081</td>\n",
              "      <td>0.106191</td>\n",
              "      <td>0.233874</td>\n",
              "      <td>0.168767</td>\n",
              "      <td>0.088874</td>\n",
              "      <td>0.031072</td>\n",
              "      <td>0.031221</td>\n",
              "      <td>0.397871</td>\n",
              "      <td>9.459945</td>\n",
              "      <td>11.387362</td>\n",
              "      <td>9.485535</td>\n",
              "      <td>16.230631</td>\n",
              "      <td>59.399960</td>\n",
              "      <td>35.644787</td>\n",
              "      <td>12.259502</td>\n",
              "      <td>...</td>\n",
              "      <td>0.316787</td>\n",
              "      <td>0.537943</td>\n",
              "      <td>0.480110</td>\n",
              "      <td>0.708013</td>\n",
              "      <td>0.568656</td>\n",
              "      <td>0.385182</td>\n",
              "      <td>0.467830</td>\n",
              "      <td>0.359173</td>\n",
              "      <td>0.150270</td>\n",
              "      <td>0.237734</td>\n",
              "      <td>0.319602</td>\n",
              "      <td>0.218449</td>\n",
              "      <td>0.201142</td>\n",
              "      <td>0.186315</td>\n",
              "      <td>0.148083</td>\n",
              "      <td>0.223006</td>\n",
              "      <td>0.282373</td>\n",
              "      <td>0.311500</td>\n",
              "      <td>0.298508</td>\n",
              "      <td>0.445633</td>\n",
              "      <td>0.315118</td>\n",
              "      <td>0.306816</td>\n",
              "      <td>0.295273</td>\n",
              "      <td>0.172138</td>\n",
              "      <td>0.084325</td>\n",
              "      <td>0.015300</td>\n",
              "      <td>0.000683</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>Fear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.223846</td>\n",
              "      <td>0.614872</td>\n",
              "      <td>0.650169</td>\n",
              "      <td>0.746610</td>\n",
              "      <td>0.706722</td>\n",
              "      <td>0.629184</td>\n",
              "      <td>0.610035</td>\n",
              "      <td>0.605721</td>\n",
              "      <td>0.612143</td>\n",
              "      <td>0.597922</td>\n",
              "      <td>0.578391</td>\n",
              "      <td>0.576046</td>\n",
              "      <td>0.578608</td>\n",
              "      <td>-147.661047</td>\n",
              "      <td>37.268954</td>\n",
              "      <td>-9.147313</td>\n",
              "      <td>2.856454</td>\n",
              "      <td>-5.396443</td>\n",
              "      <td>7.592656</td>\n",
              "      <td>-9.065101</td>\n",
              "      <td>-8.561931</td>\n",
              "      <td>-3.483552</td>\n",
              "      <td>-6.445993</td>\n",
              "      <td>-4.345832</td>\n",
              "      <td>-0.880399</td>\n",
              "      <td>-4.257676</td>\n",
              "      <td>0.107788</td>\n",
              "      <td>0.261239</td>\n",
              "      <td>0.191692</td>\n",
              "      <td>0.104158</td>\n",
              "      <td>0.035951</td>\n",
              "      <td>0.041694</td>\n",
              "      <td>0.413809</td>\n",
              "      <td>9.545310</td>\n",
              "      <td>11.484239</td>\n",
              "      <td>9.633016</td>\n",
              "      <td>16.303318</td>\n",
              "      <td>59.392890</td>\n",
              "      <td>35.709547</td>\n",
              "      <td>12.279588</td>\n",
              "      <td>...</td>\n",
              "      <td>0.318891</td>\n",
              "      <td>0.551199</td>\n",
              "      <td>0.489859</td>\n",
              "      <td>0.719811</td>\n",
              "      <td>0.576342</td>\n",
              "      <td>0.393091</td>\n",
              "      <td>0.478251</td>\n",
              "      <td>0.367332</td>\n",
              "      <td>0.160039</td>\n",
              "      <td>0.250016</td>\n",
              "      <td>0.331470</td>\n",
              "      <td>0.232280</td>\n",
              "      <td>0.211204</td>\n",
              "      <td>0.198330</td>\n",
              "      <td>0.158159</td>\n",
              "      <td>0.232196</td>\n",
              "      <td>0.299742</td>\n",
              "      <td>0.327852</td>\n",
              "      <td>0.313199</td>\n",
              "      <td>0.451021</td>\n",
              "      <td>0.322473</td>\n",
              "      <td>0.308751</td>\n",
              "      <td>0.305011</td>\n",
              "      <td>0.177827</td>\n",
              "      <td>0.089465</td>\n",
              "      <td>0.024069</td>\n",
              "      <td>0.009651</td>\n",
              "      <td>0.008738</td>\n",
              "      <td>0.009002</td>\n",
              "      <td>0.008487</td>\n",
              "      <td>0.009315</td>\n",
              "      <td>0.008949</td>\n",
              "      <td>0.009531</td>\n",
              "      <td>0.008660</td>\n",
              "      <td>0.008474</td>\n",
              "      <td>0.008989</td>\n",
              "      <td>0.009252</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>0.009274</td>\n",
              "      <td>Fear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.129947</td>\n",
              "      <td>0.479741</td>\n",
              "      <td>0.530497</td>\n",
              "      <td>0.620380</td>\n",
              "      <td>0.701526</td>\n",
              "      <td>0.583356</td>\n",
              "      <td>0.489940</td>\n",
              "      <td>0.490483</td>\n",
              "      <td>0.528225</td>\n",
              "      <td>0.563035</td>\n",
              "      <td>0.543836</td>\n",
              "      <td>0.546025</td>\n",
              "      <td>0.488869</td>\n",
              "      <td>-277.763794</td>\n",
              "      <td>95.098206</td>\n",
              "      <td>-47.637703</td>\n",
              "      <td>32.853813</td>\n",
              "      <td>-31.094694</td>\n",
              "      <td>29.501434</td>\n",
              "      <td>-36.599606</td>\n",
              "      <td>1.347704</td>\n",
              "      <td>-9.349730</td>\n",
              "      <td>-6.262607</td>\n",
              "      <td>-6.858923</td>\n",
              "      <td>-2.220073</td>\n",
              "      <td>-6.736476</td>\n",
              "      <td>0.051398</td>\n",
              "      <td>0.055435</td>\n",
              "      <td>0.053554</td>\n",
              "      <td>0.021962</td>\n",
              "      <td>0.008748</td>\n",
              "      <td>0.006275</td>\n",
              "      <td>0.009445</td>\n",
              "      <td>0.538023</td>\n",
              "      <td>2.605234</td>\n",
              "      <td>6.074339</td>\n",
              "      <td>4.441233</td>\n",
              "      <td>12.834837</td>\n",
              "      <td>15.815147</td>\n",
              "      <td>3.699942</td>\n",
              "      <td>...</td>\n",
              "      <td>0.028623</td>\n",
              "      <td>0.037766</td>\n",
              "      <td>0.057624</td>\n",
              "      <td>0.076188</td>\n",
              "      <td>0.139738</td>\n",
              "      <td>0.186121</td>\n",
              "      <td>0.069324</td>\n",
              "      <td>0.072744</td>\n",
              "      <td>0.087065</td>\n",
              "      <td>0.060644</td>\n",
              "      <td>0.037706</td>\n",
              "      <td>0.048544</td>\n",
              "      <td>0.054933</td>\n",
              "      <td>0.064526</td>\n",
              "      <td>0.025585</td>\n",
              "      <td>0.028049</td>\n",
              "      <td>0.038903</td>\n",
              "      <td>0.045632</td>\n",
              "      <td>0.046279</td>\n",
              "      <td>0.077440</td>\n",
              "      <td>0.063345</td>\n",
              "      <td>0.075133</td>\n",
              "      <td>0.041121</td>\n",
              "      <td>0.053084</td>\n",
              "      <td>0.036935</td>\n",
              "      <td>0.021848</td>\n",
              "      <td>0.011327</td>\n",
              "      <td>0.000532</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>Fear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.128188</td>\n",
              "      <td>0.508703</td>\n",
              "      <td>0.586469</td>\n",
              "      <td>0.702197</td>\n",
              "      <td>0.594640</td>\n",
              "      <td>0.483643</td>\n",
              "      <td>0.516429</td>\n",
              "      <td>0.542251</td>\n",
              "      <td>0.579736</td>\n",
              "      <td>0.562298</td>\n",
              "      <td>0.553694</td>\n",
              "      <td>0.485373</td>\n",
              "      <td>0.484502</td>\n",
              "      <td>-277.886475</td>\n",
              "      <td>95.166748</td>\n",
              "      <td>-49.346569</td>\n",
              "      <td>33.691082</td>\n",
              "      <td>-31.111177</td>\n",
              "      <td>30.956291</td>\n",
              "      <td>-36.058765</td>\n",
              "      <td>-0.091696</td>\n",
              "      <td>-9.122845</td>\n",
              "      <td>-5.356777</td>\n",
              "      <td>-5.549081</td>\n",
              "      <td>-2.720793</td>\n",
              "      <td>-5.709476</td>\n",
              "      <td>0.053169</td>\n",
              "      <td>0.060399</td>\n",
              "      <td>0.044571</td>\n",
              "      <td>0.018921</td>\n",
              "      <td>0.008483</td>\n",
              "      <td>0.005051</td>\n",
              "      <td>0.012949</td>\n",
              "      <td>0.899411</td>\n",
              "      <td>4.496017</td>\n",
              "      <td>6.565965</td>\n",
              "      <td>3.993485</td>\n",
              "      <td>13.024792</td>\n",
              "      <td>14.767900</td>\n",
              "      <td>3.861615</td>\n",
              "      <td>...</td>\n",
              "      <td>0.018193</td>\n",
              "      <td>0.071796</td>\n",
              "      <td>0.110694</td>\n",
              "      <td>0.111856</td>\n",
              "      <td>0.195477</td>\n",
              "      <td>0.138269</td>\n",
              "      <td>0.076853</td>\n",
              "      <td>0.049649</td>\n",
              "      <td>0.074115</td>\n",
              "      <td>0.025732</td>\n",
              "      <td>0.041997</td>\n",
              "      <td>0.092443</td>\n",
              "      <td>0.062046</td>\n",
              "      <td>0.048539</td>\n",
              "      <td>0.035789</td>\n",
              "      <td>0.036421</td>\n",
              "      <td>0.049161</td>\n",
              "      <td>0.074041</td>\n",
              "      <td>0.075512</td>\n",
              "      <td>0.060076</td>\n",
              "      <td>0.053002</td>\n",
              "      <td>0.068308</td>\n",
              "      <td>0.048778</td>\n",
              "      <td>0.047259</td>\n",
              "      <td>0.034073</td>\n",
              "      <td>0.023847</td>\n",
              "      <td>0.006954</td>\n",
              "      <td>0.000337</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>Fear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.090625</td>\n",
              "      <td>0.486378</td>\n",
              "      <td>0.538183</td>\n",
              "      <td>0.593669</td>\n",
              "      <td>0.712791</td>\n",
              "      <td>0.803031</td>\n",
              "      <td>0.758678</td>\n",
              "      <td>0.711637</td>\n",
              "      <td>0.678423</td>\n",
              "      <td>0.650458</td>\n",
              "      <td>0.604287</td>\n",
              "      <td>0.523501</td>\n",
              "      <td>0.451379</td>\n",
              "      <td>-299.975983</td>\n",
              "      <td>123.833115</td>\n",
              "      <td>-58.514000</td>\n",
              "      <td>49.796654</td>\n",
              "      <td>-19.890055</td>\n",
              "      <td>-2.462753</td>\n",
              "      <td>-7.365324</td>\n",
              "      <td>5.748572</td>\n",
              "      <td>-25.684937</td>\n",
              "      <td>-2.324779</td>\n",
              "      <td>7.042671</td>\n",
              "      <td>-15.331325</td>\n",
              "      <td>2.479473</td>\n",
              "      <td>0.047949</td>\n",
              "      <td>0.018844</td>\n",
              "      <td>0.019758</td>\n",
              "      <td>0.039690</td>\n",
              "      <td>0.199644</td>\n",
              "      <td>0.933736</td>\n",
              "      <td>1.300369</td>\n",
              "      <td>0.301026</td>\n",
              "      <td>0.152289</td>\n",
              "      <td>0.781222</td>\n",
              "      <td>1.540226</td>\n",
              "      <td>2.140152</td>\n",
              "      <td>7.207627</td>\n",
              "      <td>6.451104</td>\n",
              "      <td>...</td>\n",
              "      <td>0.015172</td>\n",
              "      <td>0.009112</td>\n",
              "      <td>0.008126</td>\n",
              "      <td>0.005522</td>\n",
              "      <td>0.004459</td>\n",
              "      <td>0.003620</td>\n",
              "      <td>0.002776</td>\n",
              "      <td>0.005050</td>\n",
              "      <td>0.005268</td>\n",
              "      <td>0.003335</td>\n",
              "      <td>0.006582</td>\n",
              "      <td>0.005305</td>\n",
              "      <td>0.004916</td>\n",
              "      <td>0.003693</td>\n",
              "      <td>0.003385</td>\n",
              "      <td>0.003568</td>\n",
              "      <td>0.003856</td>\n",
              "      <td>0.003173</td>\n",
              "      <td>0.003193</td>\n",
              "      <td>0.002571</td>\n",
              "      <td>0.001496</td>\n",
              "      <td>0.001269</td>\n",
              "      <td>0.000919</td>\n",
              "      <td>0.000577</td>\n",
              "      <td>0.000365</td>\n",
              "      <td>0.000083</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>Happy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 156 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          0         1         2         3  ...       152       153       154  labels\n",
              "0  0.118058  0.565005  0.608090  0.683121  ...  0.000002  0.000002  0.000002  Fear  \n",
              "1  0.223846  0.614872  0.650169  0.746610  ...  0.009252  0.009208  0.009274  Fear  \n",
              "2  0.129947  0.479741  0.530497  0.620380  ...  0.000004  0.000006  0.000007  Fear  \n",
              "3  0.128188  0.508703  0.586469  0.702197  ...  0.000003  0.000005  0.000007  Fear  \n",
              "4  0.090625  0.486378  0.538183  0.593669  ...  0.000002  0.000002  0.000002  Happy \n",
              "\n",
              "[5 rows x 156 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qlWBa_v-TG2",
        "outputId": "aa0cd9e9-957f-4088-955c-664a5f566867"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = Features.iloc[: ,:-1].values\n",
        "Y = Features['labels'].values\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, Y,test_size=0.20, random_state=0, shuffle=True)\n",
        "x_train.shape, y_train.shape, x_test.shape, y_test.shape\n",
        "\n",
        "# NORMALIZE DATA\n",
        "mean = np.mean(x_train, axis=0)\n",
        "std = np.std(x_train, axis=0)\n",
        "x_train = (x_train - mean)/std\n",
        "x_test = (x_test - mean)/std\n",
        "\n",
        "# TURN DATA INTO ARRAYS FOR KERAS\n",
        "x_train = np.array(x_train)\n",
        "y_train = np.array(y_train)\n",
        "x_test = np.array(x_test)\n",
        "y_test = np.array(y_test)\n",
        "# ONE HOT ENCODE THE TARGET\n",
        "# CNN REQUIRES INPUT AND OUTPUT ARE NUMBERS\n",
        "lb = LabelEncoder()\n",
        "y_train = to_categorical(lb.fit_transform(y_train))\n",
        "y_test = to_categorical(lb.fit_transform(y_test))\n",
        "print(y_test[0:10])\n",
        "# RESHAPE DATA TO INCLUDE 3D TENSOR \n",
        "x_train = x_train[:,:,np.newaxis]\n",
        "x_test = x_test[:,:,np.newaxis]\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "\n",
        "# Define the K-fold Cross Validator\n",
        "kfold = KFold(n_splits=2, shuffle=True)\n",
        "acc_per_fold = []\n",
        "loss_per_fold = []\n",
        "inputs = np.concatenate((x_train, x_test), axis=0)\n",
        "targets = np.concatenate((y_train, y_test), axis=0)\n",
        "inputs.shape\n",
        "targets.shape"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0.]]\n",
            "(1712, 155, 1)\n",
            "(428, 155, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2140, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lwTELzc-YYv",
        "outputId": "ad57137c-8933-453d-837f-67bf7104cd8b"
      },
      "source": [
        "lb.classes_"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Angry', 'Boredom', 'Disgust', 'Fear', 'Happy', 'Neutral',\n",
              "       'Sadness'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lu-aGGNC-baP",
        "outputId": "b3b9b79b-3e53-43b2-e12d-badde3f5dca3"
      },
      "source": [
        "model = tf.keras.Sequential()\n",
        "model.add(layers.Conv1D(256, kernel_size=(8),strides=1,dilation_rate=1,padding=\"same\", activation='relu', input_shape=(x_train.shape[1],1)))\n",
        "model.add(layers.Conv1D(256, kernel_size=(8),strides=1,activation='relu',dilation_rate=1,kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
        "model.add(layers.MaxPooling1D(pool_size=(2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Conv1D(256, kernel_size=(8),strides=1,dilation_rate=1,padding=\"same\",activation='relu'))\n",
        "model.add(layers.MaxPooling1D(pool_size=(2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.Conv1D(128, kernel_size=(8),strides=1,dilation_rate=1,padding=\"same\",activation='relu'))\n",
        "model.add(layers.MaxPooling1D(pool_size=(2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Conv1D(128, kernel_size=(8),strides=1,dilation_rate=1,padding=\"same\",activation='relu'))\n",
        "model.add(layers.MaxPooling1D(pool_size=(2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Conv1D(128, kernel_size=(8),strides=1,dilation_rate=1,padding=\"same\",activation='relu'))\n",
        "model.add(layers.MaxPooling1D(pool_size=(2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Conv1D(256, kernel_size=(8),strides=1,dilation_rate=1,padding=\"same\",activation='relu'))\n",
        "model.add(layers.MaxPooling1D(pool_size=(2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Conv1D(64, kernel_size=(8),strides=1,dilation_rate=1,padding=\"same\",activation='relu'))\n",
        "model.add(layers.MaxPooling1D(pool_size=(2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(5, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='Adam',metrics=['accuracy'])\n",
        "model.summary()\n",
        "checkpoint = ModelCheckpoint(\"SER_best_initial_model.hdf5\", monitor='val_accuracy', verbose=1, save_best_only=True, mode='max', period=1, save_weights_only=True)\n",
        "model_history=model.fit(x_train, y_train,batch_size=32, epochs=1000, validation_data=(x_test, y_test),callbacks=[checkpoint])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_15 (Conv1D)           (None, 155, 256)          2304      \n",
            "_________________________________________________________________\n",
            "conv1d_16 (Conv1D)           (None, 148, 256)          524544    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_13 (MaxPooling (None, 74, 256)           0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 74, 256)           1024      \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 74, 256)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_17 (Conv1D)           (None, 74, 256)           524544    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_14 (MaxPooling (None, 37, 256)           0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_14 (Batc (None, 37, 256)           1024      \n",
            "_________________________________________________________________\n",
            "conv1d_18 (Conv1D)           (None, 37, 128)           262272    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_15 (MaxPooling (None, 18, 128)           0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_15 (Batc (None, 18, 128)           512       \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 18, 128)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_19 (Conv1D)           (None, 18, 128)           131200    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_16 (MaxPooling (None, 9, 128)            0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_16 (Batc (None, 9, 128)            512       \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         (None, 9, 128)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_20 (Conv1D)           (None, 9, 128)            131200    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_17 (MaxPooling (None, 4, 128)            0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_17 (Batc (None, 4, 128)            512       \n",
            "_________________________________________________________________\n",
            "dropout_19 (Dropout)         (None, 4, 128)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_21 (Conv1D)           (None, 4, 256)            262400    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_18 (MaxPooling (None, 2, 256)            0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_18 (Batc (None, 2, 256)            1024      \n",
            "_________________________________________________________________\n",
            "dropout_20 (Dropout)         (None, 2, 256)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_22 (Conv1D)           (None, 2, 64)             131136    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_19 (MaxPooling (None, 1, 64)             0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_19 (Batc (None, 1, 64)             256       \n",
            "_________________________________________________________________\n",
            "dropout_21 (Dropout)         (None, 1, 64)             0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dropout_22 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 128)               8320      \n",
            "_________________________________________________________________\n",
            "dropout_23 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_24 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 5)                 325       \n",
            "=================================================================\n",
            "Total params: 1,991,365\n",
            "Trainable params: 1,988,933\n",
            "Non-trainable params: 2,432\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/1000\n",
            "41/41 [==============================] - 4s 35ms/step - loss: 5.1735 - accuracy: 0.2379 - val_loss: 4.1423 - val_accuracy: 0.3832\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.38318, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 2/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 4.5750 - accuracy: 0.2626 - val_loss: 3.9010 - val_accuracy: 0.3302\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.38318\n",
            "Epoch 3/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 4.0871 - accuracy: 0.2638 - val_loss: 3.6238 - val_accuracy: 0.3458\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.38318\n",
            "Epoch 4/1000\n",
            "41/41 [==============================] - 1s 16ms/step - loss: 3.7171 - accuracy: 0.2588 - val_loss: 3.3459 - val_accuracy: 0.3302\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.38318\n",
            "Epoch 5/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 3.3424 - accuracy: 0.3280 - val_loss: 3.0706 - val_accuracy: 0.3333\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.38318\n",
            "Epoch 6/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 3.0824 - accuracy: 0.3141 - val_loss: 2.8358 - val_accuracy: 0.4206\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.38318 to 0.42056, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 7/1000\n",
            "41/41 [==============================] - 1s 16ms/step - loss: 2.8290 - accuracy: 0.3176 - val_loss: 2.6041 - val_accuracy: 0.5234\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.42056 to 0.52336, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 8/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 2.5704 - accuracy: 0.4031 - val_loss: 2.3813 - val_accuracy: 0.5265\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.52336 to 0.52648, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 9/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 2.3558 - accuracy: 0.3862 - val_loss: 2.1667 - val_accuracy: 0.5358\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.52648 to 0.53583, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 10/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 2.2103 - accuracy: 0.3828 - val_loss: 1.9493 - val_accuracy: 0.5545\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.53583 to 0.55452, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 11/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 2.0178 - accuracy: 0.4376 - val_loss: 1.8202 - val_accuracy: 0.5234\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.55452\n",
            "Epoch 12/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.8167 - accuracy: 0.4829 - val_loss: 1.6862 - val_accuracy: 0.5202\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.55452\n",
            "Epoch 13/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.6949 - accuracy: 0.4921 - val_loss: 1.5465 - val_accuracy: 0.5421\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.55452\n",
            "Epoch 14/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.6236 - accuracy: 0.4614 - val_loss: 1.4850 - val_accuracy: 0.5358\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.55452\n",
            "Epoch 15/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.5862 - accuracy: 0.4775 - val_loss: 1.3695 - val_accuracy: 0.5452\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.55452\n",
            "Epoch 16/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.4622 - accuracy: 0.5069 - val_loss: 1.3255 - val_accuracy: 0.5483\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.55452\n",
            "Epoch 17/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.4360 - accuracy: 0.4773 - val_loss: 1.2825 - val_accuracy: 0.5389\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.55452\n",
            "Epoch 18/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.4000 - accuracy: 0.5260 - val_loss: 1.2918 - val_accuracy: 0.5576\n",
            "\n",
            "Epoch 00018: val_accuracy improved from 0.55452 to 0.55763, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 19/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.3819 - accuracy: 0.5018 - val_loss: 1.2463 - val_accuracy: 0.5514\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.55763\n",
            "Epoch 20/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.3108 - accuracy: 0.5363 - val_loss: 1.3754 - val_accuracy: 0.4984\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.55763\n",
            "Epoch 21/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.3241 - accuracy: 0.5125 - val_loss: 1.2051 - val_accuracy: 0.5358\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.55763\n",
            "Epoch 22/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.2616 - accuracy: 0.5207 - val_loss: 1.1961 - val_accuracy: 0.5389\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.55763\n",
            "Epoch 23/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.2752 - accuracy: 0.5093 - val_loss: 1.3632 - val_accuracy: 0.5234\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.55763\n",
            "Epoch 24/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.2701 - accuracy: 0.5058 - val_loss: 1.1344 - val_accuracy: 0.5639\n",
            "\n",
            "Epoch 00024: val_accuracy improved from 0.55763 to 0.56386, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 25/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.1927 - accuracy: 0.5453 - val_loss: 1.3307 - val_accuracy: 0.4922\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.56386\n",
            "Epoch 26/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.1694 - accuracy: 0.5464 - val_loss: 1.1597 - val_accuracy: 0.5483\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.56386\n",
            "Epoch 27/1000\n",
            "41/41 [==============================] - 1s 16ms/step - loss: 1.1409 - accuracy: 0.5445 - val_loss: 1.2326 - val_accuracy: 0.5171\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.56386\n",
            "Epoch 28/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.2270 - accuracy: 0.5193 - val_loss: 1.0336 - val_accuracy: 0.5763\n",
            "\n",
            "Epoch 00028: val_accuracy improved from 0.56386 to 0.57632, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 29/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.1650 - accuracy: 0.5449 - val_loss: 1.2508 - val_accuracy: 0.5109\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.57632\n",
            "Epoch 30/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.1009 - accuracy: 0.5548 - val_loss: 1.1026 - val_accuracy: 0.5670\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.57632\n",
            "Epoch 31/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.2053 - accuracy: 0.5054 - val_loss: 1.0261 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00031: val_accuracy improved from 0.57632 to 0.57944, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 32/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.1443 - accuracy: 0.5658 - val_loss: 1.0308 - val_accuracy: 0.5857\n",
            "\n",
            "Epoch 00032: val_accuracy improved from 0.57944 to 0.58567, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 33/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.1809 - accuracy: 0.5396 - val_loss: 1.1340 - val_accuracy: 0.5483\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.58567\n",
            "Epoch 34/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.1711 - accuracy: 0.5366 - val_loss: 1.0806 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.58567\n",
            "Epoch 35/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.0878 - accuracy: 0.5599 - val_loss: 1.0801 - val_accuracy: 0.5826\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.58567\n",
            "Epoch 36/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.1135 - accuracy: 0.5421 - val_loss: 1.2065 - val_accuracy: 0.5607\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.58567\n",
            "Epoch 37/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.1283 - accuracy: 0.5419 - val_loss: 1.2836 - val_accuracy: 0.5389\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.58567\n",
            "Epoch 38/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.6858 - accuracy: 0.4983 - val_loss: 1.6288 - val_accuracy: 0.5607\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.58567\n",
            "Epoch 39/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.6769 - accuracy: 0.5271 - val_loss: 1.3947 - val_accuracy: 0.5763\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.58567\n",
            "Epoch 40/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.4511 - accuracy: 0.5579 - val_loss: 1.2975 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.58567\n",
            "Epoch 41/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.3773 - accuracy: 0.5295 - val_loss: 1.2022 - val_accuracy: 0.5763\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.58567\n",
            "Epoch 42/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.3227 - accuracy: 0.5405 - val_loss: 1.2090 - val_accuracy: 0.5670\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.58567\n",
            "Epoch 43/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.2006 - accuracy: 0.5528 - val_loss: 1.4877 - val_accuracy: 0.4361\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.58567\n",
            "Epoch 44/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.1967 - accuracy: 0.5375 - val_loss: 1.0942 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.58567\n",
            "Epoch 45/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.1475 - accuracy: 0.5428 - val_loss: 1.0847 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.58567\n",
            "Epoch 46/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 1.1566 - accuracy: 0.5502 - val_loss: 1.0887 - val_accuracy: 0.5763\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.58567\n",
            "Epoch 47/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.1269 - accuracy: 0.5615 - val_loss: 1.1512 - val_accuracy: 0.5701\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.58567\n",
            "Epoch 48/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.1481 - accuracy: 0.5371 - val_loss: 1.0778 - val_accuracy: 0.5639\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.58567\n",
            "Epoch 49/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.0955 - accuracy: 0.5496 - val_loss: 1.0178 - val_accuracy: 0.5701\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.58567\n",
            "Epoch 50/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.0090 - accuracy: 0.5696 - val_loss: 1.1361 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00050: val_accuracy improved from 0.58567 to 0.58879, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 51/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.0634 - accuracy: 0.5954 - val_loss: 1.0636 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.58879\n",
            "Epoch 52/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.0672 - accuracy: 0.5777 - val_loss: 1.0232 - val_accuracy: 0.6012\n",
            "\n",
            "Epoch 00052: val_accuracy improved from 0.58879 to 0.60125, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 53/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.0346 - accuracy: 0.5828 - val_loss: 1.0510 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.60125\n",
            "Epoch 54/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.9832 - accuracy: 0.5843 - val_loss: 1.1650 - val_accuracy: 0.6262\n",
            "\n",
            "Epoch 00054: val_accuracy improved from 0.60125 to 0.62617, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 55/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.1878 - accuracy: 0.5600 - val_loss: 1.3322 - val_accuracy: 0.5826\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.62617\n",
            "Epoch 56/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.3578 - accuracy: 0.5475 - val_loss: 1.2509 - val_accuracy: 0.5826\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.62617\n",
            "Epoch 57/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.3175 - accuracy: 0.5637 - val_loss: 1.1134 - val_accuracy: 0.5826\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.62617\n",
            "Epoch 58/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.2370 - accuracy: 0.5500 - val_loss: 1.1831 - val_accuracy: 0.5732\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.62617\n",
            "Epoch 59/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.1344 - accuracy: 0.5445 - val_loss: 1.1912 - val_accuracy: 0.5607\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.62617\n",
            "Epoch 60/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.0655 - accuracy: 0.5674 - val_loss: 1.0696 - val_accuracy: 0.6106\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.62617\n",
            "Epoch 61/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.1131 - accuracy: 0.5589 - val_loss: 0.9833 - val_accuracy: 0.6199\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.62617\n",
            "Epoch 62/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.0423 - accuracy: 0.5777 - val_loss: 0.9956 - val_accuracy: 0.6231\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.62617\n",
            "Epoch 63/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.0655 - accuracy: 0.5820 - val_loss: 1.0119 - val_accuracy: 0.6012\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.62617\n",
            "Epoch 64/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.0361 - accuracy: 0.5928 - val_loss: 1.1296 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.62617\n",
            "Epoch 65/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.9910 - accuracy: 0.5779 - val_loss: 1.1151 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.62617\n",
            "Epoch 66/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.0443 - accuracy: 0.5572 - val_loss: 0.9768 - val_accuracy: 0.6044\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.62617\n",
            "Epoch 67/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.0241 - accuracy: 0.5787 - val_loss: 0.9384 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.62617\n",
            "Epoch 68/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.9488 - accuracy: 0.5941 - val_loss: 0.9126 - val_accuracy: 0.6417\n",
            "\n",
            "Epoch 00068: val_accuracy improved from 0.62617 to 0.64174, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 69/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.9227 - accuracy: 0.5935 - val_loss: 0.9178 - val_accuracy: 0.6324\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.64174\n",
            "Epoch 70/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.0190 - accuracy: 0.5855 - val_loss: 0.9274 - val_accuracy: 0.6262\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.64174\n",
            "Epoch 71/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.9396 - accuracy: 0.6055 - val_loss: 0.9554 - val_accuracy: 0.6231\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.64174\n",
            "Epoch 72/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.9508 - accuracy: 0.5785 - val_loss: 0.9182 - val_accuracy: 0.6355\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.64174\n",
            "Epoch 73/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.9645 - accuracy: 0.5903 - val_loss: 0.8933 - val_accuracy: 0.6293\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.64174\n",
            "Epoch 74/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 1.0187 - accuracy: 0.6143 - val_loss: 0.9259 - val_accuracy: 0.6355\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.64174\n",
            "Epoch 75/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.9845 - accuracy: 0.5995 - val_loss: 0.9624 - val_accuracy: 0.6262\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.64174\n",
            "Epoch 76/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.9220 - accuracy: 0.6202 - val_loss: 1.0621 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.64174\n",
            "Epoch 77/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.0111 - accuracy: 0.5970 - val_loss: 1.0707 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.64174\n",
            "Epoch 78/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.9848 - accuracy: 0.5988 - val_loss: 0.8750 - val_accuracy: 0.6480\n",
            "\n",
            "Epoch 00078: val_accuracy improved from 0.64174 to 0.64798, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 79/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.9115 - accuracy: 0.6130 - val_loss: 1.1199 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.64798\n",
            "Epoch 80/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.9606 - accuracy: 0.6138 - val_loss: 1.1417 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.64798\n",
            "Epoch 81/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.0201 - accuracy: 0.6029 - val_loss: 0.9414 - val_accuracy: 0.6262\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.64798\n",
            "Epoch 82/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.9414 - accuracy: 0.6029 - val_loss: 1.0124 - val_accuracy: 0.6293\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.64798\n",
            "Epoch 83/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.8878 - accuracy: 0.6187 - val_loss: 0.9437 - val_accuracy: 0.6293\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.64798\n",
            "Epoch 84/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.8850 - accuracy: 0.6290 - val_loss: 0.9852 - val_accuracy: 0.6449\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.64798\n",
            "Epoch 85/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 1.0085 - accuracy: 0.5959 - val_loss: 0.9199 - val_accuracy: 0.6449\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.64798\n",
            "Epoch 86/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.9368 - accuracy: 0.6087 - val_loss: 1.0193 - val_accuracy: 0.6231\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.64798\n",
            "Epoch 87/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.8998 - accuracy: 0.6271 - val_loss: 0.8979 - val_accuracy: 0.6417\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.64798\n",
            "Epoch 88/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.8555 - accuracy: 0.6428 - val_loss: 0.8509 - val_accuracy: 0.6698\n",
            "\n",
            "Epoch 00088: val_accuracy improved from 0.64798 to 0.66978, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 89/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.9220 - accuracy: 0.6237 - val_loss: 0.9699 - val_accuracy: 0.6262\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.66978\n",
            "Epoch 90/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.9328 - accuracy: 0.6250 - val_loss: 0.9880 - val_accuracy: 0.6480\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.66978\n",
            "Epoch 91/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.8908 - accuracy: 0.6361 - val_loss: 1.0151 - val_accuracy: 0.6417\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.66978\n",
            "Epoch 92/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.8546 - accuracy: 0.6448 - val_loss: 0.8241 - val_accuracy: 0.6511\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.66978\n",
            "Epoch 93/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.8075 - accuracy: 0.6525 - val_loss: 0.9686 - val_accuracy: 0.6355\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.66978\n",
            "Epoch 94/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.8470 - accuracy: 0.6512 - val_loss: 0.8189 - val_accuracy: 0.6791\n",
            "\n",
            "Epoch 00094: val_accuracy improved from 0.66978 to 0.67913, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 95/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.8780 - accuracy: 0.6429 - val_loss: 0.7810 - val_accuracy: 0.6822\n",
            "\n",
            "Epoch 00095: val_accuracy improved from 0.67913 to 0.68224, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 96/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.8404 - accuracy: 0.6601 - val_loss: 0.9430 - val_accuracy: 0.6636\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.68224\n",
            "Epoch 97/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.8726 - accuracy: 0.6671 - val_loss: 0.8563 - val_accuracy: 0.6885\n",
            "\n",
            "Epoch 00097: val_accuracy improved from 0.68224 to 0.68847, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 98/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.1277 - accuracy: 0.5902 - val_loss: 1.4930 - val_accuracy: 0.6137\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.68847\n",
            "Epoch 99/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.0410 - accuracy: 0.6256 - val_loss: 0.9006 - val_accuracy: 0.6729\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.68847\n",
            "Epoch 100/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.8916 - accuracy: 0.6639 - val_loss: 0.8124 - val_accuracy: 0.7009\n",
            "\n",
            "Epoch 00100: val_accuracy improved from 0.68847 to 0.70093, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 101/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.8463 - accuracy: 0.6618 - val_loss: 0.8427 - val_accuracy: 0.6854\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.70093\n",
            "Epoch 102/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.8218 - accuracy: 0.6766 - val_loss: 0.7838 - val_accuracy: 0.7165\n",
            "\n",
            "Epoch 00102: val_accuracy improved from 0.70093 to 0.71651, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 103/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.8149 - accuracy: 0.6654 - val_loss: 0.7971 - val_accuracy: 0.7227\n",
            "\n",
            "Epoch 00103: val_accuracy improved from 0.71651 to 0.72274, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 104/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.9364 - accuracy: 0.6549 - val_loss: 0.8573 - val_accuracy: 0.6885\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 0.72274\n",
            "Epoch 105/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.8826 - accuracy: 0.7187 - val_loss: 0.9378 - val_accuracy: 0.6822\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.72274\n",
            "Epoch 106/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.8380 - accuracy: 0.6633 - val_loss: 0.7748 - val_accuracy: 0.7196\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.72274\n",
            "Epoch 107/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.8200 - accuracy: 0.6981 - val_loss: 0.8027 - val_accuracy: 0.7072\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.72274\n",
            "Epoch 108/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.7738 - accuracy: 0.6863 - val_loss: 0.7896 - val_accuracy: 0.7196\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 0.72274\n",
            "Epoch 109/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.7801 - accuracy: 0.7051 - val_loss: 0.7354 - val_accuracy: 0.7601\n",
            "\n",
            "Epoch 00109: val_accuracy improved from 0.72274 to 0.76012, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 110/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.7654 - accuracy: 0.6997 - val_loss: 0.7352 - val_accuracy: 0.7165\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.76012\n",
            "Epoch 111/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.7617 - accuracy: 0.6892 - val_loss: 0.7332 - val_accuracy: 0.7539\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 0.76012\n",
            "Epoch 112/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.7834 - accuracy: 0.6997 - val_loss: 0.7348 - val_accuracy: 0.7539\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.76012\n",
            "Epoch 113/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.7265 - accuracy: 0.7372 - val_loss: 0.8616 - val_accuracy: 0.7134\n",
            "\n",
            "Epoch 00113: val_accuracy did not improve from 0.76012\n",
            "Epoch 114/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.8915 - accuracy: 0.6932 - val_loss: 0.9334 - val_accuracy: 0.6698\n",
            "\n",
            "Epoch 00114: val_accuracy did not improve from 0.76012\n",
            "Epoch 115/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.0873 - accuracy: 0.6356 - val_loss: 0.9365 - val_accuracy: 0.6573\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.76012\n",
            "Epoch 116/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.9554 - accuracy: 0.6834 - val_loss: 0.8390 - val_accuracy: 0.7009\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.76012\n",
            "Epoch 117/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 1.0900 - accuracy: 0.6037 - val_loss: 0.9308 - val_accuracy: 0.6729\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.76012\n",
            "Epoch 118/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.9544 - accuracy: 0.6607 - val_loss: 0.8095 - val_accuracy: 0.7072\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.76012\n",
            "Epoch 119/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.8375 - accuracy: 0.6999 - val_loss: 0.7986 - val_accuracy: 0.7259\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.76012\n",
            "Epoch 120/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.8589 - accuracy: 0.6894 - val_loss: 0.7247 - val_accuracy: 0.7445\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 0.76012\n",
            "Epoch 121/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.7689 - accuracy: 0.6906 - val_loss: 0.7347 - val_accuracy: 0.7321\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.76012\n",
            "Epoch 122/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.7473 - accuracy: 0.7221 - val_loss: 0.7114 - val_accuracy: 0.7445\n",
            "\n",
            "Epoch 00122: val_accuracy did not improve from 0.76012\n",
            "Epoch 123/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.7541 - accuracy: 0.7050 - val_loss: 0.7528 - val_accuracy: 0.7570\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.76012\n",
            "Epoch 124/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.7771 - accuracy: 0.7100 - val_loss: 0.7308 - val_accuracy: 0.7227\n",
            "\n",
            "Epoch 00124: val_accuracy did not improve from 0.76012\n",
            "Epoch 125/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.8125 - accuracy: 0.6968 - val_loss: 0.7057 - val_accuracy: 0.7445\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.76012\n",
            "Epoch 126/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.7107 - accuracy: 0.7353 - val_loss: 0.6931 - val_accuracy: 0.7414\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.76012\n",
            "Epoch 127/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.7486 - accuracy: 0.7197 - val_loss: 0.6951 - val_accuracy: 0.7632\n",
            "\n",
            "Epoch 00127: val_accuracy improved from 0.76012 to 0.76324, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 128/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.6742 - accuracy: 0.7562 - val_loss: 0.6722 - val_accuracy: 0.7726\n",
            "\n",
            "Epoch 00128: val_accuracy improved from 0.76324 to 0.77259, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 129/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.7686 - accuracy: 0.7195 - val_loss: 0.7982 - val_accuracy: 0.7321\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.77259\n",
            "Epoch 130/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.7537 - accuracy: 0.7194 - val_loss: 0.6813 - val_accuracy: 0.7601\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.77259\n",
            "Epoch 131/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.6842 - accuracy: 0.7464 - val_loss: 0.6345 - val_accuracy: 0.7819\n",
            "\n",
            "Epoch 00131: val_accuracy improved from 0.77259 to 0.78193, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 132/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.7077 - accuracy: 0.7482 - val_loss: 0.7382 - val_accuracy: 0.7695\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.78193\n",
            "Epoch 133/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.7608 - accuracy: 0.7396 - val_loss: 0.6473 - val_accuracy: 0.7632\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.78193\n",
            "Epoch 134/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.7369 - accuracy: 0.7377 - val_loss: 0.6534 - val_accuracy: 0.7757\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.78193\n",
            "Epoch 135/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.6713 - accuracy: 0.7558 - val_loss: 0.6459 - val_accuracy: 0.7819\n",
            "\n",
            "Epoch 00135: val_accuracy did not improve from 0.78193\n",
            "Epoch 136/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.6801 - accuracy: 0.7521 - val_loss: 0.6285 - val_accuracy: 0.7819\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.78193\n",
            "Epoch 137/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.6399 - accuracy: 0.7686 - val_loss: 0.6072 - val_accuracy: 0.7913\n",
            "\n",
            "Epoch 00137: val_accuracy improved from 0.78193 to 0.79128, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 138/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.6163 - accuracy: 0.7670 - val_loss: 0.6463 - val_accuracy: 0.7975\n",
            "\n",
            "Epoch 00138: val_accuracy improved from 0.79128 to 0.79751, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 139/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.5738 - accuracy: 0.8136 - val_loss: 0.6402 - val_accuracy: 0.7913\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.79751\n",
            "Epoch 140/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.7196 - accuracy: 0.7521 - val_loss: 0.6267 - val_accuracy: 0.7913\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.79751\n",
            "Epoch 141/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.6365 - accuracy: 0.7938 - val_loss: 0.6541 - val_accuracy: 0.7850\n",
            "\n",
            "Epoch 00141: val_accuracy did not improve from 0.79751\n",
            "Epoch 142/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.6521 - accuracy: 0.7503 - val_loss: 0.5922 - val_accuracy: 0.8100\n",
            "\n",
            "Epoch 00142: val_accuracy improved from 0.79751 to 0.80997, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 143/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.6128 - accuracy: 0.8085 - val_loss: 0.5732 - val_accuracy: 0.8318\n",
            "\n",
            "Epoch 00143: val_accuracy improved from 0.80997 to 0.83178, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 144/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.6802 - accuracy: 0.7881 - val_loss: 0.7119 - val_accuracy: 0.7850\n",
            "\n",
            "Epoch 00144: val_accuracy did not improve from 0.83178\n",
            "Epoch 145/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.6546 - accuracy: 0.8016 - val_loss: 0.7027 - val_accuracy: 0.7508\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.83178\n",
            "Epoch 146/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.7186 - accuracy: 0.7573 - val_loss: 0.5747 - val_accuracy: 0.8193\n",
            "\n",
            "Epoch 00146: val_accuracy did not improve from 0.83178\n",
            "Epoch 147/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.7190 - accuracy: 0.7522 - val_loss: 0.6407 - val_accuracy: 0.8318\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.83178\n",
            "Epoch 148/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.7052 - accuracy: 0.7818 - val_loss: 0.5982 - val_accuracy: 0.8131\n",
            "\n",
            "Epoch 00148: val_accuracy did not improve from 0.83178\n",
            "Epoch 149/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.6259 - accuracy: 0.7790 - val_loss: 0.6285 - val_accuracy: 0.8318\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.83178\n",
            "Epoch 150/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.6247 - accuracy: 0.7859 - val_loss: 0.5274 - val_accuracy: 0.8380\n",
            "\n",
            "Epoch 00150: val_accuracy improved from 0.83178 to 0.83801, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 151/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.5477 - accuracy: 0.8091 - val_loss: 0.6055 - val_accuracy: 0.7944\n",
            "\n",
            "Epoch 00151: val_accuracy did not improve from 0.83801\n",
            "Epoch 152/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.5749 - accuracy: 0.7990 - val_loss: 0.5749 - val_accuracy: 0.8224\n",
            "\n",
            "Epoch 00152: val_accuracy did not improve from 0.83801\n",
            "Epoch 153/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.5403 - accuracy: 0.8218 - val_loss: 0.5156 - val_accuracy: 0.8318\n",
            "\n",
            "Epoch 00153: val_accuracy did not improve from 0.83801\n",
            "Epoch 154/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.6655 - accuracy: 0.7695 - val_loss: 0.7658 - val_accuracy: 0.7570\n",
            "\n",
            "Epoch 00154: val_accuracy did not improve from 0.83801\n",
            "Epoch 155/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.6669 - accuracy: 0.7989 - val_loss: 0.7918 - val_accuracy: 0.7726\n",
            "\n",
            "Epoch 00155: val_accuracy did not improve from 0.83801\n",
            "Epoch 156/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.5916 - accuracy: 0.8261 - val_loss: 0.5429 - val_accuracy: 0.8318\n",
            "\n",
            "Epoch 00156: val_accuracy did not improve from 0.83801\n",
            "Epoch 157/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.5575 - accuracy: 0.8263 - val_loss: 0.5106 - val_accuracy: 0.8474\n",
            "\n",
            "Epoch 00157: val_accuracy improved from 0.83801 to 0.84735, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 158/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.6331 - accuracy: 0.7959 - val_loss: 0.5298 - val_accuracy: 0.8567\n",
            "\n",
            "Epoch 00158: val_accuracy improved from 0.84735 to 0.85670, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 159/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.5914 - accuracy: 0.8159 - val_loss: 0.5295 - val_accuracy: 0.8598\n",
            "\n",
            "Epoch 00159: val_accuracy improved from 0.85670 to 0.85981, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 160/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.5781 - accuracy: 0.8228 - val_loss: 0.5476 - val_accuracy: 0.8411\n",
            "\n",
            "Epoch 00160: val_accuracy did not improve from 0.85981\n",
            "Epoch 161/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.6559 - accuracy: 0.8060 - val_loss: 0.5101 - val_accuracy: 0.8474\n",
            "\n",
            "Epoch 00161: val_accuracy did not improve from 0.85981\n",
            "Epoch 162/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.6192 - accuracy: 0.8086 - val_loss: 0.5619 - val_accuracy: 0.8474\n",
            "\n",
            "Epoch 00162: val_accuracy did not improve from 0.85981\n",
            "Epoch 163/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.5190 - accuracy: 0.8503 - val_loss: 0.5082 - val_accuracy: 0.8536\n",
            "\n",
            "Epoch 00163: val_accuracy did not improve from 0.85981\n",
            "Epoch 164/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.5404 - accuracy: 0.8396 - val_loss: 0.4956 - val_accuracy: 0.8349\n",
            "\n",
            "Epoch 00164: val_accuracy did not improve from 0.85981\n",
            "Epoch 165/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.5103 - accuracy: 0.8297 - val_loss: 0.5250 - val_accuracy: 0.8505\n",
            "\n",
            "Epoch 00165: val_accuracy did not improve from 0.85981\n",
            "Epoch 166/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.5795 - accuracy: 0.8246 - val_loss: 0.5351 - val_accuracy: 0.8598\n",
            "\n",
            "Epoch 00166: val_accuracy did not improve from 0.85981\n",
            "Epoch 167/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.5448 - accuracy: 0.8306 - val_loss: 0.5414 - val_accuracy: 0.8505\n",
            "\n",
            "Epoch 00167: val_accuracy did not improve from 0.85981\n",
            "Epoch 168/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.5287 - accuracy: 0.8559 - val_loss: 0.5471 - val_accuracy: 0.8349\n",
            "\n",
            "Epoch 00168: val_accuracy did not improve from 0.85981\n",
            "Epoch 169/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.5327 - accuracy: 0.8432 - val_loss: 0.5101 - val_accuracy: 0.8598\n",
            "\n",
            "Epoch 00169: val_accuracy did not improve from 0.85981\n",
            "Epoch 170/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.5094 - accuracy: 0.8628 - val_loss: 0.6660 - val_accuracy: 0.7601\n",
            "\n",
            "Epoch 00170: val_accuracy did not improve from 0.85981\n",
            "Epoch 171/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.5607 - accuracy: 0.8268 - val_loss: 0.5772 - val_accuracy: 0.8349\n",
            "\n",
            "Epoch 00171: val_accuracy did not improve from 0.85981\n",
            "Epoch 172/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.5218 - accuracy: 0.8509 - val_loss: 0.4990 - val_accuracy: 0.8567\n",
            "\n",
            "Epoch 00172: val_accuracy did not improve from 0.85981\n",
            "Epoch 173/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.5309 - accuracy: 0.8469 - val_loss: 0.5107 - val_accuracy: 0.8598\n",
            "\n",
            "Epoch 00173: val_accuracy did not improve from 0.85981\n",
            "Epoch 174/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.4684 - accuracy: 0.8440 - val_loss: 0.4175 - val_accuracy: 0.8754\n",
            "\n",
            "Epoch 00174: val_accuracy improved from 0.85981 to 0.87539, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 175/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.5677 - accuracy: 0.8293 - val_loss: 0.6383 - val_accuracy: 0.8193\n",
            "\n",
            "Epoch 00175: val_accuracy did not improve from 0.87539\n",
            "Epoch 176/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.5606 - accuracy: 0.8380 - val_loss: 0.6135 - val_accuracy: 0.8255\n",
            "\n",
            "Epoch 00176: val_accuracy did not improve from 0.87539\n",
            "Epoch 177/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.5354 - accuracy: 0.8272 - val_loss: 0.5358 - val_accuracy: 0.8598\n",
            "\n",
            "Epoch 00177: val_accuracy did not improve from 0.87539\n",
            "Epoch 178/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.4787 - accuracy: 0.8547 - val_loss: 0.4454 - val_accuracy: 0.8910\n",
            "\n",
            "Epoch 00178: val_accuracy improved from 0.87539 to 0.89097, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 179/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.4165 - accuracy: 0.8815 - val_loss: 0.4518 - val_accuracy: 0.8816\n",
            "\n",
            "Epoch 00179: val_accuracy did not improve from 0.89097\n",
            "Epoch 180/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.4591 - accuracy: 0.8709 - val_loss: 0.4879 - val_accuracy: 0.8816\n",
            "\n",
            "Epoch 00180: val_accuracy did not improve from 0.89097\n",
            "Epoch 181/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.4756 - accuracy: 0.8721 - val_loss: 0.5205 - val_accuracy: 0.8629\n",
            "\n",
            "Epoch 00181: val_accuracy did not improve from 0.89097\n",
            "Epoch 182/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.4377 - accuracy: 0.8758 - val_loss: 0.4404 - val_accuracy: 0.8910\n",
            "\n",
            "Epoch 00182: val_accuracy did not improve from 0.89097\n",
            "Epoch 183/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.3886 - accuracy: 0.8897 - val_loss: 0.4933 - val_accuracy: 0.8723\n",
            "\n",
            "Epoch 00183: val_accuracy did not improve from 0.89097\n",
            "Epoch 184/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.4376 - accuracy: 0.8693 - val_loss: 0.5163 - val_accuracy: 0.8692\n",
            "\n",
            "Epoch 00184: val_accuracy did not improve from 0.89097\n",
            "Epoch 185/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.4147 - accuracy: 0.8925 - val_loss: 0.4299 - val_accuracy: 0.8785\n",
            "\n",
            "Epoch 00185: val_accuracy did not improve from 0.89097\n",
            "Epoch 186/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.4977 - accuracy: 0.8462 - val_loss: 0.4531 - val_accuracy: 0.8785\n",
            "\n",
            "Epoch 00186: val_accuracy did not improve from 0.89097\n",
            "Epoch 187/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.4398 - accuracy: 0.8770 - val_loss: 0.5853 - val_accuracy: 0.8255\n",
            "\n",
            "Epoch 00187: val_accuracy did not improve from 0.89097\n",
            "Epoch 188/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.4438 - accuracy: 0.8728 - val_loss: 0.4680 - val_accuracy: 0.8754\n",
            "\n",
            "Epoch 00188: val_accuracy did not improve from 0.89097\n",
            "Epoch 189/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.4269 - accuracy: 0.8874 - val_loss: 0.4961 - val_accuracy: 0.8879\n",
            "\n",
            "Epoch 00189: val_accuracy did not improve from 0.89097\n",
            "Epoch 190/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.4256 - accuracy: 0.8796 - val_loss: 0.4779 - val_accuracy: 0.8910\n",
            "\n",
            "Epoch 00190: val_accuracy did not improve from 0.89097\n",
            "Epoch 191/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.5022 - accuracy: 0.8539 - val_loss: 0.5813 - val_accuracy: 0.8754\n",
            "\n",
            "Epoch 00191: val_accuracy did not improve from 0.89097\n",
            "Epoch 192/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.4297 - accuracy: 0.8922 - val_loss: 0.5943 - val_accuracy: 0.8692\n",
            "\n",
            "Epoch 00192: val_accuracy did not improve from 0.89097\n",
            "Epoch 193/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.4579 - accuracy: 0.8690 - val_loss: 0.4318 - val_accuracy: 0.8723\n",
            "\n",
            "Epoch 00193: val_accuracy did not improve from 0.89097\n",
            "Epoch 194/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.3762 - accuracy: 0.9035 - val_loss: 0.5021 - val_accuracy: 0.8660\n",
            "\n",
            "Epoch 00194: val_accuracy did not improve from 0.89097\n",
            "Epoch 195/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.4650 - accuracy: 0.8716 - val_loss: 0.4960 - val_accuracy: 0.8723\n",
            "\n",
            "Epoch 00195: val_accuracy did not improve from 0.89097\n",
            "Epoch 196/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.4166 - accuracy: 0.8858 - val_loss: 0.6032 - val_accuracy: 0.8660\n",
            "\n",
            "Epoch 00196: val_accuracy did not improve from 0.89097\n",
            "Epoch 197/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.3723 - accuracy: 0.9045 - val_loss: 0.4977 - val_accuracy: 0.8847\n",
            "\n",
            "Epoch 00197: val_accuracy did not improve from 0.89097\n",
            "Epoch 198/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.4167 - accuracy: 0.8719 - val_loss: 0.4929 - val_accuracy: 0.8723\n",
            "\n",
            "Epoch 00198: val_accuracy did not improve from 0.89097\n",
            "Epoch 199/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.3467 - accuracy: 0.9102 - val_loss: 0.4196 - val_accuracy: 0.8972\n",
            "\n",
            "Epoch 00199: val_accuracy improved from 0.89097 to 0.89720, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 200/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.3609 - accuracy: 0.8971 - val_loss: 0.4873 - val_accuracy: 0.8754\n",
            "\n",
            "Epoch 00200: val_accuracy did not improve from 0.89720\n",
            "Epoch 201/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.3415 - accuracy: 0.9175 - val_loss: 0.4578 - val_accuracy: 0.8785\n",
            "\n",
            "Epoch 00201: val_accuracy did not improve from 0.89720\n",
            "Epoch 202/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.4643 - accuracy: 0.8760 - val_loss: 0.5098 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00202: val_accuracy did not improve from 0.89720\n",
            "Epoch 203/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.3676 - accuracy: 0.8848 - val_loss: 0.4327 - val_accuracy: 0.9034\n",
            "\n",
            "Epoch 00203: val_accuracy improved from 0.89720 to 0.90343, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 204/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.3413 - accuracy: 0.9061 - val_loss: 0.4823 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00204: val_accuracy did not improve from 0.90343\n",
            "Epoch 205/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.3352 - accuracy: 0.9276 - val_loss: 0.4733 - val_accuracy: 0.8785\n",
            "\n",
            "Epoch 00205: val_accuracy did not improve from 0.90343\n",
            "Epoch 206/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.4901 - accuracy: 0.8787 - val_loss: 0.4295 - val_accuracy: 0.8754\n",
            "\n",
            "Epoch 00206: val_accuracy did not improve from 0.90343\n",
            "Epoch 207/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.4106 - accuracy: 0.8918 - val_loss: 0.3969 - val_accuracy: 0.8879\n",
            "\n",
            "Epoch 00207: val_accuracy did not improve from 0.90343\n",
            "Epoch 208/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.3600 - accuracy: 0.9140 - val_loss: 0.4330 - val_accuracy: 0.8972\n",
            "\n",
            "Epoch 00208: val_accuracy did not improve from 0.90343\n",
            "Epoch 209/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.3636 - accuracy: 0.9038 - val_loss: 0.3968 - val_accuracy: 0.9003\n",
            "\n",
            "Epoch 00209: val_accuracy did not improve from 0.90343\n",
            "Epoch 210/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.4436 - accuracy: 0.8737 - val_loss: 0.4647 - val_accuracy: 0.9034\n",
            "\n",
            "Epoch 00210: val_accuracy did not improve from 0.90343\n",
            "Epoch 211/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.4419 - accuracy: 0.8981 - val_loss: 0.4475 - val_accuracy: 0.8816\n",
            "\n",
            "Epoch 00211: val_accuracy did not improve from 0.90343\n",
            "Epoch 212/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.4886 - accuracy: 0.8773 - val_loss: 0.4732 - val_accuracy: 0.8879\n",
            "\n",
            "Epoch 00212: val_accuracy did not improve from 0.90343\n",
            "Epoch 213/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.4511 - accuracy: 0.8876 - val_loss: 0.4903 - val_accuracy: 0.8910\n",
            "\n",
            "Epoch 00213: val_accuracy did not improve from 0.90343\n",
            "Epoch 214/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.3569 - accuracy: 0.9074 - val_loss: 0.5228 - val_accuracy: 0.8879\n",
            "\n",
            "Epoch 00214: val_accuracy did not improve from 0.90343\n",
            "Epoch 215/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.4430 - accuracy: 0.9039 - val_loss: 0.4370 - val_accuracy: 0.9034\n",
            "\n",
            "Epoch 00215: val_accuracy did not improve from 0.90343\n",
            "Epoch 216/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.3854 - accuracy: 0.9075 - val_loss: 0.4886 - val_accuracy: 0.8910\n",
            "\n",
            "Epoch 00216: val_accuracy did not improve from 0.90343\n",
            "Epoch 217/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.3740 - accuracy: 0.8973 - val_loss: 0.4512 - val_accuracy: 0.8910\n",
            "\n",
            "Epoch 00217: val_accuracy did not improve from 0.90343\n",
            "Epoch 218/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.3559 - accuracy: 0.9069 - val_loss: 0.4106 - val_accuracy: 0.9159\n",
            "\n",
            "Epoch 00218: val_accuracy improved from 0.90343 to 0.91589, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 219/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.3380 - accuracy: 0.9239 - val_loss: 0.4784 - val_accuracy: 0.8879\n",
            "\n",
            "Epoch 00219: val_accuracy did not improve from 0.91589\n",
            "Epoch 220/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.3173 - accuracy: 0.9222 - val_loss: 0.4576 - val_accuracy: 0.8910\n",
            "\n",
            "Epoch 00220: val_accuracy did not improve from 0.91589\n",
            "Epoch 221/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.3351 - accuracy: 0.9134 - val_loss: 0.5965 - val_accuracy: 0.8879\n",
            "\n",
            "Epoch 00221: val_accuracy did not improve from 0.91589\n",
            "Epoch 222/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.3162 - accuracy: 0.9190 - val_loss: 0.4468 - val_accuracy: 0.9034\n",
            "\n",
            "Epoch 00222: val_accuracy did not improve from 0.91589\n",
            "Epoch 223/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.3330 - accuracy: 0.9102 - val_loss: 0.5320 - val_accuracy: 0.8879\n",
            "\n",
            "Epoch 00223: val_accuracy did not improve from 0.91589\n",
            "Epoch 224/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.3619 - accuracy: 0.9152 - val_loss: 0.3951 - val_accuracy: 0.9190\n",
            "\n",
            "Epoch 00224: val_accuracy improved from 0.91589 to 0.91900, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 225/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.4235 - accuracy: 0.9104 - val_loss: 0.5196 - val_accuracy: 0.8879\n",
            "\n",
            "Epoch 00225: val_accuracy did not improve from 0.91900\n",
            "Epoch 226/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.3858 - accuracy: 0.9131 - val_loss: 0.4592 - val_accuracy: 0.9221\n",
            "\n",
            "Epoch 00226: val_accuracy improved from 0.91900 to 0.92212, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 227/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.4038 - accuracy: 0.9222 - val_loss: 0.4715 - val_accuracy: 0.9190\n",
            "\n",
            "Epoch 00227: val_accuracy did not improve from 0.92212\n",
            "Epoch 228/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.3093 - accuracy: 0.9292 - val_loss: 0.4877 - val_accuracy: 0.9190\n",
            "\n",
            "Epoch 00228: val_accuracy did not improve from 0.92212\n",
            "Epoch 229/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.3550 - accuracy: 0.9167 - val_loss: 0.5577 - val_accuracy: 0.8847\n",
            "\n",
            "Epoch 00229: val_accuracy did not improve from 0.92212\n",
            "Epoch 230/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.3673 - accuracy: 0.9163 - val_loss: 0.4927 - val_accuracy: 0.9097\n",
            "\n",
            "Epoch 00230: val_accuracy did not improve from 0.92212\n",
            "Epoch 231/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.3552 - accuracy: 0.9171 - val_loss: 0.4509 - val_accuracy: 0.9097\n",
            "\n",
            "Epoch 00231: val_accuracy did not improve from 0.92212\n",
            "Epoch 232/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.3649 - accuracy: 0.9199 - val_loss: 0.5137 - val_accuracy: 0.8910\n",
            "\n",
            "Epoch 00232: val_accuracy did not improve from 0.92212\n",
            "Epoch 233/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.3980 - accuracy: 0.9056 - val_loss: 0.5466 - val_accuracy: 0.8847\n",
            "\n",
            "Epoch 00233: val_accuracy did not improve from 0.92212\n",
            "Epoch 234/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.3366 - accuracy: 0.9410 - val_loss: 0.4345 - val_accuracy: 0.9159\n",
            "\n",
            "Epoch 00234: val_accuracy did not improve from 0.92212\n",
            "Epoch 235/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.3142 - accuracy: 0.9307 - val_loss: 0.4605 - val_accuracy: 0.9065\n",
            "\n",
            "Epoch 00235: val_accuracy did not improve from 0.92212\n",
            "Epoch 236/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.3384 - accuracy: 0.9235 - val_loss: 0.5087 - val_accuracy: 0.9159\n",
            "\n",
            "Epoch 00236: val_accuracy did not improve from 0.92212\n",
            "Epoch 237/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.3082 - accuracy: 0.9341 - val_loss: 0.4521 - val_accuracy: 0.9128\n",
            "\n",
            "Epoch 00237: val_accuracy did not improve from 0.92212\n",
            "Epoch 238/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.3243 - accuracy: 0.9267 - val_loss: 0.4939 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00238: val_accuracy did not improve from 0.92212\n",
            "Epoch 239/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.3487 - accuracy: 0.9171 - val_loss: 0.4412 - val_accuracy: 0.9097\n",
            "\n",
            "Epoch 00239: val_accuracy did not improve from 0.92212\n",
            "Epoch 240/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.2900 - accuracy: 0.9382 - val_loss: 0.5338 - val_accuracy: 0.8816\n",
            "\n",
            "Epoch 00240: val_accuracy did not improve from 0.92212\n",
            "Epoch 241/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2844 - accuracy: 0.9326 - val_loss: 0.5367 - val_accuracy: 0.8754\n",
            "\n",
            "Epoch 00241: val_accuracy did not improve from 0.92212\n",
            "Epoch 242/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.2911 - accuracy: 0.9371 - val_loss: 0.4486 - val_accuracy: 0.9034\n",
            "\n",
            "Epoch 00242: val_accuracy did not improve from 0.92212\n",
            "Epoch 243/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.3986 - accuracy: 0.9137 - val_loss: 0.5577 - val_accuracy: 0.8754\n",
            "\n",
            "Epoch 00243: val_accuracy did not improve from 0.92212\n",
            "Epoch 244/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.4651 - accuracy: 0.8875 - val_loss: 0.4973 - val_accuracy: 0.8910\n",
            "\n",
            "Epoch 00244: val_accuracy did not improve from 0.92212\n",
            "Epoch 245/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.3459 - accuracy: 0.9266 - val_loss: 0.4696 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00245: val_accuracy did not improve from 0.92212\n",
            "Epoch 246/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.3374 - accuracy: 0.9361 - val_loss: 0.4470 - val_accuracy: 0.9159\n",
            "\n",
            "Epoch 00246: val_accuracy did not improve from 0.92212\n",
            "Epoch 247/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.3166 - accuracy: 0.9341 - val_loss: 0.3950 - val_accuracy: 0.9159\n",
            "\n",
            "Epoch 00247: val_accuracy did not improve from 0.92212\n",
            "Epoch 248/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2910 - accuracy: 0.9332 - val_loss: 0.4696 - val_accuracy: 0.8972\n",
            "\n",
            "Epoch 00248: val_accuracy did not improve from 0.92212\n",
            "Epoch 249/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.4354 - accuracy: 0.9064 - val_loss: 0.5879 - val_accuracy: 0.8723\n",
            "\n",
            "Epoch 00249: val_accuracy did not improve from 0.92212\n",
            "Epoch 250/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.3354 - accuracy: 0.9339 - val_loss: 0.4940 - val_accuracy: 0.9065\n",
            "\n",
            "Epoch 00250: val_accuracy did not improve from 0.92212\n",
            "Epoch 251/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.3233 - accuracy: 0.9307 - val_loss: 0.4729 - val_accuracy: 0.9065\n",
            "\n",
            "Epoch 00251: val_accuracy did not improve from 0.92212\n",
            "Epoch 252/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.3629 - accuracy: 0.9236 - val_loss: 0.5006 - val_accuracy: 0.9065\n",
            "\n",
            "Epoch 00252: val_accuracy did not improve from 0.92212\n",
            "Epoch 253/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.3492 - accuracy: 0.9165 - val_loss: 0.4677 - val_accuracy: 0.9097\n",
            "\n",
            "Epoch 00253: val_accuracy did not improve from 0.92212\n",
            "Epoch 254/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.3480 - accuracy: 0.9219 - val_loss: 0.5025 - val_accuracy: 0.8910\n",
            "\n",
            "Epoch 00254: val_accuracy did not improve from 0.92212\n",
            "Epoch 255/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2721 - accuracy: 0.9478 - val_loss: 0.4241 - val_accuracy: 0.9065\n",
            "\n",
            "Epoch 00255: val_accuracy did not improve from 0.92212\n",
            "Epoch 256/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2474 - accuracy: 0.9557 - val_loss: 0.4336 - val_accuracy: 0.9159\n",
            "\n",
            "Epoch 00256: val_accuracy did not improve from 0.92212\n",
            "Epoch 257/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2666 - accuracy: 0.9486 - val_loss: 0.6019 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00257: val_accuracy did not improve from 0.92212\n",
            "Epoch 258/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.3254 - accuracy: 0.9394 - val_loss: 0.4191 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00258: val_accuracy improved from 0.92212 to 0.92523, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 259/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2965 - accuracy: 0.9378 - val_loss: 0.3832 - val_accuracy: 0.9159\n",
            "\n",
            "Epoch 00259: val_accuracy did not improve from 0.92523\n",
            "Epoch 260/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.3031 - accuracy: 0.9397 - val_loss: 0.5000 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00260: val_accuracy did not improve from 0.92523\n",
            "Epoch 261/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.3275 - accuracy: 0.9267 - val_loss: 0.4845 - val_accuracy: 0.9034\n",
            "\n",
            "Epoch 00261: val_accuracy did not improve from 0.92523\n",
            "Epoch 262/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.3161 - accuracy: 0.9401 - val_loss: 0.4451 - val_accuracy: 0.9128\n",
            "\n",
            "Epoch 00262: val_accuracy did not improve from 0.92523\n",
            "Epoch 263/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.3843 - accuracy: 0.9167 - val_loss: 0.4973 - val_accuracy: 0.9003\n",
            "\n",
            "Epoch 00263: val_accuracy did not improve from 0.92523\n",
            "Epoch 264/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.3857 - accuracy: 0.9272 - val_loss: 0.4716 - val_accuracy: 0.9065\n",
            "\n",
            "Epoch 00264: val_accuracy did not improve from 0.92523\n",
            "Epoch 265/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.3532 - accuracy: 0.9353 - val_loss: 0.4946 - val_accuracy: 0.8972\n",
            "\n",
            "Epoch 00265: val_accuracy did not improve from 0.92523\n",
            "Epoch 266/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.2708 - accuracy: 0.9563 - val_loss: 0.4463 - val_accuracy: 0.9065\n",
            "\n",
            "Epoch 00266: val_accuracy did not improve from 0.92523\n",
            "Epoch 267/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3149 - accuracy: 0.9195 - val_loss: 0.4214 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00267: val_accuracy improved from 0.92523 to 0.93146, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 268/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.2881 - accuracy: 0.9485 - val_loss: 0.5083 - val_accuracy: 0.9003\n",
            "\n",
            "Epoch 00268: val_accuracy did not improve from 0.93146\n",
            "Epoch 269/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.2857 - accuracy: 0.9381 - val_loss: 0.4291 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00269: val_accuracy did not improve from 0.93146\n",
            "Epoch 270/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2816 - accuracy: 0.9424 - val_loss: 0.4466 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00270: val_accuracy did not improve from 0.93146\n",
            "Epoch 271/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2685 - accuracy: 0.9530 - val_loss: 0.4076 - val_accuracy: 0.9159\n",
            "\n",
            "Epoch 00271: val_accuracy did not improve from 0.93146\n",
            "Epoch 272/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2584 - accuracy: 0.9473 - val_loss: 0.4640 - val_accuracy: 0.9190\n",
            "\n",
            "Epoch 00272: val_accuracy did not improve from 0.93146\n",
            "Epoch 273/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.1989 - accuracy: 0.9643 - val_loss: 0.4074 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00273: val_accuracy did not improve from 0.93146\n",
            "Epoch 274/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.2961 - accuracy: 0.9329 - val_loss: 0.4722 - val_accuracy: 0.9034\n",
            "\n",
            "Epoch 00274: val_accuracy did not improve from 0.93146\n",
            "Epoch 275/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.3281 - accuracy: 0.9276 - val_loss: 0.4257 - val_accuracy: 0.9128\n",
            "\n",
            "Epoch 00275: val_accuracy did not improve from 0.93146\n",
            "Epoch 276/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.3711 - accuracy: 0.9393 - val_loss: 0.3910 - val_accuracy: 0.9221\n",
            "\n",
            "Epoch 00276: val_accuracy did not improve from 0.93146\n",
            "Epoch 277/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2719 - accuracy: 0.9544 - val_loss: 0.3888 - val_accuracy: 0.9159\n",
            "\n",
            "Epoch 00277: val_accuracy did not improve from 0.93146\n",
            "Epoch 278/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.2613 - accuracy: 0.9433 - val_loss: 0.4387 - val_accuracy: 0.9003\n",
            "\n",
            "Epoch 00278: val_accuracy did not improve from 0.93146\n",
            "Epoch 279/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.2915 - accuracy: 0.9359 - val_loss: 0.4206 - val_accuracy: 0.9190\n",
            "\n",
            "Epoch 00279: val_accuracy did not improve from 0.93146\n",
            "Epoch 280/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2361 - accuracy: 0.9541 - val_loss: 0.5480 - val_accuracy: 0.8972\n",
            "\n",
            "Epoch 00280: val_accuracy did not improve from 0.93146\n",
            "Epoch 281/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2269 - accuracy: 0.9588 - val_loss: 0.4006 - val_accuracy: 0.9159\n",
            "\n",
            "Epoch 00281: val_accuracy did not improve from 0.93146\n",
            "Epoch 282/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2964 - accuracy: 0.9329 - val_loss: 0.4173 - val_accuracy: 0.9221\n",
            "\n",
            "Epoch 00282: val_accuracy did not improve from 0.93146\n",
            "Epoch 283/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2751 - accuracy: 0.9445 - val_loss: 0.5251 - val_accuracy: 0.9097\n",
            "\n",
            "Epoch 00283: val_accuracy did not improve from 0.93146\n",
            "Epoch 284/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2746 - accuracy: 0.9353 - val_loss: 0.4474 - val_accuracy: 0.9159\n",
            "\n",
            "Epoch 00284: val_accuracy did not improve from 0.93146\n",
            "Epoch 285/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.2653 - accuracy: 0.9494 - val_loss: 0.4522 - val_accuracy: 0.9221\n",
            "\n",
            "Epoch 00285: val_accuracy did not improve from 0.93146\n",
            "Epoch 286/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.3046 - accuracy: 0.9313 - val_loss: 0.4418 - val_accuracy: 0.9190\n",
            "\n",
            "Epoch 00286: val_accuracy did not improve from 0.93146\n",
            "Epoch 287/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.2708 - accuracy: 0.9442 - val_loss: 0.3706 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00287: val_accuracy did not improve from 0.93146\n",
            "Epoch 288/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2118 - accuracy: 0.9669 - val_loss: 0.4014 - val_accuracy: 0.9190\n",
            "\n",
            "Epoch 00288: val_accuracy did not improve from 0.93146\n",
            "Epoch 289/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1958 - accuracy: 0.9658 - val_loss: 0.4494 - val_accuracy: 0.9097\n",
            "\n",
            "Epoch 00289: val_accuracy did not improve from 0.93146\n",
            "Epoch 290/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.2858 - accuracy: 0.9503 - val_loss: 0.4895 - val_accuracy: 0.9159\n",
            "\n",
            "Epoch 00290: val_accuracy did not improve from 0.93146\n",
            "Epoch 291/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.3706 - accuracy: 0.9384 - val_loss: 0.5190 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00291: val_accuracy did not improve from 0.93146\n",
            "Epoch 292/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.3918 - accuracy: 0.9103 - val_loss: 0.4598 - val_accuracy: 0.8910\n",
            "\n",
            "Epoch 00292: val_accuracy did not improve from 0.93146\n",
            "Epoch 293/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.3104 - accuracy: 0.9297 - val_loss: 0.4241 - val_accuracy: 0.8972\n",
            "\n",
            "Epoch 00293: val_accuracy did not improve from 0.93146\n",
            "Epoch 294/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2535 - accuracy: 0.9661 - val_loss: 0.4425 - val_accuracy: 0.9034\n",
            "\n",
            "Epoch 00294: val_accuracy did not improve from 0.93146\n",
            "Epoch 295/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2750 - accuracy: 0.9514 - val_loss: 0.5149 - val_accuracy: 0.9128\n",
            "\n",
            "Epoch 00295: val_accuracy did not improve from 0.93146\n",
            "Epoch 296/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.2590 - accuracy: 0.9515 - val_loss: 0.4889 - val_accuracy: 0.9097\n",
            "\n",
            "Epoch 00296: val_accuracy did not improve from 0.93146\n",
            "Epoch 297/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2981 - accuracy: 0.9412 - val_loss: 0.3889 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00297: val_accuracy did not improve from 0.93146\n",
            "Epoch 298/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.2842 - accuracy: 0.9418 - val_loss: 0.4926 - val_accuracy: 0.8879\n",
            "\n",
            "Epoch 00298: val_accuracy did not improve from 0.93146\n",
            "Epoch 299/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2122 - accuracy: 0.9508 - val_loss: 0.5229 - val_accuracy: 0.9003\n",
            "\n",
            "Epoch 00299: val_accuracy did not improve from 0.93146\n",
            "Epoch 300/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2410 - accuracy: 0.9588 - val_loss: 0.4060 - val_accuracy: 0.9190\n",
            "\n",
            "Epoch 00300: val_accuracy did not improve from 0.93146\n",
            "Epoch 301/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2250 - accuracy: 0.9543 - val_loss: 0.4338 - val_accuracy: 0.9159\n",
            "\n",
            "Epoch 00301: val_accuracy did not improve from 0.93146\n",
            "Epoch 302/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.3268 - accuracy: 0.9276 - val_loss: 0.4518 - val_accuracy: 0.9128\n",
            "\n",
            "Epoch 00302: val_accuracy did not improve from 0.93146\n",
            "Epoch 303/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2246 - accuracy: 0.9674 - val_loss: 0.5170 - val_accuracy: 0.9034\n",
            "\n",
            "Epoch 00303: val_accuracy did not improve from 0.93146\n",
            "Epoch 304/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2545 - accuracy: 0.9455 - val_loss: 0.4397 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00304: val_accuracy did not improve from 0.93146\n",
            "Epoch 305/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2826 - accuracy: 0.9552 - val_loss: 0.4578 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00305: val_accuracy did not improve from 0.93146\n",
            "Epoch 306/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2125 - accuracy: 0.9591 - val_loss: 0.3903 - val_accuracy: 0.9221\n",
            "\n",
            "Epoch 00306: val_accuracy did not improve from 0.93146\n",
            "Epoch 307/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2492 - accuracy: 0.9559 - val_loss: 0.5127 - val_accuracy: 0.9097\n",
            "\n",
            "Epoch 00307: val_accuracy did not improve from 0.93146\n",
            "Epoch 308/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2246 - accuracy: 0.9617 - val_loss: 0.4663 - val_accuracy: 0.9190\n",
            "\n",
            "Epoch 00308: val_accuracy did not improve from 0.93146\n",
            "Epoch 309/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.3136 - accuracy: 0.9452 - val_loss: 0.5325 - val_accuracy: 0.9097\n",
            "\n",
            "Epoch 00309: val_accuracy did not improve from 0.93146\n",
            "Epoch 310/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2472 - accuracy: 0.9565 - val_loss: 0.5820 - val_accuracy: 0.9097\n",
            "\n",
            "Epoch 00310: val_accuracy did not improve from 0.93146\n",
            "Epoch 311/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2459 - accuracy: 0.9627 - val_loss: 0.5477 - val_accuracy: 0.9097\n",
            "\n",
            "Epoch 00311: val_accuracy did not improve from 0.93146\n",
            "Epoch 312/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.2718 - accuracy: 0.9492 - val_loss: 0.5323 - val_accuracy: 0.9065\n",
            "\n",
            "Epoch 00312: val_accuracy did not improve from 0.93146\n",
            "Epoch 313/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2393 - accuracy: 0.9534 - val_loss: 0.4392 - val_accuracy: 0.9159\n",
            "\n",
            "Epoch 00313: val_accuracy did not improve from 0.93146\n",
            "Epoch 314/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.2334 - accuracy: 0.9556 - val_loss: 0.4268 - val_accuracy: 0.9190\n",
            "\n",
            "Epoch 00314: val_accuracy did not improve from 0.93146\n",
            "Epoch 315/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2263 - accuracy: 0.9586 - val_loss: 0.4593 - val_accuracy: 0.9159\n",
            "\n",
            "Epoch 00315: val_accuracy did not improve from 0.93146\n",
            "Epoch 316/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2355 - accuracy: 0.9522 - val_loss: 0.4968 - val_accuracy: 0.9065\n",
            "\n",
            "Epoch 00316: val_accuracy did not improve from 0.93146\n",
            "Epoch 317/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.3339 - accuracy: 0.9400 - val_loss: 0.5047 - val_accuracy: 0.9034\n",
            "\n",
            "Epoch 00317: val_accuracy did not improve from 0.93146\n",
            "Epoch 318/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2997 - accuracy: 0.9371 - val_loss: 0.4117 - val_accuracy: 0.9128\n",
            "\n",
            "Epoch 00318: val_accuracy did not improve from 0.93146\n",
            "Epoch 319/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.2506 - accuracy: 0.9449 - val_loss: 0.4969 - val_accuracy: 0.9159\n",
            "\n",
            "Epoch 00319: val_accuracy did not improve from 0.93146\n",
            "Epoch 320/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.2549 - accuracy: 0.9515 - val_loss: 0.4430 - val_accuracy: 0.9034\n",
            "\n",
            "Epoch 00320: val_accuracy did not improve from 0.93146\n",
            "Epoch 321/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3320 - accuracy: 0.9423 - val_loss: 0.5126 - val_accuracy: 0.8972\n",
            "\n",
            "Epoch 00321: val_accuracy did not improve from 0.93146\n",
            "Epoch 322/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2965 - accuracy: 0.9407 - val_loss: 0.5510 - val_accuracy: 0.9034\n",
            "\n",
            "Epoch 00322: val_accuracy did not improve from 0.93146\n",
            "Epoch 323/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.3168 - accuracy: 0.9423 - val_loss: 0.4489 - val_accuracy: 0.9097\n",
            "\n",
            "Epoch 00323: val_accuracy did not improve from 0.93146\n",
            "Epoch 324/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1908 - accuracy: 0.9658 - val_loss: 0.4913 - val_accuracy: 0.9190\n",
            "\n",
            "Epoch 00324: val_accuracy did not improve from 0.93146\n",
            "Epoch 325/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2176 - accuracy: 0.9609 - val_loss: 0.4260 - val_accuracy: 0.9159\n",
            "\n",
            "Epoch 00325: val_accuracy did not improve from 0.93146\n",
            "Epoch 326/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2223 - accuracy: 0.9525 - val_loss: 0.4376 - val_accuracy: 0.9221\n",
            "\n",
            "Epoch 00326: val_accuracy did not improve from 0.93146\n",
            "Epoch 327/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2374 - accuracy: 0.9523 - val_loss: 0.5376 - val_accuracy: 0.9097\n",
            "\n",
            "Epoch 00327: val_accuracy did not improve from 0.93146\n",
            "Epoch 328/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1861 - accuracy: 0.9630 - val_loss: 0.5248 - val_accuracy: 0.9128\n",
            "\n",
            "Epoch 00328: val_accuracy did not improve from 0.93146\n",
            "Epoch 329/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.1739 - accuracy: 0.9664 - val_loss: 0.5522 - val_accuracy: 0.9065\n",
            "\n",
            "Epoch 00329: val_accuracy did not improve from 0.93146\n",
            "Epoch 330/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1861 - accuracy: 0.9673 - val_loss: 0.5737 - val_accuracy: 0.9097\n",
            "\n",
            "Epoch 00330: val_accuracy did not improve from 0.93146\n",
            "Epoch 331/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1535 - accuracy: 0.9725 - val_loss: 0.4368 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00331: val_accuracy did not improve from 0.93146\n",
            "Epoch 332/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1920 - accuracy: 0.9692 - val_loss: 0.4348 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00332: val_accuracy did not improve from 0.93146\n",
            "Epoch 333/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1788 - accuracy: 0.9609 - val_loss: 0.4882 - val_accuracy: 0.9221\n",
            "\n",
            "Epoch 00333: val_accuracy did not improve from 0.93146\n",
            "Epoch 334/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2191 - accuracy: 0.9479 - val_loss: 0.5131 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00334: val_accuracy did not improve from 0.93146\n",
            "Epoch 335/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2093 - accuracy: 0.9583 - val_loss: 0.4942 - val_accuracy: 0.9221\n",
            "\n",
            "Epoch 00335: val_accuracy did not improve from 0.93146\n",
            "Epoch 336/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2426 - accuracy: 0.9610 - val_loss: 0.4464 - val_accuracy: 0.9159\n",
            "\n",
            "Epoch 00336: val_accuracy did not improve from 0.93146\n",
            "Epoch 337/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2720 - accuracy: 0.9483 - val_loss: 0.4032 - val_accuracy: 0.9159\n",
            "\n",
            "Epoch 00337: val_accuracy did not improve from 0.93146\n",
            "Epoch 338/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2177 - accuracy: 0.9675 - val_loss: 0.4759 - val_accuracy: 0.9159\n",
            "\n",
            "Epoch 00338: val_accuracy did not improve from 0.93146\n",
            "Epoch 339/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2625 - accuracy: 0.9562 - val_loss: 0.4745 - val_accuracy: 0.9190\n",
            "\n",
            "Epoch 00339: val_accuracy did not improve from 0.93146\n",
            "Epoch 340/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2363 - accuracy: 0.9586 - val_loss: 0.4398 - val_accuracy: 0.9190\n",
            "\n",
            "Epoch 00340: val_accuracy did not improve from 0.93146\n",
            "Epoch 341/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1823 - accuracy: 0.9758 - val_loss: 0.4199 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00341: val_accuracy did not improve from 0.93146\n",
            "Epoch 342/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1611 - accuracy: 0.9718 - val_loss: 0.4597 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00342: val_accuracy improved from 0.93146 to 0.93458, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 343/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1689 - accuracy: 0.9697 - val_loss: 0.4845 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00343: val_accuracy did not improve from 0.93458\n",
            "Epoch 344/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1649 - accuracy: 0.9710 - val_loss: 0.4450 - val_accuracy: 0.9377\n",
            "\n",
            "Epoch 00344: val_accuracy improved from 0.93458 to 0.93769, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 345/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.2159 - accuracy: 0.9585 - val_loss: 0.4732 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00345: val_accuracy did not improve from 0.93769\n",
            "Epoch 346/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.3395 - accuracy: 0.9308 - val_loss: 0.4761 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00346: val_accuracy did not improve from 0.93769\n",
            "Epoch 347/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2946 - accuracy: 0.9471 - val_loss: 0.5659 - val_accuracy: 0.9159\n",
            "\n",
            "Epoch 00347: val_accuracy did not improve from 0.93769\n",
            "Epoch 348/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2346 - accuracy: 0.9632 - val_loss: 0.4537 - val_accuracy: 0.9159\n",
            "\n",
            "Epoch 00348: val_accuracy did not improve from 0.93769\n",
            "Epoch 349/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2632 - accuracy: 0.9460 - val_loss: 0.5022 - val_accuracy: 0.9097\n",
            "\n",
            "Epoch 00349: val_accuracy did not improve from 0.93769\n",
            "Epoch 350/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2296 - accuracy: 0.9622 - val_loss: 0.5031 - val_accuracy: 0.9190\n",
            "\n",
            "Epoch 00350: val_accuracy did not improve from 0.93769\n",
            "Epoch 351/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1742 - accuracy: 0.9758 - val_loss: 0.4713 - val_accuracy: 0.9221\n",
            "\n",
            "Epoch 00351: val_accuracy did not improve from 0.93769\n",
            "Epoch 352/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1969 - accuracy: 0.9594 - val_loss: 0.5104 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00352: val_accuracy did not improve from 0.93769\n",
            "Epoch 353/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.1700 - accuracy: 0.9703 - val_loss: 0.4721 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00353: val_accuracy did not improve from 0.93769\n",
            "Epoch 354/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2339 - accuracy: 0.9642 - val_loss: 0.4310 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00354: val_accuracy did not improve from 0.93769\n",
            "Epoch 355/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.2387 - accuracy: 0.9604 - val_loss: 0.4369 - val_accuracy: 0.9159\n",
            "\n",
            "Epoch 00355: val_accuracy did not improve from 0.93769\n",
            "Epoch 356/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1847 - accuracy: 0.9689 - val_loss: 0.4129 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00356: val_accuracy did not improve from 0.93769\n",
            "Epoch 357/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1786 - accuracy: 0.9759 - val_loss: 0.4080 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00357: val_accuracy did not improve from 0.93769\n",
            "Epoch 358/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1874 - accuracy: 0.9678 - val_loss: 0.4276 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00358: val_accuracy did not improve from 0.93769\n",
            "Epoch 359/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1404 - accuracy: 0.9840 - val_loss: 0.5073 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00359: val_accuracy did not improve from 0.93769\n",
            "Epoch 360/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1631 - accuracy: 0.9647 - val_loss: 0.4120 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00360: val_accuracy did not improve from 0.93769\n",
            "Epoch 361/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1452 - accuracy: 0.9737 - val_loss: 0.4225 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00361: val_accuracy did not improve from 0.93769\n",
            "Epoch 362/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1382 - accuracy: 0.9802 - val_loss: 0.4191 - val_accuracy: 0.9190\n",
            "\n",
            "Epoch 00362: val_accuracy did not improve from 0.93769\n",
            "Epoch 363/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2075 - accuracy: 0.9485 - val_loss: 0.4463 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00363: val_accuracy did not improve from 0.93769\n",
            "Epoch 364/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2092 - accuracy: 0.9674 - val_loss: 0.4137 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00364: val_accuracy did not improve from 0.93769\n",
            "Epoch 365/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1969 - accuracy: 0.9713 - val_loss: 0.4692 - val_accuracy: 0.9377\n",
            "\n",
            "Epoch 00365: val_accuracy did not improve from 0.93769\n",
            "Epoch 366/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.1922 - accuracy: 0.9613 - val_loss: 0.5037 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00366: val_accuracy did not improve from 0.93769\n",
            "Epoch 367/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.1451 - accuracy: 0.9778 - val_loss: 0.4207 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00367: val_accuracy did not improve from 0.93769\n",
            "Epoch 368/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1642 - accuracy: 0.9705 - val_loss: 0.3840 - val_accuracy: 0.9221\n",
            "\n",
            "Epoch 00368: val_accuracy did not improve from 0.93769\n",
            "Epoch 369/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1587 - accuracy: 0.9720 - val_loss: 0.3783 - val_accuracy: 0.9221\n",
            "\n",
            "Epoch 00369: val_accuracy did not improve from 0.93769\n",
            "Epoch 370/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1803 - accuracy: 0.9682 - val_loss: 0.4618 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00370: val_accuracy did not improve from 0.93769\n",
            "Epoch 371/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1741 - accuracy: 0.9696 - val_loss: 0.4689 - val_accuracy: 0.9159\n",
            "\n",
            "Epoch 00371: val_accuracy did not improve from 0.93769\n",
            "Epoch 372/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2468 - accuracy: 0.9544 - val_loss: 0.4778 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00372: val_accuracy did not improve from 0.93769\n",
            "Epoch 373/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2332 - accuracy: 0.9700 - val_loss: 0.5651 - val_accuracy: 0.9034\n",
            "\n",
            "Epoch 00373: val_accuracy did not improve from 0.93769\n",
            "Epoch 374/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2322 - accuracy: 0.9624 - val_loss: 0.4720 - val_accuracy: 0.9128\n",
            "\n",
            "Epoch 00374: val_accuracy did not improve from 0.93769\n",
            "Epoch 375/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.2512 - accuracy: 0.9529 - val_loss: 0.4773 - val_accuracy: 0.9221\n",
            "\n",
            "Epoch 00375: val_accuracy did not improve from 0.93769\n",
            "Epoch 376/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.2189 - accuracy: 0.9590 - val_loss: 0.3973 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00376: val_accuracy did not improve from 0.93769\n",
            "Epoch 377/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1797 - accuracy: 0.9739 - val_loss: 0.4306 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00377: val_accuracy did not improve from 0.93769\n",
            "Epoch 378/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2411 - accuracy: 0.9588 - val_loss: 0.4487 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00378: val_accuracy did not improve from 0.93769\n",
            "Epoch 379/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1915 - accuracy: 0.9658 - val_loss: 0.3957 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00379: val_accuracy did not improve from 0.93769\n",
            "Epoch 380/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1925 - accuracy: 0.9723 - val_loss: 0.3641 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00380: val_accuracy did not improve from 0.93769\n",
            "Epoch 381/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1718 - accuracy: 0.9773 - val_loss: 0.3629 - val_accuracy: 0.9408\n",
            "\n",
            "Epoch 00381: val_accuracy improved from 0.93769 to 0.94081, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 382/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1364 - accuracy: 0.9739 - val_loss: 0.4340 - val_accuracy: 0.9221\n",
            "\n",
            "Epoch 00382: val_accuracy did not improve from 0.94081\n",
            "Epoch 383/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1630 - accuracy: 0.9652 - val_loss: 0.4811 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00383: val_accuracy did not improve from 0.94081\n",
            "Epoch 384/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1737 - accuracy: 0.9656 - val_loss: 0.5161 - val_accuracy: 0.9190\n",
            "\n",
            "Epoch 00384: val_accuracy did not improve from 0.94081\n",
            "Epoch 385/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1617 - accuracy: 0.9691 - val_loss: 0.3925 - val_accuracy: 0.9377\n",
            "\n",
            "Epoch 00385: val_accuracy did not improve from 0.94081\n",
            "Epoch 386/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1406 - accuracy: 0.9743 - val_loss: 0.4660 - val_accuracy: 0.9221\n",
            "\n",
            "Epoch 00386: val_accuracy did not improve from 0.94081\n",
            "Epoch 387/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1200 - accuracy: 0.9837 - val_loss: 0.4250 - val_accuracy: 0.9221\n",
            "\n",
            "Epoch 00387: val_accuracy did not improve from 0.94081\n",
            "Epoch 388/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1800 - accuracy: 0.9658 - val_loss: 0.3813 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00388: val_accuracy did not improve from 0.94081\n",
            "Epoch 389/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2278 - accuracy: 0.9571 - val_loss: 0.6626 - val_accuracy: 0.8879\n",
            "\n",
            "Epoch 00389: val_accuracy did not improve from 0.94081\n",
            "Epoch 390/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2907 - accuracy: 0.9603 - val_loss: 0.5362 - val_accuracy: 0.9065\n",
            "\n",
            "Epoch 00390: val_accuracy did not improve from 0.94081\n",
            "Epoch 391/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.2140 - accuracy: 0.9629 - val_loss: 0.4311 - val_accuracy: 0.9221\n",
            "\n",
            "Epoch 00391: val_accuracy did not improve from 0.94081\n",
            "Epoch 392/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1692 - accuracy: 0.9714 - val_loss: 0.4606 - val_accuracy: 0.9221\n",
            "\n",
            "Epoch 00392: val_accuracy did not improve from 0.94081\n",
            "Epoch 393/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1974 - accuracy: 0.9613 - val_loss: 0.4597 - val_accuracy: 0.9221\n",
            "\n",
            "Epoch 00393: val_accuracy did not improve from 0.94081\n",
            "Epoch 394/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1658 - accuracy: 0.9747 - val_loss: 0.4307 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00394: val_accuracy did not improve from 0.94081\n",
            "Epoch 395/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1854 - accuracy: 0.9683 - val_loss: 0.4749 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00395: val_accuracy did not improve from 0.94081\n",
            "Epoch 396/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1574 - accuracy: 0.9726 - val_loss: 0.4391 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00396: val_accuracy did not improve from 0.94081\n",
            "Epoch 397/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1905 - accuracy: 0.9675 - val_loss: 0.5105 - val_accuracy: 0.9190\n",
            "\n",
            "Epoch 00397: val_accuracy did not improve from 0.94081\n",
            "Epoch 398/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1739 - accuracy: 0.9745 - val_loss: 0.4922 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00398: val_accuracy did not improve from 0.94081\n",
            "Epoch 399/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1344 - accuracy: 0.9797 - val_loss: 0.4989 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00399: val_accuracy did not improve from 0.94081\n",
            "Epoch 400/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.2949 - accuracy: 0.9460 - val_loss: 0.4082 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00400: val_accuracy did not improve from 0.94081\n",
            "Epoch 401/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2192 - accuracy: 0.9680 - val_loss: 0.4484 - val_accuracy: 0.9221\n",
            "\n",
            "Epoch 00401: val_accuracy did not improve from 0.94081\n",
            "Epoch 402/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.2006 - accuracy: 0.9709 - val_loss: 0.3980 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00402: val_accuracy did not improve from 0.94081\n",
            "Epoch 403/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1988 - accuracy: 0.9606 - val_loss: 0.4358 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00403: val_accuracy did not improve from 0.94081\n",
            "Epoch 404/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2243 - accuracy: 0.9592 - val_loss: 0.4623 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00404: val_accuracy did not improve from 0.94081\n",
            "Epoch 405/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1903 - accuracy: 0.9727 - val_loss: 0.4966 - val_accuracy: 0.9190\n",
            "\n",
            "Epoch 00405: val_accuracy did not improve from 0.94081\n",
            "Epoch 406/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1849 - accuracy: 0.9694 - val_loss: 0.3901 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00406: val_accuracy did not improve from 0.94081\n",
            "Epoch 407/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1633 - accuracy: 0.9716 - val_loss: 0.4312 - val_accuracy: 0.9221\n",
            "\n",
            "Epoch 00407: val_accuracy did not improve from 0.94081\n",
            "Epoch 408/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1711 - accuracy: 0.9724 - val_loss: 0.4499 - val_accuracy: 0.9097\n",
            "\n",
            "Epoch 00408: val_accuracy did not improve from 0.94081\n",
            "Epoch 409/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1780 - accuracy: 0.9684 - val_loss: 0.4240 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00409: val_accuracy did not improve from 0.94081\n",
            "Epoch 410/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2089 - accuracy: 0.9707 - val_loss: 0.3404 - val_accuracy: 0.9221\n",
            "\n",
            "Epoch 00410: val_accuracy did not improve from 0.94081\n",
            "Epoch 411/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1483 - accuracy: 0.9827 - val_loss: 0.4978 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00411: val_accuracy did not improve from 0.94081\n",
            "Epoch 412/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1481 - accuracy: 0.9716 - val_loss: 0.5382 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00412: val_accuracy did not improve from 0.94081\n",
            "Epoch 413/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1595 - accuracy: 0.9792 - val_loss: 0.5292 - val_accuracy: 0.9097\n",
            "\n",
            "Epoch 00413: val_accuracy did not improve from 0.94081\n",
            "Epoch 414/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1799 - accuracy: 0.9659 - val_loss: 0.5253 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00414: val_accuracy did not improve from 0.94081\n",
            "Epoch 415/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1903 - accuracy: 0.9738 - val_loss: 0.5671 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00415: val_accuracy did not improve from 0.94081\n",
            "Epoch 416/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1371 - accuracy: 0.9782 - val_loss: 0.5102 - val_accuracy: 0.9065\n",
            "\n",
            "Epoch 00416: val_accuracy did not improve from 0.94081\n",
            "Epoch 417/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1549 - accuracy: 0.9742 - val_loss: 0.5077 - val_accuracy: 0.9190\n",
            "\n",
            "Epoch 00417: val_accuracy did not improve from 0.94081\n",
            "Epoch 418/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.1751 - accuracy: 0.9686 - val_loss: 0.4028 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00418: val_accuracy did not improve from 0.94081\n",
            "Epoch 419/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2068 - accuracy: 0.9498 - val_loss: 0.4551 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00419: val_accuracy did not improve from 0.94081\n",
            "Epoch 420/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1926 - accuracy: 0.9702 - val_loss: 0.4777 - val_accuracy: 0.9221\n",
            "\n",
            "Epoch 00420: val_accuracy did not improve from 0.94081\n",
            "Epoch 421/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1937 - accuracy: 0.9682 - val_loss: 0.4866 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00421: val_accuracy did not improve from 0.94081\n",
            "Epoch 422/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1516 - accuracy: 0.9738 - val_loss: 0.4852 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00422: val_accuracy did not improve from 0.94081\n",
            "Epoch 423/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1953 - accuracy: 0.9686 - val_loss: 0.5056 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00423: val_accuracy did not improve from 0.94081\n",
            "Epoch 424/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1951 - accuracy: 0.9700 - val_loss: 0.5167 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00424: val_accuracy did not improve from 0.94081\n",
            "Epoch 425/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1888 - accuracy: 0.9650 - val_loss: 0.5408 - val_accuracy: 0.9159\n",
            "\n",
            "Epoch 00425: val_accuracy did not improve from 0.94081\n",
            "Epoch 426/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1527 - accuracy: 0.9739 - val_loss: 0.5403 - val_accuracy: 0.9159\n",
            "\n",
            "Epoch 00426: val_accuracy did not improve from 0.94081\n",
            "Epoch 427/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1809 - accuracy: 0.9707 - val_loss: 0.5040 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00427: val_accuracy did not improve from 0.94081\n",
            "Epoch 428/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2132 - accuracy: 0.9676 - val_loss: 0.4126 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00428: val_accuracy did not improve from 0.94081\n",
            "Epoch 429/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1702 - accuracy: 0.9710 - val_loss: 0.4361 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00429: val_accuracy did not improve from 0.94081\n",
            "Epoch 430/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2244 - accuracy: 0.9571 - val_loss: 0.4885 - val_accuracy: 0.9221\n",
            "\n",
            "Epoch 00430: val_accuracy did not improve from 0.94081\n",
            "Epoch 431/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1907 - accuracy: 0.9680 - val_loss: 0.4336 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00431: val_accuracy did not improve from 0.94081\n",
            "Epoch 432/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.3519 - accuracy: 0.9377 - val_loss: 0.6861 - val_accuracy: 0.8785\n",
            "\n",
            "Epoch 00432: val_accuracy did not improve from 0.94081\n",
            "Epoch 433/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.3356 - accuracy: 0.9512 - val_loss: 0.5283 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00433: val_accuracy did not improve from 0.94081\n",
            "Epoch 434/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2782 - accuracy: 0.9646 - val_loss: 0.5089 - val_accuracy: 0.9159\n",
            "\n",
            "Epoch 00434: val_accuracy did not improve from 0.94081\n",
            "Epoch 435/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2492 - accuracy: 0.9691 - val_loss: 0.5206 - val_accuracy: 0.9034\n",
            "\n",
            "Epoch 00435: val_accuracy did not improve from 0.94081\n",
            "Epoch 436/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.3058 - accuracy: 0.9597 - val_loss: 0.5974 - val_accuracy: 0.9190\n",
            "\n",
            "Epoch 00436: val_accuracy did not improve from 0.94081\n",
            "Epoch 437/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.3072 - accuracy: 0.9526 - val_loss: 0.5472 - val_accuracy: 0.9190\n",
            "\n",
            "Epoch 00437: val_accuracy did not improve from 0.94081\n",
            "Epoch 438/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2745 - accuracy: 0.9622 - val_loss: 0.5151 - val_accuracy: 0.9159\n",
            "\n",
            "Epoch 00438: val_accuracy did not improve from 0.94081\n",
            "Epoch 439/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2462 - accuracy: 0.9647 - val_loss: 0.4769 - val_accuracy: 0.9190\n",
            "\n",
            "Epoch 00439: val_accuracy did not improve from 0.94081\n",
            "Epoch 440/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2978 - accuracy: 0.9623 - val_loss: 0.4116 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00440: val_accuracy did not improve from 0.94081\n",
            "Epoch 441/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2133 - accuracy: 0.9707 - val_loss: 0.4743 - val_accuracy: 0.9221\n",
            "\n",
            "Epoch 00441: val_accuracy did not improve from 0.94081\n",
            "Epoch 442/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1797 - accuracy: 0.9763 - val_loss: 0.4492 - val_accuracy: 0.9221\n",
            "\n",
            "Epoch 00442: val_accuracy did not improve from 0.94081\n",
            "Epoch 443/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2238 - accuracy: 0.9649 - val_loss: 0.4991 - val_accuracy: 0.9221\n",
            "\n",
            "Epoch 00443: val_accuracy did not improve from 0.94081\n",
            "Epoch 444/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1824 - accuracy: 0.9746 - val_loss: 0.5329 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00444: val_accuracy did not improve from 0.94081\n",
            "Epoch 445/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1861 - accuracy: 0.9740 - val_loss: 0.4499 - val_accuracy: 0.9221\n",
            "\n",
            "Epoch 00445: val_accuracy did not improve from 0.94081\n",
            "Epoch 446/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.3026 - accuracy: 0.9482 - val_loss: 0.5110 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00446: val_accuracy did not improve from 0.94081\n",
            "Epoch 447/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2416 - accuracy: 0.9612 - val_loss: 0.4425 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00447: val_accuracy did not improve from 0.94081\n",
            "Epoch 448/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.2215 - accuracy: 0.9718 - val_loss: 0.3839 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00448: val_accuracy did not improve from 0.94081\n",
            "Epoch 449/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2197 - accuracy: 0.9570 - val_loss: 0.3922 - val_accuracy: 0.9221\n",
            "\n",
            "Epoch 00449: val_accuracy did not improve from 0.94081\n",
            "Epoch 450/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1846 - accuracy: 0.9751 - val_loss: 0.3932 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00450: val_accuracy did not improve from 0.94081\n",
            "Epoch 451/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1786 - accuracy: 0.9764 - val_loss: 0.4623 - val_accuracy: 0.9159\n",
            "\n",
            "Epoch 00451: val_accuracy did not improve from 0.94081\n",
            "Epoch 452/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2115 - accuracy: 0.9592 - val_loss: 0.4728 - val_accuracy: 0.9190\n",
            "\n",
            "Epoch 00452: val_accuracy did not improve from 0.94081\n",
            "Epoch 453/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1471 - accuracy: 0.9836 - val_loss: 0.4645 - val_accuracy: 0.9190\n",
            "\n",
            "Epoch 00453: val_accuracy did not improve from 0.94081\n",
            "Epoch 454/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1411 - accuracy: 0.9839 - val_loss: 0.4852 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00454: val_accuracy did not improve from 0.94081\n",
            "Epoch 455/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1774 - accuracy: 0.9688 - val_loss: 0.4508 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00455: val_accuracy did not improve from 0.94081\n",
            "Epoch 456/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1526 - accuracy: 0.9776 - val_loss: 0.4517 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00456: val_accuracy did not improve from 0.94081\n",
            "Epoch 457/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1484 - accuracy: 0.9699 - val_loss: 0.4058 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00457: val_accuracy did not improve from 0.94081\n",
            "Epoch 458/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1494 - accuracy: 0.9813 - val_loss: 0.4095 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00458: val_accuracy did not improve from 0.94081\n",
            "Epoch 459/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2494 - accuracy: 0.9686 - val_loss: 0.4020 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00459: val_accuracy did not improve from 0.94081\n",
            "Epoch 460/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1415 - accuracy: 0.9809 - val_loss: 0.3956 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00460: val_accuracy did not improve from 0.94081\n",
            "Epoch 461/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1849 - accuracy: 0.9776 - val_loss: 0.4367 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00461: val_accuracy did not improve from 0.94081\n",
            "Epoch 462/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1929 - accuracy: 0.9658 - val_loss: 0.4387 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00462: val_accuracy did not improve from 0.94081\n",
            "Epoch 463/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1653 - accuracy: 0.9775 - val_loss: 0.4701 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00463: val_accuracy did not improve from 0.94081\n",
            "Epoch 464/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1731 - accuracy: 0.9754 - val_loss: 0.5459 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00464: val_accuracy did not improve from 0.94081\n",
            "Epoch 465/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1809 - accuracy: 0.9721 - val_loss: 0.5784 - val_accuracy: 0.9190\n",
            "\n",
            "Epoch 00465: val_accuracy did not improve from 0.94081\n",
            "Epoch 466/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1950 - accuracy: 0.9773 - val_loss: 0.5044 - val_accuracy: 0.9128\n",
            "\n",
            "Epoch 00466: val_accuracy did not improve from 0.94081\n",
            "Epoch 467/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2336 - accuracy: 0.9711 - val_loss: 0.5279 - val_accuracy: 0.9128\n",
            "\n",
            "Epoch 00467: val_accuracy did not improve from 0.94081\n",
            "Epoch 468/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2438 - accuracy: 0.9661 - val_loss: 0.7533 - val_accuracy: 0.8972\n",
            "\n",
            "Epoch 00468: val_accuracy did not improve from 0.94081\n",
            "Epoch 469/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2999 - accuracy: 0.9587 - val_loss: 0.5496 - val_accuracy: 0.9221\n",
            "\n",
            "Epoch 00469: val_accuracy did not improve from 0.94081\n",
            "Epoch 470/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1957 - accuracy: 0.9750 - val_loss: 0.4148 - val_accuracy: 0.9377\n",
            "\n",
            "Epoch 00470: val_accuracy did not improve from 0.94081\n",
            "Epoch 471/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2172 - accuracy: 0.9742 - val_loss: 0.4537 - val_accuracy: 0.9128\n",
            "\n",
            "Epoch 00471: val_accuracy did not improve from 0.94081\n",
            "Epoch 472/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2366 - accuracy: 0.9728 - val_loss: 0.5493 - val_accuracy: 0.9003\n",
            "\n",
            "Epoch 00472: val_accuracy did not improve from 0.94081\n",
            "Epoch 473/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2733 - accuracy: 0.9635 - val_loss: 0.5058 - val_accuracy: 0.9159\n",
            "\n",
            "Epoch 00473: val_accuracy did not improve from 0.94081\n",
            "Epoch 474/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.2639 - accuracy: 0.9600 - val_loss: 0.4399 - val_accuracy: 0.9190\n",
            "\n",
            "Epoch 00474: val_accuracy did not improve from 0.94081\n",
            "Epoch 475/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1892 - accuracy: 0.9716 - val_loss: 0.4757 - val_accuracy: 0.9097\n",
            "\n",
            "Epoch 00475: val_accuracy did not improve from 0.94081\n",
            "Epoch 476/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1882 - accuracy: 0.9724 - val_loss: 0.5221 - val_accuracy: 0.9159\n",
            "\n",
            "Epoch 00476: val_accuracy did not improve from 0.94081\n",
            "Epoch 477/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1462 - accuracy: 0.9834 - val_loss: 0.5611 - val_accuracy: 0.9159\n",
            "\n",
            "Epoch 00477: val_accuracy did not improve from 0.94081\n",
            "Epoch 478/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.2071 - accuracy: 0.9682 - val_loss: 0.4735 - val_accuracy: 0.9128\n",
            "\n",
            "Epoch 00478: val_accuracy did not improve from 0.94081\n",
            "Epoch 479/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1682 - accuracy: 0.9790 - val_loss: 0.4685 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00479: val_accuracy did not improve from 0.94081\n",
            "Epoch 480/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1656 - accuracy: 0.9737 - val_loss: 0.5252 - val_accuracy: 0.9159\n",
            "\n",
            "Epoch 00480: val_accuracy did not improve from 0.94081\n",
            "Epoch 481/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1899 - accuracy: 0.9697 - val_loss: 0.5488 - val_accuracy: 0.9065\n",
            "\n",
            "Epoch 00481: val_accuracy did not improve from 0.94081\n",
            "Epoch 482/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1686 - accuracy: 0.9715 - val_loss: 0.5294 - val_accuracy: 0.9128\n",
            "\n",
            "Epoch 00482: val_accuracy did not improve from 0.94081\n",
            "Epoch 483/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1681 - accuracy: 0.9768 - val_loss: 0.5575 - val_accuracy: 0.9159\n",
            "\n",
            "Epoch 00483: val_accuracy did not improve from 0.94081\n",
            "Epoch 484/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1524 - accuracy: 0.9758 - val_loss: 0.4964 - val_accuracy: 0.9190\n",
            "\n",
            "Epoch 00484: val_accuracy did not improve from 0.94081\n",
            "Epoch 485/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1753 - accuracy: 0.9786 - val_loss: 0.5553 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00485: val_accuracy did not improve from 0.94081\n",
            "Epoch 486/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1796 - accuracy: 0.9735 - val_loss: 0.6157 - val_accuracy: 0.9128\n",
            "\n",
            "Epoch 00486: val_accuracy did not improve from 0.94081\n",
            "Epoch 487/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1923 - accuracy: 0.9765 - val_loss: 0.5425 - val_accuracy: 0.9190\n",
            "\n",
            "Epoch 00487: val_accuracy did not improve from 0.94081\n",
            "Epoch 488/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1452 - accuracy: 0.9767 - val_loss: 0.6349 - val_accuracy: 0.9159\n",
            "\n",
            "Epoch 00488: val_accuracy did not improve from 0.94081\n",
            "Epoch 489/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1770 - accuracy: 0.9792 - val_loss: 0.6417 - val_accuracy: 0.9065\n",
            "\n",
            "Epoch 00489: val_accuracy did not improve from 0.94081\n",
            "Epoch 490/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1704 - accuracy: 0.9740 - val_loss: 0.5244 - val_accuracy: 0.9128\n",
            "\n",
            "Epoch 00490: val_accuracy did not improve from 0.94081\n",
            "Epoch 491/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1712 - accuracy: 0.9753 - val_loss: 0.5083 - val_accuracy: 0.9128\n",
            "\n",
            "Epoch 00491: val_accuracy did not improve from 0.94081\n",
            "Epoch 492/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.3771 - accuracy: 0.9430 - val_loss: 0.5354 - val_accuracy: 0.8972\n",
            "\n",
            "Epoch 00492: val_accuracy did not improve from 0.94081\n",
            "Epoch 493/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2499 - accuracy: 0.9598 - val_loss: 0.4736 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00493: val_accuracy did not improve from 0.94081\n",
            "Epoch 494/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.2065 - accuracy: 0.9680 - val_loss: 0.4532 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00494: val_accuracy did not improve from 0.94081\n",
            "Epoch 495/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1677 - accuracy: 0.9800 - val_loss: 0.4229 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00495: val_accuracy did not improve from 0.94081\n",
            "Epoch 496/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1627 - accuracy: 0.9804 - val_loss: 0.4570 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00496: val_accuracy did not improve from 0.94081\n",
            "Epoch 497/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1829 - accuracy: 0.9742 - val_loss: 0.5724 - val_accuracy: 0.9190\n",
            "\n",
            "Epoch 00497: val_accuracy did not improve from 0.94081\n",
            "Epoch 498/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1743 - accuracy: 0.9764 - val_loss: 0.5475 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00498: val_accuracy did not improve from 0.94081\n",
            "Epoch 499/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1731 - accuracy: 0.9771 - val_loss: 0.5382 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00499: val_accuracy did not improve from 0.94081\n",
            "Epoch 500/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1561 - accuracy: 0.9844 - val_loss: 0.5265 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00500: val_accuracy did not improve from 0.94081\n",
            "Epoch 501/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1739 - accuracy: 0.9736 - val_loss: 0.3941 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00501: val_accuracy did not improve from 0.94081\n",
            "Epoch 502/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.2422 - accuracy: 0.9581 - val_loss: 0.4542 - val_accuracy: 0.9377\n",
            "\n",
            "Epoch 00502: val_accuracy did not improve from 0.94081\n",
            "Epoch 503/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1976 - accuracy: 0.9765 - val_loss: 0.4650 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00503: val_accuracy did not improve from 0.94081\n",
            "Epoch 504/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1404 - accuracy: 0.9799 - val_loss: 0.4682 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00504: val_accuracy did not improve from 0.94081\n",
            "Epoch 505/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1715 - accuracy: 0.9730 - val_loss: 0.5240 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00505: val_accuracy did not improve from 0.94081\n",
            "Epoch 506/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1428 - accuracy: 0.9826 - val_loss: 0.5346 - val_accuracy: 0.9097\n",
            "\n",
            "Epoch 00506: val_accuracy did not improve from 0.94081\n",
            "Epoch 507/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1417 - accuracy: 0.9775 - val_loss: 0.5098 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00507: val_accuracy did not improve from 0.94081\n",
            "Epoch 508/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1622 - accuracy: 0.9748 - val_loss: 0.5061 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00508: val_accuracy did not improve from 0.94081\n",
            "Epoch 509/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1173 - accuracy: 0.9864 - val_loss: 0.4782 - val_accuracy: 0.9221\n",
            "\n",
            "Epoch 00509: val_accuracy did not improve from 0.94081\n",
            "Epoch 510/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1490 - accuracy: 0.9811 - val_loss: 0.5541 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00510: val_accuracy did not improve from 0.94081\n",
            "Epoch 511/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1635 - accuracy: 0.9821 - val_loss: 0.4641 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00511: val_accuracy did not improve from 0.94081\n",
            "Epoch 512/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2292 - accuracy: 0.9800 - val_loss: 0.4699 - val_accuracy: 0.9377\n",
            "\n",
            "Epoch 00512: val_accuracy did not improve from 0.94081\n",
            "Epoch 513/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1402 - accuracy: 0.9796 - val_loss: 0.5116 - val_accuracy: 0.9221\n",
            "\n",
            "Epoch 00513: val_accuracy did not improve from 0.94081\n",
            "Epoch 514/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1587 - accuracy: 0.9736 - val_loss: 0.5638 - val_accuracy: 0.9159\n",
            "\n",
            "Epoch 00514: val_accuracy did not improve from 0.94081\n",
            "Epoch 515/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1441 - accuracy: 0.9812 - val_loss: 0.4909 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00515: val_accuracy did not improve from 0.94081\n",
            "Epoch 516/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1716 - accuracy: 0.9722 - val_loss: 0.5190 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00516: val_accuracy did not improve from 0.94081\n",
            "Epoch 517/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2148 - accuracy: 0.9668 - val_loss: 0.5101 - val_accuracy: 0.9128\n",
            "\n",
            "Epoch 00517: val_accuracy did not improve from 0.94081\n",
            "Epoch 518/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.1869 - accuracy: 0.9790 - val_loss: 0.4458 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00518: val_accuracy did not improve from 0.94081\n",
            "Epoch 519/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1876 - accuracy: 0.9766 - val_loss: 0.3943 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00519: val_accuracy did not improve from 0.94081\n",
            "Epoch 520/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1892 - accuracy: 0.9680 - val_loss: 0.3806 - val_accuracy: 0.9377\n",
            "\n",
            "Epoch 00520: val_accuracy did not improve from 0.94081\n",
            "Epoch 521/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1583 - accuracy: 0.9780 - val_loss: 0.4574 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00521: val_accuracy did not improve from 0.94081\n",
            "Epoch 522/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.1629 - accuracy: 0.9762 - val_loss: 0.5555 - val_accuracy: 0.9065\n",
            "\n",
            "Epoch 00522: val_accuracy did not improve from 0.94081\n",
            "Epoch 523/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.1848 - accuracy: 0.9684 - val_loss: 0.4914 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00523: val_accuracy did not improve from 0.94081\n",
            "Epoch 524/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1456 - accuracy: 0.9817 - val_loss: 0.4592 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00524: val_accuracy did not improve from 0.94081\n",
            "Epoch 525/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1703 - accuracy: 0.9747 - val_loss: 0.5026 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00525: val_accuracy did not improve from 0.94081\n",
            "Epoch 526/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1422 - accuracy: 0.9826 - val_loss: 0.4894 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00526: val_accuracy did not improve from 0.94081\n",
            "Epoch 527/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1807 - accuracy: 0.9786 - val_loss: 0.5210 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00527: val_accuracy did not improve from 0.94081\n",
            "Epoch 528/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1517 - accuracy: 0.9802 - val_loss: 0.4583 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00528: val_accuracy did not improve from 0.94081\n",
            "Epoch 529/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1531 - accuracy: 0.9795 - val_loss: 0.4861 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00529: val_accuracy did not improve from 0.94081\n",
            "Epoch 530/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2182 - accuracy: 0.9750 - val_loss: 0.4420 - val_accuracy: 0.9221\n",
            "\n",
            "Epoch 00530: val_accuracy did not improve from 0.94081\n",
            "Epoch 531/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.2258 - accuracy: 0.9653 - val_loss: 0.4789 - val_accuracy: 0.9159\n",
            "\n",
            "Epoch 00531: val_accuracy did not improve from 0.94081\n",
            "Epoch 532/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1821 - accuracy: 0.9765 - val_loss: 0.4209 - val_accuracy: 0.9128\n",
            "\n",
            "Epoch 00532: val_accuracy did not improve from 0.94081\n",
            "Epoch 533/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1593 - accuracy: 0.9721 - val_loss: 0.4326 - val_accuracy: 0.9190\n",
            "\n",
            "Epoch 00533: val_accuracy did not improve from 0.94081\n",
            "Epoch 534/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1437 - accuracy: 0.9809 - val_loss: 0.4262 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00534: val_accuracy did not improve from 0.94081\n",
            "Epoch 535/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1646 - accuracy: 0.9777 - val_loss: 0.5476 - val_accuracy: 0.9159\n",
            "\n",
            "Epoch 00535: val_accuracy did not improve from 0.94081\n",
            "Epoch 536/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.2275 - accuracy: 0.9621 - val_loss: 0.4079 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00536: val_accuracy did not improve from 0.94081\n",
            "Epoch 537/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1321 - accuracy: 0.9859 - val_loss: 0.5129 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00537: val_accuracy did not improve from 0.94081\n",
            "Epoch 538/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1877 - accuracy: 0.9716 - val_loss: 0.4096 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00538: val_accuracy did not improve from 0.94081\n",
            "Epoch 539/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1433 - accuracy: 0.9832 - val_loss: 0.4925 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00539: val_accuracy did not improve from 0.94081\n",
            "Epoch 540/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1554 - accuracy: 0.9805 - val_loss: 0.4939 - val_accuracy: 0.9190\n",
            "\n",
            "Epoch 00540: val_accuracy did not improve from 0.94081\n",
            "Epoch 541/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1973 - accuracy: 0.9728 - val_loss: 0.4920 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00541: val_accuracy did not improve from 0.94081\n",
            "Epoch 542/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1286 - accuracy: 0.9843 - val_loss: 0.4503 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00542: val_accuracy did not improve from 0.94081\n",
            "Epoch 543/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1520 - accuracy: 0.9821 - val_loss: 0.4423 - val_accuracy: 0.9190\n",
            "\n",
            "Epoch 00543: val_accuracy did not improve from 0.94081\n",
            "Epoch 544/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1197 - accuracy: 0.9847 - val_loss: 0.4122 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00544: val_accuracy did not improve from 0.94081\n",
            "Epoch 545/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1400 - accuracy: 0.9729 - val_loss: 0.4591 - val_accuracy: 0.9221\n",
            "\n",
            "Epoch 00545: val_accuracy did not improve from 0.94081\n",
            "Epoch 546/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1066 - accuracy: 0.9798 - val_loss: 0.4913 - val_accuracy: 0.9190\n",
            "\n",
            "Epoch 00546: val_accuracy did not improve from 0.94081\n",
            "Epoch 547/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1354 - accuracy: 0.9835 - val_loss: 0.4800 - val_accuracy: 0.9190\n",
            "\n",
            "Epoch 00547: val_accuracy did not improve from 0.94081\n",
            "Epoch 548/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1496 - accuracy: 0.9780 - val_loss: 0.4161 - val_accuracy: 0.9221\n",
            "\n",
            "Epoch 00548: val_accuracy did not improve from 0.94081\n",
            "Epoch 549/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1367 - accuracy: 0.9825 - val_loss: 0.4356 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00549: val_accuracy did not improve from 0.94081\n",
            "Epoch 550/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1266 - accuracy: 0.9820 - val_loss: 0.4276 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00550: val_accuracy did not improve from 0.94081\n",
            "Epoch 551/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1306 - accuracy: 0.9807 - val_loss: 0.5514 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00551: val_accuracy did not improve from 0.94081\n",
            "Epoch 552/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1193 - accuracy: 0.9824 - val_loss: 0.6412 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00552: val_accuracy did not improve from 0.94081\n",
            "Epoch 553/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1536 - accuracy: 0.9773 - val_loss: 0.7143 - val_accuracy: 0.9128\n",
            "\n",
            "Epoch 00553: val_accuracy did not improve from 0.94081\n",
            "Epoch 554/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1530 - accuracy: 0.9763 - val_loss: 0.5544 - val_accuracy: 0.9190\n",
            "\n",
            "Epoch 00554: val_accuracy did not improve from 0.94081\n",
            "Epoch 555/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1538 - accuracy: 0.9745 - val_loss: 0.5670 - val_accuracy: 0.9190\n",
            "\n",
            "Epoch 00555: val_accuracy did not improve from 0.94081\n",
            "Epoch 556/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1344 - accuracy: 0.9792 - val_loss: 0.5150 - val_accuracy: 0.9190\n",
            "\n",
            "Epoch 00556: val_accuracy did not improve from 0.94081\n",
            "Epoch 557/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1285 - accuracy: 0.9886 - val_loss: 0.4477 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00557: val_accuracy did not improve from 0.94081\n",
            "Epoch 558/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1246 - accuracy: 0.9827 - val_loss: 0.5878 - val_accuracy: 0.9065\n",
            "\n",
            "Epoch 00558: val_accuracy did not improve from 0.94081\n",
            "Epoch 559/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1564 - accuracy: 0.9814 - val_loss: 0.5167 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00559: val_accuracy did not improve from 0.94081\n",
            "Epoch 560/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.2091 - accuracy: 0.9735 - val_loss: 0.4665 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00560: val_accuracy did not improve from 0.94081\n",
            "Epoch 561/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1639 - accuracy: 0.9767 - val_loss: 0.4386 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00561: val_accuracy did not improve from 0.94081\n",
            "Epoch 562/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1764 - accuracy: 0.9772 - val_loss: 0.4111 - val_accuracy: 0.9377\n",
            "\n",
            "Epoch 00562: val_accuracy did not improve from 0.94081\n",
            "Epoch 563/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1216 - accuracy: 0.9833 - val_loss: 0.4062 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00563: val_accuracy did not improve from 0.94081\n",
            "Epoch 564/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2186 - accuracy: 0.9710 - val_loss: 0.7106 - val_accuracy: 0.9159\n",
            "\n",
            "Epoch 00564: val_accuracy did not improve from 0.94081\n",
            "Epoch 565/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.2105 - accuracy: 0.9639 - val_loss: 0.6031 - val_accuracy: 0.9159\n",
            "\n",
            "Epoch 00565: val_accuracy did not improve from 0.94081\n",
            "Epoch 566/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.2233 - accuracy: 0.9626 - val_loss: 0.6301 - val_accuracy: 0.9097\n",
            "\n",
            "Epoch 00566: val_accuracy did not improve from 0.94081\n",
            "Epoch 567/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1819 - accuracy: 0.9750 - val_loss: 0.5797 - val_accuracy: 0.9097\n",
            "\n",
            "Epoch 00567: val_accuracy did not improve from 0.94081\n",
            "Epoch 568/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1942 - accuracy: 0.9804 - val_loss: 0.4649 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00568: val_accuracy did not improve from 0.94081\n",
            "Epoch 569/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1636 - accuracy: 0.9808 - val_loss: 0.4614 - val_accuracy: 0.9065\n",
            "\n",
            "Epoch 00569: val_accuracy did not improve from 0.94081\n",
            "Epoch 570/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1401 - accuracy: 0.9786 - val_loss: 0.5135 - val_accuracy: 0.9190\n",
            "\n",
            "Epoch 00570: val_accuracy did not improve from 0.94081\n",
            "Epoch 571/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.2121 - accuracy: 0.9692 - val_loss: 0.4705 - val_accuracy: 0.9190\n",
            "\n",
            "Epoch 00571: val_accuracy did not improve from 0.94081\n",
            "Epoch 572/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1364 - accuracy: 0.9867 - val_loss: 0.5004 - val_accuracy: 0.9221\n",
            "\n",
            "Epoch 00572: val_accuracy did not improve from 0.94081\n",
            "Epoch 573/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1175 - accuracy: 0.9878 - val_loss: 0.4740 - val_accuracy: 0.9190\n",
            "\n",
            "Epoch 00573: val_accuracy did not improve from 0.94081\n",
            "Epoch 574/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.1219 - accuracy: 0.9833 - val_loss: 0.4507 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00574: val_accuracy did not improve from 0.94081\n",
            "Epoch 575/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1437 - accuracy: 0.9827 - val_loss: 0.4705 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00575: val_accuracy did not improve from 0.94081\n",
            "Epoch 576/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1510 - accuracy: 0.9755 - val_loss: 0.4859 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00576: val_accuracy did not improve from 0.94081\n",
            "Epoch 577/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1147 - accuracy: 0.9890 - val_loss: 0.4878 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00577: val_accuracy did not improve from 0.94081\n",
            "Epoch 578/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1295 - accuracy: 0.9853 - val_loss: 0.5520 - val_accuracy: 0.9221\n",
            "\n",
            "Epoch 00578: val_accuracy did not improve from 0.94081\n",
            "Epoch 579/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1257 - accuracy: 0.9827 - val_loss: 0.5450 - val_accuracy: 0.9221\n",
            "\n",
            "Epoch 00579: val_accuracy did not improve from 0.94081\n",
            "Epoch 580/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1361 - accuracy: 0.9770 - val_loss: 0.6047 - val_accuracy: 0.9221\n",
            "\n",
            "Epoch 00580: val_accuracy did not improve from 0.94081\n",
            "Epoch 581/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.1611 - accuracy: 0.9805 - val_loss: 0.4883 - val_accuracy: 0.9221\n",
            "\n",
            "Epoch 00581: val_accuracy did not improve from 0.94081\n",
            "Epoch 582/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1111 - accuracy: 0.9882 - val_loss: 0.4984 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00582: val_accuracy did not improve from 0.94081\n",
            "Epoch 583/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2319 - accuracy: 0.9674 - val_loss: 0.5494 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00583: val_accuracy did not improve from 0.94081\n",
            "Epoch 584/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1825 - accuracy: 0.9842 - val_loss: 0.5216 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00584: val_accuracy did not improve from 0.94081\n",
            "Epoch 585/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1586 - accuracy: 0.9724 - val_loss: 0.4813 - val_accuracy: 0.9190\n",
            "\n",
            "Epoch 00585: val_accuracy did not improve from 0.94081\n",
            "Epoch 586/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1739 - accuracy: 0.9802 - val_loss: 0.5266 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00586: val_accuracy did not improve from 0.94081\n",
            "Epoch 587/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1309 - accuracy: 0.9766 - val_loss: 0.5160 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00587: val_accuracy did not improve from 0.94081\n",
            "Epoch 588/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1767 - accuracy: 0.9739 - val_loss: 0.5114 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00588: val_accuracy did not improve from 0.94081\n",
            "Epoch 589/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1303 - accuracy: 0.9859 - val_loss: 0.5194 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00589: val_accuracy did not improve from 0.94081\n",
            "Epoch 590/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1466 - accuracy: 0.9753 - val_loss: 0.4715 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00590: val_accuracy did not improve from 0.94081\n",
            "Epoch 591/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.2375 - accuracy: 0.9711 - val_loss: 0.5021 - val_accuracy: 0.9159\n",
            "\n",
            "Epoch 00591: val_accuracy did not improve from 0.94081\n",
            "Epoch 592/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1806 - accuracy: 0.9805 - val_loss: 0.4736 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00592: val_accuracy did not improve from 0.94081\n",
            "Epoch 593/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1639 - accuracy: 0.9797 - val_loss: 0.5387 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00593: val_accuracy did not improve from 0.94081\n",
            "Epoch 594/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1237 - accuracy: 0.9882 - val_loss: 0.5722 - val_accuracy: 0.9221\n",
            "\n",
            "Epoch 00594: val_accuracy did not improve from 0.94081\n",
            "Epoch 595/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1327 - accuracy: 0.9780 - val_loss: 0.5181 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00595: val_accuracy did not improve from 0.94081\n",
            "Epoch 596/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1443 - accuracy: 0.9793 - val_loss: 0.4383 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00596: val_accuracy did not improve from 0.94081\n",
            "Epoch 597/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1344 - accuracy: 0.9792 - val_loss: 0.4649 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00597: val_accuracy did not improve from 0.94081\n",
            "Epoch 598/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.1554 - accuracy: 0.9840 - val_loss: 0.5417 - val_accuracy: 0.9221\n",
            "\n",
            "Epoch 00598: val_accuracy did not improve from 0.94081\n",
            "Epoch 599/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1761 - accuracy: 0.9683 - val_loss: 0.5119 - val_accuracy: 0.9190\n",
            "\n",
            "Epoch 00599: val_accuracy did not improve from 0.94081\n",
            "Epoch 600/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1340 - accuracy: 0.9801 - val_loss: 0.4890 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00600: val_accuracy did not improve from 0.94081\n",
            "Epoch 601/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1270 - accuracy: 0.9858 - val_loss: 0.5255 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00601: val_accuracy did not improve from 0.94081\n",
            "Epoch 602/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1522 - accuracy: 0.9866 - val_loss: 0.6812 - val_accuracy: 0.9128\n",
            "\n",
            "Epoch 00602: val_accuracy did not improve from 0.94081\n",
            "Epoch 603/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1806 - accuracy: 0.9715 - val_loss: 0.4573 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00603: val_accuracy did not improve from 0.94081\n",
            "Epoch 604/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1357 - accuracy: 0.9804 - val_loss: 0.4457 - val_accuracy: 0.9190\n",
            "\n",
            "Epoch 00604: val_accuracy did not improve from 0.94081\n",
            "Epoch 605/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1520 - accuracy: 0.9723 - val_loss: 0.4895 - val_accuracy: 0.9190\n",
            "\n",
            "Epoch 00605: val_accuracy did not improve from 0.94081\n",
            "Epoch 606/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.1261 - accuracy: 0.9788 - val_loss: 0.5115 - val_accuracy: 0.9221\n",
            "\n",
            "Epoch 00606: val_accuracy did not improve from 0.94081\n",
            "Epoch 607/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.0982 - accuracy: 0.9886 - val_loss: 0.4890 - val_accuracy: 0.9097\n",
            "\n",
            "Epoch 00607: val_accuracy did not improve from 0.94081\n",
            "Epoch 608/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.0931 - accuracy: 0.9914 - val_loss: 0.5107 - val_accuracy: 0.9159\n",
            "\n",
            "Epoch 00608: val_accuracy did not improve from 0.94081\n",
            "Epoch 609/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1059 - accuracy: 0.9857 - val_loss: 0.4879 - val_accuracy: 0.9128\n",
            "\n",
            "Epoch 00609: val_accuracy did not improve from 0.94081\n",
            "Epoch 610/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1360 - accuracy: 0.9779 - val_loss: 0.5160 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00610: val_accuracy did not improve from 0.94081\n",
            "Epoch 611/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1208 - accuracy: 0.9860 - val_loss: 0.4842 - val_accuracy: 0.9190\n",
            "\n",
            "Epoch 00611: val_accuracy did not improve from 0.94081\n",
            "Epoch 612/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1107 - accuracy: 0.9960 - val_loss: 0.4138 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00612: val_accuracy did not improve from 0.94081\n",
            "Epoch 613/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1353 - accuracy: 0.9784 - val_loss: 0.4561 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00613: val_accuracy did not improve from 0.94081\n",
            "Epoch 614/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1104 - accuracy: 0.9789 - val_loss: 0.4249 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00614: val_accuracy did not improve from 0.94081\n",
            "Epoch 615/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1329 - accuracy: 0.9826 - val_loss: 0.3950 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00615: val_accuracy did not improve from 0.94081\n",
            "Epoch 616/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1193 - accuracy: 0.9841 - val_loss: 0.4294 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00616: val_accuracy did not improve from 0.94081\n",
            "Epoch 617/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2165 - accuracy: 0.9712 - val_loss: 0.5181 - val_accuracy: 0.9159\n",
            "\n",
            "Epoch 00617: val_accuracy did not improve from 0.94081\n",
            "Epoch 618/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1701 - accuracy: 0.9736 - val_loss: 0.5052 - val_accuracy: 0.9097\n",
            "\n",
            "Epoch 00618: val_accuracy did not improve from 0.94081\n",
            "Epoch 619/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1648 - accuracy: 0.9807 - val_loss: 0.6055 - val_accuracy: 0.9097\n",
            "\n",
            "Epoch 00619: val_accuracy did not improve from 0.94081\n",
            "Epoch 620/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1316 - accuracy: 0.9822 - val_loss: 0.5056 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00620: val_accuracy did not improve from 0.94081\n",
            "Epoch 621/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1234 - accuracy: 0.9761 - val_loss: 0.4866 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00621: val_accuracy did not improve from 0.94081\n",
            "Epoch 622/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1481 - accuracy: 0.9690 - val_loss: 0.5318 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00622: val_accuracy did not improve from 0.94081\n",
            "Epoch 623/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1696 - accuracy: 0.9704 - val_loss: 0.5687 - val_accuracy: 0.9221\n",
            "\n",
            "Epoch 00623: val_accuracy did not improve from 0.94081\n",
            "Epoch 624/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1808 - accuracy: 0.9770 - val_loss: 0.4787 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00624: val_accuracy did not improve from 0.94081\n",
            "Epoch 625/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1414 - accuracy: 0.9884 - val_loss: 0.4457 - val_accuracy: 0.9377\n",
            "\n",
            "Epoch 00625: val_accuracy did not improve from 0.94081\n",
            "Epoch 626/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1106 - accuracy: 0.9913 - val_loss: 0.4638 - val_accuracy: 0.9221\n",
            "\n",
            "Epoch 00626: val_accuracy did not improve from 0.94081\n",
            "Epoch 627/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1426 - accuracy: 0.9801 - val_loss: 0.4610 - val_accuracy: 0.9190\n",
            "\n",
            "Epoch 00627: val_accuracy did not improve from 0.94081\n",
            "Epoch 628/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1158 - accuracy: 0.9869 - val_loss: 0.4622 - val_accuracy: 0.9221\n",
            "\n",
            "Epoch 00628: val_accuracy did not improve from 0.94081\n",
            "Epoch 629/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1257 - accuracy: 0.9901 - val_loss: 0.4938 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00629: val_accuracy did not improve from 0.94081\n",
            "Epoch 630/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.0843 - accuracy: 0.9926 - val_loss: 0.4010 - val_accuracy: 0.9221\n",
            "\n",
            "Epoch 00630: val_accuracy did not improve from 0.94081\n",
            "Epoch 631/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1026 - accuracy: 0.9891 - val_loss: 0.4774 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00631: val_accuracy did not improve from 0.94081\n",
            "Epoch 632/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1017 - accuracy: 0.9897 - val_loss: 0.5054 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00632: val_accuracy did not improve from 0.94081\n",
            "Epoch 633/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.0967 - accuracy: 0.9891 - val_loss: 0.4168 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00633: val_accuracy did not improve from 0.94081\n",
            "Epoch 634/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1209 - accuracy: 0.9821 - val_loss: 0.4995 - val_accuracy: 0.9377\n",
            "\n",
            "Epoch 00634: val_accuracy did not improve from 0.94081\n",
            "Epoch 635/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1361 - accuracy: 0.9870 - val_loss: 0.4863 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00635: val_accuracy did not improve from 0.94081\n",
            "Epoch 636/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1326 - accuracy: 0.9796 - val_loss: 0.5539 - val_accuracy: 0.9221\n",
            "\n",
            "Epoch 00636: val_accuracy did not improve from 0.94081\n",
            "Epoch 637/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.2044 - accuracy: 0.9822 - val_loss: 0.4797 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00637: val_accuracy did not improve from 0.94081\n",
            "Epoch 638/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1443 - accuracy: 0.9823 - val_loss: 0.5329 - val_accuracy: 0.9221\n",
            "\n",
            "Epoch 00638: val_accuracy did not improve from 0.94081\n",
            "Epoch 639/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1144 - accuracy: 0.9811 - val_loss: 0.4730 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00639: val_accuracy did not improve from 0.94081\n",
            "Epoch 640/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1498 - accuracy: 0.9782 - val_loss: 0.4276 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00640: val_accuracy did not improve from 0.94081\n",
            "Epoch 641/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1154 - accuracy: 0.9859 - val_loss: 0.5157 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00641: val_accuracy did not improve from 0.94081\n",
            "Epoch 642/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1832 - accuracy: 0.9777 - val_loss: 0.4819 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00642: val_accuracy did not improve from 0.94081\n",
            "Epoch 643/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1514 - accuracy: 0.9795 - val_loss: 0.4285 - val_accuracy: 0.9190\n",
            "\n",
            "Epoch 00643: val_accuracy did not improve from 0.94081\n",
            "Epoch 644/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1314 - accuracy: 0.9830 - val_loss: 0.5613 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00644: val_accuracy did not improve from 0.94081\n",
            "Epoch 645/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1517 - accuracy: 0.9849 - val_loss: 0.5450 - val_accuracy: 0.9221\n",
            "\n",
            "Epoch 00645: val_accuracy did not improve from 0.94081\n",
            "Epoch 646/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1136 - accuracy: 0.9904 - val_loss: 0.4920 - val_accuracy: 0.9221\n",
            "\n",
            "Epoch 00646: val_accuracy did not improve from 0.94081\n",
            "Epoch 647/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.0995 - accuracy: 0.9879 - val_loss: 0.4946 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00647: val_accuracy did not improve from 0.94081\n",
            "Epoch 648/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.0818 - accuracy: 0.9925 - val_loss: 0.4873 - val_accuracy: 0.9190\n",
            "\n",
            "Epoch 00648: val_accuracy did not improve from 0.94081\n",
            "Epoch 649/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.0985 - accuracy: 0.9916 - val_loss: 0.5162 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00649: val_accuracy did not improve from 0.94081\n",
            "Epoch 650/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1182 - accuracy: 0.9840 - val_loss: 0.5588 - val_accuracy: 0.9159\n",
            "\n",
            "Epoch 00650: val_accuracy did not improve from 0.94081\n",
            "Epoch 651/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1602 - accuracy: 0.9801 - val_loss: 0.5765 - val_accuracy: 0.9159\n",
            "\n",
            "Epoch 00651: val_accuracy did not improve from 0.94081\n",
            "Epoch 652/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1010 - accuracy: 0.9858 - val_loss: 0.4700 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00652: val_accuracy did not improve from 0.94081\n",
            "Epoch 653/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1577 - accuracy: 0.9786 - val_loss: 0.4232 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00653: val_accuracy did not improve from 0.94081\n",
            "Epoch 654/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1269 - accuracy: 0.9879 - val_loss: 0.4526 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00654: val_accuracy did not improve from 0.94081\n",
            "Epoch 655/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1009 - accuracy: 0.9892 - val_loss: 0.4765 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00655: val_accuracy did not improve from 0.94081\n",
            "Epoch 656/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.2032 - accuracy: 0.9674 - val_loss: 0.4716 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00656: val_accuracy did not improve from 0.94081\n",
            "Epoch 657/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1801 - accuracy: 0.9845 - val_loss: 0.5384 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00657: val_accuracy did not improve from 0.94081\n",
            "Epoch 658/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2323 - accuracy: 0.9564 - val_loss: 0.5466 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00658: val_accuracy did not improve from 0.94081\n",
            "Epoch 659/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1797 - accuracy: 0.9807 - val_loss: 0.4817 - val_accuracy: 0.9377\n",
            "\n",
            "Epoch 00659: val_accuracy did not improve from 0.94081\n",
            "Epoch 660/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1702 - accuracy: 0.9824 - val_loss: 0.4378 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00660: val_accuracy did not improve from 0.94081\n",
            "Epoch 661/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3752 - accuracy: 0.9413 - val_loss: 0.4919 - val_accuracy: 0.9128\n",
            "\n",
            "Epoch 00661: val_accuracy did not improve from 0.94081\n",
            "Epoch 662/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.3057 - accuracy: 0.9680 - val_loss: 0.4517 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00662: val_accuracy did not improve from 0.94081\n",
            "Epoch 663/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.2215 - accuracy: 0.9786 - val_loss: 0.4054 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00663: val_accuracy did not improve from 0.94081\n",
            "Epoch 664/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2156 - accuracy: 0.9718 - val_loss: 0.4279 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00664: val_accuracy did not improve from 0.94081\n",
            "Epoch 665/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.2062 - accuracy: 0.9774 - val_loss: 0.4208 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00665: val_accuracy did not improve from 0.94081\n",
            "Epoch 666/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1787 - accuracy: 0.9788 - val_loss: 0.4232 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00666: val_accuracy did not improve from 0.94081\n",
            "Epoch 667/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1671 - accuracy: 0.9869 - val_loss: 0.4263 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00667: val_accuracy did not improve from 0.94081\n",
            "Epoch 668/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1641 - accuracy: 0.9770 - val_loss: 0.4449 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00668: val_accuracy did not improve from 0.94081\n",
            "Epoch 669/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1982 - accuracy: 0.9749 - val_loss: 0.4514 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00669: val_accuracy did not improve from 0.94081\n",
            "Epoch 670/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2866 - accuracy: 0.9585 - val_loss: 0.5365 - val_accuracy: 0.9097\n",
            "\n",
            "Epoch 00670: val_accuracy did not improve from 0.94081\n",
            "Epoch 671/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2621 - accuracy: 0.9705 - val_loss: 0.5196 - val_accuracy: 0.9190\n",
            "\n",
            "Epoch 00671: val_accuracy did not improve from 0.94081\n",
            "Epoch 672/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.2276 - accuracy: 0.9752 - val_loss: 0.5010 - val_accuracy: 0.9221\n",
            "\n",
            "Epoch 00672: val_accuracy did not improve from 0.94081\n",
            "Epoch 673/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2285 - accuracy: 0.9769 - val_loss: 0.4935 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00673: val_accuracy did not improve from 0.94081\n",
            "Epoch 674/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.2188 - accuracy: 0.9758 - val_loss: 0.4952 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00674: val_accuracy did not improve from 0.94081\n",
            "Epoch 675/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1774 - accuracy: 0.9804 - val_loss: 0.4849 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00675: val_accuracy did not improve from 0.94081\n",
            "Epoch 676/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1826 - accuracy: 0.9826 - val_loss: 0.4345 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00676: val_accuracy did not improve from 0.94081\n",
            "Epoch 677/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1753 - accuracy: 0.9742 - val_loss: 0.4893 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00677: val_accuracy did not improve from 0.94081\n",
            "Epoch 678/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1780 - accuracy: 0.9756 - val_loss: 0.4891 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00678: val_accuracy did not improve from 0.94081\n",
            "Epoch 679/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.2312 - accuracy: 0.9752 - val_loss: 0.5662 - val_accuracy: 0.9190\n",
            "\n",
            "Epoch 00679: val_accuracy did not improve from 0.94081\n",
            "Epoch 680/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2175 - accuracy: 0.9837 - val_loss: 0.5230 - val_accuracy: 0.9159\n",
            "\n",
            "Epoch 00680: val_accuracy did not improve from 0.94081\n",
            "Epoch 681/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1970 - accuracy: 0.9821 - val_loss: 0.4791 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00681: val_accuracy did not improve from 0.94081\n",
            "Epoch 682/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2014 - accuracy: 0.9772 - val_loss: 0.4868 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00682: val_accuracy did not improve from 0.94081\n",
            "Epoch 683/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1811 - accuracy: 0.9880 - val_loss: 0.4856 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00683: val_accuracy did not improve from 0.94081\n",
            "Epoch 684/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1526 - accuracy: 0.9820 - val_loss: 0.4739 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00684: val_accuracy did not improve from 0.94081\n",
            "Epoch 685/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.2270 - accuracy: 0.9675 - val_loss: 0.4803 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00685: val_accuracy did not improve from 0.94081\n",
            "Epoch 686/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1729 - accuracy: 0.9722 - val_loss: 0.5154 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00686: val_accuracy did not improve from 0.94081\n",
            "Epoch 687/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1544 - accuracy: 0.9803 - val_loss: 0.5411 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00687: val_accuracy did not improve from 0.94081\n",
            "Epoch 688/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1552 - accuracy: 0.9854 - val_loss: 0.5068 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00688: val_accuracy did not improve from 0.94081\n",
            "Epoch 689/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1590 - accuracy: 0.9829 - val_loss: 0.5718 - val_accuracy: 0.9221\n",
            "\n",
            "Epoch 00689: val_accuracy did not improve from 0.94081\n",
            "Epoch 690/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1218 - accuracy: 0.9845 - val_loss: 0.4761 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00690: val_accuracy did not improve from 0.94081\n",
            "Epoch 691/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1794 - accuracy: 0.9692 - val_loss: 0.4785 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00691: val_accuracy did not improve from 0.94081\n",
            "Epoch 692/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1280 - accuracy: 0.9758 - val_loss: 0.5012 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00692: val_accuracy did not improve from 0.94081\n",
            "Epoch 693/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1607 - accuracy: 0.9706 - val_loss: 0.5589 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00693: val_accuracy did not improve from 0.94081\n",
            "Epoch 694/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1268 - accuracy: 0.9868 - val_loss: 0.5166 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00694: val_accuracy did not improve from 0.94081\n",
            "Epoch 695/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1338 - accuracy: 0.9839 - val_loss: 0.4382 - val_accuracy: 0.9190\n",
            "\n",
            "Epoch 00695: val_accuracy did not improve from 0.94081\n",
            "Epoch 696/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1268 - accuracy: 0.9838 - val_loss: 0.4251 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00696: val_accuracy did not improve from 0.94081\n",
            "Epoch 697/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1434 - accuracy: 0.9805 - val_loss: 0.4769 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00697: val_accuracy did not improve from 0.94081\n",
            "Epoch 698/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.1327 - accuracy: 0.9798 - val_loss: 0.4759 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00698: val_accuracy did not improve from 0.94081\n",
            "Epoch 699/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1700 - accuracy: 0.9850 - val_loss: 0.4841 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00699: val_accuracy did not improve from 0.94081\n",
            "Epoch 700/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1941 - accuracy: 0.9768 - val_loss: 0.4904 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00700: val_accuracy did not improve from 0.94081\n",
            "Epoch 701/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1807 - accuracy: 0.9738 - val_loss: 0.4564 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00701: val_accuracy did not improve from 0.94081\n",
            "Epoch 702/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1331 - accuracy: 0.9870 - val_loss: 0.5081 - val_accuracy: 0.9221\n",
            "\n",
            "Epoch 00702: val_accuracy did not improve from 0.94081\n",
            "Epoch 703/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.2751 - accuracy: 0.9658 - val_loss: 0.7014 - val_accuracy: 0.9003\n",
            "\n",
            "Epoch 00703: val_accuracy did not improve from 0.94081\n",
            "Epoch 704/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.2868 - accuracy: 0.9677 - val_loss: 0.5550 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00704: val_accuracy did not improve from 0.94081\n",
            "Epoch 705/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.2144 - accuracy: 0.9784 - val_loss: 0.5258 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00705: val_accuracy did not improve from 0.94081\n",
            "Epoch 706/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2647 - accuracy: 0.9761 - val_loss: 0.4609 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00706: val_accuracy did not improve from 0.94081\n",
            "Epoch 707/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2465 - accuracy: 0.9708 - val_loss: 0.5176 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00707: val_accuracy did not improve from 0.94081\n",
            "Epoch 708/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1905 - accuracy: 0.9771 - val_loss: 0.5497 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00708: val_accuracy did not improve from 0.94081\n",
            "Epoch 709/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1770 - accuracy: 0.9796 - val_loss: 0.5624 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00709: val_accuracy did not improve from 0.94081\n",
            "Epoch 710/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1861 - accuracy: 0.9788 - val_loss: 0.5251 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00710: val_accuracy did not improve from 0.94081\n",
            "Epoch 711/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1717 - accuracy: 0.9865 - val_loss: 0.4754 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00711: val_accuracy did not improve from 0.94081\n",
            "Epoch 712/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1486 - accuracy: 0.9860 - val_loss: 0.4800 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00712: val_accuracy did not improve from 0.94081\n",
            "Epoch 713/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1405 - accuracy: 0.9858 - val_loss: 0.5418 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00713: val_accuracy did not improve from 0.94081\n",
            "Epoch 714/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1583 - accuracy: 0.9764 - val_loss: 0.4338 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00714: val_accuracy did not improve from 0.94081\n",
            "Epoch 715/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1728 - accuracy: 0.9749 - val_loss: 0.4408 - val_accuracy: 0.9221\n",
            "\n",
            "Epoch 00715: val_accuracy did not improve from 0.94081\n",
            "Epoch 716/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1932 - accuracy: 0.9826 - val_loss: 0.3867 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00716: val_accuracy did not improve from 0.94081\n",
            "Epoch 717/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.2274 - accuracy: 0.9719 - val_loss: 0.4370 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00717: val_accuracy did not improve from 0.94081\n",
            "Epoch 718/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1649 - accuracy: 0.9838 - val_loss: 0.4397 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00718: val_accuracy did not improve from 0.94081\n",
            "Epoch 719/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1451 - accuracy: 0.9901 - val_loss: 0.4201 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00719: val_accuracy did not improve from 0.94081\n",
            "Epoch 720/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1572 - accuracy: 0.9788 - val_loss: 0.4553 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00720: val_accuracy did not improve from 0.94081\n",
            "Epoch 721/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1717 - accuracy: 0.9741 - val_loss: 0.4211 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00721: val_accuracy did not improve from 0.94081\n",
            "Epoch 722/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1590 - accuracy: 0.9853 - val_loss: 0.4821 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00722: val_accuracy did not improve from 0.94081\n",
            "Epoch 723/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1546 - accuracy: 0.9832 - val_loss: 0.4057 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00723: val_accuracy did not improve from 0.94081\n",
            "Epoch 724/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1326 - accuracy: 0.9822 - val_loss: 0.4472 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00724: val_accuracy did not improve from 0.94081\n",
            "Epoch 725/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1282 - accuracy: 0.9818 - val_loss: 0.4121 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00725: val_accuracy did not improve from 0.94081\n",
            "Epoch 726/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1177 - accuracy: 0.9911 - val_loss: 0.3858 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00726: val_accuracy did not improve from 0.94081\n",
            "Epoch 727/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1459 - accuracy: 0.9804 - val_loss: 0.4580 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00727: val_accuracy did not improve from 0.94081\n",
            "Epoch 728/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1079 - accuracy: 0.9876 - val_loss: 0.3962 - val_accuracy: 0.9408\n",
            "\n",
            "Epoch 00728: val_accuracy did not improve from 0.94081\n",
            "Epoch 729/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1210 - accuracy: 0.9864 - val_loss: 0.4939 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00729: val_accuracy did not improve from 0.94081\n",
            "Epoch 730/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1249 - accuracy: 0.9846 - val_loss: 0.5071 - val_accuracy: 0.9377\n",
            "\n",
            "Epoch 00730: val_accuracy did not improve from 0.94081\n",
            "Epoch 731/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1287 - accuracy: 0.9831 - val_loss: 0.5483 - val_accuracy: 0.9377\n",
            "\n",
            "Epoch 00731: val_accuracy did not improve from 0.94081\n",
            "Epoch 732/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1978 - accuracy: 0.9790 - val_loss: 0.4925 - val_accuracy: 0.9439\n",
            "\n",
            "Epoch 00732: val_accuracy improved from 0.94081 to 0.94393, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 733/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.2057 - accuracy: 0.9723 - val_loss: 0.4858 - val_accuracy: 0.9439\n",
            "\n",
            "Epoch 00733: val_accuracy did not improve from 0.94393\n",
            "Epoch 734/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4216 - accuracy: 0.9530 - val_loss: 0.5301 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00734: val_accuracy did not improve from 0.94393\n",
            "Epoch 735/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2933 - accuracy: 0.9692 - val_loss: 0.4550 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00735: val_accuracy did not improve from 0.94393\n",
            "Epoch 736/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2212 - accuracy: 0.9805 - val_loss: 0.4587 - val_accuracy: 0.9408\n",
            "\n",
            "Epoch 00736: val_accuracy did not improve from 0.94393\n",
            "Epoch 737/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.2328 - accuracy: 0.9743 - val_loss: 0.4766 - val_accuracy: 0.9439\n",
            "\n",
            "Epoch 00737: val_accuracy did not improve from 0.94393\n",
            "Epoch 738/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2006 - accuracy: 0.9808 - val_loss: 0.4385 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00738: val_accuracy did not improve from 0.94393\n",
            "Epoch 739/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1835 - accuracy: 0.9859 - val_loss: 0.4352 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00739: val_accuracy did not improve from 0.94393\n",
            "Epoch 740/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1966 - accuracy: 0.9758 - val_loss: 0.4180 - val_accuracy: 0.9377\n",
            "\n",
            "Epoch 00740: val_accuracy did not improve from 0.94393\n",
            "Epoch 741/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1728 - accuracy: 0.9812 - val_loss: 0.4442 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00741: val_accuracy did not improve from 0.94393\n",
            "Epoch 742/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2390 - accuracy: 0.9749 - val_loss: 0.4621 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00742: val_accuracy did not improve from 0.94393\n",
            "Epoch 743/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1520 - accuracy: 0.9846 - val_loss: 0.4607 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00743: val_accuracy did not improve from 0.94393\n",
            "Epoch 744/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.1559 - accuracy: 0.9844 - val_loss: 0.4511 - val_accuracy: 0.9377\n",
            "\n",
            "Epoch 00744: val_accuracy did not improve from 0.94393\n",
            "Epoch 745/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1547 - accuracy: 0.9887 - val_loss: 0.4638 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00745: val_accuracy did not improve from 0.94393\n",
            "Epoch 746/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1225 - accuracy: 0.9890 - val_loss: 0.5169 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00746: val_accuracy did not improve from 0.94393\n",
            "Epoch 747/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1725 - accuracy: 0.9748 - val_loss: 0.5317 - val_accuracy: 0.9221\n",
            "\n",
            "Epoch 00747: val_accuracy did not improve from 0.94393\n",
            "Epoch 748/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.2281 - accuracy: 0.9773 - val_loss: 0.4345 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00748: val_accuracy did not improve from 0.94393\n",
            "Epoch 749/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1507 - accuracy: 0.9843 - val_loss: 0.4852 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00749: val_accuracy did not improve from 0.94393\n",
            "Epoch 750/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1374 - accuracy: 0.9871 - val_loss: 0.4775 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00750: val_accuracy did not improve from 0.94393\n",
            "Epoch 751/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1366 - accuracy: 0.9795 - val_loss: 0.5113 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00751: val_accuracy did not improve from 0.94393\n",
            "Epoch 752/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1634 - accuracy: 0.9848 - val_loss: 0.5333 - val_accuracy: 0.9221\n",
            "\n",
            "Epoch 00752: val_accuracy did not improve from 0.94393\n",
            "Epoch 753/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1295 - accuracy: 0.9818 - val_loss: 0.5174 - val_accuracy: 0.9221\n",
            "\n",
            "Epoch 00753: val_accuracy did not improve from 0.94393\n",
            "Epoch 754/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1009 - accuracy: 0.9897 - val_loss: 0.5310 - val_accuracy: 0.9221\n",
            "\n",
            "Epoch 00754: val_accuracy did not improve from 0.94393\n",
            "Epoch 755/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1653 - accuracy: 0.9786 - val_loss: 0.5799 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00755: val_accuracy did not improve from 0.94393\n",
            "Epoch 756/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.2045 - accuracy: 0.9781 - val_loss: 0.5854 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00756: val_accuracy did not improve from 0.94393\n",
            "Epoch 757/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.1691 - accuracy: 0.9867 - val_loss: 0.5250 - val_accuracy: 0.9221\n",
            "\n",
            "Epoch 00757: val_accuracy did not improve from 0.94393\n",
            "Epoch 758/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1661 - accuracy: 0.9800 - val_loss: 0.5129 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00758: val_accuracy did not improve from 0.94393\n",
            "Epoch 759/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1258 - accuracy: 0.9889 - val_loss: 0.5090 - val_accuracy: 0.9377\n",
            "\n",
            "Epoch 00759: val_accuracy did not improve from 0.94393\n",
            "Epoch 760/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1296 - accuracy: 0.9888 - val_loss: 0.5166 - val_accuracy: 0.9377\n",
            "\n",
            "Epoch 00760: val_accuracy did not improve from 0.94393\n",
            "Epoch 761/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1779 - accuracy: 0.9798 - val_loss: 0.5395 - val_accuracy: 0.9377\n",
            "\n",
            "Epoch 00761: val_accuracy did not improve from 0.94393\n",
            "Epoch 762/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.2662 - accuracy: 0.9589 - val_loss: 0.5519 - val_accuracy: 0.9159\n",
            "\n",
            "Epoch 00762: val_accuracy did not improve from 0.94393\n",
            "Epoch 763/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.2460 - accuracy: 0.9586 - val_loss: 0.5608 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00763: val_accuracy did not improve from 0.94393\n",
            "Epoch 764/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2111 - accuracy: 0.9728 - val_loss: 0.5797 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00764: val_accuracy did not improve from 0.94393\n",
            "Epoch 765/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.2037 - accuracy: 0.9702 - val_loss: 0.4886 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00765: val_accuracy did not improve from 0.94393\n",
            "Epoch 766/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1666 - accuracy: 0.9849 - val_loss: 0.4705 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00766: val_accuracy did not improve from 0.94393\n",
            "Epoch 767/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1579 - accuracy: 0.9826 - val_loss: 0.4672 - val_accuracy: 0.9408\n",
            "\n",
            "Epoch 00767: val_accuracy did not improve from 0.94393\n",
            "Epoch 768/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1612 - accuracy: 0.9777 - val_loss: 0.5398 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00768: val_accuracy did not improve from 0.94393\n",
            "Epoch 769/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1739 - accuracy: 0.9795 - val_loss: 0.4898 - val_accuracy: 0.9439\n",
            "\n",
            "Epoch 00769: val_accuracy did not improve from 0.94393\n",
            "Epoch 770/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1803 - accuracy: 0.9816 - val_loss: 0.5782 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00770: val_accuracy did not improve from 0.94393\n",
            "Epoch 771/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.1691 - accuracy: 0.9784 - val_loss: 0.5184 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00771: val_accuracy did not improve from 0.94393\n",
            "Epoch 772/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1424 - accuracy: 0.9812 - val_loss: 0.4833 - val_accuracy: 0.9377\n",
            "\n",
            "Epoch 00772: val_accuracy did not improve from 0.94393\n",
            "Epoch 773/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1288 - accuracy: 0.9865 - val_loss: 0.4381 - val_accuracy: 0.9377\n",
            "\n",
            "Epoch 00773: val_accuracy did not improve from 0.94393\n",
            "Epoch 774/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1153 - accuracy: 0.9899 - val_loss: 0.4512 - val_accuracy: 0.9408\n",
            "\n",
            "Epoch 00774: val_accuracy did not improve from 0.94393\n",
            "Epoch 775/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.0981 - accuracy: 0.9940 - val_loss: 0.4824 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00775: val_accuracy did not improve from 0.94393\n",
            "Epoch 776/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1153 - accuracy: 0.9852 - val_loss: 0.4528 - val_accuracy: 0.9408\n",
            "\n",
            "Epoch 00776: val_accuracy did not improve from 0.94393\n",
            "Epoch 777/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1183 - accuracy: 0.9919 - val_loss: 0.4851 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00777: val_accuracy did not improve from 0.94393\n",
            "Epoch 778/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1371 - accuracy: 0.9805 - val_loss: 0.4754 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00778: val_accuracy did not improve from 0.94393\n",
            "Epoch 779/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1522 - accuracy: 0.9765 - val_loss: 0.4546 - val_accuracy: 0.9408\n",
            "\n",
            "Epoch 00779: val_accuracy did not improve from 0.94393\n",
            "Epoch 780/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.1535 - accuracy: 0.9839 - val_loss: 0.4278 - val_accuracy: 0.9502\n",
            "\n",
            "Epoch 00780: val_accuracy improved from 0.94393 to 0.95016, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 781/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.2433 - accuracy: 0.9622 - val_loss: 0.5649 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00781: val_accuracy did not improve from 0.95016\n",
            "Epoch 782/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.2516 - accuracy: 0.9677 - val_loss: 0.4511 - val_accuracy: 0.9439\n",
            "\n",
            "Epoch 00782: val_accuracy did not improve from 0.95016\n",
            "Epoch 783/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.2054 - accuracy: 0.9794 - val_loss: 0.4331 - val_accuracy: 0.9502\n",
            "\n",
            "Epoch 00783: val_accuracy did not improve from 0.95016\n",
            "Epoch 784/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.2066 - accuracy: 0.9781 - val_loss: 0.4391 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00784: val_accuracy did not improve from 0.95016\n",
            "Epoch 785/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2347 - accuracy: 0.9695 - val_loss: 0.5036 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00785: val_accuracy did not improve from 0.95016\n",
            "Epoch 786/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.2049 - accuracy: 0.9856 - val_loss: 0.5224 - val_accuracy: 0.9408\n",
            "\n",
            "Epoch 00786: val_accuracy did not improve from 0.95016\n",
            "Epoch 787/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1835 - accuracy: 0.9809 - val_loss: 0.5182 - val_accuracy: 0.9408\n",
            "\n",
            "Epoch 00787: val_accuracy did not improve from 0.95016\n",
            "Epoch 788/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1586 - accuracy: 0.9856 - val_loss: 0.4868 - val_accuracy: 0.9439\n",
            "\n",
            "Epoch 00788: val_accuracy did not improve from 0.95016\n",
            "Epoch 789/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1539 - accuracy: 0.9784 - val_loss: 0.4951 - val_accuracy: 0.9439\n",
            "\n",
            "Epoch 00789: val_accuracy did not improve from 0.95016\n",
            "Epoch 790/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1282 - accuracy: 0.9848 - val_loss: 0.5232 - val_accuracy: 0.9377\n",
            "\n",
            "Epoch 00790: val_accuracy did not improve from 0.95016\n",
            "Epoch 791/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1227 - accuracy: 0.9937 - val_loss: 0.5106 - val_accuracy: 0.9439\n",
            "\n",
            "Epoch 00791: val_accuracy did not improve from 0.95016\n",
            "Epoch 792/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1163 - accuracy: 0.9868 - val_loss: 0.5367 - val_accuracy: 0.9502\n",
            "\n",
            "Epoch 00792: val_accuracy did not improve from 0.95016\n",
            "Epoch 793/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1183 - accuracy: 0.9873 - val_loss: 0.5580 - val_accuracy: 0.9408\n",
            "\n",
            "Epoch 00793: val_accuracy did not improve from 0.95016\n",
            "Epoch 794/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.2042 - accuracy: 0.9735 - val_loss: 0.5403 - val_accuracy: 0.9408\n",
            "\n",
            "Epoch 00794: val_accuracy did not improve from 0.95016\n",
            "Epoch 795/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1671 - accuracy: 0.9800 - val_loss: 0.5281 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00795: val_accuracy did not improve from 0.95016\n",
            "Epoch 796/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3036 - accuracy: 0.9660 - val_loss: 0.5423 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00796: val_accuracy did not improve from 0.95016\n",
            "Epoch 797/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.2570 - accuracy: 0.9687 - val_loss: 0.5186 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00797: val_accuracy did not improve from 0.95016\n",
            "Epoch 798/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.2836 - accuracy: 0.9690 - val_loss: 0.4623 - val_accuracy: 0.9470\n",
            "\n",
            "Epoch 00798: val_accuracy did not improve from 0.95016\n",
            "Epoch 799/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.2452 - accuracy: 0.9697 - val_loss: 0.4805 - val_accuracy: 0.9439\n",
            "\n",
            "Epoch 00799: val_accuracy did not improve from 0.95016\n",
            "Epoch 800/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.2050 - accuracy: 0.9878 - val_loss: 0.4994 - val_accuracy: 0.9377\n",
            "\n",
            "Epoch 00800: val_accuracy did not improve from 0.95016\n",
            "Epoch 801/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1985 - accuracy: 0.9842 - val_loss: 0.5518 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00801: val_accuracy did not improve from 0.95016\n",
            "Epoch 802/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1859 - accuracy: 0.9807 - val_loss: 0.5177 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00802: val_accuracy did not improve from 0.95016\n",
            "Epoch 803/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1822 - accuracy: 0.9832 - val_loss: 0.5184 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00803: val_accuracy did not improve from 0.95016\n",
            "Epoch 804/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1696 - accuracy: 0.9881 - val_loss: 0.5100 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00804: val_accuracy did not improve from 0.95016\n",
            "Epoch 805/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.1879 - accuracy: 0.9763 - val_loss: 0.4862 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00805: val_accuracy did not improve from 0.95016\n",
            "Epoch 806/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.2153 - accuracy: 0.9746 - val_loss: 0.5176 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00806: val_accuracy did not improve from 0.95016\n",
            "Epoch 807/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1948 - accuracy: 0.9785 - val_loss: 0.5878 - val_accuracy: 0.9221\n",
            "\n",
            "Epoch 00807: val_accuracy did not improve from 0.95016\n",
            "Epoch 808/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1848 - accuracy: 0.9825 - val_loss: 0.5686 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00808: val_accuracy did not improve from 0.95016\n",
            "Epoch 809/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1662 - accuracy: 0.9817 - val_loss: 0.5773 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00809: val_accuracy did not improve from 0.95016\n",
            "Epoch 810/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1862 - accuracy: 0.9811 - val_loss: 0.5482 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00810: val_accuracy did not improve from 0.95016\n",
            "Epoch 811/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1928 - accuracy: 0.9779 - val_loss: 0.5189 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00811: val_accuracy did not improve from 0.95016\n",
            "Epoch 812/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1470 - accuracy: 0.9881 - val_loss: 0.5105 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00812: val_accuracy did not improve from 0.95016\n",
            "Epoch 813/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1639 - accuracy: 0.9829 - val_loss: 0.5239 - val_accuracy: 0.9377\n",
            "\n",
            "Epoch 00813: val_accuracy did not improve from 0.95016\n",
            "Epoch 814/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1893 - accuracy: 0.9793 - val_loss: 0.5519 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00814: val_accuracy did not improve from 0.95016\n",
            "Epoch 815/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1828 - accuracy: 0.9874 - val_loss: 0.5148 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00815: val_accuracy did not improve from 0.95016\n",
            "Epoch 816/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1693 - accuracy: 0.9839 - val_loss: 0.4980 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00816: val_accuracy did not improve from 0.95016\n",
            "Epoch 817/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.2110 - accuracy: 0.9694 - val_loss: 0.5119 - val_accuracy: 0.9221\n",
            "\n",
            "Epoch 00817: val_accuracy did not improve from 0.95016\n",
            "Epoch 818/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1735 - accuracy: 0.9811 - val_loss: 0.5276 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00818: val_accuracy did not improve from 0.95016\n",
            "Epoch 819/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1334 - accuracy: 0.9866 - val_loss: 0.5422 - val_accuracy: 0.9221\n",
            "\n",
            "Epoch 00819: val_accuracy did not improve from 0.95016\n",
            "Epoch 820/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1422 - accuracy: 0.9882 - val_loss: 0.5183 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00820: val_accuracy did not improve from 0.95016\n",
            "Epoch 821/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1105 - accuracy: 0.9937 - val_loss: 0.5184 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00821: val_accuracy did not improve from 0.95016\n",
            "Epoch 822/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1229 - accuracy: 0.9890 - val_loss: 0.4774 - val_accuracy: 0.9408\n",
            "\n",
            "Epoch 00822: val_accuracy did not improve from 0.95016\n",
            "Epoch 823/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1265 - accuracy: 0.9852 - val_loss: 0.4888 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00823: val_accuracy did not improve from 0.95016\n",
            "Epoch 824/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1789 - accuracy: 0.9765 - val_loss: 0.4621 - val_accuracy: 0.9439\n",
            "\n",
            "Epoch 00824: val_accuracy did not improve from 0.95016\n",
            "Epoch 825/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1373 - accuracy: 0.9889 - val_loss: 0.5390 - val_accuracy: 0.9408\n",
            "\n",
            "Epoch 00825: val_accuracy did not improve from 0.95016\n",
            "Epoch 826/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.2859 - accuracy: 0.9579 - val_loss: 0.6819 - val_accuracy: 0.9003\n",
            "\n",
            "Epoch 00826: val_accuracy did not improve from 0.95016\n",
            "Epoch 827/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3566 - accuracy: 0.9595 - val_loss: 0.5414 - val_accuracy: 0.9159\n",
            "\n",
            "Epoch 00827: val_accuracy did not improve from 0.95016\n",
            "Epoch 828/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.2986 - accuracy: 0.9612 - val_loss: 0.5163 - val_accuracy: 0.9097\n",
            "\n",
            "Epoch 00828: val_accuracy did not improve from 0.95016\n",
            "Epoch 829/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2438 - accuracy: 0.9744 - val_loss: 0.5255 - val_accuracy: 0.9097\n",
            "\n",
            "Epoch 00829: val_accuracy did not improve from 0.95016\n",
            "Epoch 830/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.2114 - accuracy: 0.9727 - val_loss: 0.5693 - val_accuracy: 0.9159\n",
            "\n",
            "Epoch 00830: val_accuracy did not improve from 0.95016\n",
            "Epoch 831/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.2065 - accuracy: 0.9800 - val_loss: 0.4666 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00831: val_accuracy did not improve from 0.95016\n",
            "Epoch 832/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1906 - accuracy: 0.9820 - val_loss: 0.5058 - val_accuracy: 0.9221\n",
            "\n",
            "Epoch 00832: val_accuracy did not improve from 0.95016\n",
            "Epoch 833/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1778 - accuracy: 0.9816 - val_loss: 0.5284 - val_accuracy: 0.9190\n",
            "\n",
            "Epoch 00833: val_accuracy did not improve from 0.95016\n",
            "Epoch 834/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1634 - accuracy: 0.9795 - val_loss: 0.5201 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00834: val_accuracy did not improve from 0.95016\n",
            "Epoch 835/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.2005 - accuracy: 0.9835 - val_loss: 0.4759 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00835: val_accuracy did not improve from 0.95016\n",
            "Epoch 836/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1468 - accuracy: 0.9858 - val_loss: 0.5114 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00836: val_accuracy did not improve from 0.95016\n",
            "Epoch 837/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1382 - accuracy: 0.9873 - val_loss: 0.4936 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00837: val_accuracy did not improve from 0.95016\n",
            "Epoch 838/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1544 - accuracy: 0.9803 - val_loss: 0.4935 - val_accuracy: 0.9190\n",
            "\n",
            "Epoch 00838: val_accuracy did not improve from 0.95016\n",
            "Epoch 839/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1208 - accuracy: 0.9860 - val_loss: 0.5078 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00839: val_accuracy did not improve from 0.95016\n",
            "Epoch 840/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1383 - accuracy: 0.9853 - val_loss: 0.5606 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00840: val_accuracy did not improve from 0.95016\n",
            "Epoch 841/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1304 - accuracy: 0.9827 - val_loss: 0.5361 - val_accuracy: 0.9221\n",
            "\n",
            "Epoch 00841: val_accuracy did not improve from 0.95016\n",
            "Epoch 842/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1702 - accuracy: 0.9809 - val_loss: 0.5208 - val_accuracy: 0.9221\n",
            "\n",
            "Epoch 00842: val_accuracy did not improve from 0.95016\n",
            "Epoch 843/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1494 - accuracy: 0.9873 - val_loss: 0.5008 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00843: val_accuracy did not improve from 0.95016\n",
            "Epoch 844/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1067 - accuracy: 0.9894 - val_loss: 0.5473 - val_accuracy: 0.9408\n",
            "\n",
            "Epoch 00844: val_accuracy did not improve from 0.95016\n",
            "Epoch 845/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.0934 - accuracy: 0.9885 - val_loss: 0.5594 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00845: val_accuracy did not improve from 0.95016\n",
            "Epoch 846/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.0914 - accuracy: 0.9902 - val_loss: 0.5439 - val_accuracy: 0.9408\n",
            "\n",
            "Epoch 00846: val_accuracy did not improve from 0.95016\n",
            "Epoch 847/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1051 - accuracy: 0.9890 - val_loss: 0.5176 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00847: val_accuracy did not improve from 0.95016\n",
            "Epoch 848/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1310 - accuracy: 0.9864 - val_loss: 0.5715 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00848: val_accuracy did not improve from 0.95016\n",
            "Epoch 849/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1318 - accuracy: 0.9818 - val_loss: 0.4705 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00849: val_accuracy did not improve from 0.95016\n",
            "Epoch 850/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.0960 - accuracy: 0.9882 - val_loss: 0.5059 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00850: val_accuracy did not improve from 0.95016\n",
            "Epoch 851/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.0959 - accuracy: 0.9894 - val_loss: 0.5192 - val_accuracy: 0.9377\n",
            "\n",
            "Epoch 00851: val_accuracy did not improve from 0.95016\n",
            "Epoch 852/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.0910 - accuracy: 0.9888 - val_loss: 0.4851 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00852: val_accuracy did not improve from 0.95016\n",
            "Epoch 853/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.0957 - accuracy: 0.9871 - val_loss: 0.5057 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00853: val_accuracy did not improve from 0.95016\n",
            "Epoch 854/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1206 - accuracy: 0.9860 - val_loss: 0.5311 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00854: val_accuracy did not improve from 0.95016\n",
            "Epoch 855/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1121 - accuracy: 0.9892 - val_loss: 0.5150 - val_accuracy: 0.9377\n",
            "\n",
            "Epoch 00855: val_accuracy did not improve from 0.95016\n",
            "Epoch 856/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1267 - accuracy: 0.9860 - val_loss: 0.5085 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00856: val_accuracy did not improve from 0.95016\n",
            "Epoch 857/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.1019 - accuracy: 0.9926 - val_loss: 0.5276 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00857: val_accuracy did not improve from 0.95016\n",
            "Epoch 858/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1087 - accuracy: 0.9838 - val_loss: 0.5422 - val_accuracy: 0.9190\n",
            "\n",
            "Epoch 00858: val_accuracy did not improve from 0.95016\n",
            "Epoch 859/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.0993 - accuracy: 0.9873 - val_loss: 0.5373 - val_accuracy: 0.9221\n",
            "\n",
            "Epoch 00859: val_accuracy did not improve from 0.95016\n",
            "Epoch 860/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.1263 - accuracy: 0.9795 - val_loss: 0.5493 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00860: val_accuracy did not improve from 0.95016\n",
            "Epoch 861/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1121 - accuracy: 0.9870 - val_loss: 0.4821 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00861: val_accuracy did not improve from 0.95016\n",
            "Epoch 862/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.0942 - accuracy: 0.9833 - val_loss: 0.4906 - val_accuracy: 0.9221\n",
            "\n",
            "Epoch 00862: val_accuracy did not improve from 0.95016\n",
            "Epoch 863/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1271 - accuracy: 0.9864 - val_loss: 0.5245 - val_accuracy: 0.9190\n",
            "\n",
            "Epoch 00863: val_accuracy did not improve from 0.95016\n",
            "Epoch 864/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1049 - accuracy: 0.9861 - val_loss: 0.5049 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00864: val_accuracy did not improve from 0.95016\n",
            "Epoch 865/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.0780 - accuracy: 0.9944 - val_loss: 0.4830 - val_accuracy: 0.9377\n",
            "\n",
            "Epoch 00865: val_accuracy did not improve from 0.95016\n",
            "Epoch 866/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1394 - accuracy: 0.9865 - val_loss: 0.5302 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00866: val_accuracy did not improve from 0.95016\n",
            "Epoch 867/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.0747 - accuracy: 0.9948 - val_loss: 0.5393 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00867: val_accuracy did not improve from 0.95016\n",
            "Epoch 868/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.0828 - accuracy: 0.9893 - val_loss: 0.4601 - val_accuracy: 0.9408\n",
            "\n",
            "Epoch 00868: val_accuracy did not improve from 0.95016\n",
            "Epoch 869/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.0885 - accuracy: 0.9919 - val_loss: 0.5122 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00869: val_accuracy did not improve from 0.95016\n",
            "Epoch 870/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1102 - accuracy: 0.9843 - val_loss: 0.5584 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00870: val_accuracy did not improve from 0.95016\n",
            "Epoch 871/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.0948 - accuracy: 0.9908 - val_loss: 0.4631 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00871: val_accuracy did not improve from 0.95016\n",
            "Epoch 872/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.0902 - accuracy: 0.9905 - val_loss: 0.4451 - val_accuracy: 0.9377\n",
            "\n",
            "Epoch 00872: val_accuracy did not improve from 0.95016\n",
            "Epoch 873/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.0992 - accuracy: 0.9896 - val_loss: 0.4918 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00873: val_accuracy did not improve from 0.95016\n",
            "Epoch 874/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.1014 - accuracy: 0.9915 - val_loss: 0.4283 - val_accuracy: 0.9470\n",
            "\n",
            "Epoch 00874: val_accuracy did not improve from 0.95016\n",
            "Epoch 875/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1035 - accuracy: 0.9905 - val_loss: 0.4736 - val_accuracy: 0.9377\n",
            "\n",
            "Epoch 00875: val_accuracy did not improve from 0.95016\n",
            "Epoch 876/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.0846 - accuracy: 0.9925 - val_loss: 0.4854 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00876: val_accuracy did not improve from 0.95016\n",
            "Epoch 877/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1369 - accuracy: 0.9829 - val_loss: 0.4898 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00877: val_accuracy did not improve from 0.95016\n",
            "Epoch 878/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1201 - accuracy: 0.9888 - val_loss: 0.4440 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00878: val_accuracy did not improve from 0.95016\n",
            "Epoch 879/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1219 - accuracy: 0.9821 - val_loss: 0.4837 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00879: val_accuracy did not improve from 0.95016\n",
            "Epoch 880/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1196 - accuracy: 0.9821 - val_loss: 0.4666 - val_accuracy: 0.9439\n",
            "\n",
            "Epoch 00880: val_accuracy did not improve from 0.95016\n",
            "Epoch 881/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.0955 - accuracy: 0.9861 - val_loss: 0.4285 - val_accuracy: 0.9439\n",
            "\n",
            "Epoch 00881: val_accuracy did not improve from 0.95016\n",
            "Epoch 882/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.1706 - accuracy: 0.9711 - val_loss: 0.5593 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00882: val_accuracy did not improve from 0.95016\n",
            "Epoch 883/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1749 - accuracy: 0.9821 - val_loss: 0.5051 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00883: val_accuracy did not improve from 0.95016\n",
            "Epoch 884/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1612 - accuracy: 0.9827 - val_loss: 0.5135 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00884: val_accuracy did not improve from 0.95016\n",
            "Epoch 885/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.1583 - accuracy: 0.9877 - val_loss: 0.5063 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00885: val_accuracy did not improve from 0.95016\n",
            "Epoch 886/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1741 - accuracy: 0.9855 - val_loss: 0.5182 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00886: val_accuracy did not improve from 0.95016\n",
            "Epoch 887/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1534 - accuracy: 0.9851 - val_loss: 0.5146 - val_accuracy: 0.9377\n",
            "\n",
            "Epoch 00887: val_accuracy did not improve from 0.95016\n",
            "Epoch 888/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1426 - accuracy: 0.9836 - val_loss: 0.5241 - val_accuracy: 0.9377\n",
            "\n",
            "Epoch 00888: val_accuracy did not improve from 0.95016\n",
            "Epoch 889/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.1639 - accuracy: 0.9860 - val_loss: 0.4876 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00889: val_accuracy did not improve from 0.95016\n",
            "Epoch 890/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1218 - accuracy: 0.9845 - val_loss: 0.4926 - val_accuracy: 0.9377\n",
            "\n",
            "Epoch 00890: val_accuracy did not improve from 0.95016\n",
            "Epoch 891/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1234 - accuracy: 0.9883 - val_loss: 0.4954 - val_accuracy: 0.9377\n",
            "\n",
            "Epoch 00891: val_accuracy did not improve from 0.95016\n",
            "Epoch 892/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1012 - accuracy: 0.9895 - val_loss: 0.5119 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00892: val_accuracy did not improve from 0.95016\n",
            "Epoch 893/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.0928 - accuracy: 0.9927 - val_loss: 0.4821 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00893: val_accuracy did not improve from 0.95016\n",
            "Epoch 894/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.0877 - accuracy: 0.9924 - val_loss: 0.4806 - val_accuracy: 0.9408\n",
            "\n",
            "Epoch 00894: val_accuracy did not improve from 0.95016\n",
            "Epoch 895/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.0981 - accuracy: 0.9893 - val_loss: 0.4804 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00895: val_accuracy did not improve from 0.95016\n",
            "Epoch 896/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.0960 - accuracy: 0.9873 - val_loss: 0.5392 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00896: val_accuracy did not improve from 0.95016\n",
            "Epoch 897/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.0964 - accuracy: 0.9831 - val_loss: 0.5470 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00897: val_accuracy did not improve from 0.95016\n",
            "Epoch 898/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1316 - accuracy: 0.9820 - val_loss: 0.5068 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00898: val_accuracy did not improve from 0.95016\n",
            "Epoch 899/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.0892 - accuracy: 0.9910 - val_loss: 0.4699 - val_accuracy: 0.9377\n",
            "\n",
            "Epoch 00899: val_accuracy did not improve from 0.95016\n",
            "Epoch 900/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.0980 - accuracy: 0.9896 - val_loss: 0.6044 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00900: val_accuracy did not improve from 0.95016\n",
            "Epoch 901/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.0996 - accuracy: 0.9898 - val_loss: 0.4823 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00901: val_accuracy did not improve from 0.95016\n",
            "Epoch 902/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.1098 - accuracy: 0.9868 - val_loss: 0.4791 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00902: val_accuracy did not improve from 0.95016\n",
            "Epoch 903/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.0972 - accuracy: 0.9914 - val_loss: 0.5390 - val_accuracy: 0.9408\n",
            "\n",
            "Epoch 00903: val_accuracy did not improve from 0.95016\n",
            "Epoch 904/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1587 - accuracy: 0.9839 - val_loss: 0.4673 - val_accuracy: 0.9408\n",
            "\n",
            "Epoch 00904: val_accuracy did not improve from 0.95016\n",
            "Epoch 905/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.0943 - accuracy: 0.9881 - val_loss: 0.4383 - val_accuracy: 0.9377\n",
            "\n",
            "Epoch 00905: val_accuracy did not improve from 0.95016\n",
            "Epoch 906/1000\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 0.0857 - accuracy: 0.9843 - val_loss: 0.3841 - val_accuracy: 0.9502\n",
            "\n",
            "Epoch 00906: val_accuracy did not improve from 0.95016\n",
            "Epoch 907/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.0904 - accuracy: 0.9885 - val_loss: 0.3537 - val_accuracy: 0.9377\n",
            "\n",
            "Epoch 00907: val_accuracy did not improve from 0.95016\n",
            "Epoch 908/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1018 - accuracy: 0.9882 - val_loss: 0.3773 - val_accuracy: 0.9408\n",
            "\n",
            "Epoch 00908: val_accuracy did not improve from 0.95016\n",
            "Epoch 909/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1167 - accuracy: 0.9887 - val_loss: 0.5055 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00909: val_accuracy did not improve from 0.95016\n",
            "Epoch 910/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.0769 - accuracy: 0.9916 - val_loss: 0.4264 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00910: val_accuracy did not improve from 0.95016\n",
            "Epoch 911/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1668 - accuracy: 0.9764 - val_loss: 0.6148 - val_accuracy: 0.9190\n",
            "\n",
            "Epoch 00911: val_accuracy did not improve from 0.95016\n",
            "Epoch 912/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.2106 - accuracy: 0.9727 - val_loss: 0.5592 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00912: val_accuracy did not improve from 0.95016\n",
            "Epoch 913/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.1336 - accuracy: 0.9805 - val_loss: 0.5156 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00913: val_accuracy did not improve from 0.95016\n",
            "Epoch 914/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1098 - accuracy: 0.9874 - val_loss: 0.4802 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00914: val_accuracy did not improve from 0.95016\n",
            "Epoch 915/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.1578 - accuracy: 0.9739 - val_loss: 0.4511 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00915: val_accuracy did not improve from 0.95016\n",
            "Epoch 916/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1427 - accuracy: 0.9790 - val_loss: 0.5059 - val_accuracy: 0.9190\n",
            "\n",
            "Epoch 00916: val_accuracy did not improve from 0.95016\n",
            "Epoch 917/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1617 - accuracy: 0.9688 - val_loss: 0.4740 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00917: val_accuracy did not improve from 0.95016\n",
            "Epoch 918/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1414 - accuracy: 0.9884 - val_loss: 0.4739 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00918: val_accuracy did not improve from 0.95016\n",
            "Epoch 919/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1182 - accuracy: 0.9901 - val_loss: 0.4946 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00919: val_accuracy did not improve from 0.95016\n",
            "Epoch 920/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.1420 - accuracy: 0.9787 - val_loss: 0.4862 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00920: val_accuracy did not improve from 0.95016\n",
            "Epoch 921/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1112 - accuracy: 0.9902 - val_loss: 0.5147 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00921: val_accuracy did not improve from 0.95016\n",
            "Epoch 922/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1517 - accuracy: 0.9859 - val_loss: 0.5125 - val_accuracy: 0.9377\n",
            "\n",
            "Epoch 00922: val_accuracy did not improve from 0.95016\n",
            "Epoch 923/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1375 - accuracy: 0.9818 - val_loss: 0.4509 - val_accuracy: 0.9408\n",
            "\n",
            "Epoch 00923: val_accuracy did not improve from 0.95016\n",
            "Epoch 924/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1157 - accuracy: 0.9846 - val_loss: 0.4549 - val_accuracy: 0.9439\n",
            "\n",
            "Epoch 00924: val_accuracy did not improve from 0.95016\n",
            "Epoch 925/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1140 - accuracy: 0.9793 - val_loss: 0.4959 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00925: val_accuracy did not improve from 0.95016\n",
            "Epoch 926/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.0858 - accuracy: 0.9941 - val_loss: 0.5206 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00926: val_accuracy did not improve from 0.95016\n",
            "Epoch 927/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1261 - accuracy: 0.9817 - val_loss: 0.5722 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00927: val_accuracy did not improve from 0.95016\n",
            "Epoch 928/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.1248 - accuracy: 0.9817 - val_loss: 0.5862 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00928: val_accuracy did not improve from 0.95016\n",
            "Epoch 929/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.0913 - accuracy: 0.9954 - val_loss: 0.5665 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00929: val_accuracy did not improve from 0.95016\n",
            "Epoch 930/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.0889 - accuracy: 0.9876 - val_loss: 0.4934 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00930: val_accuracy did not improve from 0.95016\n",
            "Epoch 931/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1399 - accuracy: 0.9830 - val_loss: 0.5055 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00931: val_accuracy did not improve from 0.95016\n",
            "Epoch 932/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1215 - accuracy: 0.9847 - val_loss: 0.4695 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00932: val_accuracy did not improve from 0.95016\n",
            "Epoch 933/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1088 - accuracy: 0.9854 - val_loss: 0.4956 - val_accuracy: 0.9377\n",
            "\n",
            "Epoch 00933: val_accuracy did not improve from 0.95016\n",
            "Epoch 934/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1079 - accuracy: 0.9833 - val_loss: 0.5706 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00934: val_accuracy did not improve from 0.95016\n",
            "Epoch 935/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1208 - accuracy: 0.9842 - val_loss: 0.4325 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00935: val_accuracy did not improve from 0.95016\n",
            "Epoch 936/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1209 - accuracy: 0.9865 - val_loss: 0.5176 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00936: val_accuracy did not improve from 0.95016\n",
            "Epoch 937/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1069 - accuracy: 0.9891 - val_loss: 0.4640 - val_accuracy: 0.9377\n",
            "\n",
            "Epoch 00937: val_accuracy did not improve from 0.95016\n",
            "Epoch 938/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1340 - accuracy: 0.9845 - val_loss: 0.5164 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00938: val_accuracy did not improve from 0.95016\n",
            "Epoch 939/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.0887 - accuracy: 0.9876 - val_loss: 0.5497 - val_accuracy: 0.9221\n",
            "\n",
            "Epoch 00939: val_accuracy did not improve from 0.95016\n",
            "Epoch 940/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.0918 - accuracy: 0.9902 - val_loss: 0.4596 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00940: val_accuracy did not improve from 0.95016\n",
            "Epoch 941/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.1018 - accuracy: 0.9905 - val_loss: 0.4849 - val_accuracy: 0.9377\n",
            "\n",
            "Epoch 00941: val_accuracy did not improve from 0.95016\n",
            "Epoch 942/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.1933 - accuracy: 0.9727 - val_loss: 0.5738 - val_accuracy: 0.9190\n",
            "\n",
            "Epoch 00942: val_accuracy did not improve from 0.95016\n",
            "Epoch 943/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.1435 - accuracy: 0.9845 - val_loss: 0.5261 - val_accuracy: 0.9128\n",
            "\n",
            "Epoch 00943: val_accuracy did not improve from 0.95016\n",
            "Epoch 944/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1906 - accuracy: 0.9772 - val_loss: 0.4945 - val_accuracy: 0.9377\n",
            "\n",
            "Epoch 00944: val_accuracy did not improve from 0.95016\n",
            "Epoch 945/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1254 - accuracy: 0.9905 - val_loss: 0.5301 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00945: val_accuracy did not improve from 0.95016\n",
            "Epoch 946/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.1528 - accuracy: 0.9752 - val_loss: 0.4570 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00946: val_accuracy did not improve from 0.95016\n",
            "Epoch 947/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1558 - accuracy: 0.9775 - val_loss: 0.4956 - val_accuracy: 0.9377\n",
            "\n",
            "Epoch 00947: val_accuracy did not improve from 0.95016\n",
            "Epoch 948/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1184 - accuracy: 0.9880 - val_loss: 0.4815 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00948: val_accuracy did not improve from 0.95016\n",
            "Epoch 949/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.1472 - accuracy: 0.9853 - val_loss: 0.4461 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00949: val_accuracy did not improve from 0.95016\n",
            "Epoch 950/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1445 - accuracy: 0.9854 - val_loss: 0.4593 - val_accuracy: 0.9221\n",
            "\n",
            "Epoch 00950: val_accuracy did not improve from 0.95016\n",
            "Epoch 951/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1408 - accuracy: 0.9839 - val_loss: 0.4659 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00951: val_accuracy did not improve from 0.95016\n",
            "Epoch 952/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.1382 - accuracy: 0.9857 - val_loss: 0.4906 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00952: val_accuracy did not improve from 0.95016\n",
            "Epoch 953/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1265 - accuracy: 0.9852 - val_loss: 0.5091 - val_accuracy: 0.9221\n",
            "\n",
            "Epoch 00953: val_accuracy did not improve from 0.95016\n",
            "Epoch 954/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.1799 - accuracy: 0.9766 - val_loss: 0.5143 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00954: val_accuracy did not improve from 0.95016\n",
            "Epoch 955/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1288 - accuracy: 0.9856 - val_loss: 0.4232 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00955: val_accuracy did not improve from 0.95016\n",
            "Epoch 956/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1165 - accuracy: 0.9913 - val_loss: 0.4095 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00956: val_accuracy did not improve from 0.95016\n",
            "Epoch 957/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1317 - accuracy: 0.9879 - val_loss: 0.4430 - val_accuracy: 0.9377\n",
            "\n",
            "Epoch 00957: val_accuracy did not improve from 0.95016\n",
            "Epoch 958/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.1136 - accuracy: 0.9875 - val_loss: 0.4279 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00958: val_accuracy did not improve from 0.95016\n",
            "Epoch 959/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.1287 - accuracy: 0.9848 - val_loss: 0.4369 - val_accuracy: 0.9439\n",
            "\n",
            "Epoch 00959: val_accuracy did not improve from 0.95016\n",
            "Epoch 960/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.0999 - accuracy: 0.9891 - val_loss: 0.3862 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00960: val_accuracy did not improve from 0.95016\n",
            "Epoch 961/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.0841 - accuracy: 0.9943 - val_loss: 0.3984 - val_accuracy: 0.9377\n",
            "\n",
            "Epoch 00961: val_accuracy did not improve from 0.95016\n",
            "Epoch 962/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.0865 - accuracy: 0.9932 - val_loss: 0.4106 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00962: val_accuracy did not improve from 0.95016\n",
            "Epoch 963/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.0857 - accuracy: 0.9917 - val_loss: 0.4077 - val_accuracy: 0.9408\n",
            "\n",
            "Epoch 00963: val_accuracy did not improve from 0.95016\n",
            "Epoch 964/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.0837 - accuracy: 0.9889 - val_loss: 0.4505 - val_accuracy: 0.9377\n",
            "\n",
            "Epoch 00964: val_accuracy did not improve from 0.95016\n",
            "Epoch 965/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.0926 - accuracy: 0.9897 - val_loss: 0.5138 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00965: val_accuracy did not improve from 0.95016\n",
            "Epoch 966/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.1625 - accuracy: 0.9760 - val_loss: 0.4200 - val_accuracy: 0.9190\n",
            "\n",
            "Epoch 00966: val_accuracy did not improve from 0.95016\n",
            "Epoch 967/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.1293 - accuracy: 0.9834 - val_loss: 0.3894 - val_accuracy: 0.9377\n",
            "\n",
            "Epoch 00967: val_accuracy did not improve from 0.95016\n",
            "Epoch 968/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.1076 - accuracy: 0.9867 - val_loss: 0.3789 - val_accuracy: 0.9377\n",
            "\n",
            "Epoch 00968: val_accuracy did not improve from 0.95016\n",
            "Epoch 969/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.1058 - accuracy: 0.9904 - val_loss: 0.3993 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00969: val_accuracy did not improve from 0.95016\n",
            "Epoch 970/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.0851 - accuracy: 0.9907 - val_loss: 0.4329 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00970: val_accuracy did not improve from 0.95016\n",
            "Epoch 971/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.0890 - accuracy: 0.9926 - val_loss: 0.4470 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00971: val_accuracy did not improve from 0.95016\n",
            "Epoch 972/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.0707 - accuracy: 0.9928 - val_loss: 0.4383 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00972: val_accuracy did not improve from 0.95016\n",
            "Epoch 973/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.1031 - accuracy: 0.9879 - val_loss: 0.4291 - val_accuracy: 0.9377\n",
            "\n",
            "Epoch 00973: val_accuracy did not improve from 0.95016\n",
            "Epoch 974/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.0894 - accuracy: 0.9890 - val_loss: 0.5623 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00974: val_accuracy did not improve from 0.95016\n",
            "Epoch 975/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.0925 - accuracy: 0.9862 - val_loss: 0.4843 - val_accuracy: 0.9221\n",
            "\n",
            "Epoch 00975: val_accuracy did not improve from 0.95016\n",
            "Epoch 976/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1303 - accuracy: 0.9847 - val_loss: 0.4337 - val_accuracy: 0.9377\n",
            "\n",
            "Epoch 00976: val_accuracy did not improve from 0.95016\n",
            "Epoch 977/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1120 - accuracy: 0.9817 - val_loss: 0.3926 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00977: val_accuracy did not improve from 0.95016\n",
            "Epoch 978/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.0774 - accuracy: 0.9904 - val_loss: 0.4721 - val_accuracy: 0.9377\n",
            "\n",
            "Epoch 00978: val_accuracy did not improve from 0.95016\n",
            "Epoch 979/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1211 - accuracy: 0.9862 - val_loss: 0.4524 - val_accuracy: 0.9377\n",
            "\n",
            "Epoch 00979: val_accuracy did not improve from 0.95016\n",
            "Epoch 980/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.0735 - accuracy: 0.9927 - val_loss: 0.4238 - val_accuracy: 0.9408\n",
            "\n",
            "Epoch 00980: val_accuracy did not improve from 0.95016\n",
            "Epoch 981/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1167 - accuracy: 0.9857 - val_loss: 0.4773 - val_accuracy: 0.9408\n",
            "\n",
            "Epoch 00981: val_accuracy did not improve from 0.95016\n",
            "Epoch 982/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1070 - accuracy: 0.9842 - val_loss: 0.4469 - val_accuracy: 0.9470\n",
            "\n",
            "Epoch 00982: val_accuracy did not improve from 0.95016\n",
            "Epoch 983/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1491 - accuracy: 0.9783 - val_loss: 0.4343 - val_accuracy: 0.9408\n",
            "\n",
            "Epoch 00983: val_accuracy did not improve from 0.95016\n",
            "Epoch 984/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1223 - accuracy: 0.9837 - val_loss: 0.4303 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00984: val_accuracy did not improve from 0.95016\n",
            "Epoch 985/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.0891 - accuracy: 0.9944 - val_loss: 0.4462 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00985: val_accuracy did not improve from 0.95016\n",
            "Epoch 986/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.0852 - accuracy: 0.9923 - val_loss: 0.4507 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00986: val_accuracy did not improve from 0.95016\n",
            "Epoch 987/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.1432 - accuracy: 0.9807 - val_loss: 0.4156 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00987: val_accuracy did not improve from 0.95016\n",
            "Epoch 988/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1037 - accuracy: 0.9796 - val_loss: 0.4531 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00988: val_accuracy did not improve from 0.95016\n",
            "Epoch 989/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1072 - accuracy: 0.9826 - val_loss: 0.5061 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00989: val_accuracy did not improve from 0.95016\n",
            "Epoch 990/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1371 - accuracy: 0.9860 - val_loss: 0.4551 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 00990: val_accuracy did not improve from 0.95016\n",
            "Epoch 991/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.0953 - accuracy: 0.9924 - val_loss: 0.4433 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00991: val_accuracy did not improve from 0.95016\n",
            "Epoch 992/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.1228 - accuracy: 0.9822 - val_loss: 0.4865 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00992: val_accuracy did not improve from 0.95016\n",
            "Epoch 993/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.1054 - accuracy: 0.9885 - val_loss: 0.5091 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00993: val_accuracy did not improve from 0.95016\n",
            "Epoch 994/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.1145 - accuracy: 0.9866 - val_loss: 0.4702 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00994: val_accuracy did not improve from 0.95016\n",
            "Epoch 995/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.0985 - accuracy: 0.9853 - val_loss: 0.5276 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00995: val_accuracy did not improve from 0.95016\n",
            "Epoch 996/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.0715 - accuracy: 0.9952 - val_loss: 0.5347 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00996: val_accuracy did not improve from 0.95016\n",
            "Epoch 997/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.0762 - accuracy: 0.9926 - val_loss: 0.5068 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00997: val_accuracy did not improve from 0.95016\n",
            "Epoch 998/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.0829 - accuracy: 0.9915 - val_loss: 0.5021 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00998: val_accuracy did not improve from 0.95016\n",
            "Epoch 999/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.1025 - accuracy: 0.9890 - val_loss: 0.5299 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00999: val_accuracy did not improve from 0.95016\n",
            "Epoch 1000/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.0815 - accuracy: 0.9890 - val_loss: 0.4898 - val_accuracy: 0.9283\n",
            "\n",
            "Epoch 01000: val_accuracy did not improve from 0.95016\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2GKkSKsn-g0R",
        "outputId": "e1648b29-7ac4-403a-c539-67955e1447aa"
      },
      "source": [
        "# PLOT MODEL HISTORY OF ACCURACY AND LOSS OVER EPOCHS\n",
        "# Plot the results\n",
        "train_loss=model_history.history['loss']\n",
        "val_loss=model_history.history['val_loss']\n",
        "train_acc=model_history.history['accuracy']\n",
        "val_acc=model_history.history['val_accuracy']\n",
        "plt.rcParams['figure.dpi'] = 150 \n",
        "plt.figure(1,figsize=(7,5))\n",
        "plt.plot(train_loss)\n",
        "plt.plot(val_loss)\n",
        "plt.xlabel('Number of epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training loss vs Validation loss')\n",
        "plt.grid(True)\n",
        "plt.legend(['Training','Validation'], loc=1)\n",
        "plt.style.use(['seaborn-darkgrid'])\n",
        "\n",
        "plt.rcParams['figure.dpi'] = 150 \n",
        "plt.figure(2,figsize=(7,5))\n",
        "plt.plot(train_acc)\n",
        "plt.plot(val_acc)\n",
        "plt.xlabel('Number of epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training accuracy vs Validation accuracy')\n",
        "plt.grid(True)\n",
        "plt.legend(['Training','Validation'],loc=4)\n",
        "plt.style.use(['seaborn-darkgrid'])      \n",
        "\n",
        "# PRINT LOSS AND ACCURACY PERCENTAGE ON TEST SET\n",
        "print(\"Loss of the model is - \" , model.evaluate(x_test,y_test)[0])\n",
        "print(\"Accuracy of the model is - \" , model.evaluate(x_test,y_test)[1]*100 , \"%\") \n",
        "\n",
        "# PREDICTION LABELS\n",
        "predictions = model.predict(x_test, batch_size=32)\n",
        "predictions=predictions.argmax(axis=1)\n",
        "predictions\n",
        "predictions = predictions.astype(int).flatten()\n",
        "predictions = (lb.inverse_transform((predictions)))\n",
        "predictions = pd.DataFrame({'Predicted Values': predictions}) \n",
        "\n",
        "# ACTUAL LABELS\n",
        "TRUE = y_test.argmax(axis=1)\n",
        "TRUE = TRUE.astype(int).flatten()\n",
        "TRUE = (lb.inverse_transform((TRUE)))\n",
        "TRUE = pd.DataFrame({'TRUE Values': TRUE})\n",
        "\n",
        "# COMBINE PREDICTION AND ACTUAL LABELS\n",
        "finaldf = TRUE.join(predictions)\n",
        "finaldf[10:25] \n",
        "# CREATE CONFUSION MATRIX OF ACTUAL VS. PREDICTION -SGD-MFCC\n",
        "cm = confusion_matrix(TRUE, predictions)\n",
        "plt.figure(figsize = (9,7))\n",
        "plt.rcParams['figure.dpi'] = 150 \n",
        "cm = pd.DataFrame(cm , index = [i for i in lb.classes_] , columns = [i for i in lb.classes_])\n",
        "ax = sns.heatmap(cm, linecolor='white', cmap='Accent', linewidth=1, annot=True, fmt='')\n",
        "bottom, top = ax.get_ylim()\n",
        "ax.set_ylim(bottom + 0.6, top - 0.6)\n",
        "plt.title('Confusion Matrix', size=20)\n",
        "plt.xlabel('Predicted Classes', size=15)\n",
        "plt.ylabel('True Classes', size=15)\n",
        "plt.savefig('Initial_Model_Confusion_Matrix-SGD-SPECTROGRAM.png')\n",
        "plt.show() \n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(TRUE, predictions, target_names = ['Angry', 'Fear', 'Happy', 'Neutral', 'Sad']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4898 - accuracy: 0.9283\n",
            "Loss of the model is -  0.48982158303260803\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4898 - accuracy: 0.9283\n",
            "Accuracy of the model is -  92.83488988876343 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1050x750 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1050x750 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1350x1050 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Angry       0.96      0.94      0.95       112\n",
            "        Fear       0.97      0.93      0.95        41\n",
            "       Happy       0.83      0.95      0.88        40\n",
            "     Neutral       0.86      0.93      0.90        46\n",
            "         Sad       0.96      0.90      0.93        82\n",
            "\n",
            "    accuracy                           0.93       321\n",
            "   macro avg       0.92      0.93      0.92       321\n",
            "weighted avg       0.93      0.93      0.93       321\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3HucjYkDQA0"
      },
      "source": [
        "#Accuarte class labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "i9VY87ueDTaZ",
        "outputId": "e61db76f-a972-4d4a-815b-2b3a5a32f775"
      },
      "source": [
        "data_path = pd.concat([df], axis = 0)\n",
        "data_path.to_csv(\"data_path.csv\",index=False)\n",
        "data_path.head(50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emotion</th>\n",
              "      <th>source</th>\n",
              "      <th>path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Fear</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis/Emo-db/08a01Ab.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Happy</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis/Emo-db/12a01Fb.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Happy</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis/Emo-db/03a01Fa.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Happy</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis/Emo-db/09a01Fa.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Neutral</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis/Emo-db/08a01Na.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Angry</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis/Emo-db/08a01Wa.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Happy</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis/Emo-db/13a01Fd.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Neutral</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis/Emo-db/03a01Nc.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Angry</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis/Emo-db/08a01Wc.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Happy</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis/Emo-db/08a01Fd.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Boredom</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis/Emo-db/08a01Lc.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Angry</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis/Emo-db/03a01Wa.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Disgust</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis/Emo-db/13a01Ea.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Fear</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis/Emo-db/11a01Ab.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Boredom</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis/Emo-db/11a01Ld.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Happy</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis/Emo-db/16a01Fc.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Boredom</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis/Emo-db/12a01Lb.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Neutral</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis/Emo-db/09a01Nb.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Angry</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis/Emo-db/12a01Wc.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Angry</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis/Emo-db/11a01Wc.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Happy</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis/Emo-db/15a01Fb.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Angry</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis/Emo-db/10a01Wa.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Disgust</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis/Emo-db/13a01Ec.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Neutral</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis/Emo-db/10a01Nb.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Fear</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis/Emo-db/13a01Ac.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Neutral</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis/Emo-db/12a01Nb.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Fear</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis/Emo-db/10a01Ac.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>Neutral</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis/Emo-db/11a01Nd.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Angry</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis/Emo-db/09a01Wb.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Fear</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis/Emo-db/11a01Aa.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>Disgust</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis/Emo-db/09a01Ea.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>Angry</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis/Emo-db/13a01Wb.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>Fear</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis/Emo-db/14a01Ac.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>Fear</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis/Emo-db/14a01Aa.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>Sadness</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis/Emo-db/16a01Tb.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>Angry</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis/Emo-db/14a01Wa.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>Neutral</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis/Emo-db/15a01Nb.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>Angry</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis/Emo-db/15a01Wa.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>Disgust</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis/Emo-db/14a01Ea.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>Boredom</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis/Emo-db/15a01La.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>Angry</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis/Emo-db/16a01Wb.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>Neutral</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis/Emo-db/13a01Nb.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>Boredom</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis/Emo-db/13a01Lb.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>Disgust</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis/Emo-db/15a01Ea.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>Disgust</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis/Emo-db/16a01Ec.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>Neutral</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis/Emo-db/14a01Na.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>Boredom</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis/Emo-db/16a01Lb.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>Angry</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis/Emo-db/14a01Wc.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>Neutral</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis/Emo-db/16a01Nc.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>Disgust</td>\n",
              "      <td>EMO</td>\n",
              "      <td>/content/drive/MyDrive/Speech Emotion analysis/Emo-db/09a02Ea.wav</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    emotion  ...                                                               path\n",
              "0   Fear     ...  /content/drive/MyDrive/Speech Emotion analysis/Emo-db/08a01Ab.wav\n",
              "1   Happy    ...  /content/drive/MyDrive/Speech Emotion analysis/Emo-db/12a01Fb.wav\n",
              "2   Happy    ...  /content/drive/MyDrive/Speech Emotion analysis/Emo-db/03a01Fa.wav\n",
              "3   Happy    ...  /content/drive/MyDrive/Speech Emotion analysis/Emo-db/09a01Fa.wav\n",
              "4   Neutral  ...  /content/drive/MyDrive/Speech Emotion analysis/Emo-db/08a01Na.wav\n",
              "5   Angry    ...  /content/drive/MyDrive/Speech Emotion analysis/Emo-db/08a01Wa.wav\n",
              "6   Happy    ...  /content/drive/MyDrive/Speech Emotion analysis/Emo-db/13a01Fd.wav\n",
              "7   Neutral  ...  /content/drive/MyDrive/Speech Emotion analysis/Emo-db/03a01Nc.wav\n",
              "8   Angry    ...  /content/drive/MyDrive/Speech Emotion analysis/Emo-db/08a01Wc.wav\n",
              "9   Happy    ...  /content/drive/MyDrive/Speech Emotion analysis/Emo-db/08a01Fd.wav\n",
              "10  Boredom  ...  /content/drive/MyDrive/Speech Emotion analysis/Emo-db/08a01Lc.wav\n",
              "11  Angry    ...  /content/drive/MyDrive/Speech Emotion analysis/Emo-db/03a01Wa.wav\n",
              "12  Disgust  ...  /content/drive/MyDrive/Speech Emotion analysis/Emo-db/13a01Ea.wav\n",
              "13  Fear     ...  /content/drive/MyDrive/Speech Emotion analysis/Emo-db/11a01Ab.wav\n",
              "14  Boredom  ...  /content/drive/MyDrive/Speech Emotion analysis/Emo-db/11a01Ld.wav\n",
              "15  Happy    ...  /content/drive/MyDrive/Speech Emotion analysis/Emo-db/16a01Fc.wav\n",
              "16  Boredom  ...  /content/drive/MyDrive/Speech Emotion analysis/Emo-db/12a01Lb.wav\n",
              "17  Neutral  ...  /content/drive/MyDrive/Speech Emotion analysis/Emo-db/09a01Nb.wav\n",
              "18  Angry    ...  /content/drive/MyDrive/Speech Emotion analysis/Emo-db/12a01Wc.wav\n",
              "19  Angry    ...  /content/drive/MyDrive/Speech Emotion analysis/Emo-db/11a01Wc.wav\n",
              "20  Happy    ...  /content/drive/MyDrive/Speech Emotion analysis/Emo-db/15a01Fb.wav\n",
              "21  Angry    ...  /content/drive/MyDrive/Speech Emotion analysis/Emo-db/10a01Wa.wav\n",
              "22  Disgust  ...  /content/drive/MyDrive/Speech Emotion analysis/Emo-db/13a01Ec.wav\n",
              "23  Neutral  ...  /content/drive/MyDrive/Speech Emotion analysis/Emo-db/10a01Nb.wav\n",
              "24  Fear     ...  /content/drive/MyDrive/Speech Emotion analysis/Emo-db/13a01Ac.wav\n",
              "25  Neutral  ...  /content/drive/MyDrive/Speech Emotion analysis/Emo-db/12a01Nb.wav\n",
              "26  Fear     ...  /content/drive/MyDrive/Speech Emotion analysis/Emo-db/10a01Ac.wav\n",
              "27  Neutral  ...  /content/drive/MyDrive/Speech Emotion analysis/Emo-db/11a01Nd.wav\n",
              "28  Angry    ...  /content/drive/MyDrive/Speech Emotion analysis/Emo-db/09a01Wb.wav\n",
              "29  Fear     ...  /content/drive/MyDrive/Speech Emotion analysis/Emo-db/11a01Aa.wav\n",
              "30  Disgust  ...  /content/drive/MyDrive/Speech Emotion analysis/Emo-db/09a01Ea.wav\n",
              "31  Angry    ...  /content/drive/MyDrive/Speech Emotion analysis/Emo-db/13a01Wb.wav\n",
              "32  Fear     ...  /content/drive/MyDrive/Speech Emotion analysis/Emo-db/14a01Ac.wav\n",
              "33  Fear     ...  /content/drive/MyDrive/Speech Emotion analysis/Emo-db/14a01Aa.wav\n",
              "34  Sadness  ...  /content/drive/MyDrive/Speech Emotion analysis/Emo-db/16a01Tb.wav\n",
              "35  Angry    ...  /content/drive/MyDrive/Speech Emotion analysis/Emo-db/14a01Wa.wav\n",
              "36  Neutral  ...  /content/drive/MyDrive/Speech Emotion analysis/Emo-db/15a01Nb.wav\n",
              "37  Angry    ...  /content/drive/MyDrive/Speech Emotion analysis/Emo-db/15a01Wa.wav\n",
              "38  Disgust  ...  /content/drive/MyDrive/Speech Emotion analysis/Emo-db/14a01Ea.wav\n",
              "39  Boredom  ...  /content/drive/MyDrive/Speech Emotion analysis/Emo-db/15a01La.wav\n",
              "40  Angry    ...  /content/drive/MyDrive/Speech Emotion analysis/Emo-db/16a01Wb.wav\n",
              "41  Neutral  ...  /content/drive/MyDrive/Speech Emotion analysis/Emo-db/13a01Nb.wav\n",
              "42  Boredom  ...  /content/drive/MyDrive/Speech Emotion analysis/Emo-db/13a01Lb.wav\n",
              "43  Disgust  ...  /content/drive/MyDrive/Speech Emotion analysis/Emo-db/15a01Ea.wav\n",
              "44  Disgust  ...  /content/drive/MyDrive/Speech Emotion analysis/Emo-db/16a01Ec.wav\n",
              "45  Neutral  ...  /content/drive/MyDrive/Speech Emotion analysis/Emo-db/14a01Na.wav\n",
              "46  Boredom  ...  /content/drive/MyDrive/Speech Emotion analysis/Emo-db/16a01Lb.wav\n",
              "47  Angry    ...  /content/drive/MyDrive/Speech Emotion analysis/Emo-db/14a01Wc.wav\n",
              "48  Neutral  ...  /content/drive/MyDrive/Speech Emotion analysis/Emo-db/16a01Nc.wav\n",
              "49  Disgust  ...  /content/drive/MyDrive/Speech Emotion analysis/Emo-db/09a02Ea.wav\n",
              "\n",
              "[50 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "TUDhxIzeDfX9",
        "outputId": "70f97527-3e85-4624-9869-b1fd6719e98b"
      },
      "source": [
        "plt.title('Count of Emotions', size=16)\n",
        "sns.countplot(data_path.emotion)\n",
        "plt.ylabel('Count', size=12) \n",
        "plt.xlabel('Emotions', size=12)\n",
        "sns.despine(top=True, right=True, left=False, bottom=False)\n",
        "plt.show()  "
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNdHFKzADjQ4"
      },
      "source": [
        "def create_waveplot(data, sr, e):\n",
        "    plt.figure(figsize=(10, 3))\n",
        "    plt.title('Waveplot for audio with {} emotion'.format(e), size=15)\n",
        "    librosa.display.waveplot(data, sr=sr)\n",
        "    plt.show()\n",
        "\n",
        "def create_spectrogram(data, sr, e):\n",
        "    # stft function converts the data into short term fourier transform\n",
        "    X = librosa.stft(data)\n",
        "    Xdb = librosa.amplitude_to_db(abs(X))\n",
        "    plt.figure(figsize=(12, 3))\n",
        "    plt.title('Spectrogram for audio with {} emotion'.format(e), size=15)\n",
        "    librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='hz')   \n",
        "    #librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='log')\n",
        "    plt.colorbar()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3K5rL7EDl_x"
      },
      "source": [
        "def noise(data):\n",
        "    noise_amp = 0.015*np.random.uniform()*np.amax(data)\n",
        "    data = data + noise_amp*np.random.normal(size=data.shape[0])\n",
        "    return data\n",
        "\n",
        "def stretch(data, rate=0.8):\n",
        "    return librosa.effects.time_stretch(data, rate)\n",
        "\n",
        "def shift(data):\n",
        "    shift_range = int(np.random.uniform(low=-5, high = 5)*1000)\n",
        "    return np.roll(data, shift_range)\n",
        "\n",
        "def pitch(data, sampling_rate, pitch_factor=0.7):\n",
        "    return librosa.effects.pitch_shift(data, sampling_rate, pitch_factor)\n",
        "\n",
        "def pitch2(data, sampling_rate, pitch_factor=0.6):\n",
        "    return librosa.effects.pitch_shift(data, sampling_rate, pitch_factor)\n",
        "\n",
        "# taking any example and checking for techniques.\n",
        "path = np.array(data_path.path)[1]\n",
        "data, sample_rate = librosa.load(path)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tCgOhzgDoZH"
      },
      "source": [
        "def extract_features(data):\n",
        "    # ZCR\n",
        "    result = np.array([])\n",
        "    zcr = np.mean(librosa.feature.zero_crossing_rate(y=data).T, axis=0)\n",
        "    result=np.hstack((result, zcr)) # stacking horizontally\n",
        "\n",
        "    # Chroma_stft\n",
        "    stft = np.abs(librosa.stft(data))\n",
        "    chroma_stft = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T, axis=0)\n",
        "    result = np.hstack((result, chroma_stft)) # stacking horizontally\n",
        "\n",
        "    # MFCC\n",
        "    mfcc = np.mean(librosa.feature.mfcc(y=data, sr=sample_rate,n_mfcc=13).T, axis=0)\n",
        "    result = np.hstack((result, mfcc)) # stacking horizontally\n",
        "\n",
        "    # Root Mean Square Value\n",
        "    rms = np.mean(librosa.feature.rms(y=data).T, axis=0)\n",
        "    result = np.hstack((result, rms)) # stacking horizontally\n",
        "\n",
        "    # MelSpectogram\n",
        "    mel = np.mean(librosa.feature.melspectrogram(y=data, sr=sample_rate).T, axis=0)\n",
        "    result = np.hstack((result, mel)) # stacking horizontally\n",
        "       \n",
        "    return result"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHWplpQXDqxP"
      },
      "source": [
        "def get_features(path):\n",
        "    # duration and offset are used to take care of the no audio in start and the ending of each audio files as seen above.\n",
        "    data, sample_rate = librosa.load(path, duration=2.5, offset=0.6)\n",
        "    result = np.array([])\n",
        "    \n",
        "    # without augmentation\n",
        "    res1 = extract_features(data)\n",
        "    result = np.array(res1)\n",
        "    \n",
        "    # data with noise\n",
        "    noise_data = noise(data)\n",
        "    res2 = extract_features(noise_data)\n",
        "    result = np.vstack((result, res2)) # stacking vertically\n",
        "    \n",
        "    # data with stretching and pitching\n",
        "    new_data = stretch(data)\n",
        "    data_stretch_pitch = pitch(new_data, sample_rate)\n",
        "    res3 = extract_features(data_stretch_pitch)\n",
        "    result = np.vstack((result, res3)) # stacking vertically\n",
        "\n",
        "    # data with stretching and pitching\n",
        "    new_data = stretch(data)\n",
        "    data_stretch_pitch = pitch2(new_data, sample_rate)\n",
        "    res4 = extract_features(data_stretch_pitch)\n",
        "    result = np.vstack((result, res4)) # stacking vertically\n",
        "    \n",
        "    return result"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBHuFZnFDtcx"
      },
      "source": [
        "X, Y = [], []\n",
        "for path, emotion in zip(df.path, df.emotion):\n",
        "    feature = get_features(path)\n",
        "    for ele in feature:\n",
        "        X.append(ele)\n",
        "        # appending emotion 3 times as we have made 3 augmentation techniques on each audio file.\n",
        "        Y.append(emotion)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FblW_yooDw6G",
        "outputId": "5f232e62-e7bd-437b-8151-f48d672e6baf"
      },
      "source": [
        "len(X), len(Y), data_path.path.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2140, 2140, (535,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "GJDztvMgDzVC",
        "outputId": "2a9bd9a6-8568-4bec-d3b4-c04480dd9434"
      },
      "source": [
        "Features = pd.DataFrame(X)\n",
        "Features['labels'] = Y\n",
        "Features.to_csv('features.csv', index=False)\n",
        "Features.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>116</th>\n",
              "      <th>117</th>\n",
              "      <th>118</th>\n",
              "      <th>119</th>\n",
              "      <th>120</th>\n",
              "      <th>121</th>\n",
              "      <th>122</th>\n",
              "      <th>123</th>\n",
              "      <th>124</th>\n",
              "      <th>125</th>\n",
              "      <th>126</th>\n",
              "      <th>127</th>\n",
              "      <th>128</th>\n",
              "      <th>129</th>\n",
              "      <th>130</th>\n",
              "      <th>131</th>\n",
              "      <th>132</th>\n",
              "      <th>133</th>\n",
              "      <th>134</th>\n",
              "      <th>135</th>\n",
              "      <th>136</th>\n",
              "      <th>137</th>\n",
              "      <th>138</th>\n",
              "      <th>139</th>\n",
              "      <th>140</th>\n",
              "      <th>141</th>\n",
              "      <th>142</th>\n",
              "      <th>143</th>\n",
              "      <th>144</th>\n",
              "      <th>145</th>\n",
              "      <th>146</th>\n",
              "      <th>147</th>\n",
              "      <th>148</th>\n",
              "      <th>149</th>\n",
              "      <th>150</th>\n",
              "      <th>151</th>\n",
              "      <th>152</th>\n",
              "      <th>153</th>\n",
              "      <th>154</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.118058</td>\n",
              "      <td>0.565005</td>\n",
              "      <td>0.608090</td>\n",
              "      <td>0.683121</td>\n",
              "      <td>0.617558</td>\n",
              "      <td>0.536719</td>\n",
              "      <td>0.544609</td>\n",
              "      <td>0.565097</td>\n",
              "      <td>0.586288</td>\n",
              "      <td>0.556638</td>\n",
              "      <td>0.535788</td>\n",
              "      <td>0.521537</td>\n",
              "      <td>0.521607</td>\n",
              "      <td>-239.242264</td>\n",
              "      <td>93.311470</td>\n",
              "      <td>-47.721405</td>\n",
              "      <td>36.792530</td>\n",
              "      <td>-29.406725</td>\n",
              "      <td>30.540400</td>\n",
              "      <td>-26.404978</td>\n",
              "      <td>-2.567815</td>\n",
              "      <td>-6.565616</td>\n",
              "      <td>-9.454045</td>\n",
              "      <td>-2.605035</td>\n",
              "      <td>-2.645095</td>\n",
              "      <td>-1.123081</td>\n",
              "      <td>0.106191</td>\n",
              "      <td>0.233874</td>\n",
              "      <td>0.168767</td>\n",
              "      <td>0.088874</td>\n",
              "      <td>0.031072</td>\n",
              "      <td>0.031221</td>\n",
              "      <td>0.397871</td>\n",
              "      <td>9.459945</td>\n",
              "      <td>11.387362</td>\n",
              "      <td>9.485535</td>\n",
              "      <td>16.230631</td>\n",
              "      <td>59.399960</td>\n",
              "      <td>35.644787</td>\n",
              "      <td>12.259502</td>\n",
              "      <td>...</td>\n",
              "      <td>0.316787</td>\n",
              "      <td>0.537943</td>\n",
              "      <td>0.480110</td>\n",
              "      <td>0.708013</td>\n",
              "      <td>0.568656</td>\n",
              "      <td>0.385182</td>\n",
              "      <td>0.467830</td>\n",
              "      <td>0.359173</td>\n",
              "      <td>0.150270</td>\n",
              "      <td>0.237734</td>\n",
              "      <td>0.319602</td>\n",
              "      <td>0.218449</td>\n",
              "      <td>0.201142</td>\n",
              "      <td>0.186315</td>\n",
              "      <td>0.148083</td>\n",
              "      <td>0.223006</td>\n",
              "      <td>0.282373</td>\n",
              "      <td>0.311500</td>\n",
              "      <td>0.298508</td>\n",
              "      <td>0.445633</td>\n",
              "      <td>0.315118</td>\n",
              "      <td>0.306816</td>\n",
              "      <td>0.295273</td>\n",
              "      <td>0.172138</td>\n",
              "      <td>0.084325</td>\n",
              "      <td>0.015300</td>\n",
              "      <td>0.000683</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>Fear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.159499</td>\n",
              "      <td>0.573767</td>\n",
              "      <td>0.600857</td>\n",
              "      <td>0.691580</td>\n",
              "      <td>0.649872</td>\n",
              "      <td>0.566836</td>\n",
              "      <td>0.556375</td>\n",
              "      <td>0.561781</td>\n",
              "      <td>0.584952</td>\n",
              "      <td>0.579911</td>\n",
              "      <td>0.540382</td>\n",
              "      <td>0.529151</td>\n",
              "      <td>0.536371</td>\n",
              "      <td>-212.458281</td>\n",
              "      <td>71.303091</td>\n",
              "      <td>-30.481553</td>\n",
              "      <td>19.917075</td>\n",
              "      <td>-16.839288</td>\n",
              "      <td>19.180154</td>\n",
              "      <td>-18.517549</td>\n",
              "      <td>-7.573117</td>\n",
              "      <td>-3.823415</td>\n",
              "      <td>-9.756145</td>\n",
              "      <td>-4.119056</td>\n",
              "      <td>-1.069780</td>\n",
              "      <td>-4.083046</td>\n",
              "      <td>0.106222</td>\n",
              "      <td>0.234373</td>\n",
              "      <td>0.168069</td>\n",
              "      <td>0.088786</td>\n",
              "      <td>0.030733</td>\n",
              "      <td>0.031965</td>\n",
              "      <td>0.397646</td>\n",
              "      <td>9.454449</td>\n",
              "      <td>11.388666</td>\n",
              "      <td>9.495469</td>\n",
              "      <td>16.227837</td>\n",
              "      <td>59.403681</td>\n",
              "      <td>35.644948</td>\n",
              "      <td>12.250106</td>\n",
              "      <td>...</td>\n",
              "      <td>0.316398</td>\n",
              "      <td>0.537562</td>\n",
              "      <td>0.481137</td>\n",
              "      <td>0.708676</td>\n",
              "      <td>0.567509</td>\n",
              "      <td>0.384902</td>\n",
              "      <td>0.468691</td>\n",
              "      <td>0.358894</td>\n",
              "      <td>0.150201</td>\n",
              "      <td>0.238689</td>\n",
              "      <td>0.320092</td>\n",
              "      <td>0.218630</td>\n",
              "      <td>0.201674</td>\n",
              "      <td>0.187551</td>\n",
              "      <td>0.148555</td>\n",
              "      <td>0.223557</td>\n",
              "      <td>0.282249</td>\n",
              "      <td>0.311300</td>\n",
              "      <td>0.298656</td>\n",
              "      <td>0.445160</td>\n",
              "      <td>0.315555</td>\n",
              "      <td>0.307073</td>\n",
              "      <td>0.295669</td>\n",
              "      <td>0.172210</td>\n",
              "      <td>0.084641</td>\n",
              "      <td>0.015526</td>\n",
              "      <td>0.000879</td>\n",
              "      <td>0.000173</td>\n",
              "      <td>0.000162</td>\n",
              "      <td>0.000162</td>\n",
              "      <td>0.000157</td>\n",
              "      <td>0.000151</td>\n",
              "      <td>0.000154</td>\n",
              "      <td>0.000155</td>\n",
              "      <td>0.000145</td>\n",
              "      <td>0.000163</td>\n",
              "      <td>0.000170</td>\n",
              "      <td>0.000166</td>\n",
              "      <td>0.000172</td>\n",
              "      <td>Fear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.129947</td>\n",
              "      <td>0.479741</td>\n",
              "      <td>0.530497</td>\n",
              "      <td>0.620380</td>\n",
              "      <td>0.701526</td>\n",
              "      <td>0.583356</td>\n",
              "      <td>0.489940</td>\n",
              "      <td>0.490483</td>\n",
              "      <td>0.528225</td>\n",
              "      <td>0.563035</td>\n",
              "      <td>0.543836</td>\n",
              "      <td>0.546025</td>\n",
              "      <td>0.488869</td>\n",
              "      <td>-277.763794</td>\n",
              "      <td>95.098206</td>\n",
              "      <td>-47.637703</td>\n",
              "      <td>32.853813</td>\n",
              "      <td>-31.094694</td>\n",
              "      <td>29.501434</td>\n",
              "      <td>-36.599606</td>\n",
              "      <td>1.347704</td>\n",
              "      <td>-9.349730</td>\n",
              "      <td>-6.262607</td>\n",
              "      <td>-6.858923</td>\n",
              "      <td>-2.220073</td>\n",
              "      <td>-6.736476</td>\n",
              "      <td>0.051398</td>\n",
              "      <td>0.055435</td>\n",
              "      <td>0.053554</td>\n",
              "      <td>0.021962</td>\n",
              "      <td>0.008748</td>\n",
              "      <td>0.006275</td>\n",
              "      <td>0.009445</td>\n",
              "      <td>0.538023</td>\n",
              "      <td>2.605234</td>\n",
              "      <td>6.074339</td>\n",
              "      <td>4.441233</td>\n",
              "      <td>12.834837</td>\n",
              "      <td>15.815147</td>\n",
              "      <td>3.699942</td>\n",
              "      <td>...</td>\n",
              "      <td>0.028623</td>\n",
              "      <td>0.037766</td>\n",
              "      <td>0.057624</td>\n",
              "      <td>0.076188</td>\n",
              "      <td>0.139738</td>\n",
              "      <td>0.186121</td>\n",
              "      <td>0.069324</td>\n",
              "      <td>0.072744</td>\n",
              "      <td>0.087065</td>\n",
              "      <td>0.060644</td>\n",
              "      <td>0.037706</td>\n",
              "      <td>0.048544</td>\n",
              "      <td>0.054933</td>\n",
              "      <td>0.064526</td>\n",
              "      <td>0.025585</td>\n",
              "      <td>0.028049</td>\n",
              "      <td>0.038903</td>\n",
              "      <td>0.045632</td>\n",
              "      <td>0.046279</td>\n",
              "      <td>0.077440</td>\n",
              "      <td>0.063345</td>\n",
              "      <td>0.075133</td>\n",
              "      <td>0.041121</td>\n",
              "      <td>0.053084</td>\n",
              "      <td>0.036935</td>\n",
              "      <td>0.021848</td>\n",
              "      <td>0.011327</td>\n",
              "      <td>0.000532</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>Fear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.128188</td>\n",
              "      <td>0.508703</td>\n",
              "      <td>0.586469</td>\n",
              "      <td>0.702197</td>\n",
              "      <td>0.594640</td>\n",
              "      <td>0.483643</td>\n",
              "      <td>0.516429</td>\n",
              "      <td>0.542251</td>\n",
              "      <td>0.579736</td>\n",
              "      <td>0.562298</td>\n",
              "      <td>0.553694</td>\n",
              "      <td>0.485373</td>\n",
              "      <td>0.484502</td>\n",
              "      <td>-277.886475</td>\n",
              "      <td>95.166748</td>\n",
              "      <td>-49.346569</td>\n",
              "      <td>33.691082</td>\n",
              "      <td>-31.111177</td>\n",
              "      <td>30.956291</td>\n",
              "      <td>-36.058765</td>\n",
              "      <td>-0.091696</td>\n",
              "      <td>-9.122845</td>\n",
              "      <td>-5.356777</td>\n",
              "      <td>-5.549081</td>\n",
              "      <td>-2.720793</td>\n",
              "      <td>-5.709476</td>\n",
              "      <td>0.053169</td>\n",
              "      <td>0.060399</td>\n",
              "      <td>0.044571</td>\n",
              "      <td>0.018921</td>\n",
              "      <td>0.008483</td>\n",
              "      <td>0.005051</td>\n",
              "      <td>0.012949</td>\n",
              "      <td>0.899411</td>\n",
              "      <td>4.496017</td>\n",
              "      <td>6.565965</td>\n",
              "      <td>3.993485</td>\n",
              "      <td>13.024792</td>\n",
              "      <td>14.767900</td>\n",
              "      <td>3.861615</td>\n",
              "      <td>...</td>\n",
              "      <td>0.018193</td>\n",
              "      <td>0.071796</td>\n",
              "      <td>0.110694</td>\n",
              "      <td>0.111856</td>\n",
              "      <td>0.195477</td>\n",
              "      <td>0.138269</td>\n",
              "      <td>0.076853</td>\n",
              "      <td>0.049649</td>\n",
              "      <td>0.074115</td>\n",
              "      <td>0.025732</td>\n",
              "      <td>0.041997</td>\n",
              "      <td>0.092443</td>\n",
              "      <td>0.062046</td>\n",
              "      <td>0.048539</td>\n",
              "      <td>0.035789</td>\n",
              "      <td>0.036421</td>\n",
              "      <td>0.049161</td>\n",
              "      <td>0.074041</td>\n",
              "      <td>0.075512</td>\n",
              "      <td>0.060076</td>\n",
              "      <td>0.053002</td>\n",
              "      <td>0.068308</td>\n",
              "      <td>0.048778</td>\n",
              "      <td>0.047259</td>\n",
              "      <td>0.034073</td>\n",
              "      <td>0.023847</td>\n",
              "      <td>0.006954</td>\n",
              "      <td>0.000337</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>Fear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.090625</td>\n",
              "      <td>0.486378</td>\n",
              "      <td>0.538183</td>\n",
              "      <td>0.593669</td>\n",
              "      <td>0.712791</td>\n",
              "      <td>0.803031</td>\n",
              "      <td>0.758678</td>\n",
              "      <td>0.711637</td>\n",
              "      <td>0.678423</td>\n",
              "      <td>0.650458</td>\n",
              "      <td>0.604287</td>\n",
              "      <td>0.523501</td>\n",
              "      <td>0.451379</td>\n",
              "      <td>-299.975983</td>\n",
              "      <td>123.833115</td>\n",
              "      <td>-58.514000</td>\n",
              "      <td>49.796654</td>\n",
              "      <td>-19.890055</td>\n",
              "      <td>-2.462753</td>\n",
              "      <td>-7.365324</td>\n",
              "      <td>5.748572</td>\n",
              "      <td>-25.684937</td>\n",
              "      <td>-2.324779</td>\n",
              "      <td>7.042671</td>\n",
              "      <td>-15.331325</td>\n",
              "      <td>2.479473</td>\n",
              "      <td>0.047949</td>\n",
              "      <td>0.018844</td>\n",
              "      <td>0.019758</td>\n",
              "      <td>0.039690</td>\n",
              "      <td>0.199644</td>\n",
              "      <td>0.933736</td>\n",
              "      <td>1.300369</td>\n",
              "      <td>0.301026</td>\n",
              "      <td>0.152289</td>\n",
              "      <td>0.781222</td>\n",
              "      <td>1.540226</td>\n",
              "      <td>2.140152</td>\n",
              "      <td>7.207627</td>\n",
              "      <td>6.451104</td>\n",
              "      <td>...</td>\n",
              "      <td>0.015172</td>\n",
              "      <td>0.009112</td>\n",
              "      <td>0.008126</td>\n",
              "      <td>0.005522</td>\n",
              "      <td>0.004459</td>\n",
              "      <td>0.003620</td>\n",
              "      <td>0.002776</td>\n",
              "      <td>0.005050</td>\n",
              "      <td>0.005268</td>\n",
              "      <td>0.003335</td>\n",
              "      <td>0.006582</td>\n",
              "      <td>0.005305</td>\n",
              "      <td>0.004916</td>\n",
              "      <td>0.003693</td>\n",
              "      <td>0.003385</td>\n",
              "      <td>0.003568</td>\n",
              "      <td>0.003856</td>\n",
              "      <td>0.003173</td>\n",
              "      <td>0.003193</td>\n",
              "      <td>0.002571</td>\n",
              "      <td>0.001496</td>\n",
              "      <td>0.001269</td>\n",
              "      <td>0.000919</td>\n",
              "      <td>0.000577</td>\n",
              "      <td>0.000365</td>\n",
              "      <td>0.000083</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>Happy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 156 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          0         1         2         3  ...       152       153       154  labels\n",
              "0  0.118058  0.565005  0.608090  0.683121  ...  0.000002  0.000002  0.000002  Fear  \n",
              "1  0.159499  0.573767  0.600857  0.691580  ...  0.000170  0.000166  0.000172  Fear  \n",
              "2  0.129947  0.479741  0.530497  0.620380  ...  0.000004  0.000006  0.000007  Fear  \n",
              "3  0.128188  0.508703  0.586469  0.702197  ...  0.000003  0.000005  0.000007  Fear  \n",
              "4  0.090625  0.486378  0.538183  0.593669  ...  0.000002  0.000002  0.000002  Happy \n",
              "\n",
              "[5 rows x 156 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JeskUKt3D1uy",
        "outputId": "aa34cbfe-bd65-4366-9998-c9be266f9005"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = Features.iloc[: ,:-1].values\n",
        "Y = Features['labels'].values\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, Y,test_size=0.20, random_state=0, shuffle=True)\n",
        "x_train.shape, y_train.shape, x_test.shape, y_test.shape\n",
        "\n",
        "# NORMALIZE DATA\n",
        "mean = np.mean(x_train, axis=0)\n",
        "std = np.std(x_train, axis=0)\n",
        "x_train = (x_train - mean)/std\n",
        "x_test = (x_test - mean)/std\n",
        "\n",
        "# TURN DATA INTO ARRAYS FOR KERAS\n",
        "x_train = np.array(x_train)\n",
        "y_train = np.array(y_train)\n",
        "x_test = np.array(x_test)\n",
        "y_test = np.array(y_test)\n",
        "# ONE HOT ENCODE THE TARGET\n",
        "# CNN REQUIRES INPUT AND OUTPUT ARE NUMBERS\n",
        "lb = LabelEncoder()\n",
        "y_train = to_categorical(lb.fit_transform(y_train))\n",
        "y_test = to_categorical(lb.fit_transform(y_test))\n",
        "print(y_test[0:10])\n",
        "# RESHAPE DATA TO INCLUDE 3D TENSOR \n",
        "x_train = x_train[:,:,np.newaxis]\n",
        "x_test = x_test[:,:,np.newaxis]\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "\n",
        "# Define the K-fold Cross Validator\n",
        "kfold = KFold(n_splits=2, shuffle=True)\n",
        "acc_per_fold = []\n",
        "loss_per_fold = []\n",
        "inputs = np.concatenate((x_train, x_test), axis=0)\n",
        "targets = np.concatenate((y_train, y_test), axis=0)\n",
        "inputs.shape\n",
        "targets.shape\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0.]]\n",
            "(1712, 155, 1)\n",
            "(428, 155, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2140, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FJqo6ZnD6mX",
        "outputId": "b1fdedc6-ac1a-4dc5-f8bc-8e1f8282a0be"
      },
      "source": [
        "lb.classes_"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Angry', 'Boredom', 'Disgust', 'Fear', 'Happy', 'Neutral',\n",
              "       'Sadness'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhRABwswD9FK",
        "outputId": "c0816df5-50cf-4853-fb52-a169ebba0c8c"
      },
      "source": [
        "model = tf.keras.Sequential()\n",
        "model.add(layers.Conv1D(256, kernel_size=(8),strides=1,dilation_rate=1,padding=\"same\", activation='relu', input_shape=(x_train.shape[1],1)))\n",
        "model.add(layers.Conv1D(256, kernel_size=(8),strides=1,activation='relu',dilation_rate=1,kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
        "model.add(layers.MaxPooling1D(pool_size=(2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Conv1D(256, kernel_size=(8),strides=1,dilation_rate=1,padding=\"same\",activation='relu'))\n",
        "model.add(layers.MaxPooling1D(pool_size=(2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.Conv1D(128, kernel_size=(8),strides=1,dilation_rate=1,padding=\"same\",activation='relu'))\n",
        "model.add(layers.MaxPooling1D(pool_size=(2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Conv1D(128, kernel_size=(8),strides=1,dilation_rate=1,padding=\"same\",activation='relu'))\n",
        "model.add(layers.MaxPooling1D(pool_size=(2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Conv1D(128, kernel_size=(8),strides=1,dilation_rate=1,padding=\"same\",activation='relu'))\n",
        "model.add(layers.MaxPooling1D(pool_size=(2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Conv1D(256, kernel_size=(8),strides=1,dilation_rate=1,padding=\"same\",activation='relu'))\n",
        "model.add(layers.MaxPooling1D(pool_size=(2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Conv1D(64, kernel_size=(8),strides=1,dilation_rate=1,padding=\"same\",activation='relu'))\n",
        "model.add(layers.MaxPooling1D(pool_size=(2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(7, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='Adam',metrics=['accuracy'])\n",
        "model.summary()\n",
        "checkpoint = ModelCheckpoint(\"SER_best_initial_model.hdf5\", monitor='val_accuracy', verbose=1, save_best_only=True, mode='max', period=1, save_weights_only=True)\n",
        "model_history=model.fit(x_train, y_train,batch_size=32, epochs=1000, validation_data=(x_test, y_test),callbacks=[checkpoint])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_31 (Conv1D)           (None, 155, 256)          2304      \n",
            "_________________________________________________________________\n",
            "conv1d_32 (Conv1D)           (None, 148, 256)          524544    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_27 (MaxPooling (None, 74, 256)           0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_27 (Batc (None, 74, 256)           1024      \n",
            "_________________________________________________________________\n",
            "dropout_34 (Dropout)         (None, 74, 256)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_33 (Conv1D)           (None, 74, 256)           524544    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_28 (MaxPooling (None, 37, 256)           0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_28 (Batc (None, 37, 256)           1024      \n",
            "_________________________________________________________________\n",
            "conv1d_34 (Conv1D)           (None, 37, 128)           262272    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_29 (MaxPooling (None, 18, 128)           0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_29 (Batc (None, 18, 128)           512       \n",
            "_________________________________________________________________\n",
            "dropout_35 (Dropout)         (None, 18, 128)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_35 (Conv1D)           (None, 18, 128)           131200    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_30 (MaxPooling (None, 9, 128)            0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_30 (Batc (None, 9, 128)            512       \n",
            "_________________________________________________________________\n",
            "dropout_36 (Dropout)         (None, 9, 128)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_36 (Conv1D)           (None, 9, 128)            131200    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_31 (MaxPooling (None, 4, 128)            0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_31 (Batc (None, 4, 128)            512       \n",
            "_________________________________________________________________\n",
            "dropout_37 (Dropout)         (None, 4, 128)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_37 (Conv1D)           (None, 4, 256)            262400    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_32 (MaxPooling (None, 2, 256)            0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_32 (Batc (None, 2, 256)            1024      \n",
            "_________________________________________________________________\n",
            "dropout_38 (Dropout)         (None, 2, 256)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_38 (Conv1D)           (None, 2, 64)             131136    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_33 (MaxPooling (None, 1, 64)             0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_33 (Batc (None, 1, 64)             256       \n",
            "_________________________________________________________________\n",
            "dropout_39 (Dropout)         (None, 1, 64)             0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dropout_40 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 128)               8320      \n",
            "_________________________________________________________________\n",
            "dropout_41 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_42 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 7)                 455       \n",
            "=================================================================\n",
            "Total params: 1,991,495\n",
            "Trainable params: 1,989,063\n",
            "Non-trainable params: 2,432\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/1000\n",
            "41/41 [==============================] - 4s 27ms/step - loss: 5.7256 - accuracy: 0.1683 - val_loss: 4.5192 - val_accuracy: 0.1838\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.18380, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 2/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 5.0098 - accuracy: 0.1690 - val_loss: 4.2717 - val_accuracy: 0.2368\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.18380 to 0.23676, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 3/1000\n",
            "41/41 [==============================] - 1s 16ms/step - loss: 4.4763 - accuracy: 0.1935 - val_loss: 4.0027 - val_accuracy: 0.2336\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.23676\n",
            "Epoch 4/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 4.1589 - accuracy: 0.1765 - val_loss: 3.7250 - val_accuracy: 0.2336\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.23676\n",
            "Epoch 5/1000\n",
            "41/41 [==============================] - 1s 16ms/step - loss: 3.8696 - accuracy: 0.1678 - val_loss: 3.4738 - val_accuracy: 0.1994\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.23676\n",
            "Epoch 6/1000\n",
            "41/41 [==============================] - 1s 16ms/step - loss: 3.4725 - accuracy: 0.2102 - val_loss: 3.2348 - val_accuracy: 0.2118\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.23676\n",
            "Epoch 7/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 3.2184 - accuracy: 0.2164 - val_loss: 3.0241 - val_accuracy: 0.2461\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.23676 to 0.24611, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 8/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 3.0441 - accuracy: 0.1784 - val_loss: 2.8456 - val_accuracy: 0.2741\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.24611 to 0.27414, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 9/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 2.8466 - accuracy: 0.2106 - val_loss: 2.6856 - val_accuracy: 0.3240\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.27414 to 0.32399, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 10/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 2.6618 - accuracy: 0.2191 - val_loss: 2.5459 - val_accuracy: 0.3053\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.32399\n",
            "Epoch 11/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 2.5525 - accuracy: 0.2184 - val_loss: 2.4227 - val_accuracy: 0.2928\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.32399\n",
            "Epoch 12/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 2.3936 - accuracy: 0.2700 - val_loss: 2.3024 - val_accuracy: 0.3333\n",
            "\n",
            "Epoch 00012: val_accuracy improved from 0.32399 to 0.33333, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 13/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 2.2858 - accuracy: 0.2593 - val_loss: 2.1743 - val_accuracy: 0.3676\n",
            "\n",
            "Epoch 00013: val_accuracy improved from 0.33333 to 0.36760, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 14/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 2.2004 - accuracy: 0.2534 - val_loss: 2.0588 - val_accuracy: 0.3583\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.36760\n",
            "Epoch 15/1000\n",
            "41/41 [==============================] - 1s 16ms/step - loss: 2.0737 - accuracy: 0.2912 - val_loss: 1.9316 - val_accuracy: 0.3364\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.36760\n",
            "Epoch 16/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.9819 - accuracy: 0.3250 - val_loss: 1.8233 - val_accuracy: 0.3614\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.36760\n",
            "Epoch 17/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.9369 - accuracy: 0.3313 - val_loss: 1.7399 - val_accuracy: 0.3645\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.36760\n",
            "Epoch 18/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.8307 - accuracy: 0.3334 - val_loss: 1.7065 - val_accuracy: 0.3614\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.36760\n",
            "Epoch 19/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 1.7800 - accuracy: 0.3441 - val_loss: 1.7733 - val_accuracy: 0.3769\n",
            "\n",
            "Epoch 00019: val_accuracy improved from 0.36760 to 0.37695, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 20/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 1.7528 - accuracy: 0.3444 - val_loss: 1.6440 - val_accuracy: 0.3894\n",
            "\n",
            "Epoch 00020: val_accuracy improved from 0.37695 to 0.38941, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 21/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.6761 - accuracy: 0.3483 - val_loss: 1.5859 - val_accuracy: 0.3801\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.38941\n",
            "Epoch 22/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.6082 - accuracy: 0.3387 - val_loss: 1.5088 - val_accuracy: 0.3832\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.38941\n",
            "Epoch 23/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.6128 - accuracy: 0.3862 - val_loss: 1.5009 - val_accuracy: 0.3894\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.38941\n",
            "Epoch 24/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.5678 - accuracy: 0.3831 - val_loss: 1.4898 - val_accuracy: 0.4268\n",
            "\n",
            "Epoch 00024: val_accuracy improved from 0.38941 to 0.42679, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 25/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.6223 - accuracy: 0.3566 - val_loss: 1.5732 - val_accuracy: 0.3583\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.42679\n",
            "Epoch 26/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.6075 - accuracy: 0.3498 - val_loss: 1.4588 - val_accuracy: 0.4299\n",
            "\n",
            "Epoch 00026: val_accuracy improved from 0.42679 to 0.42991, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 27/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.5088 - accuracy: 0.3896 - val_loss: 1.4273 - val_accuracy: 0.4268\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.42991\n",
            "Epoch 28/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.5604 - accuracy: 0.3670 - val_loss: 1.4662 - val_accuracy: 0.4579\n",
            "\n",
            "Epoch 00028: val_accuracy improved from 0.42991 to 0.45794, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 29/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.5589 - accuracy: 0.3650 - val_loss: 1.4599 - val_accuracy: 0.4237\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.45794\n",
            "Epoch 30/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.4720 - accuracy: 0.4030 - val_loss: 1.4699 - val_accuracy: 0.4548\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.45794\n",
            "Epoch 31/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.5036 - accuracy: 0.3425 - val_loss: 1.5019 - val_accuracy: 0.4393\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.45794\n",
            "Epoch 32/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.4436 - accuracy: 0.4293 - val_loss: 1.4203 - val_accuracy: 0.4050\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.45794\n",
            "Epoch 33/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.4336 - accuracy: 0.4088 - val_loss: 1.3752 - val_accuracy: 0.4922\n",
            "\n",
            "Epoch 00033: val_accuracy improved from 0.45794 to 0.49221, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 34/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.4919 - accuracy: 0.3923 - val_loss: 1.3879 - val_accuracy: 0.4642\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.49221\n",
            "Epoch 35/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.4547 - accuracy: 0.4149 - val_loss: 1.3462 - val_accuracy: 0.4486\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.49221\n",
            "Epoch 36/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.3851 - accuracy: 0.4233 - val_loss: 1.3790 - val_accuracy: 0.4766\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.49221\n",
            "Epoch 37/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 1.4137 - accuracy: 0.4049 - val_loss: 1.4124 - val_accuracy: 0.4081\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.49221\n",
            "Epoch 38/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 1.3887 - accuracy: 0.4376 - val_loss: 1.4035 - val_accuracy: 0.4237\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.49221\n",
            "Epoch 39/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.4150 - accuracy: 0.4282 - val_loss: 1.6961 - val_accuracy: 0.3271\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.49221\n",
            "Epoch 40/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.3870 - accuracy: 0.4125 - val_loss: 1.3588 - val_accuracy: 0.4393\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.49221\n",
            "Epoch 41/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 1.4441 - accuracy: 0.4283 - val_loss: 1.3309 - val_accuracy: 0.4829\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.49221\n",
            "Epoch 42/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 1.3896 - accuracy: 0.4304 - val_loss: 1.3558 - val_accuracy: 0.4143\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.49221\n",
            "Epoch 43/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.4603 - accuracy: 0.3939 - val_loss: 1.2498 - val_accuracy: 0.5016\n",
            "\n",
            "Epoch 00043: val_accuracy improved from 0.49221 to 0.50156, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 44/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 1.4140 - accuracy: 0.4150 - val_loss: 1.2424 - val_accuracy: 0.5234\n",
            "\n",
            "Epoch 00044: val_accuracy improved from 0.50156 to 0.52336, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 45/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.3420 - accuracy: 0.4443 - val_loss: 1.2632 - val_accuracy: 0.4766\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.52336\n",
            "Epoch 46/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.3392 - accuracy: 0.4487 - val_loss: 1.3012 - val_accuracy: 0.4798\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.52336\n",
            "Epoch 47/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.3152 - accuracy: 0.4601 - val_loss: 1.3850 - val_accuracy: 0.4517\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.52336\n",
            "Epoch 48/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.3149 - accuracy: 0.4585 - val_loss: 1.5570 - val_accuracy: 0.3583\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.52336\n",
            "Epoch 49/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.3797 - accuracy: 0.4422 - val_loss: 1.2835 - val_accuracy: 0.5078\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.52336\n",
            "Epoch 50/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.3522 - accuracy: 0.4524 - val_loss: 1.4466 - val_accuracy: 0.4268\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.52336\n",
            "Epoch 51/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 1.3349 - accuracy: 0.4609 - val_loss: 1.2039 - val_accuracy: 0.5171\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.52336\n",
            "Epoch 52/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.3547 - accuracy: 0.4269 - val_loss: 1.3753 - val_accuracy: 0.4361\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.52336\n",
            "Epoch 53/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.3493 - accuracy: 0.4688 - val_loss: 1.2895 - val_accuracy: 0.5327\n",
            "\n",
            "Epoch 00053: val_accuracy improved from 0.52336 to 0.53271, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 54/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.3273 - accuracy: 0.4516 - val_loss: 1.2715 - val_accuracy: 0.4891\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.53271\n",
            "Epoch 55/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 1.3438 - accuracy: 0.4708 - val_loss: 1.1770 - val_accuracy: 0.5670\n",
            "\n",
            "Epoch 00055: val_accuracy improved from 0.53271 to 0.56698, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 56/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 1.2914 - accuracy: 0.4851 - val_loss: 1.2665 - val_accuracy: 0.5016\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.56698\n",
            "Epoch 57/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.5695 - accuracy: 0.4373 - val_loss: 1.4223 - val_accuracy: 0.5389\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.56698\n",
            "Epoch 58/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.5545 - accuracy: 0.4614 - val_loss: 1.3007 - val_accuracy: 0.5452\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.56698\n",
            "Epoch 59/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.4081 - accuracy: 0.4600 - val_loss: 1.2722 - val_accuracy: 0.5265\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.56698\n",
            "Epoch 60/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.4482 - accuracy: 0.4417 - val_loss: 1.3981 - val_accuracy: 0.4984\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.56698\n",
            "Epoch 61/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.4065 - accuracy: 0.4863 - val_loss: 1.2946 - val_accuracy: 0.5265\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.56698\n",
            "Epoch 62/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.3720 - accuracy: 0.4704 - val_loss: 1.3009 - val_accuracy: 0.5140\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.56698\n",
            "Epoch 63/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.2628 - accuracy: 0.4848 - val_loss: 1.2081 - val_accuracy: 0.5109\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.56698\n",
            "Epoch 64/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.3267 - accuracy: 0.4825 - val_loss: 1.2136 - val_accuracy: 0.5171\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.56698\n",
            "Epoch 65/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.3112 - accuracy: 0.4785 - val_loss: 1.2571 - val_accuracy: 0.5171\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.56698\n",
            "Epoch 66/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.2293 - accuracy: 0.4919 - val_loss: 1.2048 - val_accuracy: 0.5234\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.56698\n",
            "Epoch 67/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.2416 - accuracy: 0.5108 - val_loss: 1.1901 - val_accuracy: 0.5296\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.56698\n",
            "Epoch 68/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.2158 - accuracy: 0.5303 - val_loss: 1.2227 - val_accuracy: 0.5234\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.56698\n",
            "Epoch 69/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.2072 - accuracy: 0.4857 - val_loss: 1.2105 - val_accuracy: 0.5358\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.56698\n",
            "Epoch 70/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.5326 - accuracy: 0.4710 - val_loss: 1.4898 - val_accuracy: 0.5109\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.56698\n",
            "Epoch 71/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.5094 - accuracy: 0.5000 - val_loss: 1.2302 - val_accuracy: 0.5452\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.56698\n",
            "Epoch 72/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.3813 - accuracy: 0.4645 - val_loss: 1.1512 - val_accuracy: 0.5763\n",
            "\n",
            "Epoch 00072: val_accuracy improved from 0.56698 to 0.57632, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 73/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.3314 - accuracy: 0.5037 - val_loss: 1.1903 - val_accuracy: 0.5421\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.57632\n",
            "Epoch 74/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.2679 - accuracy: 0.5233 - val_loss: 1.2316 - val_accuracy: 0.5047\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.57632\n",
            "Epoch 75/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.2471 - accuracy: 0.5217 - val_loss: 1.1559 - val_accuracy: 0.5358\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.57632\n",
            "Epoch 76/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.2814 - accuracy: 0.5021 - val_loss: 1.1083 - val_accuracy: 0.5421\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.57632\n",
            "Epoch 77/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.1925 - accuracy: 0.5282 - val_loss: 1.0861 - val_accuracy: 0.5732\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.57632\n",
            "Epoch 78/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 1.1951 - accuracy: 0.5242 - val_loss: 1.2405 - val_accuracy: 0.5358\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.57632\n",
            "Epoch 79/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 1.1419 - accuracy: 0.5599 - val_loss: 1.5932 - val_accuracy: 0.4143\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.57632\n",
            "Epoch 80/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 1.2431 - accuracy: 0.5470 - val_loss: 1.1405 - val_accuracy: 0.5545\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.57632\n",
            "Epoch 81/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.1945 - accuracy: 0.5553 - val_loss: 1.1016 - val_accuracy: 0.5514\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.57632\n",
            "Epoch 82/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.1031 - accuracy: 0.5458 - val_loss: 1.2210 - val_accuracy: 0.4984\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.57632\n",
            "Epoch 83/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.1148 - accuracy: 0.5427 - val_loss: 0.9835 - val_accuracy: 0.6106\n",
            "\n",
            "Epoch 00083: val_accuracy improved from 0.57632 to 0.61059, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 84/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.1275 - accuracy: 0.5340 - val_loss: 1.0074 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.61059\n",
            "Epoch 85/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 1.1405 - accuracy: 0.5561 - val_loss: 1.0751 - val_accuracy: 0.6012\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.61059\n",
            "Epoch 86/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.1091 - accuracy: 0.5305 - val_loss: 0.9900 - val_accuracy: 0.5919\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.61059\n",
            "Epoch 87/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.1071 - accuracy: 0.5490 - val_loss: 0.9549 - val_accuracy: 0.6106\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.61059\n",
            "Epoch 88/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.0695 - accuracy: 0.5646 - val_loss: 0.9900 - val_accuracy: 0.5857\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.61059\n",
            "Epoch 89/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.1180 - accuracy: 0.5524 - val_loss: 0.9390 - val_accuracy: 0.5732\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.61059\n",
            "Epoch 90/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.0608 - accuracy: 0.5663 - val_loss: 1.0241 - val_accuracy: 0.6012\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.61059\n",
            "Epoch 91/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.0413 - accuracy: 0.5632 - val_loss: 0.9516 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.61059\n",
            "Epoch 92/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.0560 - accuracy: 0.5761 - val_loss: 0.9913 - val_accuracy: 0.5701\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.61059\n",
            "Epoch 93/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.0424 - accuracy: 0.5488 - val_loss: 0.9684 - val_accuracy: 0.5826\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.61059\n",
            "Epoch 94/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.0351 - accuracy: 0.6007 - val_loss: 1.2554 - val_accuracy: 0.5732\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.61059\n",
            "Epoch 95/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.0651 - accuracy: 0.5888 - val_loss: 1.0742 - val_accuracy: 0.5670\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.61059\n",
            "Epoch 96/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.0554 - accuracy: 0.5825 - val_loss: 0.9485 - val_accuracy: 0.6106\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.61059\n",
            "Epoch 97/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.0243 - accuracy: 0.5511 - val_loss: 1.0066 - val_accuracy: 0.5981\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.61059\n",
            "Epoch 98/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.3081 - accuracy: 0.5280 - val_loss: 1.2381 - val_accuracy: 0.5576\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.61059\n",
            "Epoch 99/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.2347 - accuracy: 0.5569 - val_loss: 1.0392 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.61059\n",
            "Epoch 100/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.1764 - accuracy: 0.5440 - val_loss: 1.0115 - val_accuracy: 0.5701\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.61059\n",
            "Epoch 101/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.1197 - accuracy: 0.5698 - val_loss: 1.0108 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.61059\n",
            "Epoch 102/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 1.0545 - accuracy: 0.5734 - val_loss: 1.0066 - val_accuracy: 0.5919\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.61059\n",
            "Epoch 103/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.1119 - accuracy: 0.5489 - val_loss: 0.9148 - val_accuracy: 0.6262\n",
            "\n",
            "Epoch 00103: val_accuracy improved from 0.61059 to 0.62617, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 104/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.0861 - accuracy: 0.5639 - val_loss: 0.9138 - val_accuracy: 0.5857\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 0.62617\n",
            "Epoch 105/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.0703 - accuracy: 0.5556 - val_loss: 0.9347 - val_accuracy: 0.5919\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.62617\n",
            "Epoch 106/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.0297 - accuracy: 0.5624 - val_loss: 0.9852 - val_accuracy: 0.6012\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.62617\n",
            "Epoch 107/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.0200 - accuracy: 0.6027 - val_loss: 0.9152 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.62617\n",
            "Epoch 108/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.9849 - accuracy: 0.5869 - val_loss: 0.8948 - val_accuracy: 0.6449\n",
            "\n",
            "Epoch 00108: val_accuracy improved from 0.62617 to 0.64486, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 109/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.9670 - accuracy: 0.6072 - val_loss: 1.0151 - val_accuracy: 0.5888\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.64486\n",
            "Epoch 110/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.9553 - accuracy: 0.5860 - val_loss: 1.0896 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.64486\n",
            "Epoch 111/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.9357 - accuracy: 0.6053 - val_loss: 0.9639 - val_accuracy: 0.6044\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 0.64486\n",
            "Epoch 112/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.9982 - accuracy: 0.5907 - val_loss: 0.9812 - val_accuracy: 0.5919\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.64486\n",
            "Epoch 113/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.0099 - accuracy: 0.5636 - val_loss: 0.9046 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00113: val_accuracy did not improve from 0.64486\n",
            "Epoch 114/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 1.0023 - accuracy: 0.5582 - val_loss: 0.9622 - val_accuracy: 0.6511\n",
            "\n",
            "Epoch 00114: val_accuracy improved from 0.64486 to 0.65109, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 115/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.9395 - accuracy: 0.5799 - val_loss: 0.9534 - val_accuracy: 0.6044\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.65109\n",
            "Epoch 116/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.8986 - accuracy: 0.6062 - val_loss: 0.9112 - val_accuracy: 0.6168\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.65109\n",
            "Epoch 117/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.9794 - accuracy: 0.6082 - val_loss: 1.0300 - val_accuracy: 0.5763\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.65109\n",
            "Epoch 118/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.9066 - accuracy: 0.6056 - val_loss: 0.8824 - val_accuracy: 0.6324\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.65109\n",
            "Epoch 119/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.9522 - accuracy: 0.5877 - val_loss: 0.9013 - val_accuracy: 0.6293\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.65109\n",
            "Epoch 120/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.9176 - accuracy: 0.6010 - val_loss: 0.8409 - val_accuracy: 0.6573\n",
            "\n",
            "Epoch 00120: val_accuracy improved from 0.65109 to 0.65732, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 121/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.8980 - accuracy: 0.6285 - val_loss: 0.9828 - val_accuracy: 0.6386\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.65732\n",
            "Epoch 122/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.9271 - accuracy: 0.5865 - val_loss: 1.1433 - val_accuracy: 0.5919\n",
            "\n",
            "Epoch 00122: val_accuracy did not improve from 0.65732\n",
            "Epoch 123/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.9468 - accuracy: 0.6148 - val_loss: 0.9177 - val_accuracy: 0.6324\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.65732\n",
            "Epoch 124/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.8921 - accuracy: 0.6271 - val_loss: 0.8617 - val_accuracy: 0.6199\n",
            "\n",
            "Epoch 00124: val_accuracy did not improve from 0.65732\n",
            "Epoch 125/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.9488 - accuracy: 0.6189 - val_loss: 0.7856 - val_accuracy: 0.6449\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.65732\n",
            "Epoch 126/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.8502 - accuracy: 0.5895 - val_loss: 0.8075 - val_accuracy: 0.6355\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.65732\n",
            "Epoch 127/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.8609 - accuracy: 0.6267 - val_loss: 0.8811 - val_accuracy: 0.6231\n",
            "\n",
            "Epoch 00127: val_accuracy did not improve from 0.65732\n",
            "Epoch 128/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.8976 - accuracy: 0.6158 - val_loss: 0.8558 - val_accuracy: 0.6417\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.65732\n",
            "Epoch 129/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.9388 - accuracy: 0.6102 - val_loss: 0.7889 - val_accuracy: 0.6604\n",
            "\n",
            "Epoch 00129: val_accuracy improved from 0.65732 to 0.66044, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 130/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 1.0207 - accuracy: 0.5674 - val_loss: 0.8506 - val_accuracy: 0.6386\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.66044\n",
            "Epoch 131/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.8562 - accuracy: 0.6474 - val_loss: 0.8387 - val_accuracy: 0.6293\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.66044\n",
            "Epoch 132/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.8861 - accuracy: 0.6292 - val_loss: 0.8252 - val_accuracy: 0.6916\n",
            "\n",
            "Epoch 00132: val_accuracy improved from 0.66044 to 0.69159, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 133/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.8676 - accuracy: 0.6308 - val_loss: 0.8835 - val_accuracy: 0.6168\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.69159\n",
            "Epoch 134/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.8947 - accuracy: 0.6304 - val_loss: 0.7647 - val_accuracy: 0.6480\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.69159\n",
            "Epoch 135/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.8556 - accuracy: 0.6289 - val_loss: 0.7798 - val_accuracy: 0.6667\n",
            "\n",
            "Epoch 00135: val_accuracy did not improve from 0.69159\n",
            "Epoch 136/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 1.0074 - accuracy: 0.5972 - val_loss: 1.0090 - val_accuracy: 0.6542\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.69159\n",
            "Epoch 137/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.9761 - accuracy: 0.5957 - val_loss: 0.8307 - val_accuracy: 0.6449\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 0.69159\n",
            "Epoch 138/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.9206 - accuracy: 0.6143 - val_loss: 0.8153 - val_accuracy: 0.6698\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.69159\n",
            "Epoch 139/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.9296 - accuracy: 0.6238 - val_loss: 0.8335 - val_accuracy: 0.6916\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.69159\n",
            "Epoch 140/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.9094 - accuracy: 0.6054 - val_loss: 0.8007 - val_accuracy: 0.6667\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.69159\n",
            "Epoch 141/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.8662 - accuracy: 0.6146 - val_loss: 0.7654 - val_accuracy: 0.6978\n",
            "\n",
            "Epoch 00141: val_accuracy improved from 0.69159 to 0.69782, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 142/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.8293 - accuracy: 0.6464 - val_loss: 0.7167 - val_accuracy: 0.6916\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.69782\n",
            "Epoch 143/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.8653 - accuracy: 0.6444 - val_loss: 0.8073 - val_accuracy: 0.6729\n",
            "\n",
            "Epoch 00143: val_accuracy did not improve from 0.69782\n",
            "Epoch 144/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.8764 - accuracy: 0.6234 - val_loss: 0.8906 - val_accuracy: 0.6791\n",
            "\n",
            "Epoch 00144: val_accuracy did not improve from 0.69782\n",
            "Epoch 145/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.8132 - accuracy: 0.6603 - val_loss: 0.8585 - val_accuracy: 0.6978\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.69782\n",
            "Epoch 146/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.8098 - accuracy: 0.6533 - val_loss: 0.8807 - val_accuracy: 0.6480\n",
            "\n",
            "Epoch 00146: val_accuracy did not improve from 0.69782\n",
            "Epoch 147/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.8340 - accuracy: 0.6243 - val_loss: 0.8141 - val_accuracy: 0.6885\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.69782\n",
            "Epoch 148/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.7703 - accuracy: 0.6600 - val_loss: 1.0181 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00148: val_accuracy did not improve from 0.69782\n",
            "Epoch 149/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.8384 - accuracy: 0.6531 - val_loss: 0.8998 - val_accuracy: 0.6386\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.69782\n",
            "Epoch 150/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.8824 - accuracy: 0.6301 - val_loss: 0.7203 - val_accuracy: 0.7259\n",
            "\n",
            "Epoch 00150: val_accuracy improved from 0.69782 to 0.72586, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 151/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.8123 - accuracy: 0.6411 - val_loss: 0.7507 - val_accuracy: 0.6916\n",
            "\n",
            "Epoch 00151: val_accuracy did not improve from 0.72586\n",
            "Epoch 152/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.8612 - accuracy: 0.6370 - val_loss: 0.9439 - val_accuracy: 0.7009\n",
            "\n",
            "Epoch 00152: val_accuracy did not improve from 0.72586\n",
            "Epoch 153/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.9197 - accuracy: 0.6209 - val_loss: 0.9124 - val_accuracy: 0.6573\n",
            "\n",
            "Epoch 00153: val_accuracy did not improve from 0.72586\n",
            "Epoch 154/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.8940 - accuracy: 0.6343 - val_loss: 0.7966 - val_accuracy: 0.6636\n",
            "\n",
            "Epoch 00154: val_accuracy did not improve from 0.72586\n",
            "Epoch 155/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.7926 - accuracy: 0.6636 - val_loss: 0.7344 - val_accuracy: 0.7134\n",
            "\n",
            "Epoch 00155: val_accuracy did not improve from 0.72586\n",
            "Epoch 156/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.7905 - accuracy: 0.6571 - val_loss: 0.6957 - val_accuracy: 0.7227\n",
            "\n",
            "Epoch 00156: val_accuracy did not improve from 0.72586\n",
            "Epoch 157/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.7940 - accuracy: 0.6482 - val_loss: 0.7243 - val_accuracy: 0.6885\n",
            "\n",
            "Epoch 00157: val_accuracy did not improve from 0.72586\n",
            "Epoch 158/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.8403 - accuracy: 0.6332 - val_loss: 0.9524 - val_accuracy: 0.6355\n",
            "\n",
            "Epoch 00158: val_accuracy did not improve from 0.72586\n",
            "Epoch 159/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.9517 - accuracy: 0.6353 - val_loss: 0.9221 - val_accuracy: 0.6947\n",
            "\n",
            "Epoch 00159: val_accuracy did not improve from 0.72586\n",
            "Epoch 160/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.9429 - accuracy: 0.6123 - val_loss: 0.8419 - val_accuracy: 0.6822\n",
            "\n",
            "Epoch 00160: val_accuracy did not improve from 0.72586\n",
            "Epoch 161/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.9588 - accuracy: 0.6254 - val_loss: 1.0719 - val_accuracy: 0.6199\n",
            "\n",
            "Epoch 00161: val_accuracy did not improve from 0.72586\n",
            "Epoch 162/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.9885 - accuracy: 0.6160 - val_loss: 0.8686 - val_accuracy: 0.6542\n",
            "\n",
            "Epoch 00162: val_accuracy did not improve from 0.72586\n",
            "Epoch 163/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.8807 - accuracy: 0.5985 - val_loss: 0.8503 - val_accuracy: 0.6542\n",
            "\n",
            "Epoch 00163: val_accuracy did not improve from 0.72586\n",
            "Epoch 164/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.8701 - accuracy: 0.6366 - val_loss: 0.7691 - val_accuracy: 0.6760\n",
            "\n",
            "Epoch 00164: val_accuracy did not improve from 0.72586\n",
            "Epoch 165/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.8272 - accuracy: 0.6465 - val_loss: 0.7522 - val_accuracy: 0.6947\n",
            "\n",
            "Epoch 00165: val_accuracy did not improve from 0.72586\n",
            "Epoch 166/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.7782 - accuracy: 0.6721 - val_loss: 0.7250 - val_accuracy: 0.6885\n",
            "\n",
            "Epoch 00166: val_accuracy did not improve from 0.72586\n",
            "Epoch 167/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.7371 - accuracy: 0.6961 - val_loss: 0.7151 - val_accuracy: 0.6760\n",
            "\n",
            "Epoch 00167: val_accuracy did not improve from 0.72586\n",
            "Epoch 168/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.7294 - accuracy: 0.6961 - val_loss: 0.8996 - val_accuracy: 0.6417\n",
            "\n",
            "Epoch 00168: val_accuracy did not improve from 0.72586\n",
            "Epoch 169/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.9271 - accuracy: 0.6167 - val_loss: 0.9250 - val_accuracy: 0.6511\n",
            "\n",
            "Epoch 00169: val_accuracy did not improve from 0.72586\n",
            "Epoch 170/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.8303 - accuracy: 0.6592 - val_loss: 0.8225 - val_accuracy: 0.6636\n",
            "\n",
            "Epoch 00170: val_accuracy did not improve from 0.72586\n",
            "Epoch 171/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.7874 - accuracy: 0.6789 - val_loss: 0.8313 - val_accuracy: 0.6760\n",
            "\n",
            "Epoch 00171: val_accuracy did not improve from 0.72586\n",
            "Epoch 172/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.7249 - accuracy: 0.7115 - val_loss: 0.7650 - val_accuracy: 0.6604\n",
            "\n",
            "Epoch 00172: val_accuracy did not improve from 0.72586\n",
            "Epoch 173/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.7534 - accuracy: 0.6486 - val_loss: 0.8107 - val_accuracy: 0.6480\n",
            "\n",
            "Epoch 00173: val_accuracy did not improve from 0.72586\n",
            "Epoch 174/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.7568 - accuracy: 0.6732 - val_loss: 0.7735 - val_accuracy: 0.6791\n",
            "\n",
            "Epoch 00174: val_accuracy did not improve from 0.72586\n",
            "Epoch 175/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.7685 - accuracy: 0.6724 - val_loss: 0.7001 - val_accuracy: 0.6916\n",
            "\n",
            "Epoch 00175: val_accuracy did not improve from 0.72586\n",
            "Epoch 176/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.7196 - accuracy: 0.6965 - val_loss: 0.7749 - val_accuracy: 0.6854\n",
            "\n",
            "Epoch 00176: val_accuracy did not improve from 0.72586\n",
            "Epoch 177/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.7463 - accuracy: 0.6564 - val_loss: 0.8383 - val_accuracy: 0.6667\n",
            "\n",
            "Epoch 00177: val_accuracy did not improve from 0.72586\n",
            "Epoch 178/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.7509 - accuracy: 0.6680 - val_loss: 0.6597 - val_accuracy: 0.6822\n",
            "\n",
            "Epoch 00178: val_accuracy did not improve from 0.72586\n",
            "Epoch 179/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.6851 - accuracy: 0.6692 - val_loss: 0.6991 - val_accuracy: 0.6978\n",
            "\n",
            "Epoch 00179: val_accuracy did not improve from 0.72586\n",
            "Epoch 180/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.6876 - accuracy: 0.6681 - val_loss: 0.8318 - val_accuracy: 0.6604\n",
            "\n",
            "Epoch 00180: val_accuracy did not improve from 0.72586\n",
            "Epoch 181/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.7499 - accuracy: 0.6895 - val_loss: 0.8550 - val_accuracy: 0.6636\n",
            "\n",
            "Epoch 00181: val_accuracy did not improve from 0.72586\n",
            "Epoch 182/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.7600 - accuracy: 0.6636 - val_loss: 0.6954 - val_accuracy: 0.6947\n",
            "\n",
            "Epoch 00182: val_accuracy did not improve from 0.72586\n",
            "Epoch 183/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.7622 - accuracy: 0.6748 - val_loss: 0.6961 - val_accuracy: 0.6947\n",
            "\n",
            "Epoch 00183: val_accuracy did not improve from 0.72586\n",
            "Epoch 184/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.6951 - accuracy: 0.6840 - val_loss: 0.8103 - val_accuracy: 0.6854\n",
            "\n",
            "Epoch 00184: val_accuracy did not improve from 0.72586\n",
            "Epoch 185/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.7330 - accuracy: 0.6668 - val_loss: 0.7262 - val_accuracy: 0.6978\n",
            "\n",
            "Epoch 00185: val_accuracy did not improve from 0.72586\n",
            "Epoch 186/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.6953 - accuracy: 0.7045 - val_loss: 0.7312 - val_accuracy: 0.6978\n",
            "\n",
            "Epoch 00186: val_accuracy did not improve from 0.72586\n",
            "Epoch 187/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.7778 - accuracy: 0.6621 - val_loss: 0.6523 - val_accuracy: 0.7134\n",
            "\n",
            "Epoch 00187: val_accuracy did not improve from 0.72586\n",
            "Epoch 188/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.6814 - accuracy: 0.7006 - val_loss: 0.7653 - val_accuracy: 0.7009\n",
            "\n",
            "Epoch 00188: val_accuracy did not improve from 0.72586\n",
            "Epoch 189/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.7175 - accuracy: 0.6961 - val_loss: 0.7330 - val_accuracy: 0.6760\n",
            "\n",
            "Epoch 00189: val_accuracy did not improve from 0.72586\n",
            "Epoch 190/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.7246 - accuracy: 0.6897 - val_loss: 0.8372 - val_accuracy: 0.6511\n",
            "\n",
            "Epoch 00190: val_accuracy did not improve from 0.72586\n",
            "Epoch 191/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.6879 - accuracy: 0.6958 - val_loss: 0.8074 - val_accuracy: 0.6822\n",
            "\n",
            "Epoch 00191: val_accuracy did not improve from 0.72586\n",
            "Epoch 192/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.6862 - accuracy: 0.6783 - val_loss: 0.7055 - val_accuracy: 0.6978\n",
            "\n",
            "Epoch 00192: val_accuracy did not improve from 0.72586\n",
            "Epoch 193/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.6685 - accuracy: 0.7111 - val_loss: 0.6637 - val_accuracy: 0.7009\n",
            "\n",
            "Epoch 00193: val_accuracy did not improve from 0.72586\n",
            "Epoch 194/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.7427 - accuracy: 0.6510 - val_loss: 0.8650 - val_accuracy: 0.6604\n",
            "\n",
            "Epoch 00194: val_accuracy did not improve from 0.72586\n",
            "Epoch 195/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.7016 - accuracy: 0.6868 - val_loss: 0.6923 - val_accuracy: 0.7009\n",
            "\n",
            "Epoch 00195: val_accuracy did not improve from 0.72586\n",
            "Epoch 196/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.7717 - accuracy: 0.7061 - val_loss: 0.7305 - val_accuracy: 0.7103\n",
            "\n",
            "Epoch 00196: val_accuracy did not improve from 0.72586\n",
            "Epoch 197/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.7349 - accuracy: 0.6931 - val_loss: 0.7766 - val_accuracy: 0.6822\n",
            "\n",
            "Epoch 00197: val_accuracy did not improve from 0.72586\n",
            "Epoch 198/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.7164 - accuracy: 0.7230 - val_loss: 0.6891 - val_accuracy: 0.7040\n",
            "\n",
            "Epoch 00198: val_accuracy did not improve from 0.72586\n",
            "Epoch 199/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.6787 - accuracy: 0.6865 - val_loss: 0.6888 - val_accuracy: 0.7040\n",
            "\n",
            "Epoch 00199: val_accuracy did not improve from 0.72586\n",
            "Epoch 200/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.6347 - accuracy: 0.7267 - val_loss: 0.7926 - val_accuracy: 0.7009\n",
            "\n",
            "Epoch 00200: val_accuracy did not improve from 0.72586\n",
            "Epoch 201/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.7247 - accuracy: 0.6735 - val_loss: 0.7816 - val_accuracy: 0.6916\n",
            "\n",
            "Epoch 00201: val_accuracy did not improve from 0.72586\n",
            "Epoch 202/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.6792 - accuracy: 0.7274 - val_loss: 0.7235 - val_accuracy: 0.6885\n",
            "\n",
            "Epoch 00202: val_accuracy did not improve from 0.72586\n",
            "Epoch 203/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.6937 - accuracy: 0.7032 - val_loss: 0.8507 - val_accuracy: 0.6791\n",
            "\n",
            "Epoch 00203: val_accuracy did not improve from 0.72586\n",
            "Epoch 204/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.8406 - accuracy: 0.6609 - val_loss: 0.8499 - val_accuracy: 0.6885\n",
            "\n",
            "Epoch 00204: val_accuracy did not improve from 0.72586\n",
            "Epoch 205/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.8131 - accuracy: 0.6894 - val_loss: 0.6942 - val_accuracy: 0.7072\n",
            "\n",
            "Epoch 00205: val_accuracy did not improve from 0.72586\n",
            "Epoch 206/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.7717 - accuracy: 0.6980 - val_loss: 0.7270 - val_accuracy: 0.7103\n",
            "\n",
            "Epoch 00206: val_accuracy did not improve from 0.72586\n",
            "Epoch 207/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.7986 - accuracy: 0.6920 - val_loss: 0.9560 - val_accuracy: 0.6667\n",
            "\n",
            "Epoch 00207: val_accuracy did not improve from 0.72586\n",
            "Epoch 208/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.8154 - accuracy: 0.6698 - val_loss: 0.7206 - val_accuracy: 0.7196\n",
            "\n",
            "Epoch 00208: val_accuracy did not improve from 0.72586\n",
            "Epoch 209/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.7501 - accuracy: 0.6903 - val_loss: 0.6715 - val_accuracy: 0.7227\n",
            "\n",
            "Epoch 00209: val_accuracy did not improve from 0.72586\n",
            "Epoch 210/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.7657 - accuracy: 0.6708 - val_loss: 0.8079 - val_accuracy: 0.7072\n",
            "\n",
            "Epoch 00210: val_accuracy did not improve from 0.72586\n",
            "Epoch 211/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.7358 - accuracy: 0.6783 - val_loss: 0.7356 - val_accuracy: 0.7134\n",
            "\n",
            "Epoch 00211: val_accuracy did not improve from 0.72586\n",
            "Epoch 212/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.7029 - accuracy: 0.6908 - val_loss: 0.8011 - val_accuracy: 0.7134\n",
            "\n",
            "Epoch 00212: val_accuracy did not improve from 0.72586\n",
            "Epoch 213/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.6627 - accuracy: 0.7348 - val_loss: 0.7260 - val_accuracy: 0.7134\n",
            "\n",
            "Epoch 00213: val_accuracy did not improve from 0.72586\n",
            "Epoch 214/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.7021 - accuracy: 0.7113 - val_loss: 0.7069 - val_accuracy: 0.7040\n",
            "\n",
            "Epoch 00214: val_accuracy did not improve from 0.72586\n",
            "Epoch 215/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.7129 - accuracy: 0.6955 - val_loss: 0.7790 - val_accuracy: 0.7009\n",
            "\n",
            "Epoch 00215: val_accuracy did not improve from 0.72586\n",
            "Epoch 216/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.6536 - accuracy: 0.7473 - val_loss: 0.6959 - val_accuracy: 0.7259\n",
            "\n",
            "Epoch 00216: val_accuracy did not improve from 0.72586\n",
            "Epoch 217/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.6119 - accuracy: 0.7300 - val_loss: 0.6795 - val_accuracy: 0.7259\n",
            "\n",
            "Epoch 00217: val_accuracy did not improve from 0.72586\n",
            "Epoch 218/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.6290 - accuracy: 0.7110 - val_loss: 0.6772 - val_accuracy: 0.7352\n",
            "\n",
            "Epoch 00218: val_accuracy improved from 0.72586 to 0.73520, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 219/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.5983 - accuracy: 0.7054 - val_loss: 0.7100 - val_accuracy: 0.7072\n",
            "\n",
            "Epoch 00219: val_accuracy did not improve from 0.73520\n",
            "Epoch 220/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.5943 - accuracy: 0.7370 - val_loss: 0.7049 - val_accuracy: 0.6947\n",
            "\n",
            "Epoch 00220: val_accuracy did not improve from 0.73520\n",
            "Epoch 221/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.6409 - accuracy: 0.7230 - val_loss: 0.8498 - val_accuracy: 0.6916\n",
            "\n",
            "Epoch 00221: val_accuracy did not improve from 0.73520\n",
            "Epoch 222/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.7067 - accuracy: 0.7323 - val_loss: 0.6804 - val_accuracy: 0.7134\n",
            "\n",
            "Epoch 00222: val_accuracy did not improve from 0.73520\n",
            "Epoch 223/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.6682 - accuracy: 0.7143 - val_loss: 0.6662 - val_accuracy: 0.7259\n",
            "\n",
            "Epoch 00223: val_accuracy did not improve from 0.73520\n",
            "Epoch 224/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.6466 - accuracy: 0.7278 - val_loss: 0.6346 - val_accuracy: 0.7414\n",
            "\n",
            "Epoch 00224: val_accuracy improved from 0.73520 to 0.74143, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 225/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.6158 - accuracy: 0.7167 - val_loss: 0.7746 - val_accuracy: 0.6978\n",
            "\n",
            "Epoch 00225: val_accuracy did not improve from 0.74143\n",
            "Epoch 226/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.6323 - accuracy: 0.7358 - val_loss: 0.6240 - val_accuracy: 0.7227\n",
            "\n",
            "Epoch 00226: val_accuracy did not improve from 0.74143\n",
            "Epoch 227/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.5614 - accuracy: 0.7237 - val_loss: 0.6807 - val_accuracy: 0.7227\n",
            "\n",
            "Epoch 00227: val_accuracy did not improve from 0.74143\n",
            "Epoch 228/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.5751 - accuracy: 0.7294 - val_loss: 0.7264 - val_accuracy: 0.7445\n",
            "\n",
            "Epoch 00228: val_accuracy improved from 0.74143 to 0.74455, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 229/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.6925 - accuracy: 0.7189 - val_loss: 0.7343 - val_accuracy: 0.7352\n",
            "\n",
            "Epoch 00229: val_accuracy did not improve from 0.74455\n",
            "Epoch 230/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.6018 - accuracy: 0.7301 - val_loss: 0.5965 - val_accuracy: 0.7259\n",
            "\n",
            "Epoch 00230: val_accuracy did not improve from 0.74455\n",
            "Epoch 231/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.6089 - accuracy: 0.7248 - val_loss: 0.6472 - val_accuracy: 0.7227\n",
            "\n",
            "Epoch 00231: val_accuracy did not improve from 0.74455\n",
            "Epoch 232/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.6454 - accuracy: 0.7342 - val_loss: 0.8390 - val_accuracy: 0.6854\n",
            "\n",
            "Epoch 00232: val_accuracy did not improve from 0.74455\n",
            "Epoch 233/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.6465 - accuracy: 0.7270 - val_loss: 0.8044 - val_accuracy: 0.6916\n",
            "\n",
            "Epoch 00233: val_accuracy did not improve from 0.74455\n",
            "Epoch 234/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.6567 - accuracy: 0.7433 - val_loss: 0.6928 - val_accuracy: 0.7290\n",
            "\n",
            "Epoch 00234: val_accuracy did not improve from 0.74455\n",
            "Epoch 235/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.6710 - accuracy: 0.7367 - val_loss: 0.9156 - val_accuracy: 0.6698\n",
            "\n",
            "Epoch 00235: val_accuracy did not improve from 0.74455\n",
            "Epoch 236/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.9066 - accuracy: 0.6538 - val_loss: 0.7377 - val_accuracy: 0.6978\n",
            "\n",
            "Epoch 00236: val_accuracy did not improve from 0.74455\n",
            "Epoch 237/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.6997 - accuracy: 0.7201 - val_loss: 0.6814 - val_accuracy: 0.7632\n",
            "\n",
            "Epoch 00237: val_accuracy improved from 0.74455 to 0.76324, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 238/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.6295 - accuracy: 0.7641 - val_loss: 0.6545 - val_accuracy: 0.7321\n",
            "\n",
            "Epoch 00238: val_accuracy did not improve from 0.76324\n",
            "Epoch 239/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.6297 - accuracy: 0.7210 - val_loss: 0.7396 - val_accuracy: 0.7165\n",
            "\n",
            "Epoch 00239: val_accuracy did not improve from 0.76324\n",
            "Epoch 240/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.6307 - accuracy: 0.7479 - val_loss: 0.6739 - val_accuracy: 0.7134\n",
            "\n",
            "Epoch 00240: val_accuracy did not improve from 0.76324\n",
            "Epoch 241/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.6340 - accuracy: 0.7350 - val_loss: 0.7346 - val_accuracy: 0.7134\n",
            "\n",
            "Epoch 00241: val_accuracy did not improve from 0.76324\n",
            "Epoch 242/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.6578 - accuracy: 0.7298 - val_loss: 0.8070 - val_accuracy: 0.7383\n",
            "\n",
            "Epoch 00242: val_accuracy did not improve from 0.76324\n",
            "Epoch 243/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.5770 - accuracy: 0.7504 - val_loss: 0.7292 - val_accuracy: 0.7414\n",
            "\n",
            "Epoch 00243: val_accuracy did not improve from 0.76324\n",
            "Epoch 244/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.5312 - accuracy: 0.7586 - val_loss: 0.7808 - val_accuracy: 0.7290\n",
            "\n",
            "Epoch 00244: val_accuracy did not improve from 0.76324\n",
            "Epoch 245/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.5928 - accuracy: 0.7355 - val_loss: 0.6999 - val_accuracy: 0.7321\n",
            "\n",
            "Epoch 00245: val_accuracy did not improve from 0.76324\n",
            "Epoch 246/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.6266 - accuracy: 0.7476 - val_loss: 0.9954 - val_accuracy: 0.6760\n",
            "\n",
            "Epoch 00246: val_accuracy did not improve from 0.76324\n",
            "Epoch 247/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.6220 - accuracy: 0.7435 - val_loss: 0.9053 - val_accuracy: 0.7009\n",
            "\n",
            "Epoch 00247: val_accuracy did not improve from 0.76324\n",
            "Epoch 248/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.5573 - accuracy: 0.7433 - val_loss: 0.9927 - val_accuracy: 0.7072\n",
            "\n",
            "Epoch 00248: val_accuracy did not improve from 0.76324\n",
            "Epoch 249/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.6736 - accuracy: 0.7286 - val_loss: 0.8245 - val_accuracy: 0.7383\n",
            "\n",
            "Epoch 00249: val_accuracy did not improve from 0.76324\n",
            "Epoch 250/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.7209 - accuracy: 0.7398 - val_loss: 0.7409 - val_accuracy: 0.7352\n",
            "\n",
            "Epoch 00250: val_accuracy did not improve from 0.76324\n",
            "Epoch 251/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.6682 - accuracy: 0.7565 - val_loss: 0.6199 - val_accuracy: 0.7290\n",
            "\n",
            "Epoch 00251: val_accuracy did not improve from 0.76324\n",
            "Epoch 252/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.6389 - accuracy: 0.7198 - val_loss: 0.7022 - val_accuracy: 0.7290\n",
            "\n",
            "Epoch 00252: val_accuracy did not improve from 0.76324\n",
            "Epoch 253/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.6039 - accuracy: 0.7564 - val_loss: 0.9288 - val_accuracy: 0.6854\n",
            "\n",
            "Epoch 00253: val_accuracy did not improve from 0.76324\n",
            "Epoch 254/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.6009 - accuracy: 0.7386 - val_loss: 0.8191 - val_accuracy: 0.6822\n",
            "\n",
            "Epoch 00254: val_accuracy did not improve from 0.76324\n",
            "Epoch 255/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.6485 - accuracy: 0.7230 - val_loss: 0.7988 - val_accuracy: 0.7009\n",
            "\n",
            "Epoch 00255: val_accuracy did not improve from 0.76324\n",
            "Epoch 256/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.6062 - accuracy: 0.7272 - val_loss: 0.7347 - val_accuracy: 0.7196\n",
            "\n",
            "Epoch 00256: val_accuracy did not improve from 0.76324\n",
            "Epoch 257/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.6202 - accuracy: 0.7301 - val_loss: 0.9868 - val_accuracy: 0.6822\n",
            "\n",
            "Epoch 00257: val_accuracy did not improve from 0.76324\n",
            "Epoch 258/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.5763 - accuracy: 0.7196 - val_loss: 0.9218 - val_accuracy: 0.7072\n",
            "\n",
            "Epoch 00258: val_accuracy did not improve from 0.76324\n",
            "Epoch 259/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.6430 - accuracy: 0.7342 - val_loss: 0.6401 - val_accuracy: 0.7227\n",
            "\n",
            "Epoch 00259: val_accuracy did not improve from 0.76324\n",
            "Epoch 260/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.7348 - accuracy: 0.7090 - val_loss: 0.7933 - val_accuracy: 0.7040\n",
            "\n",
            "Epoch 00260: val_accuracy did not improve from 0.76324\n",
            "Epoch 261/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.7121 - accuracy: 0.7255 - val_loss: 0.6759 - val_accuracy: 0.7321\n",
            "\n",
            "Epoch 00261: val_accuracy did not improve from 0.76324\n",
            "Epoch 262/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.6814 - accuracy: 0.7329 - val_loss: 0.6487 - val_accuracy: 0.7477\n",
            "\n",
            "Epoch 00262: val_accuracy did not improve from 0.76324\n",
            "Epoch 263/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.6137 - accuracy: 0.7436 - val_loss: 0.6732 - val_accuracy: 0.7477\n",
            "\n",
            "Epoch 00263: val_accuracy did not improve from 0.76324\n",
            "Epoch 264/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.6360 - accuracy: 0.7591 - val_loss: 0.6659 - val_accuracy: 0.7383\n",
            "\n",
            "Epoch 00264: val_accuracy did not improve from 0.76324\n",
            "Epoch 265/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.5937 - accuracy: 0.7366 - val_loss: 0.6014 - val_accuracy: 0.7508\n",
            "\n",
            "Epoch 00265: val_accuracy did not improve from 0.76324\n",
            "Epoch 266/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.5993 - accuracy: 0.7597 - val_loss: 0.6661 - val_accuracy: 0.7664\n",
            "\n",
            "Epoch 00266: val_accuracy improved from 0.76324 to 0.76636, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 267/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.7433 - accuracy: 0.7228 - val_loss: 0.6609 - val_accuracy: 0.7632\n",
            "\n",
            "Epoch 00267: val_accuracy did not improve from 0.76636\n",
            "Epoch 268/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.6338 - accuracy: 0.7444 - val_loss: 0.7091 - val_accuracy: 0.7601\n",
            "\n",
            "Epoch 00268: val_accuracy did not improve from 0.76636\n",
            "Epoch 269/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.6315 - accuracy: 0.7227 - val_loss: 0.6593 - val_accuracy: 0.7259\n",
            "\n",
            "Epoch 00269: val_accuracy did not improve from 0.76636\n",
            "Epoch 270/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.6214 - accuracy: 0.7401 - val_loss: 0.6391 - val_accuracy: 0.7539\n",
            "\n",
            "Epoch 00270: val_accuracy did not improve from 0.76636\n",
            "Epoch 271/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.6391 - accuracy: 0.7288 - val_loss: 0.8130 - val_accuracy: 0.7539\n",
            "\n",
            "Epoch 00271: val_accuracy did not improve from 0.76636\n",
            "Epoch 272/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.6230 - accuracy: 0.7664 - val_loss: 0.7489 - val_accuracy: 0.7477\n",
            "\n",
            "Epoch 00272: val_accuracy did not improve from 0.76636\n",
            "Epoch 273/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.6178 - accuracy: 0.7437 - val_loss: 0.6356 - val_accuracy: 0.7539\n",
            "\n",
            "Epoch 00273: val_accuracy did not improve from 0.76636\n",
            "Epoch 274/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.5586 - accuracy: 0.7460 - val_loss: 0.7549 - val_accuracy: 0.7290\n",
            "\n",
            "Epoch 00274: val_accuracy did not improve from 0.76636\n",
            "Epoch 275/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.5623 - accuracy: 0.7549 - val_loss: 0.7048 - val_accuracy: 0.7383\n",
            "\n",
            "Epoch 00275: val_accuracy did not improve from 0.76636\n",
            "Epoch 276/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.5774 - accuracy: 0.7585 - val_loss: 0.7291 - val_accuracy: 0.7477\n",
            "\n",
            "Epoch 00276: val_accuracy did not improve from 0.76636\n",
            "Epoch 277/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.5775 - accuracy: 0.7503 - val_loss: 0.7772 - val_accuracy: 0.7414\n",
            "\n",
            "Epoch 00277: val_accuracy did not improve from 0.76636\n",
            "Epoch 278/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.6337 - accuracy: 0.7278 - val_loss: 1.1475 - val_accuracy: 0.6293\n",
            "\n",
            "Epoch 00278: val_accuracy did not improve from 0.76636\n",
            "Epoch 279/1000\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.6146 - accuracy: 0.7427 - val_loss: 0.7911 - val_accuracy: 0.7445\n",
            "\n",
            "Epoch 00279: val_accuracy did not improve from 0.76636\n",
            "Epoch 280/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.5216 - accuracy: 0.7713 - val_loss: 0.6937 - val_accuracy: 0.7414\n",
            "\n",
            "Epoch 00280: val_accuracy did not improve from 0.76636\n",
            "Epoch 281/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.5474 - accuracy: 0.7528 - val_loss: 0.8857 - val_accuracy: 0.7040\n",
            "\n",
            "Epoch 00281: val_accuracy did not improve from 0.76636\n",
            "Epoch 282/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.5617 - accuracy: 0.7245 - val_loss: 0.7221 - val_accuracy: 0.7445\n",
            "\n",
            "Epoch 00282: val_accuracy did not improve from 0.76636\n",
            "Epoch 283/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.5958 - accuracy: 0.7634 - val_loss: 0.6698 - val_accuracy: 0.7383\n",
            "\n",
            "Epoch 00283: val_accuracy did not improve from 0.76636\n",
            "Epoch 284/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.5833 - accuracy: 0.7612 - val_loss: 0.6519 - val_accuracy: 0.7570\n",
            "\n",
            "Epoch 00284: val_accuracy did not improve from 0.76636\n",
            "Epoch 285/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.5623 - accuracy: 0.7338 - val_loss: 0.6513 - val_accuracy: 0.7539\n",
            "\n",
            "Epoch 00285: val_accuracy did not improve from 0.76636\n",
            "Epoch 286/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.5772 - accuracy: 0.7520 - val_loss: 0.6926 - val_accuracy: 0.7352\n",
            "\n",
            "Epoch 00286: val_accuracy did not improve from 0.76636\n",
            "Epoch 287/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.5354 - accuracy: 0.7686 - val_loss: 0.8038 - val_accuracy: 0.7227\n",
            "\n",
            "Epoch 00287: val_accuracy did not improve from 0.76636\n",
            "Epoch 288/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.5402 - accuracy: 0.7460 - val_loss: 0.7995 - val_accuracy: 0.7321\n",
            "\n",
            "Epoch 00288: val_accuracy did not improve from 0.76636\n",
            "Epoch 289/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.6442 - accuracy: 0.7131 - val_loss: 0.7365 - val_accuracy: 0.7445\n",
            "\n",
            "Epoch 00289: val_accuracy did not improve from 0.76636\n",
            "Epoch 290/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.6277 - accuracy: 0.7543 - val_loss: 0.8068 - val_accuracy: 0.7259\n",
            "\n",
            "Epoch 00290: val_accuracy did not improve from 0.76636\n",
            "Epoch 291/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.6770 - accuracy: 0.7280 - val_loss: 0.7102 - val_accuracy: 0.7570\n",
            "\n",
            "Epoch 00291: val_accuracy did not improve from 0.76636\n",
            "Epoch 292/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.7153 - accuracy: 0.7240 - val_loss: 0.7085 - val_accuracy: 0.7477\n",
            "\n",
            "Epoch 00292: val_accuracy did not improve from 0.76636\n",
            "Epoch 293/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.6242 - accuracy: 0.7540 - val_loss: 0.7235 - val_accuracy: 0.7321\n",
            "\n",
            "Epoch 00293: val_accuracy did not improve from 0.76636\n",
            "Epoch 294/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.6699 - accuracy: 0.7620 - val_loss: 0.6889 - val_accuracy: 0.7352\n",
            "\n",
            "Epoch 00294: val_accuracy did not improve from 0.76636\n",
            "Epoch 295/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.6670 - accuracy: 0.7246 - val_loss: 0.6993 - val_accuracy: 0.7290\n",
            "\n",
            "Epoch 00295: val_accuracy did not improve from 0.76636\n",
            "Epoch 296/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.5649 - accuracy: 0.7718 - val_loss: 0.6984 - val_accuracy: 0.7508\n",
            "\n",
            "Epoch 00296: val_accuracy did not improve from 0.76636\n",
            "Epoch 297/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.5205 - accuracy: 0.7571 - val_loss: 0.8082 - val_accuracy: 0.7165\n",
            "\n",
            "Epoch 00297: val_accuracy did not improve from 0.76636\n",
            "Epoch 298/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.5334 - accuracy: 0.7575 - val_loss: 0.7032 - val_accuracy: 0.7539\n",
            "\n",
            "Epoch 00298: val_accuracy did not improve from 0.76636\n",
            "Epoch 299/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.5463 - accuracy: 0.7480 - val_loss: 0.6348 - val_accuracy: 0.7601\n",
            "\n",
            "Epoch 00299: val_accuracy did not improve from 0.76636\n",
            "Epoch 300/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.5561 - accuracy: 0.7605 - val_loss: 0.7691 - val_accuracy: 0.7414\n",
            "\n",
            "Epoch 00300: val_accuracy did not improve from 0.76636\n",
            "Epoch 301/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4981 - accuracy: 0.7754 - val_loss: 0.7861 - val_accuracy: 0.7290\n",
            "\n",
            "Epoch 00301: val_accuracy did not improve from 0.76636\n",
            "Epoch 302/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.5955 - accuracy: 0.7574 - val_loss: 0.6549 - val_accuracy: 0.7477\n",
            "\n",
            "Epoch 00302: val_accuracy did not improve from 0.76636\n",
            "Epoch 303/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.5454 - accuracy: 0.7587 - val_loss: 0.6201 - val_accuracy: 0.7632\n",
            "\n",
            "Epoch 00303: val_accuracy did not improve from 0.76636\n",
            "Epoch 304/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.6168 - accuracy: 0.7545 - val_loss: 0.8662 - val_accuracy: 0.7383\n",
            "\n",
            "Epoch 00304: val_accuracy did not improve from 0.76636\n",
            "Epoch 305/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.8701 - accuracy: 0.7061 - val_loss: 0.7921 - val_accuracy: 0.7259\n",
            "\n",
            "Epoch 00305: val_accuracy did not improve from 0.76636\n",
            "Epoch 306/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.7802 - accuracy: 0.7069 - val_loss: 0.7532 - val_accuracy: 0.7383\n",
            "\n",
            "Epoch 00306: val_accuracy did not improve from 0.76636\n",
            "Epoch 307/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.6386 - accuracy: 0.7578 - val_loss: 0.8560 - val_accuracy: 0.7196\n",
            "\n",
            "Epoch 00307: val_accuracy did not improve from 0.76636\n",
            "Epoch 308/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.7204 - accuracy: 0.7286 - val_loss: 0.8030 - val_accuracy: 0.7352\n",
            "\n",
            "Epoch 00308: val_accuracy did not improve from 0.76636\n",
            "Epoch 309/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.6850 - accuracy: 0.7498 - val_loss: 0.6624 - val_accuracy: 0.7352\n",
            "\n",
            "Epoch 00309: val_accuracy did not improve from 0.76636\n",
            "Epoch 310/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.6713 - accuracy: 0.7200 - val_loss: 0.6852 - val_accuracy: 0.7165\n",
            "\n",
            "Epoch 00310: val_accuracy did not improve from 0.76636\n",
            "Epoch 311/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.6437 - accuracy: 0.7390 - val_loss: 0.7253 - val_accuracy: 0.7134\n",
            "\n",
            "Epoch 00311: val_accuracy did not improve from 0.76636\n",
            "Epoch 312/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.6146 - accuracy: 0.7565 - val_loss: 0.6939 - val_accuracy: 0.7290\n",
            "\n",
            "Epoch 00312: val_accuracy did not improve from 0.76636\n",
            "Epoch 313/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.6181 - accuracy: 0.7487 - val_loss: 0.7574 - val_accuracy: 0.7196\n",
            "\n",
            "Epoch 00313: val_accuracy did not improve from 0.76636\n",
            "Epoch 314/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.5840 - accuracy: 0.7505 - val_loss: 0.7372 - val_accuracy: 0.7290\n",
            "\n",
            "Epoch 00314: val_accuracy did not improve from 0.76636\n",
            "Epoch 315/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.5453 - accuracy: 0.7770 - val_loss: 0.6952 - val_accuracy: 0.7383\n",
            "\n",
            "Epoch 00315: val_accuracy did not improve from 0.76636\n",
            "Epoch 316/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.5676 - accuracy: 0.7485 - val_loss: 0.6953 - val_accuracy: 0.7445\n",
            "\n",
            "Epoch 00316: val_accuracy did not improve from 0.76636\n",
            "Epoch 317/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.5197 - accuracy: 0.7791 - val_loss: 0.7704 - val_accuracy: 0.7570\n",
            "\n",
            "Epoch 00317: val_accuracy did not improve from 0.76636\n",
            "Epoch 318/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.5684 - accuracy: 0.7583 - val_loss: 0.7685 - val_accuracy: 0.7290\n",
            "\n",
            "Epoch 00318: val_accuracy did not improve from 0.76636\n",
            "Epoch 319/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.5252 - accuracy: 0.7801 - val_loss: 0.7632 - val_accuracy: 0.7477\n",
            "\n",
            "Epoch 00319: val_accuracy did not improve from 0.76636\n",
            "Epoch 320/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.5168 - accuracy: 0.7827 - val_loss: 0.6826 - val_accuracy: 0.7664\n",
            "\n",
            "Epoch 00320: val_accuracy did not improve from 0.76636\n",
            "Epoch 321/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.5259 - accuracy: 0.7541 - val_loss: 0.6947 - val_accuracy: 0.7570\n",
            "\n",
            "Epoch 00321: val_accuracy did not improve from 0.76636\n",
            "Epoch 322/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.5652 - accuracy: 0.7691 - val_loss: 0.7715 - val_accuracy: 0.7539\n",
            "\n",
            "Epoch 00322: val_accuracy did not improve from 0.76636\n",
            "Epoch 323/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.5990 - accuracy: 0.7625 - val_loss: 0.7340 - val_accuracy: 0.7259\n",
            "\n",
            "Epoch 00323: val_accuracy did not improve from 0.76636\n",
            "Epoch 324/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.5538 - accuracy: 0.7665 - val_loss: 0.6750 - val_accuracy: 0.7695\n",
            "\n",
            "Epoch 00324: val_accuracy improved from 0.76636 to 0.76947, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 325/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.5531 - accuracy: 0.7590 - val_loss: 0.6984 - val_accuracy: 0.7072\n",
            "\n",
            "Epoch 00325: val_accuracy did not improve from 0.76947\n",
            "Epoch 326/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.5601 - accuracy: 0.7544 - val_loss: 0.6902 - val_accuracy: 0.7508\n",
            "\n",
            "Epoch 00326: val_accuracy did not improve from 0.76947\n",
            "Epoch 327/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.5802 - accuracy: 0.7749 - val_loss: 0.7302 - val_accuracy: 0.7445\n",
            "\n",
            "Epoch 00327: val_accuracy did not improve from 0.76947\n",
            "Epoch 328/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4925 - accuracy: 0.7943 - val_loss: 0.6204 - val_accuracy: 0.7601\n",
            "\n",
            "Epoch 00328: val_accuracy did not improve from 0.76947\n",
            "Epoch 329/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.5301 - accuracy: 0.7442 - val_loss: 0.6783 - val_accuracy: 0.7539\n",
            "\n",
            "Epoch 00329: val_accuracy did not improve from 0.76947\n",
            "Epoch 330/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4920 - accuracy: 0.7670 - val_loss: 0.5652 - val_accuracy: 0.7726\n",
            "\n",
            "Epoch 00330: val_accuracy improved from 0.76947 to 0.77259, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 331/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.5469 - accuracy: 0.7618 - val_loss: 0.6519 - val_accuracy: 0.7664\n",
            "\n",
            "Epoch 00331: val_accuracy did not improve from 0.77259\n",
            "Epoch 332/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.6024 - accuracy: 0.7586 - val_loss: 0.6199 - val_accuracy: 0.7477\n",
            "\n",
            "Epoch 00332: val_accuracy did not improve from 0.77259\n",
            "Epoch 333/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.5423 - accuracy: 0.7513 - val_loss: 0.7473 - val_accuracy: 0.7165\n",
            "\n",
            "Epoch 00333: val_accuracy did not improve from 0.77259\n",
            "Epoch 334/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.6011 - accuracy: 0.7618 - val_loss: 0.6551 - val_accuracy: 0.7477\n",
            "\n",
            "Epoch 00334: val_accuracy did not improve from 0.77259\n",
            "Epoch 335/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.5188 - accuracy: 0.7815 - val_loss: 0.6540 - val_accuracy: 0.7477\n",
            "\n",
            "Epoch 00335: val_accuracy did not improve from 0.77259\n",
            "Epoch 336/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.5210 - accuracy: 0.7378 - val_loss: 0.6913 - val_accuracy: 0.7321\n",
            "\n",
            "Epoch 00336: val_accuracy did not improve from 0.77259\n",
            "Epoch 337/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.5310 - accuracy: 0.7769 - val_loss: 0.6768 - val_accuracy: 0.7414\n",
            "\n",
            "Epoch 00337: val_accuracy did not improve from 0.77259\n",
            "Epoch 338/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.6275 - accuracy: 0.7317 - val_loss: 0.7413 - val_accuracy: 0.7539\n",
            "\n",
            "Epoch 00338: val_accuracy did not improve from 0.77259\n",
            "Epoch 339/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.4889 - accuracy: 0.7930 - val_loss: 0.7345 - val_accuracy: 0.7788\n",
            "\n",
            "Epoch 00339: val_accuracy improved from 0.77259 to 0.77882, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 340/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.5069 - accuracy: 0.7831 - val_loss: 0.6773 - val_accuracy: 0.7601\n",
            "\n",
            "Epoch 00340: val_accuracy did not improve from 0.77882\n",
            "Epoch 341/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4713 - accuracy: 0.7954 - val_loss: 0.7812 - val_accuracy: 0.7477\n",
            "\n",
            "Epoch 00341: val_accuracy did not improve from 0.77882\n",
            "Epoch 342/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.5197 - accuracy: 0.7969 - val_loss: 0.6992 - val_accuracy: 0.7601\n",
            "\n",
            "Epoch 00342: val_accuracy did not improve from 0.77882\n",
            "Epoch 343/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.5218 - accuracy: 0.7794 - val_loss: 0.7357 - val_accuracy: 0.7570\n",
            "\n",
            "Epoch 00343: val_accuracy did not improve from 0.77882\n",
            "Epoch 344/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.5477 - accuracy: 0.7534 - val_loss: 0.6392 - val_accuracy: 0.7477\n",
            "\n",
            "Epoch 00344: val_accuracy did not improve from 0.77882\n",
            "Epoch 345/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.5139 - accuracy: 0.7786 - val_loss: 0.7160 - val_accuracy: 0.7445\n",
            "\n",
            "Epoch 00345: val_accuracy did not improve from 0.77882\n",
            "Epoch 346/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.5619 - accuracy: 0.7693 - val_loss: 0.7955 - val_accuracy: 0.7570\n",
            "\n",
            "Epoch 00346: val_accuracy did not improve from 0.77882\n",
            "Epoch 347/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.5627 - accuracy: 0.7501 - val_loss: 0.6694 - val_accuracy: 0.7508\n",
            "\n",
            "Epoch 00347: val_accuracy did not improve from 0.77882\n",
            "Epoch 348/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.5349 - accuracy: 0.7825 - val_loss: 0.6733 - val_accuracy: 0.7601\n",
            "\n",
            "Epoch 00348: val_accuracy did not improve from 0.77882\n",
            "Epoch 349/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.5368 - accuracy: 0.7897 - val_loss: 0.7049 - val_accuracy: 0.7664\n",
            "\n",
            "Epoch 00349: val_accuracy did not improve from 0.77882\n",
            "Epoch 350/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.5496 - accuracy: 0.7775 - val_loss: 0.6754 - val_accuracy: 0.7664\n",
            "\n",
            "Epoch 00350: val_accuracy did not improve from 0.77882\n",
            "Epoch 351/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.5127 - accuracy: 0.7919 - val_loss: 0.7111 - val_accuracy: 0.7664\n",
            "\n",
            "Epoch 00351: val_accuracy did not improve from 0.77882\n",
            "Epoch 352/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.5644 - accuracy: 0.7770 - val_loss: 0.8323 - val_accuracy: 0.7477\n",
            "\n",
            "Epoch 00352: val_accuracy did not improve from 0.77882\n",
            "Epoch 353/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.6036 - accuracy: 0.7587 - val_loss: 0.7278 - val_accuracy: 0.7570\n",
            "\n",
            "Epoch 00353: val_accuracy did not improve from 0.77882\n",
            "Epoch 354/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.5449 - accuracy: 0.7757 - val_loss: 0.6356 - val_accuracy: 0.7726\n",
            "\n",
            "Epoch 00354: val_accuracy did not improve from 0.77882\n",
            "Epoch 355/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.5483 - accuracy: 0.7940 - val_loss: 0.7511 - val_accuracy: 0.7664\n",
            "\n",
            "Epoch 00355: val_accuracy did not improve from 0.77882\n",
            "Epoch 356/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.4860 - accuracy: 0.7894 - val_loss: 0.5879 - val_accuracy: 0.7819\n",
            "\n",
            "Epoch 00356: val_accuracy improved from 0.77882 to 0.78193, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 357/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.5163 - accuracy: 0.7954 - val_loss: 0.6377 - val_accuracy: 0.7913\n",
            "\n",
            "Epoch 00357: val_accuracy improved from 0.78193 to 0.79128, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 358/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.5309 - accuracy: 0.7752 - val_loss: 0.7296 - val_accuracy: 0.7695\n",
            "\n",
            "Epoch 00358: val_accuracy did not improve from 0.79128\n",
            "Epoch 359/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.7038 - accuracy: 0.7514 - val_loss: 0.7029 - val_accuracy: 0.7664\n",
            "\n",
            "Epoch 00359: val_accuracy did not improve from 0.79128\n",
            "Epoch 360/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.6870 - accuracy: 0.7789 - val_loss: 0.6816 - val_accuracy: 0.7726\n",
            "\n",
            "Epoch 00360: val_accuracy did not improve from 0.79128\n",
            "Epoch 361/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.6477 - accuracy: 0.7762 - val_loss: 0.7158 - val_accuracy: 0.7757\n",
            "\n",
            "Epoch 00361: val_accuracy did not improve from 0.79128\n",
            "Epoch 362/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.6266 - accuracy: 0.7661 - val_loss: 0.7380 - val_accuracy: 0.7757\n",
            "\n",
            "Epoch 00362: val_accuracy did not improve from 0.79128\n",
            "Epoch 363/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.6148 - accuracy: 0.7844 - val_loss: 0.7068 - val_accuracy: 0.7664\n",
            "\n",
            "Epoch 00363: val_accuracy did not improve from 0.79128\n",
            "Epoch 364/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.5426 - accuracy: 0.7815 - val_loss: 0.7753 - val_accuracy: 0.7726\n",
            "\n",
            "Epoch 00364: val_accuracy did not improve from 0.79128\n",
            "Epoch 365/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.5386 - accuracy: 0.7952 - val_loss: 0.7230 - val_accuracy: 0.7882\n",
            "\n",
            "Epoch 00365: val_accuracy did not improve from 0.79128\n",
            "Epoch 366/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.5606 - accuracy: 0.8073 - val_loss: 0.7350 - val_accuracy: 0.7664\n",
            "\n",
            "Epoch 00366: val_accuracy did not improve from 0.79128\n",
            "Epoch 367/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.5082 - accuracy: 0.8031 - val_loss: 0.7339 - val_accuracy: 0.7570\n",
            "\n",
            "Epoch 00367: val_accuracy did not improve from 0.79128\n",
            "Epoch 368/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.5943 - accuracy: 0.8102 - val_loss: 0.7177 - val_accuracy: 0.7508\n",
            "\n",
            "Epoch 00368: val_accuracy did not improve from 0.79128\n",
            "Epoch 369/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.6380 - accuracy: 0.7770 - val_loss: 0.6525 - val_accuracy: 0.7695\n",
            "\n",
            "Epoch 00369: val_accuracy did not improve from 0.79128\n",
            "Epoch 370/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.5436 - accuracy: 0.7922 - val_loss: 0.6503 - val_accuracy: 0.7819\n",
            "\n",
            "Epoch 00370: val_accuracy did not improve from 0.79128\n",
            "Epoch 371/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.5637 - accuracy: 0.7801 - val_loss: 0.6501 - val_accuracy: 0.7632\n",
            "\n",
            "Epoch 00371: val_accuracy did not improve from 0.79128\n",
            "Epoch 372/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.4931 - accuracy: 0.7980 - val_loss: 0.6755 - val_accuracy: 0.7913\n",
            "\n",
            "Epoch 00372: val_accuracy did not improve from 0.79128\n",
            "Epoch 373/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.5338 - accuracy: 0.8086 - val_loss: 0.6001 - val_accuracy: 0.7975\n",
            "\n",
            "Epoch 00373: val_accuracy improved from 0.79128 to 0.79751, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 374/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.5330 - accuracy: 0.8006 - val_loss: 0.6112 - val_accuracy: 0.7819\n",
            "\n",
            "Epoch 00374: val_accuracy did not improve from 0.79751\n",
            "Epoch 375/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.5054 - accuracy: 0.8026 - val_loss: 0.6296 - val_accuracy: 0.7882\n",
            "\n",
            "Epoch 00375: val_accuracy did not improve from 0.79751\n",
            "Epoch 376/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.5517 - accuracy: 0.8076 - val_loss: 0.7399 - val_accuracy: 0.7508\n",
            "\n",
            "Epoch 00376: val_accuracy did not improve from 0.79751\n",
            "Epoch 377/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.6056 - accuracy: 0.7900 - val_loss: 0.7221 - val_accuracy: 0.7664\n",
            "\n",
            "Epoch 00377: val_accuracy did not improve from 0.79751\n",
            "Epoch 378/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.5228 - accuracy: 0.8183 - val_loss: 0.6527 - val_accuracy: 0.7788\n",
            "\n",
            "Epoch 00378: val_accuracy did not improve from 0.79751\n",
            "Epoch 379/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.5479 - accuracy: 0.7694 - val_loss: 0.6534 - val_accuracy: 0.7726\n",
            "\n",
            "Epoch 00379: val_accuracy did not improve from 0.79751\n",
            "Epoch 380/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.5138 - accuracy: 0.8067 - val_loss: 0.6418 - val_accuracy: 0.7975\n",
            "\n",
            "Epoch 00380: val_accuracy did not improve from 0.79751\n",
            "Epoch 381/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.5319 - accuracy: 0.7839 - val_loss: 0.6084 - val_accuracy: 0.7882\n",
            "\n",
            "Epoch 00381: val_accuracy did not improve from 0.79751\n",
            "Epoch 382/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.5324 - accuracy: 0.8073 - val_loss: 0.6157 - val_accuracy: 0.7913\n",
            "\n",
            "Epoch 00382: val_accuracy did not improve from 0.79751\n",
            "Epoch 383/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4945 - accuracy: 0.8152 - val_loss: 0.6158 - val_accuracy: 0.7819\n",
            "\n",
            "Epoch 00383: val_accuracy did not improve from 0.79751\n",
            "Epoch 384/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.5012 - accuracy: 0.8094 - val_loss: 0.6029 - val_accuracy: 0.8006\n",
            "\n",
            "Epoch 00384: val_accuracy improved from 0.79751 to 0.80062, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 385/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.5441 - accuracy: 0.7666 - val_loss: 0.6423 - val_accuracy: 0.7819\n",
            "\n",
            "Epoch 00385: val_accuracy did not improve from 0.80062\n",
            "Epoch 386/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4544 - accuracy: 0.8275 - val_loss: 0.5866 - val_accuracy: 0.8193\n",
            "\n",
            "Epoch 00386: val_accuracy improved from 0.80062 to 0.81931, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 387/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.5080 - accuracy: 0.8012 - val_loss: 0.5884 - val_accuracy: 0.8162\n",
            "\n",
            "Epoch 00387: val_accuracy did not improve from 0.81931\n",
            "Epoch 388/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.5162 - accuracy: 0.7999 - val_loss: 0.8442 - val_accuracy: 0.7445\n",
            "\n",
            "Epoch 00388: val_accuracy did not improve from 0.81931\n",
            "Epoch 389/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.5046 - accuracy: 0.7848 - val_loss: 0.6197 - val_accuracy: 0.8069\n",
            "\n",
            "Epoch 00389: val_accuracy did not improve from 0.81931\n",
            "Epoch 390/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4571 - accuracy: 0.8192 - val_loss: 0.6305 - val_accuracy: 0.7975\n",
            "\n",
            "Epoch 00390: val_accuracy did not improve from 0.81931\n",
            "Epoch 391/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4499 - accuracy: 0.8146 - val_loss: 0.7248 - val_accuracy: 0.7695\n",
            "\n",
            "Epoch 00391: val_accuracy did not improve from 0.81931\n",
            "Epoch 392/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.4605 - accuracy: 0.8118 - val_loss: 0.6971 - val_accuracy: 0.8006\n",
            "\n",
            "Epoch 00392: val_accuracy did not improve from 0.81931\n",
            "Epoch 393/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.4313 - accuracy: 0.8279 - val_loss: 0.6440 - val_accuracy: 0.8006\n",
            "\n",
            "Epoch 00393: val_accuracy did not improve from 0.81931\n",
            "Epoch 394/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4375 - accuracy: 0.8097 - val_loss: 0.5797 - val_accuracy: 0.8069\n",
            "\n",
            "Epoch 00394: val_accuracy did not improve from 0.81931\n",
            "Epoch 395/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4338 - accuracy: 0.8332 - val_loss: 0.5949 - val_accuracy: 0.8006\n",
            "\n",
            "Epoch 00395: val_accuracy did not improve from 0.81931\n",
            "Epoch 396/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4448 - accuracy: 0.8113 - val_loss: 0.6493 - val_accuracy: 0.8006\n",
            "\n",
            "Epoch 00396: val_accuracy did not improve from 0.81931\n",
            "Epoch 397/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4946 - accuracy: 0.8024 - val_loss: 0.7404 - val_accuracy: 0.8037\n",
            "\n",
            "Epoch 00397: val_accuracy did not improve from 0.81931\n",
            "Epoch 398/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4271 - accuracy: 0.8403 - val_loss: 0.6421 - val_accuracy: 0.8162\n",
            "\n",
            "Epoch 00398: val_accuracy did not improve from 0.81931\n",
            "Epoch 399/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.5363 - accuracy: 0.7872 - val_loss: 0.6952 - val_accuracy: 0.7819\n",
            "\n",
            "Epoch 00399: val_accuracy did not improve from 0.81931\n",
            "Epoch 400/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4979 - accuracy: 0.8184 - val_loss: 0.6494 - val_accuracy: 0.7913\n",
            "\n",
            "Epoch 00400: val_accuracy did not improve from 0.81931\n",
            "Epoch 401/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.5094 - accuracy: 0.8050 - val_loss: 0.5824 - val_accuracy: 0.8069\n",
            "\n",
            "Epoch 00401: val_accuracy did not improve from 0.81931\n",
            "Epoch 402/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.4871 - accuracy: 0.8387 - val_loss: 0.5386 - val_accuracy: 0.8193\n",
            "\n",
            "Epoch 00402: val_accuracy did not improve from 0.81931\n",
            "Epoch 403/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.4594 - accuracy: 0.8224 - val_loss: 0.6453 - val_accuracy: 0.8037\n",
            "\n",
            "Epoch 00403: val_accuracy did not improve from 0.81931\n",
            "Epoch 404/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4695 - accuracy: 0.8101 - val_loss: 0.6573 - val_accuracy: 0.7975\n",
            "\n",
            "Epoch 00404: val_accuracy did not improve from 0.81931\n",
            "Epoch 405/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4248 - accuracy: 0.8245 - val_loss: 0.5870 - val_accuracy: 0.8069\n",
            "\n",
            "Epoch 00405: val_accuracy did not improve from 0.81931\n",
            "Epoch 406/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.5325 - accuracy: 0.8010 - val_loss: 0.5342 - val_accuracy: 0.8318\n",
            "\n",
            "Epoch 00406: val_accuracy improved from 0.81931 to 0.83178, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 407/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4629 - accuracy: 0.8305 - val_loss: 0.5542 - val_accuracy: 0.8131\n",
            "\n",
            "Epoch 00407: val_accuracy did not improve from 0.83178\n",
            "Epoch 408/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.5064 - accuracy: 0.8054 - val_loss: 0.6002 - val_accuracy: 0.8100\n",
            "\n",
            "Epoch 00408: val_accuracy did not improve from 0.83178\n",
            "Epoch 409/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.6128 - accuracy: 0.7910 - val_loss: 0.7992 - val_accuracy: 0.7664\n",
            "\n",
            "Epoch 00409: val_accuracy did not improve from 0.83178\n",
            "Epoch 410/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.5084 - accuracy: 0.8393 - val_loss: 0.5857 - val_accuracy: 0.8193\n",
            "\n",
            "Epoch 00410: val_accuracy did not improve from 0.83178\n",
            "Epoch 411/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.4901 - accuracy: 0.8227 - val_loss: 0.5698 - val_accuracy: 0.8069\n",
            "\n",
            "Epoch 00411: val_accuracy did not improve from 0.83178\n",
            "Epoch 412/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.4761 - accuracy: 0.8255 - val_loss: 0.6298 - val_accuracy: 0.8131\n",
            "\n",
            "Epoch 00412: val_accuracy did not improve from 0.83178\n",
            "Epoch 413/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.5950 - accuracy: 0.8111 - val_loss: 0.9485 - val_accuracy: 0.7570\n",
            "\n",
            "Epoch 00413: val_accuracy did not improve from 0.83178\n",
            "Epoch 414/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.6263 - accuracy: 0.8032 - val_loss: 0.6771 - val_accuracy: 0.8069\n",
            "\n",
            "Epoch 00414: val_accuracy did not improve from 0.83178\n",
            "Epoch 415/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.5248 - accuracy: 0.8120 - val_loss: 0.7176 - val_accuracy: 0.7975\n",
            "\n",
            "Epoch 00415: val_accuracy did not improve from 0.83178\n",
            "Epoch 416/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.5515 - accuracy: 0.8110 - val_loss: 0.7719 - val_accuracy: 0.7570\n",
            "\n",
            "Epoch 00416: val_accuracy did not improve from 0.83178\n",
            "Epoch 417/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.5878 - accuracy: 0.8045 - val_loss: 0.7716 - val_accuracy: 0.7850\n",
            "\n",
            "Epoch 00417: val_accuracy did not improve from 0.83178\n",
            "Epoch 418/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.6362 - accuracy: 0.8211 - val_loss: 0.7424 - val_accuracy: 0.8006\n",
            "\n",
            "Epoch 00418: val_accuracy did not improve from 0.83178\n",
            "Epoch 419/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.5450 - accuracy: 0.8285 - val_loss: 0.7086 - val_accuracy: 0.8100\n",
            "\n",
            "Epoch 00419: val_accuracy did not improve from 0.83178\n",
            "Epoch 420/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.5437 - accuracy: 0.7932 - val_loss: 0.7595 - val_accuracy: 0.8006\n",
            "\n",
            "Epoch 00420: val_accuracy did not improve from 0.83178\n",
            "Epoch 421/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.5820 - accuracy: 0.8023 - val_loss: 0.7485 - val_accuracy: 0.7975\n",
            "\n",
            "Epoch 00421: val_accuracy did not improve from 0.83178\n",
            "Epoch 422/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4750 - accuracy: 0.8376 - val_loss: 0.6793 - val_accuracy: 0.7850\n",
            "\n",
            "Epoch 00422: val_accuracy did not improve from 0.83178\n",
            "Epoch 423/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4642 - accuracy: 0.8443 - val_loss: 0.6271 - val_accuracy: 0.8224\n",
            "\n",
            "Epoch 00423: val_accuracy did not improve from 0.83178\n",
            "Epoch 424/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4835 - accuracy: 0.8332 - val_loss: 0.6479 - val_accuracy: 0.8069\n",
            "\n",
            "Epoch 00424: val_accuracy did not improve from 0.83178\n",
            "Epoch 425/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4994 - accuracy: 0.8266 - val_loss: 0.6550 - val_accuracy: 0.7882\n",
            "\n",
            "Epoch 00425: val_accuracy did not improve from 0.83178\n",
            "Epoch 426/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.5207 - accuracy: 0.8266 - val_loss: 0.6916 - val_accuracy: 0.7850\n",
            "\n",
            "Epoch 00426: val_accuracy did not improve from 0.83178\n",
            "Epoch 427/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4599 - accuracy: 0.8367 - val_loss: 0.6228 - val_accuracy: 0.8069\n",
            "\n",
            "Epoch 00427: val_accuracy did not improve from 0.83178\n",
            "Epoch 428/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.5044 - accuracy: 0.8457 - val_loss: 0.6560 - val_accuracy: 0.7975\n",
            "\n",
            "Epoch 00428: val_accuracy did not improve from 0.83178\n",
            "Epoch 429/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4472 - accuracy: 0.8333 - val_loss: 0.6729 - val_accuracy: 0.7944\n",
            "\n",
            "Epoch 00429: val_accuracy did not improve from 0.83178\n",
            "Epoch 430/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4150 - accuracy: 0.8308 - val_loss: 0.6897 - val_accuracy: 0.7850\n",
            "\n",
            "Epoch 00430: val_accuracy did not improve from 0.83178\n",
            "Epoch 431/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4859 - accuracy: 0.8212 - val_loss: 0.7044 - val_accuracy: 0.7819\n",
            "\n",
            "Epoch 00431: val_accuracy did not improve from 0.83178\n",
            "Epoch 432/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4254 - accuracy: 0.8427 - val_loss: 0.6595 - val_accuracy: 0.8069\n",
            "\n",
            "Epoch 00432: val_accuracy did not improve from 0.83178\n",
            "Epoch 433/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.4564 - accuracy: 0.8089 - val_loss: 0.7387 - val_accuracy: 0.7913\n",
            "\n",
            "Epoch 00433: val_accuracy did not improve from 0.83178\n",
            "Epoch 434/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4620 - accuracy: 0.8264 - val_loss: 0.6697 - val_accuracy: 0.7975\n",
            "\n",
            "Epoch 00434: val_accuracy did not improve from 0.83178\n",
            "Epoch 435/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4925 - accuracy: 0.8197 - val_loss: 0.8470 - val_accuracy: 0.7695\n",
            "\n",
            "Epoch 00435: val_accuracy did not improve from 0.83178\n",
            "Epoch 436/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4460 - accuracy: 0.8394 - val_loss: 0.6533 - val_accuracy: 0.8131\n",
            "\n",
            "Epoch 00436: val_accuracy did not improve from 0.83178\n",
            "Epoch 437/1000\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 0.4407 - accuracy: 0.8390 - val_loss: 0.6006 - val_accuracy: 0.8100\n",
            "\n",
            "Epoch 00437: val_accuracy did not improve from 0.83178\n",
            "Epoch 438/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.4661 - accuracy: 0.8353 - val_loss: 0.6599 - val_accuracy: 0.8006\n",
            "\n",
            "Epoch 00438: val_accuracy did not improve from 0.83178\n",
            "Epoch 439/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.4378 - accuracy: 0.8419 - val_loss: 0.7127 - val_accuracy: 0.7975\n",
            "\n",
            "Epoch 00439: val_accuracy did not improve from 0.83178\n",
            "Epoch 440/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3794 - accuracy: 0.8607 - val_loss: 0.6261 - val_accuracy: 0.8162\n",
            "\n",
            "Epoch 00440: val_accuracy did not improve from 0.83178\n",
            "Epoch 441/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3742 - accuracy: 0.8548 - val_loss: 0.6269 - val_accuracy: 0.8131\n",
            "\n",
            "Epoch 00441: val_accuracy did not improve from 0.83178\n",
            "Epoch 442/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4353 - accuracy: 0.8370 - val_loss: 0.6216 - val_accuracy: 0.8006\n",
            "\n",
            "Epoch 00442: val_accuracy did not improve from 0.83178\n",
            "Epoch 443/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.4421 - accuracy: 0.8392 - val_loss: 0.5751 - val_accuracy: 0.8287\n",
            "\n",
            "Epoch 00443: val_accuracy did not improve from 0.83178\n",
            "Epoch 444/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4202 - accuracy: 0.8588 - val_loss: 0.6498 - val_accuracy: 0.7975\n",
            "\n",
            "Epoch 00444: val_accuracy did not improve from 0.83178\n",
            "Epoch 445/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4329 - accuracy: 0.8363 - val_loss: 0.6232 - val_accuracy: 0.8162\n",
            "\n",
            "Epoch 00445: val_accuracy did not improve from 0.83178\n",
            "Epoch 446/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4192 - accuracy: 0.8456 - val_loss: 0.6220 - val_accuracy: 0.8100\n",
            "\n",
            "Epoch 00446: val_accuracy did not improve from 0.83178\n",
            "Epoch 447/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4144 - accuracy: 0.8400 - val_loss: 0.6427 - val_accuracy: 0.8131\n",
            "\n",
            "Epoch 00447: val_accuracy did not improve from 0.83178\n",
            "Epoch 448/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4257 - accuracy: 0.8462 - val_loss: 0.6940 - val_accuracy: 0.8131\n",
            "\n",
            "Epoch 00448: val_accuracy did not improve from 0.83178\n",
            "Epoch 449/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.5067 - accuracy: 0.8113 - val_loss: 0.5843 - val_accuracy: 0.7913\n",
            "\n",
            "Epoch 00449: val_accuracy did not improve from 0.83178\n",
            "Epoch 450/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4856 - accuracy: 0.8430 - val_loss: 0.6122 - val_accuracy: 0.8069\n",
            "\n",
            "Epoch 00450: val_accuracy did not improve from 0.83178\n",
            "Epoch 451/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4737 - accuracy: 0.8309 - val_loss: 0.5199 - val_accuracy: 0.8349\n",
            "\n",
            "Epoch 00451: val_accuracy improved from 0.83178 to 0.83489, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 452/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4075 - accuracy: 0.8614 - val_loss: 0.5522 - val_accuracy: 0.8380\n",
            "\n",
            "Epoch 00452: val_accuracy improved from 0.83489 to 0.83801, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 453/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3747 - accuracy: 0.8760 - val_loss: 0.5727 - val_accuracy: 0.8193\n",
            "\n",
            "Epoch 00453: val_accuracy did not improve from 0.83801\n",
            "Epoch 454/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3753 - accuracy: 0.8497 - val_loss: 0.5712 - val_accuracy: 0.8193\n",
            "\n",
            "Epoch 00454: val_accuracy did not improve from 0.83801\n",
            "Epoch 455/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3904 - accuracy: 0.8543 - val_loss: 0.5907 - val_accuracy: 0.8131\n",
            "\n",
            "Epoch 00455: val_accuracy did not improve from 0.83801\n",
            "Epoch 456/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4351 - accuracy: 0.8356 - val_loss: 0.6728 - val_accuracy: 0.8006\n",
            "\n",
            "Epoch 00456: val_accuracy did not improve from 0.83801\n",
            "Epoch 457/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4049 - accuracy: 0.8626 - val_loss: 0.6144 - val_accuracy: 0.8193\n",
            "\n",
            "Epoch 00457: val_accuracy did not improve from 0.83801\n",
            "Epoch 458/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.4207 - accuracy: 0.8445 - val_loss: 0.6715 - val_accuracy: 0.8037\n",
            "\n",
            "Epoch 00458: val_accuracy did not improve from 0.83801\n",
            "Epoch 459/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3670 - accuracy: 0.8763 - val_loss: 0.6084 - val_accuracy: 0.8287\n",
            "\n",
            "Epoch 00459: val_accuracy did not improve from 0.83801\n",
            "Epoch 460/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3660 - accuracy: 0.8633 - val_loss: 0.6897 - val_accuracy: 0.8224\n",
            "\n",
            "Epoch 00460: val_accuracy did not improve from 0.83801\n",
            "Epoch 461/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3695 - accuracy: 0.8553 - val_loss: 0.6731 - val_accuracy: 0.8255\n",
            "\n",
            "Epoch 00461: val_accuracy did not improve from 0.83801\n",
            "Epoch 462/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3795 - accuracy: 0.8510 - val_loss: 0.6373 - val_accuracy: 0.8162\n",
            "\n",
            "Epoch 00462: val_accuracy did not improve from 0.83801\n",
            "Epoch 463/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3956 - accuracy: 0.8365 - val_loss: 0.7738 - val_accuracy: 0.8162\n",
            "\n",
            "Epoch 00463: val_accuracy did not improve from 0.83801\n",
            "Epoch 464/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4963 - accuracy: 0.8333 - val_loss: 0.8323 - val_accuracy: 0.8006\n",
            "\n",
            "Epoch 00464: val_accuracy did not improve from 0.83801\n",
            "Epoch 465/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.5610 - accuracy: 0.8361 - val_loss: 0.7301 - val_accuracy: 0.8193\n",
            "\n",
            "Epoch 00465: val_accuracy did not improve from 0.83801\n",
            "Epoch 466/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.5432 - accuracy: 0.8415 - val_loss: 0.6880 - val_accuracy: 0.8131\n",
            "\n",
            "Epoch 00466: val_accuracy did not improve from 0.83801\n",
            "Epoch 467/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.5241 - accuracy: 0.8367 - val_loss: 0.6771 - val_accuracy: 0.8255\n",
            "\n",
            "Epoch 00467: val_accuracy did not improve from 0.83801\n",
            "Epoch 468/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.5211 - accuracy: 0.8524 - val_loss: 0.7025 - val_accuracy: 0.8037\n",
            "\n",
            "Epoch 00468: val_accuracy did not improve from 0.83801\n",
            "Epoch 469/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.5139 - accuracy: 0.8338 - val_loss: 0.6367 - val_accuracy: 0.8131\n",
            "\n",
            "Epoch 00469: val_accuracy did not improve from 0.83801\n",
            "Epoch 470/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.4733 - accuracy: 0.8615 - val_loss: 0.6255 - val_accuracy: 0.8193\n",
            "\n",
            "Epoch 00470: val_accuracy did not improve from 0.83801\n",
            "Epoch 471/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4391 - accuracy: 0.8630 - val_loss: 0.6316 - val_accuracy: 0.8193\n",
            "\n",
            "Epoch 00471: val_accuracy did not improve from 0.83801\n",
            "Epoch 472/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4270 - accuracy: 0.8568 - val_loss: 0.5962 - val_accuracy: 0.8224\n",
            "\n",
            "Epoch 00472: val_accuracy did not improve from 0.83801\n",
            "Epoch 473/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4690 - accuracy: 0.8370 - val_loss: 0.6069 - val_accuracy: 0.8193\n",
            "\n",
            "Epoch 00473: val_accuracy did not improve from 0.83801\n",
            "Epoch 474/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4744 - accuracy: 0.8316 - val_loss: 0.5667 - val_accuracy: 0.8255\n",
            "\n",
            "Epoch 00474: val_accuracy did not improve from 0.83801\n",
            "Epoch 475/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4410 - accuracy: 0.8549 - val_loss: 0.6218 - val_accuracy: 0.8380\n",
            "\n",
            "Epoch 00475: val_accuracy did not improve from 0.83801\n",
            "Epoch 476/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4131 - accuracy: 0.8589 - val_loss: 0.5808 - val_accuracy: 0.8131\n",
            "\n",
            "Epoch 00476: val_accuracy did not improve from 0.83801\n",
            "Epoch 477/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4845 - accuracy: 0.8396 - val_loss: 0.6981 - val_accuracy: 0.8162\n",
            "\n",
            "Epoch 00477: val_accuracy did not improve from 0.83801\n",
            "Epoch 478/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4462 - accuracy: 0.8706 - val_loss: 0.6087 - val_accuracy: 0.8287\n",
            "\n",
            "Epoch 00478: val_accuracy did not improve from 0.83801\n",
            "Epoch 479/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.4313 - accuracy: 0.8733 - val_loss: 0.6549 - val_accuracy: 0.8224\n",
            "\n",
            "Epoch 00479: val_accuracy did not improve from 0.83801\n",
            "Epoch 480/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3957 - accuracy: 0.8559 - val_loss: 0.6499 - val_accuracy: 0.8318\n",
            "\n",
            "Epoch 00480: val_accuracy did not improve from 0.83801\n",
            "Epoch 481/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3735 - accuracy: 0.8774 - val_loss: 0.5936 - val_accuracy: 0.8318\n",
            "\n",
            "Epoch 00481: val_accuracy did not improve from 0.83801\n",
            "Epoch 482/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4272 - accuracy: 0.8548 - val_loss: 0.6579 - val_accuracy: 0.8193\n",
            "\n",
            "Epoch 00482: val_accuracy did not improve from 0.83801\n",
            "Epoch 483/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3816 - accuracy: 0.8665 - val_loss: 0.6157 - val_accuracy: 0.8224\n",
            "\n",
            "Epoch 00483: val_accuracy did not improve from 0.83801\n",
            "Epoch 484/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3972 - accuracy: 0.8658 - val_loss: 0.6118 - val_accuracy: 0.8318\n",
            "\n",
            "Epoch 00484: val_accuracy did not improve from 0.83801\n",
            "Epoch 485/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3891 - accuracy: 0.8744 - val_loss: 0.6473 - val_accuracy: 0.8100\n",
            "\n",
            "Epoch 00485: val_accuracy did not improve from 0.83801\n",
            "Epoch 486/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3939 - accuracy: 0.8693 - val_loss: 0.7156 - val_accuracy: 0.8037\n",
            "\n",
            "Epoch 00486: val_accuracy did not improve from 0.83801\n",
            "Epoch 487/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3570 - accuracy: 0.8812 - val_loss: 0.7203 - val_accuracy: 0.8131\n",
            "\n",
            "Epoch 00487: val_accuracy did not improve from 0.83801\n",
            "Epoch 488/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.5387 - accuracy: 0.8314 - val_loss: 0.7087 - val_accuracy: 0.8131\n",
            "\n",
            "Epoch 00488: val_accuracy did not improve from 0.83801\n",
            "Epoch 489/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4038 - accuracy: 0.8763 - val_loss: 0.6560 - val_accuracy: 0.8069\n",
            "\n",
            "Epoch 00489: val_accuracy did not improve from 0.83801\n",
            "Epoch 490/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.5242 - accuracy: 0.8321 - val_loss: 0.6506 - val_accuracy: 0.8131\n",
            "\n",
            "Epoch 00490: val_accuracy did not improve from 0.83801\n",
            "Epoch 491/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3942 - accuracy: 0.8618 - val_loss: 0.6157 - val_accuracy: 0.8193\n",
            "\n",
            "Epoch 00491: val_accuracy did not improve from 0.83801\n",
            "Epoch 492/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4382 - accuracy: 0.8693 - val_loss: 0.7326 - val_accuracy: 0.8006\n",
            "\n",
            "Epoch 00492: val_accuracy did not improve from 0.83801\n",
            "Epoch 493/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3954 - accuracy: 0.8583 - val_loss: 0.5702 - val_accuracy: 0.8224\n",
            "\n",
            "Epoch 00493: val_accuracy did not improve from 0.83801\n",
            "Epoch 494/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.3580 - accuracy: 0.8713 - val_loss: 0.6166 - val_accuracy: 0.8069\n",
            "\n",
            "Epoch 00494: val_accuracy did not improve from 0.83801\n",
            "Epoch 495/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3461 - accuracy: 0.8808 - val_loss: 0.6310 - val_accuracy: 0.8100\n",
            "\n",
            "Epoch 00495: val_accuracy did not improve from 0.83801\n",
            "Epoch 496/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3813 - accuracy: 0.8562 - val_loss: 0.6398 - val_accuracy: 0.8255\n",
            "\n",
            "Epoch 00496: val_accuracy did not improve from 0.83801\n",
            "Epoch 497/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.5365 - accuracy: 0.8343 - val_loss: 0.7716 - val_accuracy: 0.7944\n",
            "\n",
            "Epoch 00497: val_accuracy did not improve from 0.83801\n",
            "Epoch 498/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.4806 - accuracy: 0.8471 - val_loss: 0.6973 - val_accuracy: 0.8100\n",
            "\n",
            "Epoch 00498: val_accuracy did not improve from 0.83801\n",
            "Epoch 499/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.5153 - accuracy: 0.8376 - val_loss: 0.6562 - val_accuracy: 0.8131\n",
            "\n",
            "Epoch 00499: val_accuracy did not improve from 0.83801\n",
            "Epoch 500/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4587 - accuracy: 0.8548 - val_loss: 0.6093 - val_accuracy: 0.8224\n",
            "\n",
            "Epoch 00500: val_accuracy did not improve from 0.83801\n",
            "Epoch 501/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4589 - accuracy: 0.8564 - val_loss: 0.6126 - val_accuracy: 0.8100\n",
            "\n",
            "Epoch 00501: val_accuracy did not improve from 0.83801\n",
            "Epoch 502/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4483 - accuracy: 0.8621 - val_loss: 0.6518 - val_accuracy: 0.8224\n",
            "\n",
            "Epoch 00502: val_accuracy did not improve from 0.83801\n",
            "Epoch 503/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3979 - accuracy: 0.8697 - val_loss: 0.5760 - val_accuracy: 0.8193\n",
            "\n",
            "Epoch 00503: val_accuracy did not improve from 0.83801\n",
            "Epoch 504/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3770 - accuracy: 0.8599 - val_loss: 0.6511 - val_accuracy: 0.8131\n",
            "\n",
            "Epoch 00504: val_accuracy did not improve from 0.83801\n",
            "Epoch 505/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3396 - accuracy: 0.8707 - val_loss: 0.6028 - val_accuracy: 0.8255\n",
            "\n",
            "Epoch 00505: val_accuracy did not improve from 0.83801\n",
            "Epoch 506/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3800 - accuracy: 0.8708 - val_loss: 0.6214 - val_accuracy: 0.8131\n",
            "\n",
            "Epoch 00506: val_accuracy did not improve from 0.83801\n",
            "Epoch 507/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3558 - accuracy: 0.8706 - val_loss: 0.6848 - val_accuracy: 0.8131\n",
            "\n",
            "Epoch 00507: val_accuracy did not improve from 0.83801\n",
            "Epoch 508/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4163 - accuracy: 0.8607 - val_loss: 0.7122 - val_accuracy: 0.8131\n",
            "\n",
            "Epoch 00508: val_accuracy did not improve from 0.83801\n",
            "Epoch 509/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.4239 - accuracy: 0.8315 - val_loss: 0.6801 - val_accuracy: 0.8162\n",
            "\n",
            "Epoch 00509: val_accuracy did not improve from 0.83801\n",
            "Epoch 510/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3869 - accuracy: 0.8797 - val_loss: 0.5933 - val_accuracy: 0.8287\n",
            "\n",
            "Epoch 00510: val_accuracy did not improve from 0.83801\n",
            "Epoch 511/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4101 - accuracy: 0.8586 - val_loss: 0.5749 - val_accuracy: 0.8131\n",
            "\n",
            "Epoch 00511: val_accuracy did not improve from 0.83801\n",
            "Epoch 512/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4574 - accuracy: 0.8494 - val_loss: 0.6808 - val_accuracy: 0.8193\n",
            "\n",
            "Epoch 00512: val_accuracy did not improve from 0.83801\n",
            "Epoch 513/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4099 - accuracy: 0.8616 - val_loss: 0.6189 - val_accuracy: 0.8349\n",
            "\n",
            "Epoch 00513: val_accuracy did not improve from 0.83801\n",
            "Epoch 514/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.4231 - accuracy: 0.8525 - val_loss: 0.6649 - val_accuracy: 0.8255\n",
            "\n",
            "Epoch 00514: val_accuracy did not improve from 0.83801\n",
            "Epoch 515/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4095 - accuracy: 0.8689 - val_loss: 0.6353 - val_accuracy: 0.8162\n",
            "\n",
            "Epoch 00515: val_accuracy did not improve from 0.83801\n",
            "Epoch 516/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3658 - accuracy: 0.8644 - val_loss: 0.6367 - val_accuracy: 0.8349\n",
            "\n",
            "Epoch 00516: val_accuracy did not improve from 0.83801\n",
            "Epoch 517/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3038 - accuracy: 0.8904 - val_loss: 0.6652 - val_accuracy: 0.8224\n",
            "\n",
            "Epoch 00517: val_accuracy did not improve from 0.83801\n",
            "Epoch 518/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.3918 - accuracy: 0.8602 - val_loss: 0.6613 - val_accuracy: 0.8255\n",
            "\n",
            "Epoch 00518: val_accuracy did not improve from 0.83801\n",
            "Epoch 519/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3997 - accuracy: 0.8567 - val_loss: 0.5932 - val_accuracy: 0.8255\n",
            "\n",
            "Epoch 00519: val_accuracy did not improve from 0.83801\n",
            "Epoch 520/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3412 - accuracy: 0.8763 - val_loss: 0.6224 - val_accuracy: 0.8318\n",
            "\n",
            "Epoch 00520: val_accuracy did not improve from 0.83801\n",
            "Epoch 521/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3909 - accuracy: 0.8578 - val_loss: 0.6266 - val_accuracy: 0.8287\n",
            "\n",
            "Epoch 00521: val_accuracy did not improve from 0.83801\n",
            "Epoch 522/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3991 - accuracy: 0.8763 - val_loss: 0.6059 - val_accuracy: 0.8318\n",
            "\n",
            "Epoch 00522: val_accuracy did not improve from 0.83801\n",
            "Epoch 523/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3562 - accuracy: 0.8693 - val_loss: 0.6430 - val_accuracy: 0.8193\n",
            "\n",
            "Epoch 00523: val_accuracy did not improve from 0.83801\n",
            "Epoch 524/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4851 - accuracy: 0.8484 - val_loss: 0.7553 - val_accuracy: 0.8100\n",
            "\n",
            "Epoch 00524: val_accuracy did not improve from 0.83801\n",
            "Epoch 525/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4417 - accuracy: 0.8624 - val_loss: 0.7160 - val_accuracy: 0.8162\n",
            "\n",
            "Epoch 00525: val_accuracy did not improve from 0.83801\n",
            "Epoch 526/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4040 - accuracy: 0.8571 - val_loss: 0.7039 - val_accuracy: 0.8037\n",
            "\n",
            "Epoch 00526: val_accuracy did not improve from 0.83801\n",
            "Epoch 527/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4228 - accuracy: 0.8604 - val_loss: 0.7204 - val_accuracy: 0.8100\n",
            "\n",
            "Epoch 00527: val_accuracy did not improve from 0.83801\n",
            "Epoch 528/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4653 - accuracy: 0.8580 - val_loss: 0.7016 - val_accuracy: 0.8069\n",
            "\n",
            "Epoch 00528: val_accuracy did not improve from 0.83801\n",
            "Epoch 529/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3838 - accuracy: 0.8654 - val_loss: 0.7185 - val_accuracy: 0.8131\n",
            "\n",
            "Epoch 00529: val_accuracy did not improve from 0.83801\n",
            "Epoch 530/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3790 - accuracy: 0.8728 - val_loss: 0.7276 - val_accuracy: 0.8037\n",
            "\n",
            "Epoch 00530: val_accuracy did not improve from 0.83801\n",
            "Epoch 531/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3613 - accuracy: 0.8678 - val_loss: 0.7394 - val_accuracy: 0.8069\n",
            "\n",
            "Epoch 00531: val_accuracy did not improve from 0.83801\n",
            "Epoch 532/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3150 - accuracy: 0.8836 - val_loss: 0.7550 - val_accuracy: 0.8224\n",
            "\n",
            "Epoch 00532: val_accuracy did not improve from 0.83801\n",
            "Epoch 533/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3818 - accuracy: 0.8687 - val_loss: 0.6991 - val_accuracy: 0.8162\n",
            "\n",
            "Epoch 00533: val_accuracy did not improve from 0.83801\n",
            "Epoch 534/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3913 - accuracy: 0.8768 - val_loss: 0.6213 - val_accuracy: 0.8255\n",
            "\n",
            "Epoch 00534: val_accuracy did not improve from 0.83801\n",
            "Epoch 535/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3329 - accuracy: 0.8812 - val_loss: 0.6511 - val_accuracy: 0.8287\n",
            "\n",
            "Epoch 00535: val_accuracy did not improve from 0.83801\n",
            "Epoch 536/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.3353 - accuracy: 0.8823 - val_loss: 0.6475 - val_accuracy: 0.8131\n",
            "\n",
            "Epoch 00536: val_accuracy did not improve from 0.83801\n",
            "Epoch 537/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3077 - accuracy: 0.8931 - val_loss: 0.7127 - val_accuracy: 0.8131\n",
            "\n",
            "Epoch 00537: val_accuracy did not improve from 0.83801\n",
            "Epoch 538/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3408 - accuracy: 0.8798 - val_loss: 0.7064 - val_accuracy: 0.8255\n",
            "\n",
            "Epoch 00538: val_accuracy did not improve from 0.83801\n",
            "Epoch 539/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3679 - accuracy: 0.8690 - val_loss: 0.7736 - val_accuracy: 0.8100\n",
            "\n",
            "Epoch 00539: val_accuracy did not improve from 0.83801\n",
            "Epoch 540/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3412 - accuracy: 0.8727 - val_loss: 0.6754 - val_accuracy: 0.8255\n",
            "\n",
            "Epoch 00540: val_accuracy did not improve from 0.83801\n",
            "Epoch 541/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3847 - accuracy: 0.8696 - val_loss: 0.8036 - val_accuracy: 0.7975\n",
            "\n",
            "Epoch 00541: val_accuracy did not improve from 0.83801\n",
            "Epoch 542/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4433 - accuracy: 0.8636 - val_loss: 0.7037 - val_accuracy: 0.8318\n",
            "\n",
            "Epoch 00542: val_accuracy did not improve from 0.83801\n",
            "Epoch 543/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4613 - accuracy: 0.8745 - val_loss: 0.8312 - val_accuracy: 0.8287\n",
            "\n",
            "Epoch 00543: val_accuracy did not improve from 0.83801\n",
            "Epoch 544/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3963 - accuracy: 0.8767 - val_loss: 0.7700 - val_accuracy: 0.8255\n",
            "\n",
            "Epoch 00544: val_accuracy did not improve from 0.83801\n",
            "Epoch 545/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3580 - accuracy: 0.8764 - val_loss: 0.7485 - val_accuracy: 0.8442\n",
            "\n",
            "Epoch 00545: val_accuracy improved from 0.83801 to 0.84424, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 546/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.5120 - accuracy: 0.8390 - val_loss: 0.8895 - val_accuracy: 0.7850\n",
            "\n",
            "Epoch 00546: val_accuracy did not improve from 0.84424\n",
            "Epoch 547/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4907 - accuracy: 0.8627 - val_loss: 0.7104 - val_accuracy: 0.8255\n",
            "\n",
            "Epoch 00547: val_accuracy did not improve from 0.84424\n",
            "Epoch 548/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4731 - accuracy: 0.8631 - val_loss: 0.8645 - val_accuracy: 0.8193\n",
            "\n",
            "Epoch 00548: val_accuracy did not improve from 0.84424\n",
            "Epoch 549/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.6010 - accuracy: 0.8361 - val_loss: 0.7789 - val_accuracy: 0.8162\n",
            "\n",
            "Epoch 00549: val_accuracy did not improve from 0.84424\n",
            "Epoch 550/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.4934 - accuracy: 0.8531 - val_loss: 0.7045 - val_accuracy: 0.8131\n",
            "\n",
            "Epoch 00550: val_accuracy did not improve from 0.84424\n",
            "Epoch 551/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4441 - accuracy: 0.8690 - val_loss: 0.6979 - val_accuracy: 0.8287\n",
            "\n",
            "Epoch 00551: val_accuracy did not improve from 0.84424\n",
            "Epoch 552/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3974 - accuracy: 0.8764 - val_loss: 0.7609 - val_accuracy: 0.8037\n",
            "\n",
            "Epoch 00552: val_accuracy did not improve from 0.84424\n",
            "Epoch 553/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.4183 - accuracy: 0.8622 - val_loss: 0.7646 - val_accuracy: 0.8100\n",
            "\n",
            "Epoch 00553: val_accuracy did not improve from 0.84424\n",
            "Epoch 554/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.4373 - accuracy: 0.8508 - val_loss: 0.6954 - val_accuracy: 0.8193\n",
            "\n",
            "Epoch 00554: val_accuracy did not improve from 0.84424\n",
            "Epoch 555/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4172 - accuracy: 0.8593 - val_loss: 0.7216 - val_accuracy: 0.8193\n",
            "\n",
            "Epoch 00555: val_accuracy did not improve from 0.84424\n",
            "Epoch 556/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4096 - accuracy: 0.8629 - val_loss: 0.7263 - val_accuracy: 0.8100\n",
            "\n",
            "Epoch 00556: val_accuracy did not improve from 0.84424\n",
            "Epoch 557/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3723 - accuracy: 0.8666 - val_loss: 0.6802 - val_accuracy: 0.8255\n",
            "\n",
            "Epoch 00557: val_accuracy did not improve from 0.84424\n",
            "Epoch 558/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3572 - accuracy: 0.8842 - val_loss: 0.6238 - val_accuracy: 0.8411\n",
            "\n",
            "Epoch 00558: val_accuracy did not improve from 0.84424\n",
            "Epoch 559/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4373 - accuracy: 0.8597 - val_loss: 0.6460 - val_accuracy: 0.8318\n",
            "\n",
            "Epoch 00559: val_accuracy did not improve from 0.84424\n",
            "Epoch 560/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3420 - accuracy: 0.8896 - val_loss: 0.6668 - val_accuracy: 0.8255\n",
            "\n",
            "Epoch 00560: val_accuracy did not improve from 0.84424\n",
            "Epoch 561/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3608 - accuracy: 0.8845 - val_loss: 0.6752 - val_accuracy: 0.8349\n",
            "\n",
            "Epoch 00561: val_accuracy did not improve from 0.84424\n",
            "Epoch 562/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3387 - accuracy: 0.8885 - val_loss: 0.6601 - val_accuracy: 0.8349\n",
            "\n",
            "Epoch 00562: val_accuracy did not improve from 0.84424\n",
            "Epoch 563/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3626 - accuracy: 0.8958 - val_loss: 0.6745 - val_accuracy: 0.8287\n",
            "\n",
            "Epoch 00563: val_accuracy did not improve from 0.84424\n",
            "Epoch 564/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3601 - accuracy: 0.8891 - val_loss: 0.7026 - val_accuracy: 0.8224\n",
            "\n",
            "Epoch 00564: val_accuracy did not improve from 0.84424\n",
            "Epoch 565/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4420 - accuracy: 0.8751 - val_loss: 0.6884 - val_accuracy: 0.8349\n",
            "\n",
            "Epoch 00565: val_accuracy did not improve from 0.84424\n",
            "Epoch 566/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3729 - accuracy: 0.8584 - val_loss: 0.8273 - val_accuracy: 0.8162\n",
            "\n",
            "Epoch 00566: val_accuracy did not improve from 0.84424\n",
            "Epoch 567/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3974 - accuracy: 0.8626 - val_loss: 0.6523 - val_accuracy: 0.8287\n",
            "\n",
            "Epoch 00567: val_accuracy did not improve from 0.84424\n",
            "Epoch 568/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3978 - accuracy: 0.8606 - val_loss: 0.6821 - val_accuracy: 0.8224\n",
            "\n",
            "Epoch 00568: val_accuracy did not improve from 0.84424\n",
            "Epoch 569/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4020 - accuracy: 0.8621 - val_loss: 0.6634 - val_accuracy: 0.8255\n",
            "\n",
            "Epoch 00569: val_accuracy did not improve from 0.84424\n",
            "Epoch 570/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4369 - accuracy: 0.8684 - val_loss: 0.6963 - val_accuracy: 0.8287\n",
            "\n",
            "Epoch 00570: val_accuracy did not improve from 0.84424\n",
            "Epoch 571/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3814 - accuracy: 0.8755 - val_loss: 0.6401 - val_accuracy: 0.8318\n",
            "\n",
            "Epoch 00571: val_accuracy did not improve from 0.84424\n",
            "Epoch 572/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4398 - accuracy: 0.8756 - val_loss: 0.6511 - val_accuracy: 0.8255\n",
            "\n",
            "Epoch 00572: val_accuracy did not improve from 0.84424\n",
            "Epoch 573/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.5084 - accuracy: 0.8342 - val_loss: 0.7953 - val_accuracy: 0.8069\n",
            "\n",
            "Epoch 00573: val_accuracy did not improve from 0.84424\n",
            "Epoch 574/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.5419 - accuracy: 0.8508 - val_loss: 0.7545 - val_accuracy: 0.8287\n",
            "\n",
            "Epoch 00574: val_accuracy did not improve from 0.84424\n",
            "Epoch 575/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.4080 - accuracy: 0.8791 - val_loss: 0.7795 - val_accuracy: 0.8318\n",
            "\n",
            "Epoch 00575: val_accuracy did not improve from 0.84424\n",
            "Epoch 576/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.4356 - accuracy: 0.8599 - val_loss: 0.7055 - val_accuracy: 0.8318\n",
            "\n",
            "Epoch 00576: val_accuracy did not improve from 0.84424\n",
            "Epoch 577/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.4253 - accuracy: 0.8506 - val_loss: 0.7011 - val_accuracy: 0.8318\n",
            "\n",
            "Epoch 00577: val_accuracy did not improve from 0.84424\n",
            "Epoch 578/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.3859 - accuracy: 0.8719 - val_loss: 0.6586 - val_accuracy: 0.8287\n",
            "\n",
            "Epoch 00578: val_accuracy did not improve from 0.84424\n",
            "Epoch 579/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3561 - accuracy: 0.8928 - val_loss: 0.6499 - val_accuracy: 0.8287\n",
            "\n",
            "Epoch 00579: val_accuracy did not improve from 0.84424\n",
            "Epoch 580/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3334 - accuracy: 0.8873 - val_loss: 0.6534 - val_accuracy: 0.8287\n",
            "\n",
            "Epoch 00580: val_accuracy did not improve from 0.84424\n",
            "Epoch 581/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3071 - accuracy: 0.8850 - val_loss: 0.6703 - val_accuracy: 0.8318\n",
            "\n",
            "Epoch 00581: val_accuracy did not improve from 0.84424\n",
            "Epoch 582/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3123 - accuracy: 0.8818 - val_loss: 0.6185 - val_accuracy: 0.8380\n",
            "\n",
            "Epoch 00582: val_accuracy did not improve from 0.84424\n",
            "Epoch 583/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3036 - accuracy: 0.8875 - val_loss: 0.6277 - val_accuracy: 0.8287\n",
            "\n",
            "Epoch 00583: val_accuracy did not improve from 0.84424\n",
            "Epoch 584/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3261 - accuracy: 0.8789 - val_loss: 0.7074 - val_accuracy: 0.8318\n",
            "\n",
            "Epoch 00584: val_accuracy did not improve from 0.84424\n",
            "Epoch 585/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3826 - accuracy: 0.8697 - val_loss: 0.7817 - val_accuracy: 0.8349\n",
            "\n",
            "Epoch 00585: val_accuracy did not improve from 0.84424\n",
            "Epoch 586/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4258 - accuracy: 0.8808 - val_loss: 0.6692 - val_accuracy: 0.8255\n",
            "\n",
            "Epoch 00586: val_accuracy did not improve from 0.84424\n",
            "Epoch 587/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3481 - accuracy: 0.8858 - val_loss: 0.7276 - val_accuracy: 0.8224\n",
            "\n",
            "Epoch 00587: val_accuracy did not improve from 0.84424\n",
            "Epoch 588/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3407 - accuracy: 0.8800 - val_loss: 0.6338 - val_accuracy: 0.8380\n",
            "\n",
            "Epoch 00588: val_accuracy did not improve from 0.84424\n",
            "Epoch 589/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3738 - accuracy: 0.8744 - val_loss: 0.6899 - val_accuracy: 0.8193\n",
            "\n",
            "Epoch 00589: val_accuracy did not improve from 0.84424\n",
            "Epoch 590/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3109 - accuracy: 0.8814 - val_loss: 0.6390 - val_accuracy: 0.8224\n",
            "\n",
            "Epoch 00590: val_accuracy did not improve from 0.84424\n",
            "Epoch 591/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3397 - accuracy: 0.8766 - val_loss: 0.7145 - val_accuracy: 0.8224\n",
            "\n",
            "Epoch 00591: val_accuracy did not improve from 0.84424\n",
            "Epoch 592/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3468 - accuracy: 0.8696 - val_loss: 0.6583 - val_accuracy: 0.8255\n",
            "\n",
            "Epoch 00592: val_accuracy did not improve from 0.84424\n",
            "Epoch 593/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3156 - accuracy: 0.8968 - val_loss: 0.6423 - val_accuracy: 0.8318\n",
            "\n",
            "Epoch 00593: val_accuracy did not improve from 0.84424\n",
            "Epoch 594/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3180 - accuracy: 0.8833 - val_loss: 0.7461 - val_accuracy: 0.8255\n",
            "\n",
            "Epoch 00594: val_accuracy did not improve from 0.84424\n",
            "Epoch 595/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.2923 - accuracy: 0.8913 - val_loss: 0.7064 - val_accuracy: 0.8349\n",
            "\n",
            "Epoch 00595: val_accuracy did not improve from 0.84424\n",
            "Epoch 596/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2786 - accuracy: 0.8899 - val_loss: 0.7497 - val_accuracy: 0.8411\n",
            "\n",
            "Epoch 00596: val_accuracy did not improve from 0.84424\n",
            "Epoch 597/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3570 - accuracy: 0.8712 - val_loss: 0.7726 - val_accuracy: 0.8193\n",
            "\n",
            "Epoch 00597: val_accuracy did not improve from 0.84424\n",
            "Epoch 598/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3420 - accuracy: 0.8892 - val_loss: 0.7501 - val_accuracy: 0.8255\n",
            "\n",
            "Epoch 00598: val_accuracy did not improve from 0.84424\n",
            "Epoch 599/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3138 - accuracy: 0.8929 - val_loss: 0.6823 - val_accuracy: 0.8349\n",
            "\n",
            "Epoch 00599: val_accuracy did not improve from 0.84424\n",
            "Epoch 600/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.2980 - accuracy: 0.8971 - val_loss: 0.6251 - val_accuracy: 0.8411\n",
            "\n",
            "Epoch 00600: val_accuracy did not improve from 0.84424\n",
            "Epoch 601/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3539 - accuracy: 0.8852 - val_loss: 0.6125 - val_accuracy: 0.8442\n",
            "\n",
            "Epoch 00601: val_accuracy did not improve from 0.84424\n",
            "Epoch 602/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3230 - accuracy: 0.8914 - val_loss: 0.7190 - val_accuracy: 0.8505\n",
            "\n",
            "Epoch 00602: val_accuracy improved from 0.84424 to 0.85047, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 603/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3077 - accuracy: 0.8842 - val_loss: 0.7722 - val_accuracy: 0.8287\n",
            "\n",
            "Epoch 00603: val_accuracy did not improve from 0.85047\n",
            "Epoch 604/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2918 - accuracy: 0.8971 - val_loss: 0.7743 - val_accuracy: 0.8255\n",
            "\n",
            "Epoch 00604: val_accuracy did not improve from 0.85047\n",
            "Epoch 605/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3536 - accuracy: 0.8754 - val_loss: 0.7369 - val_accuracy: 0.8224\n",
            "\n",
            "Epoch 00605: val_accuracy did not improve from 0.85047\n",
            "Epoch 606/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3653 - accuracy: 0.8566 - val_loss: 0.6328 - val_accuracy: 0.8349\n",
            "\n",
            "Epoch 00606: val_accuracy did not improve from 0.85047\n",
            "Epoch 607/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3100 - accuracy: 0.9020 - val_loss: 0.5937 - val_accuracy: 0.8287\n",
            "\n",
            "Epoch 00607: val_accuracy did not improve from 0.85047\n",
            "Epoch 608/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3107 - accuracy: 0.8744 - val_loss: 0.6051 - val_accuracy: 0.8349\n",
            "\n",
            "Epoch 00608: val_accuracy did not improve from 0.85047\n",
            "Epoch 609/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.2807 - accuracy: 0.9029 - val_loss: 0.6708 - val_accuracy: 0.8318\n",
            "\n",
            "Epoch 00609: val_accuracy did not improve from 0.85047\n",
            "Epoch 610/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3062 - accuracy: 0.8881 - val_loss: 0.6331 - val_accuracy: 0.8255\n",
            "\n",
            "Epoch 00610: val_accuracy did not improve from 0.85047\n",
            "Epoch 611/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3843 - accuracy: 0.8706 - val_loss: 0.6588 - val_accuracy: 0.8287\n",
            "\n",
            "Epoch 00611: val_accuracy did not improve from 0.85047\n",
            "Epoch 612/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3720 - accuracy: 0.8836 - val_loss: 0.7484 - val_accuracy: 0.8255\n",
            "\n",
            "Epoch 00612: val_accuracy did not improve from 0.85047\n",
            "Epoch 613/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3464 - accuracy: 0.8893 - val_loss: 0.8214 - val_accuracy: 0.8006\n",
            "\n",
            "Epoch 00613: val_accuracy did not improve from 0.85047\n",
            "Epoch 614/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3801 - accuracy: 0.8891 - val_loss: 0.6180 - val_accuracy: 0.8287\n",
            "\n",
            "Epoch 00614: val_accuracy did not improve from 0.85047\n",
            "Epoch 615/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3363 - accuracy: 0.8912 - val_loss: 0.6812 - val_accuracy: 0.8193\n",
            "\n",
            "Epoch 00615: val_accuracy did not improve from 0.85047\n",
            "Epoch 616/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3300 - accuracy: 0.8936 - val_loss: 0.6459 - val_accuracy: 0.8349\n",
            "\n",
            "Epoch 00616: val_accuracy did not improve from 0.85047\n",
            "Epoch 617/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3391 - accuracy: 0.8861 - val_loss: 0.7494 - val_accuracy: 0.8193\n",
            "\n",
            "Epoch 00617: val_accuracy did not improve from 0.85047\n",
            "Epoch 618/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3261 - accuracy: 0.8893 - val_loss: 0.6841 - val_accuracy: 0.8349\n",
            "\n",
            "Epoch 00618: val_accuracy did not improve from 0.85047\n",
            "Epoch 619/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3029 - accuracy: 0.8902 - val_loss: 0.7338 - val_accuracy: 0.8318\n",
            "\n",
            "Epoch 00619: val_accuracy did not improve from 0.85047\n",
            "Epoch 620/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3110 - accuracy: 0.8845 - val_loss: 0.7327 - val_accuracy: 0.8224\n",
            "\n",
            "Epoch 00620: val_accuracy did not improve from 0.85047\n",
            "Epoch 621/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3208 - accuracy: 0.8852 - val_loss: 0.8043 - val_accuracy: 0.8162\n",
            "\n",
            "Epoch 00621: val_accuracy did not improve from 0.85047\n",
            "Epoch 622/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3508 - accuracy: 0.8707 - val_loss: 0.8106 - val_accuracy: 0.8287\n",
            "\n",
            "Epoch 00622: val_accuracy did not improve from 0.85047\n",
            "Epoch 623/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4959 - accuracy: 0.8653 - val_loss: 0.7783 - val_accuracy: 0.7882\n",
            "\n",
            "Epoch 00623: val_accuracy did not improve from 0.85047\n",
            "Epoch 624/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3863 - accuracy: 0.8740 - val_loss: 0.6918 - val_accuracy: 0.8100\n",
            "\n",
            "Epoch 00624: val_accuracy did not improve from 0.85047\n",
            "Epoch 625/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3874 - accuracy: 0.8707 - val_loss: 0.6725 - val_accuracy: 0.8193\n",
            "\n",
            "Epoch 00625: val_accuracy did not improve from 0.85047\n",
            "Epoch 626/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4088 - accuracy: 0.8686 - val_loss: 0.7602 - val_accuracy: 0.8193\n",
            "\n",
            "Epoch 00626: val_accuracy did not improve from 0.85047\n",
            "Epoch 627/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4032 - accuracy: 0.8789 - val_loss: 0.7536 - val_accuracy: 0.8162\n",
            "\n",
            "Epoch 00627: val_accuracy did not improve from 0.85047\n",
            "Epoch 628/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3746 - accuracy: 0.8691 - val_loss: 0.7419 - val_accuracy: 0.8037\n",
            "\n",
            "Epoch 00628: val_accuracy did not improve from 0.85047\n",
            "Epoch 629/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3623 - accuracy: 0.8826 - val_loss: 0.7358 - val_accuracy: 0.8131\n",
            "\n",
            "Epoch 00629: val_accuracy did not improve from 0.85047\n",
            "Epoch 630/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3421 - accuracy: 0.8893 - val_loss: 0.6299 - val_accuracy: 0.8224\n",
            "\n",
            "Epoch 00630: val_accuracy did not improve from 0.85047\n",
            "Epoch 631/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3597 - accuracy: 0.8776 - val_loss: 0.7117 - val_accuracy: 0.8193\n",
            "\n",
            "Epoch 00631: val_accuracy did not improve from 0.85047\n",
            "Epoch 632/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3426 - accuracy: 0.8653 - val_loss: 0.6381 - val_accuracy: 0.8349\n",
            "\n",
            "Epoch 00632: val_accuracy did not improve from 0.85047\n",
            "Epoch 633/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3389 - accuracy: 0.8820 - val_loss: 0.6730 - val_accuracy: 0.8131\n",
            "\n",
            "Epoch 00633: val_accuracy did not improve from 0.85047\n",
            "Epoch 634/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3415 - accuracy: 0.8755 - val_loss: 0.7004 - val_accuracy: 0.8006\n",
            "\n",
            "Epoch 00634: val_accuracy did not improve from 0.85047\n",
            "Epoch 635/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.4178 - accuracy: 0.8797 - val_loss: 0.6748 - val_accuracy: 0.8131\n",
            "\n",
            "Epoch 00635: val_accuracy did not improve from 0.85047\n",
            "Epoch 636/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3309 - accuracy: 0.8992 - val_loss: 0.6793 - val_accuracy: 0.8255\n",
            "\n",
            "Epoch 00636: val_accuracy did not improve from 0.85047\n",
            "Epoch 637/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3595 - accuracy: 0.8773 - val_loss: 0.7553 - val_accuracy: 0.8224\n",
            "\n",
            "Epoch 00637: val_accuracy did not improve from 0.85047\n",
            "Epoch 638/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3655 - accuracy: 0.8822 - val_loss: 0.7397 - val_accuracy: 0.8224\n",
            "\n",
            "Epoch 00638: val_accuracy did not improve from 0.85047\n",
            "Epoch 639/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3636 - accuracy: 0.8897 - val_loss: 0.6457 - val_accuracy: 0.8349\n",
            "\n",
            "Epoch 00639: val_accuracy did not improve from 0.85047\n",
            "Epoch 640/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4005 - accuracy: 0.9002 - val_loss: 0.7415 - val_accuracy: 0.8255\n",
            "\n",
            "Epoch 00640: val_accuracy did not improve from 0.85047\n",
            "Epoch 641/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4037 - accuracy: 0.8800 - val_loss: 0.7428 - val_accuracy: 0.8255\n",
            "\n",
            "Epoch 00641: val_accuracy did not improve from 0.85047\n",
            "Epoch 642/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3669 - accuracy: 0.8815 - val_loss: 0.7122 - val_accuracy: 0.8224\n",
            "\n",
            "Epoch 00642: val_accuracy did not improve from 0.85047\n",
            "Epoch 643/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3750 - accuracy: 0.8731 - val_loss: 0.6752 - val_accuracy: 0.8255\n",
            "\n",
            "Epoch 00643: val_accuracy did not improve from 0.85047\n",
            "Epoch 644/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3549 - accuracy: 0.8807 - val_loss: 0.6384 - val_accuracy: 0.8411\n",
            "\n",
            "Epoch 00644: val_accuracy did not improve from 0.85047\n",
            "Epoch 645/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.3887 - accuracy: 0.8610 - val_loss: 0.6943 - val_accuracy: 0.8380\n",
            "\n",
            "Epoch 00645: val_accuracy did not improve from 0.85047\n",
            "Epoch 646/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3086 - accuracy: 0.9035 - val_loss: 0.6598 - val_accuracy: 0.8442\n",
            "\n",
            "Epoch 00646: val_accuracy did not improve from 0.85047\n",
            "Epoch 647/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2952 - accuracy: 0.9001 - val_loss: 0.6874 - val_accuracy: 0.8349\n",
            "\n",
            "Epoch 00647: val_accuracy did not improve from 0.85047\n",
            "Epoch 648/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3115 - accuracy: 0.8729 - val_loss: 0.7213 - val_accuracy: 0.8318\n",
            "\n",
            "Epoch 00648: val_accuracy did not improve from 0.85047\n",
            "Epoch 649/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3534 - accuracy: 0.8811 - val_loss: 0.9009 - val_accuracy: 0.8037\n",
            "\n",
            "Epoch 00649: val_accuracy did not improve from 0.85047\n",
            "Epoch 650/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4094 - accuracy: 0.8549 - val_loss: 0.7954 - val_accuracy: 0.8069\n",
            "\n",
            "Epoch 00650: val_accuracy did not improve from 0.85047\n",
            "Epoch 651/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.4059 - accuracy: 0.8880 - val_loss: 0.7237 - val_accuracy: 0.8287\n",
            "\n",
            "Epoch 00651: val_accuracy did not improve from 0.85047\n",
            "Epoch 652/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3598 - accuracy: 0.8850 - val_loss: 0.7051 - val_accuracy: 0.8287\n",
            "\n",
            "Epoch 00652: val_accuracy did not improve from 0.85047\n",
            "Epoch 653/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3750 - accuracy: 0.8782 - val_loss: 0.7622 - val_accuracy: 0.8224\n",
            "\n",
            "Epoch 00653: val_accuracy did not improve from 0.85047\n",
            "Epoch 654/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4157 - accuracy: 0.8549 - val_loss: 0.7637 - val_accuracy: 0.8224\n",
            "\n",
            "Epoch 00654: val_accuracy did not improve from 0.85047\n",
            "Epoch 655/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3870 - accuracy: 0.8650 - val_loss: 0.6842 - val_accuracy: 0.8255\n",
            "\n",
            "Epoch 00655: val_accuracy did not improve from 0.85047\n",
            "Epoch 656/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3383 - accuracy: 0.8838 - val_loss: 0.6714 - val_accuracy: 0.8287\n",
            "\n",
            "Epoch 00656: val_accuracy did not improve from 0.85047\n",
            "Epoch 657/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3052 - accuracy: 0.8801 - val_loss: 0.7256 - val_accuracy: 0.8287\n",
            "\n",
            "Epoch 00657: val_accuracy did not improve from 0.85047\n",
            "Epoch 658/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3253 - accuracy: 0.8816 - val_loss: 0.6873 - val_accuracy: 0.8349\n",
            "\n",
            "Epoch 00658: val_accuracy did not improve from 0.85047\n",
            "Epoch 659/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.3241 - accuracy: 0.8989 - val_loss: 0.8284 - val_accuracy: 0.8100\n",
            "\n",
            "Epoch 00659: val_accuracy did not improve from 0.85047\n",
            "Epoch 660/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3138 - accuracy: 0.8924 - val_loss: 0.7552 - val_accuracy: 0.8224\n",
            "\n",
            "Epoch 00660: val_accuracy did not improve from 0.85047\n",
            "Epoch 661/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3601 - accuracy: 0.8776 - val_loss: 0.8049 - val_accuracy: 0.8069\n",
            "\n",
            "Epoch 00661: val_accuracy did not improve from 0.85047\n",
            "Epoch 662/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3889 - accuracy: 0.8708 - val_loss: 0.6486 - val_accuracy: 0.8255\n",
            "\n",
            "Epoch 00662: val_accuracy did not improve from 0.85047\n",
            "Epoch 663/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3553 - accuracy: 0.8753 - val_loss: 0.6254 - val_accuracy: 0.8318\n",
            "\n",
            "Epoch 00663: val_accuracy did not improve from 0.85047\n",
            "Epoch 664/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3814 - accuracy: 0.8578 - val_loss: 0.6276 - val_accuracy: 0.8380\n",
            "\n",
            "Epoch 00664: val_accuracy did not improve from 0.85047\n",
            "Epoch 665/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3544 - accuracy: 0.8981 - val_loss: 0.6148 - val_accuracy: 0.8411\n",
            "\n",
            "Epoch 00665: val_accuracy did not improve from 0.85047\n",
            "Epoch 666/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4014 - accuracy: 0.8684 - val_loss: 0.7237 - val_accuracy: 0.8131\n",
            "\n",
            "Epoch 00666: val_accuracy did not improve from 0.85047\n",
            "Epoch 667/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3904 - accuracy: 0.8572 - val_loss: 0.6505 - val_accuracy: 0.8349\n",
            "\n",
            "Epoch 00667: val_accuracy did not improve from 0.85047\n",
            "Epoch 668/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3434 - accuracy: 0.8765 - val_loss: 0.6780 - val_accuracy: 0.8318\n",
            "\n",
            "Epoch 00668: val_accuracy did not improve from 0.85047\n",
            "Epoch 669/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3725 - accuracy: 0.8747 - val_loss: 0.7150 - val_accuracy: 0.8287\n",
            "\n",
            "Epoch 00669: val_accuracy did not improve from 0.85047\n",
            "Epoch 670/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3693 - accuracy: 0.8629 - val_loss: 0.7757 - val_accuracy: 0.8131\n",
            "\n",
            "Epoch 00670: val_accuracy did not improve from 0.85047\n",
            "Epoch 671/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3328 - accuracy: 0.8831 - val_loss: 0.6901 - val_accuracy: 0.8255\n",
            "\n",
            "Epoch 00671: val_accuracy did not improve from 0.85047\n",
            "Epoch 672/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.4021 - accuracy: 0.8586 - val_loss: 0.6947 - val_accuracy: 0.8193\n",
            "\n",
            "Epoch 00672: val_accuracy did not improve from 0.85047\n",
            "Epoch 673/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4377 - accuracy: 0.8611 - val_loss: 0.7109 - val_accuracy: 0.8287\n",
            "\n",
            "Epoch 00673: val_accuracy did not improve from 0.85047\n",
            "Epoch 674/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3497 - accuracy: 0.8846 - val_loss: 0.6864 - val_accuracy: 0.8255\n",
            "\n",
            "Epoch 00674: val_accuracy did not improve from 0.85047\n",
            "Epoch 675/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3800 - accuracy: 0.8763 - val_loss: 0.6534 - val_accuracy: 0.8287\n",
            "\n",
            "Epoch 00675: val_accuracy did not improve from 0.85047\n",
            "Epoch 676/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3283 - accuracy: 0.8842 - val_loss: 0.6777 - val_accuracy: 0.8255\n",
            "\n",
            "Epoch 00676: val_accuracy did not improve from 0.85047\n",
            "Epoch 677/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3079 - accuracy: 0.8889 - val_loss: 0.6569 - val_accuracy: 0.8380\n",
            "\n",
            "Epoch 00677: val_accuracy did not improve from 0.85047\n",
            "Epoch 678/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3557 - accuracy: 0.8739 - val_loss: 0.6138 - val_accuracy: 0.8287\n",
            "\n",
            "Epoch 00678: val_accuracy did not improve from 0.85047\n",
            "Epoch 679/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3234 - accuracy: 0.8878 - val_loss: 0.6200 - val_accuracy: 0.8318\n",
            "\n",
            "Epoch 00679: val_accuracy did not improve from 0.85047\n",
            "Epoch 680/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3053 - accuracy: 0.8827 - val_loss: 0.6306 - val_accuracy: 0.8380\n",
            "\n",
            "Epoch 00680: val_accuracy did not improve from 0.85047\n",
            "Epoch 681/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3252 - accuracy: 0.8847 - val_loss: 0.6072 - val_accuracy: 0.8474\n",
            "\n",
            "Epoch 00681: val_accuracy did not improve from 0.85047\n",
            "Epoch 682/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3215 - accuracy: 0.8930 - val_loss: 0.7034 - val_accuracy: 0.8349\n",
            "\n",
            "Epoch 00682: val_accuracy did not improve from 0.85047\n",
            "Epoch 683/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3006 - accuracy: 0.8947 - val_loss: 0.6816 - val_accuracy: 0.8380\n",
            "\n",
            "Epoch 00683: val_accuracy did not improve from 0.85047\n",
            "Epoch 684/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3307 - accuracy: 0.8761 - val_loss: 0.6660 - val_accuracy: 0.8442\n",
            "\n",
            "Epoch 00684: val_accuracy did not improve from 0.85047\n",
            "Epoch 685/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.2831 - accuracy: 0.8918 - val_loss: 0.6452 - val_accuracy: 0.8442\n",
            "\n",
            "Epoch 00685: val_accuracy did not improve from 0.85047\n",
            "Epoch 686/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.2813 - accuracy: 0.8884 - val_loss: 0.7492 - val_accuracy: 0.8318\n",
            "\n",
            "Epoch 00686: val_accuracy did not improve from 0.85047\n",
            "Epoch 687/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2602 - accuracy: 0.9122 - val_loss: 0.6895 - val_accuracy: 0.8380\n",
            "\n",
            "Epoch 00687: val_accuracy did not improve from 0.85047\n",
            "Epoch 688/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.2994 - accuracy: 0.8894 - val_loss: 0.6552 - val_accuracy: 0.8318\n",
            "\n",
            "Epoch 00688: val_accuracy did not improve from 0.85047\n",
            "Epoch 689/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.2944 - accuracy: 0.9011 - val_loss: 0.6906 - val_accuracy: 0.8255\n",
            "\n",
            "Epoch 00689: val_accuracy did not improve from 0.85047\n",
            "Epoch 690/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.2931 - accuracy: 0.8877 - val_loss: 0.7626 - val_accuracy: 0.8224\n",
            "\n",
            "Epoch 00690: val_accuracy did not improve from 0.85047\n",
            "Epoch 691/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3145 - accuracy: 0.8885 - val_loss: 0.7820 - val_accuracy: 0.8255\n",
            "\n",
            "Epoch 00691: val_accuracy did not improve from 0.85047\n",
            "Epoch 692/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.2935 - accuracy: 0.8946 - val_loss: 0.7771 - val_accuracy: 0.8255\n",
            "\n",
            "Epoch 00692: val_accuracy did not improve from 0.85047\n",
            "Epoch 693/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.2922 - accuracy: 0.8983 - val_loss: 0.7013 - val_accuracy: 0.8224\n",
            "\n",
            "Epoch 00693: val_accuracy did not improve from 0.85047\n",
            "Epoch 694/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3070 - accuracy: 0.8974 - val_loss: 0.7869 - val_accuracy: 0.8255\n",
            "\n",
            "Epoch 00694: val_accuracy did not improve from 0.85047\n",
            "Epoch 695/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3492 - accuracy: 0.8863 - val_loss: 0.8418 - val_accuracy: 0.8224\n",
            "\n",
            "Epoch 00695: val_accuracy did not improve from 0.85047\n",
            "Epoch 696/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3608 - accuracy: 0.8741 - val_loss: 0.7530 - val_accuracy: 0.8131\n",
            "\n",
            "Epoch 00696: val_accuracy did not improve from 0.85047\n",
            "Epoch 697/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3330 - accuracy: 0.8839 - val_loss: 0.7482 - val_accuracy: 0.8162\n",
            "\n",
            "Epoch 00697: val_accuracy did not improve from 0.85047\n",
            "Epoch 698/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3251 - accuracy: 0.8771 - val_loss: 0.7402 - val_accuracy: 0.8193\n",
            "\n",
            "Epoch 00698: val_accuracy did not improve from 0.85047\n",
            "Epoch 699/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3096 - accuracy: 0.8983 - val_loss: 0.7054 - val_accuracy: 0.8255\n",
            "\n",
            "Epoch 00699: val_accuracy did not improve from 0.85047\n",
            "Epoch 700/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3233 - accuracy: 0.8869 - val_loss: 0.6942 - val_accuracy: 0.8349\n",
            "\n",
            "Epoch 00700: val_accuracy did not improve from 0.85047\n",
            "Epoch 701/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2959 - accuracy: 0.8982 - val_loss: 0.7242 - val_accuracy: 0.8380\n",
            "\n",
            "Epoch 00701: val_accuracy did not improve from 0.85047\n",
            "Epoch 702/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.2768 - accuracy: 0.8857 - val_loss: 0.7324 - val_accuracy: 0.8287\n",
            "\n",
            "Epoch 00702: val_accuracy did not improve from 0.85047\n",
            "Epoch 703/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3052 - accuracy: 0.8812 - val_loss: 0.6585 - val_accuracy: 0.8380\n",
            "\n",
            "Epoch 00703: val_accuracy did not improve from 0.85047\n",
            "Epoch 704/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3203 - accuracy: 0.8873 - val_loss: 0.7240 - val_accuracy: 0.8255\n",
            "\n",
            "Epoch 00704: val_accuracy did not improve from 0.85047\n",
            "Epoch 705/1000\n",
            "41/41 [==============================] - 1s 18ms/step - loss: 0.3464 - accuracy: 0.8623 - val_loss: 0.6808 - val_accuracy: 0.8318\n",
            "\n",
            "Epoch 00705: val_accuracy did not improve from 0.85047\n",
            "Epoch 706/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3253 - accuracy: 0.8934 - val_loss: 0.7339 - val_accuracy: 0.8224\n",
            "\n",
            "Epoch 00706: val_accuracy did not improve from 0.85047\n",
            "Epoch 707/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.2824 - accuracy: 0.8936 - val_loss: 0.7567 - val_accuracy: 0.8255\n",
            "\n",
            "Epoch 00707: val_accuracy did not improve from 0.85047\n",
            "Epoch 708/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3059 - accuracy: 0.9016 - val_loss: 0.6825 - val_accuracy: 0.8349\n",
            "\n",
            "Epoch 00708: val_accuracy did not improve from 0.85047\n",
            "Epoch 709/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.2988 - accuracy: 0.8953 - val_loss: 0.6394 - val_accuracy: 0.8442\n",
            "\n",
            "Epoch 00709: val_accuracy did not improve from 0.85047\n",
            "Epoch 710/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3805 - accuracy: 0.8598 - val_loss: 0.7152 - val_accuracy: 0.8255\n",
            "\n",
            "Epoch 00710: val_accuracy did not improve from 0.85047\n",
            "Epoch 711/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3414 - accuracy: 0.8891 - val_loss: 0.7555 - val_accuracy: 0.8224\n",
            "\n",
            "Epoch 00711: val_accuracy did not improve from 0.85047\n",
            "Epoch 712/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3054 - accuracy: 0.8933 - val_loss: 0.7133 - val_accuracy: 0.8224\n",
            "\n",
            "Epoch 00712: val_accuracy did not improve from 0.85047\n",
            "Epoch 713/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2852 - accuracy: 0.8869 - val_loss: 0.6927 - val_accuracy: 0.8349\n",
            "\n",
            "Epoch 00713: val_accuracy did not improve from 0.85047\n",
            "Epoch 714/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3053 - accuracy: 0.8862 - val_loss: 0.6848 - val_accuracy: 0.8318\n",
            "\n",
            "Epoch 00714: val_accuracy did not improve from 0.85047\n",
            "Epoch 715/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.5289 - accuracy: 0.8512 - val_loss: 1.2966 - val_accuracy: 0.7570\n",
            "\n",
            "Epoch 00715: val_accuracy did not improve from 0.85047\n",
            "Epoch 716/1000\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 0.7258 - accuracy: 0.8103 - val_loss: 0.9325 - val_accuracy: 0.7850\n",
            "\n",
            "Epoch 00716: val_accuracy did not improve from 0.85047\n",
            "Epoch 717/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.6431 - accuracy: 0.8619 - val_loss: 0.8761 - val_accuracy: 0.7913\n",
            "\n",
            "Epoch 00717: val_accuracy did not improve from 0.85047\n",
            "Epoch 718/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.5621 - accuracy: 0.8638 - val_loss: 0.8290 - val_accuracy: 0.8100\n",
            "\n",
            "Epoch 00718: val_accuracy did not improve from 0.85047\n",
            "Epoch 719/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.4861 - accuracy: 0.8848 - val_loss: 0.7642 - val_accuracy: 0.8224\n",
            "\n",
            "Epoch 00719: val_accuracy did not improve from 0.85047\n",
            "Epoch 720/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.5706 - accuracy: 0.8494 - val_loss: 0.8105 - val_accuracy: 0.8224\n",
            "\n",
            "Epoch 00720: val_accuracy did not improve from 0.85047\n",
            "Epoch 721/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.5261 - accuracy: 0.8718 - val_loss: 0.8518 - val_accuracy: 0.8162\n",
            "\n",
            "Epoch 00721: val_accuracy did not improve from 0.85047\n",
            "Epoch 722/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.5432 - accuracy: 0.8708 - val_loss: 0.9549 - val_accuracy: 0.8037\n",
            "\n",
            "Epoch 00722: val_accuracy did not improve from 0.85047\n",
            "Epoch 723/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.5631 - accuracy: 0.8673 - val_loss: 0.8760 - val_accuracy: 0.8100\n",
            "\n",
            "Epoch 00723: val_accuracy did not improve from 0.85047\n",
            "Epoch 724/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.5225 - accuracy: 0.8582 - val_loss: 0.8194 - val_accuracy: 0.8193\n",
            "\n",
            "Epoch 00724: val_accuracy did not improve from 0.85047\n",
            "Epoch 725/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.5095 - accuracy: 0.8709 - val_loss: 0.7858 - val_accuracy: 0.8162\n",
            "\n",
            "Epoch 00725: val_accuracy did not improve from 0.85047\n",
            "Epoch 726/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.4749 - accuracy: 0.8765 - val_loss: 0.7789 - val_accuracy: 0.8162\n",
            "\n",
            "Epoch 00726: val_accuracy did not improve from 0.85047\n",
            "Epoch 727/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4643 - accuracy: 0.8938 - val_loss: 0.8417 - val_accuracy: 0.8131\n",
            "\n",
            "Epoch 00727: val_accuracy did not improve from 0.85047\n",
            "Epoch 728/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4326 - accuracy: 0.8858 - val_loss: 0.8583 - val_accuracy: 0.8162\n",
            "\n",
            "Epoch 00728: val_accuracy did not improve from 0.85047\n",
            "Epoch 729/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4334 - accuracy: 0.8838 - val_loss: 0.8626 - val_accuracy: 0.8193\n",
            "\n",
            "Epoch 00729: val_accuracy did not improve from 0.85047\n",
            "Epoch 730/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.4778 - accuracy: 0.8725 - val_loss: 0.7985 - val_accuracy: 0.8131\n",
            "\n",
            "Epoch 00730: val_accuracy did not improve from 0.85047\n",
            "Epoch 731/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.4568 - accuracy: 0.8692 - val_loss: 0.7501 - val_accuracy: 0.8162\n",
            "\n",
            "Epoch 00731: val_accuracy did not improve from 0.85047\n",
            "Epoch 732/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3924 - accuracy: 0.9031 - val_loss: 0.7598 - val_accuracy: 0.8162\n",
            "\n",
            "Epoch 00732: val_accuracy did not improve from 0.85047\n",
            "Epoch 733/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4025 - accuracy: 0.8940 - val_loss: 0.7648 - val_accuracy: 0.8162\n",
            "\n",
            "Epoch 00733: val_accuracy did not improve from 0.85047\n",
            "Epoch 734/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.4619 - accuracy: 0.8742 - val_loss: 0.7894 - val_accuracy: 0.8193\n",
            "\n",
            "Epoch 00734: val_accuracy did not improve from 0.85047\n",
            "Epoch 735/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3943 - accuracy: 0.8773 - val_loss: 0.8047 - val_accuracy: 0.8193\n",
            "\n",
            "Epoch 00735: val_accuracy did not improve from 0.85047\n",
            "Epoch 736/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4051 - accuracy: 0.8900 - val_loss: 0.8840 - val_accuracy: 0.8255\n",
            "\n",
            "Epoch 00736: val_accuracy did not improve from 0.85047\n",
            "Epoch 737/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4026 - accuracy: 0.8877 - val_loss: 0.8592 - val_accuracy: 0.8255\n",
            "\n",
            "Epoch 00737: val_accuracy did not improve from 0.85047\n",
            "Epoch 738/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3923 - accuracy: 0.8801 - val_loss: 0.8083 - val_accuracy: 0.8224\n",
            "\n",
            "Epoch 00738: val_accuracy did not improve from 0.85047\n",
            "Epoch 739/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3707 - accuracy: 0.8876 - val_loss: 0.8357 - val_accuracy: 0.8287\n",
            "\n",
            "Epoch 00739: val_accuracy did not improve from 0.85047\n",
            "Epoch 740/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3386 - accuracy: 0.9046 - val_loss: 0.8149 - val_accuracy: 0.8255\n",
            "\n",
            "Epoch 00740: val_accuracy did not improve from 0.85047\n",
            "Epoch 741/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3722 - accuracy: 0.8847 - val_loss: 0.7342 - val_accuracy: 0.8318\n",
            "\n",
            "Epoch 00741: val_accuracy did not improve from 0.85047\n",
            "Epoch 742/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3307 - accuracy: 0.8985 - val_loss: 0.7595 - val_accuracy: 0.8318\n",
            "\n",
            "Epoch 00742: val_accuracy did not improve from 0.85047\n",
            "Epoch 743/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3477 - accuracy: 0.8871 - val_loss: 0.7718 - val_accuracy: 0.8318\n",
            "\n",
            "Epoch 00743: val_accuracy did not improve from 0.85047\n",
            "Epoch 744/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3452 - accuracy: 0.8904 - val_loss: 0.7174 - val_accuracy: 0.8380\n",
            "\n",
            "Epoch 00744: val_accuracy did not improve from 0.85047\n",
            "Epoch 745/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3827 - accuracy: 0.8707 - val_loss: 0.7451 - val_accuracy: 0.8318\n",
            "\n",
            "Epoch 00745: val_accuracy did not improve from 0.85047\n",
            "Epoch 746/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3274 - accuracy: 0.8931 - val_loss: 0.7297 - val_accuracy: 0.8287\n",
            "\n",
            "Epoch 00746: val_accuracy did not improve from 0.85047\n",
            "Epoch 747/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3183 - accuracy: 0.8986 - val_loss: 0.8057 - val_accuracy: 0.8287\n",
            "\n",
            "Epoch 00747: val_accuracy did not improve from 0.85047\n",
            "Epoch 748/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3186 - accuracy: 0.8942 - val_loss: 0.7491 - val_accuracy: 0.8380\n",
            "\n",
            "Epoch 00748: val_accuracy did not improve from 0.85047\n",
            "Epoch 749/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3358 - accuracy: 0.8926 - val_loss: 0.6693 - val_accuracy: 0.8349\n",
            "\n",
            "Epoch 00749: val_accuracy did not improve from 0.85047\n",
            "Epoch 750/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3997 - accuracy: 0.8921 - val_loss: 0.6967 - val_accuracy: 0.8349\n",
            "\n",
            "Epoch 00750: val_accuracy did not improve from 0.85047\n",
            "Epoch 751/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3518 - accuracy: 0.8707 - val_loss: 0.7095 - val_accuracy: 0.8380\n",
            "\n",
            "Epoch 00751: val_accuracy did not improve from 0.85047\n",
            "Epoch 752/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3663 - accuracy: 0.8878 - val_loss: 0.7979 - val_accuracy: 0.8255\n",
            "\n",
            "Epoch 00752: val_accuracy did not improve from 0.85047\n",
            "Epoch 753/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4269 - accuracy: 0.8919 - val_loss: 0.7414 - val_accuracy: 0.8287\n",
            "\n",
            "Epoch 00753: val_accuracy did not improve from 0.85047\n",
            "Epoch 754/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3787 - accuracy: 0.8798 - val_loss: 0.6618 - val_accuracy: 0.8349\n",
            "\n",
            "Epoch 00754: val_accuracy did not improve from 0.85047\n",
            "Epoch 755/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3624 - accuracy: 0.8793 - val_loss: 0.6587 - val_accuracy: 0.8318\n",
            "\n",
            "Epoch 00755: val_accuracy did not improve from 0.85047\n",
            "Epoch 756/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3415 - accuracy: 0.8924 - val_loss: 0.6816 - val_accuracy: 0.8318\n",
            "\n",
            "Epoch 00756: val_accuracy did not improve from 0.85047\n",
            "Epoch 757/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3306 - accuracy: 0.8749 - val_loss: 0.6596 - val_accuracy: 0.8349\n",
            "\n",
            "Epoch 00757: val_accuracy did not improve from 0.85047\n",
            "Epoch 758/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3117 - accuracy: 0.8890 - val_loss: 0.6913 - val_accuracy: 0.8442\n",
            "\n",
            "Epoch 00758: val_accuracy did not improve from 0.85047\n",
            "Epoch 759/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3144 - accuracy: 0.8919 - val_loss: 0.7175 - val_accuracy: 0.8318\n",
            "\n",
            "Epoch 00759: val_accuracy did not improve from 0.85047\n",
            "Epoch 760/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3377 - accuracy: 0.8754 - val_loss: 0.7679 - val_accuracy: 0.8193\n",
            "\n",
            "Epoch 00760: val_accuracy did not improve from 0.85047\n",
            "Epoch 761/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3651 - accuracy: 0.8842 - val_loss: 0.6795 - val_accuracy: 0.8411\n",
            "\n",
            "Epoch 00761: val_accuracy did not improve from 0.85047\n",
            "Epoch 762/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3347 - accuracy: 0.8950 - val_loss: 0.6901 - val_accuracy: 0.8411\n",
            "\n",
            "Epoch 00762: val_accuracy did not improve from 0.85047\n",
            "Epoch 763/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3149 - accuracy: 0.8966 - val_loss: 0.6726 - val_accuracy: 0.8442\n",
            "\n",
            "Epoch 00763: val_accuracy did not improve from 0.85047\n",
            "Epoch 764/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2979 - accuracy: 0.9023 - val_loss: 0.6904 - val_accuracy: 0.8411\n",
            "\n",
            "Epoch 00764: val_accuracy did not improve from 0.85047\n",
            "Epoch 765/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3294 - accuracy: 0.8828 - val_loss: 0.7118 - val_accuracy: 0.8505\n",
            "\n",
            "Epoch 00765: val_accuracy did not improve from 0.85047\n",
            "Epoch 766/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3099 - accuracy: 0.8790 - val_loss: 0.7045 - val_accuracy: 0.8474\n",
            "\n",
            "Epoch 00766: val_accuracy did not improve from 0.85047\n",
            "Epoch 767/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3337 - accuracy: 0.8919 - val_loss: 0.7068 - val_accuracy: 0.8411\n",
            "\n",
            "Epoch 00767: val_accuracy did not improve from 0.85047\n",
            "Epoch 768/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2954 - accuracy: 0.8933 - val_loss: 0.6769 - val_accuracy: 0.8474\n",
            "\n",
            "Epoch 00768: val_accuracy did not improve from 0.85047\n",
            "Epoch 769/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3166 - accuracy: 0.8986 - val_loss: 0.6944 - val_accuracy: 0.8318\n",
            "\n",
            "Epoch 00769: val_accuracy did not improve from 0.85047\n",
            "Epoch 770/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3357 - accuracy: 0.8844 - val_loss: 0.6729 - val_accuracy: 0.8442\n",
            "\n",
            "Epoch 00770: val_accuracy did not improve from 0.85047\n",
            "Epoch 771/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2813 - accuracy: 0.8998 - val_loss: 0.6855 - val_accuracy: 0.8442\n",
            "\n",
            "Epoch 00771: val_accuracy did not improve from 0.85047\n",
            "Epoch 772/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3145 - accuracy: 0.8953 - val_loss: 0.7631 - val_accuracy: 0.8193\n",
            "\n",
            "Epoch 00772: val_accuracy did not improve from 0.85047\n",
            "Epoch 773/1000\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 0.3086 - accuracy: 0.8974 - val_loss: 0.7221 - val_accuracy: 0.8224\n",
            "\n",
            "Epoch 00773: val_accuracy did not improve from 0.85047\n",
            "Epoch 774/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3237 - accuracy: 0.8954 - val_loss: 0.6873 - val_accuracy: 0.8380\n",
            "\n",
            "Epoch 00774: val_accuracy did not improve from 0.85047\n",
            "Epoch 775/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3168 - accuracy: 0.8776 - val_loss: 0.7122 - val_accuracy: 0.8318\n",
            "\n",
            "Epoch 00775: val_accuracy did not improve from 0.85047\n",
            "Epoch 776/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3081 - accuracy: 0.8908 - val_loss: 0.6924 - val_accuracy: 0.8411\n",
            "\n",
            "Epoch 00776: val_accuracy did not improve from 0.85047\n",
            "Epoch 777/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3065 - accuracy: 0.8798 - val_loss: 0.6833 - val_accuracy: 0.8411\n",
            "\n",
            "Epoch 00777: val_accuracy did not improve from 0.85047\n",
            "Epoch 778/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2810 - accuracy: 0.9061 - val_loss: 0.7566 - val_accuracy: 0.8380\n",
            "\n",
            "Epoch 00778: val_accuracy did not improve from 0.85047\n",
            "Epoch 779/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2912 - accuracy: 0.8984 - val_loss: 0.7594 - val_accuracy: 0.8380\n",
            "\n",
            "Epoch 00779: val_accuracy did not improve from 0.85047\n",
            "Epoch 780/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2987 - accuracy: 0.8932 - val_loss: 0.7390 - val_accuracy: 0.8349\n",
            "\n",
            "Epoch 00780: val_accuracy did not improve from 0.85047\n",
            "Epoch 781/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2798 - accuracy: 0.9042 - val_loss: 0.7111 - val_accuracy: 0.8255\n",
            "\n",
            "Epoch 00781: val_accuracy did not improve from 0.85047\n",
            "Epoch 782/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.2852 - accuracy: 0.8954 - val_loss: 0.7132 - val_accuracy: 0.8318\n",
            "\n",
            "Epoch 00782: val_accuracy did not improve from 0.85047\n",
            "Epoch 783/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2951 - accuracy: 0.8954 - val_loss: 0.6905 - val_accuracy: 0.8442\n",
            "\n",
            "Epoch 00783: val_accuracy did not improve from 0.85047\n",
            "Epoch 784/1000\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 0.2691 - accuracy: 0.9016 - val_loss: 0.6364 - val_accuracy: 0.8567\n",
            "\n",
            "Epoch 00784: val_accuracy improved from 0.85047 to 0.85670, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 785/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3401 - accuracy: 0.8818 - val_loss: 0.6763 - val_accuracy: 0.8318\n",
            "\n",
            "Epoch 00785: val_accuracy did not improve from 0.85670\n",
            "Epoch 786/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.2580 - accuracy: 0.8913 - val_loss: 0.6505 - val_accuracy: 0.8380\n",
            "\n",
            "Epoch 00786: val_accuracy did not improve from 0.85670\n",
            "Epoch 787/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3258 - accuracy: 0.9016 - val_loss: 0.7531 - val_accuracy: 0.8224\n",
            "\n",
            "Epoch 00787: val_accuracy did not improve from 0.85670\n",
            "Epoch 788/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3643 - accuracy: 0.8843 - val_loss: 0.8490 - val_accuracy: 0.8006\n",
            "\n",
            "Epoch 00788: val_accuracy did not improve from 0.85670\n",
            "Epoch 789/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3860 - accuracy: 0.8758 - val_loss: 0.7550 - val_accuracy: 0.8193\n",
            "\n",
            "Epoch 00789: val_accuracy did not improve from 0.85670\n",
            "Epoch 790/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3364 - accuracy: 0.8955 - val_loss: 0.6953 - val_accuracy: 0.8318\n",
            "\n",
            "Epoch 00790: val_accuracy did not improve from 0.85670\n",
            "Epoch 791/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3316 - accuracy: 0.8891 - val_loss: 0.7223 - val_accuracy: 0.8287\n",
            "\n",
            "Epoch 00791: val_accuracy did not improve from 0.85670\n",
            "Epoch 792/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3198 - accuracy: 0.8915 - val_loss: 0.7446 - val_accuracy: 0.8318\n",
            "\n",
            "Epoch 00792: val_accuracy did not improve from 0.85670\n",
            "Epoch 793/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3088 - accuracy: 0.8956 - val_loss: 0.7722 - val_accuracy: 0.8255\n",
            "\n",
            "Epoch 00793: val_accuracy did not improve from 0.85670\n",
            "Epoch 794/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.2897 - accuracy: 0.9026 - val_loss: 0.8878 - val_accuracy: 0.8131\n",
            "\n",
            "Epoch 00794: val_accuracy did not improve from 0.85670\n",
            "Epoch 795/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3830 - accuracy: 0.8743 - val_loss: 0.7527 - val_accuracy: 0.8224\n",
            "\n",
            "Epoch 00795: val_accuracy did not improve from 0.85670\n",
            "Epoch 796/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3177 - accuracy: 0.8876 - val_loss: 0.7143 - val_accuracy: 0.8287\n",
            "\n",
            "Epoch 00796: val_accuracy did not improve from 0.85670\n",
            "Epoch 797/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2953 - accuracy: 0.8921 - val_loss: 0.6903 - val_accuracy: 0.8349\n",
            "\n",
            "Epoch 00797: val_accuracy did not improve from 0.85670\n",
            "Epoch 798/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.2938 - accuracy: 0.8977 - val_loss: 0.7148 - val_accuracy: 0.8411\n",
            "\n",
            "Epoch 00798: val_accuracy did not improve from 0.85670\n",
            "Epoch 799/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3443 - accuracy: 0.8780 - val_loss: 0.7740 - val_accuracy: 0.8162\n",
            "\n",
            "Epoch 00799: val_accuracy did not improve from 0.85670\n",
            "Epoch 800/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3449 - accuracy: 0.8737 - val_loss: 0.7883 - val_accuracy: 0.8224\n",
            "\n",
            "Epoch 00800: val_accuracy did not improve from 0.85670\n",
            "Epoch 801/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3182 - accuracy: 0.8834 - val_loss: 0.7789 - val_accuracy: 0.8224\n",
            "\n",
            "Epoch 00801: val_accuracy did not improve from 0.85670\n",
            "Epoch 802/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.2968 - accuracy: 0.8900 - val_loss: 0.7324 - val_accuracy: 0.8349\n",
            "\n",
            "Epoch 00802: val_accuracy did not improve from 0.85670\n",
            "Epoch 803/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2971 - accuracy: 0.8844 - val_loss: 0.6971 - val_accuracy: 0.8349\n",
            "\n",
            "Epoch 00803: val_accuracy did not improve from 0.85670\n",
            "Epoch 804/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.2811 - accuracy: 0.9057 - val_loss: 0.6813 - val_accuracy: 0.8349\n",
            "\n",
            "Epoch 00804: val_accuracy did not improve from 0.85670\n",
            "Epoch 805/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2872 - accuracy: 0.8954 - val_loss: 0.7558 - val_accuracy: 0.8411\n",
            "\n",
            "Epoch 00805: val_accuracy did not improve from 0.85670\n",
            "Epoch 806/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2885 - accuracy: 0.8820 - val_loss: 0.7717 - val_accuracy: 0.8287\n",
            "\n",
            "Epoch 00806: val_accuracy did not improve from 0.85670\n",
            "Epoch 807/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2806 - accuracy: 0.8930 - val_loss: 0.7575 - val_accuracy: 0.8287\n",
            "\n",
            "Epoch 00807: val_accuracy did not improve from 0.85670\n",
            "Epoch 808/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2791 - accuracy: 0.8812 - val_loss: 0.6996 - val_accuracy: 0.8442\n",
            "\n",
            "Epoch 00808: val_accuracy did not improve from 0.85670\n",
            "Epoch 809/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3010 - accuracy: 0.8778 - val_loss: 0.7252 - val_accuracy: 0.8411\n",
            "\n",
            "Epoch 00809: val_accuracy did not improve from 0.85670\n",
            "Epoch 810/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3094 - accuracy: 0.8876 - val_loss: 0.6891 - val_accuracy: 0.8380\n",
            "\n",
            "Epoch 00810: val_accuracy did not improve from 0.85670\n",
            "Epoch 811/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2808 - accuracy: 0.9077 - val_loss: 0.7344 - val_accuracy: 0.8380\n",
            "\n",
            "Epoch 00811: val_accuracy did not improve from 0.85670\n",
            "Epoch 812/1000\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 0.2638 - accuracy: 0.8813 - val_loss: 0.7685 - val_accuracy: 0.8442\n",
            "\n",
            "Epoch 00812: val_accuracy did not improve from 0.85670\n",
            "Epoch 813/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2978 - accuracy: 0.8957 - val_loss: 0.7182 - val_accuracy: 0.8411\n",
            "\n",
            "Epoch 00813: val_accuracy did not improve from 0.85670\n",
            "Epoch 814/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2622 - accuracy: 0.9018 - val_loss: 0.7364 - val_accuracy: 0.8349\n",
            "\n",
            "Epoch 00814: val_accuracy did not improve from 0.85670\n",
            "Epoch 815/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2661 - accuracy: 0.9121 - val_loss: 0.7396 - val_accuracy: 0.8442\n",
            "\n",
            "Epoch 00815: val_accuracy did not improve from 0.85670\n",
            "Epoch 816/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2816 - accuracy: 0.8867 - val_loss: 0.6441 - val_accuracy: 0.8442\n",
            "\n",
            "Epoch 00816: val_accuracy did not improve from 0.85670\n",
            "Epoch 817/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2800 - accuracy: 0.8915 - val_loss: 0.7035 - val_accuracy: 0.8349\n",
            "\n",
            "Epoch 00817: val_accuracy did not improve from 0.85670\n",
            "Epoch 818/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2979 - accuracy: 0.8861 - val_loss: 0.7291 - val_accuracy: 0.8349\n",
            "\n",
            "Epoch 00818: val_accuracy did not improve from 0.85670\n",
            "Epoch 819/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3023 - accuracy: 0.8902 - val_loss: 0.8035 - val_accuracy: 0.8318\n",
            "\n",
            "Epoch 00819: val_accuracy did not improve from 0.85670\n",
            "Epoch 820/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3321 - accuracy: 0.8899 - val_loss: 0.7490 - val_accuracy: 0.8442\n",
            "\n",
            "Epoch 00820: val_accuracy did not improve from 0.85670\n",
            "Epoch 821/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3490 - accuracy: 0.8732 - val_loss: 0.7514 - val_accuracy: 0.8380\n",
            "\n",
            "Epoch 00821: val_accuracy did not improve from 0.85670\n",
            "Epoch 822/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3112 - accuracy: 0.8941 - val_loss: 0.7410 - val_accuracy: 0.8318\n",
            "\n",
            "Epoch 00822: val_accuracy did not improve from 0.85670\n",
            "Epoch 823/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3128 - accuracy: 0.8930 - val_loss: 0.6853 - val_accuracy: 0.8349\n",
            "\n",
            "Epoch 00823: val_accuracy did not improve from 0.85670\n",
            "Epoch 824/1000\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 0.2647 - accuracy: 0.9024 - val_loss: 0.6817 - val_accuracy: 0.8474\n",
            "\n",
            "Epoch 00824: val_accuracy did not improve from 0.85670\n",
            "Epoch 825/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3594 - accuracy: 0.8850 - val_loss: 0.6669 - val_accuracy: 0.8380\n",
            "\n",
            "Epoch 00825: val_accuracy did not improve from 0.85670\n",
            "Epoch 826/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3122 - accuracy: 0.8882 - val_loss: 0.6488 - val_accuracy: 0.8411\n",
            "\n",
            "Epoch 00826: val_accuracy did not improve from 0.85670\n",
            "Epoch 827/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2651 - accuracy: 0.9108 - val_loss: 0.6917 - val_accuracy: 0.8505\n",
            "\n",
            "Epoch 00827: val_accuracy did not improve from 0.85670\n",
            "Epoch 828/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.2367 - accuracy: 0.9005 - val_loss: 0.7005 - val_accuracy: 0.8442\n",
            "\n",
            "Epoch 00828: val_accuracy did not improve from 0.85670\n",
            "Epoch 829/1000\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 0.2421 - accuracy: 0.9084 - val_loss: 0.7226 - val_accuracy: 0.8442\n",
            "\n",
            "Epoch 00829: val_accuracy did not improve from 0.85670\n",
            "Epoch 830/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2663 - accuracy: 0.9052 - val_loss: 0.7917 - val_accuracy: 0.8131\n",
            "\n",
            "Epoch 00830: val_accuracy did not improve from 0.85670\n",
            "Epoch 831/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3291 - accuracy: 0.8830 - val_loss: 0.8033 - val_accuracy: 0.8193\n",
            "\n",
            "Epoch 00831: val_accuracy did not improve from 0.85670\n",
            "Epoch 832/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3080 - accuracy: 0.8977 - val_loss: 0.7527 - val_accuracy: 0.8349\n",
            "\n",
            "Epoch 00832: val_accuracy did not improve from 0.85670\n",
            "Epoch 833/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2876 - accuracy: 0.9088 - val_loss: 0.7470 - val_accuracy: 0.8411\n",
            "\n",
            "Epoch 00833: val_accuracy did not improve from 0.85670\n",
            "Epoch 834/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2724 - accuracy: 0.8922 - val_loss: 0.7580 - val_accuracy: 0.8349\n",
            "\n",
            "Epoch 00834: val_accuracy did not improve from 0.85670\n",
            "Epoch 835/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.2650 - accuracy: 0.9057 - val_loss: 0.7652 - val_accuracy: 0.8380\n",
            "\n",
            "Epoch 00835: val_accuracy did not improve from 0.85670\n",
            "Epoch 836/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3020 - accuracy: 0.8913 - val_loss: 0.8759 - val_accuracy: 0.8193\n",
            "\n",
            "Epoch 00836: val_accuracy did not improve from 0.85670\n",
            "Epoch 837/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.7852 - accuracy: 0.7936 - val_loss: 1.0639 - val_accuracy: 0.7632\n",
            "\n",
            "Epoch 00837: val_accuracy did not improve from 0.85670\n",
            "Epoch 838/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.5127 - accuracy: 0.8656 - val_loss: 0.7231 - val_accuracy: 0.8349\n",
            "\n",
            "Epoch 00838: val_accuracy did not improve from 0.85670\n",
            "Epoch 839/1000\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 0.4994 - accuracy: 0.8832 - val_loss: 0.6899 - val_accuracy: 0.8380\n",
            "\n",
            "Epoch 00839: val_accuracy did not improve from 0.85670\n",
            "Epoch 840/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.4398 - accuracy: 0.8893 - val_loss: 0.7036 - val_accuracy: 0.8474\n",
            "\n",
            "Epoch 00840: val_accuracy did not improve from 0.85670\n",
            "Epoch 841/1000\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 0.4467 - accuracy: 0.8876 - val_loss: 0.6812 - val_accuracy: 0.8442\n",
            "\n",
            "Epoch 00841: val_accuracy did not improve from 0.85670\n",
            "Epoch 842/1000\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 0.4046 - accuracy: 0.8728 - val_loss: 0.7238 - val_accuracy: 0.8442\n",
            "\n",
            "Epoch 00842: val_accuracy did not improve from 0.85670\n",
            "Epoch 843/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3957 - accuracy: 0.8728 - val_loss: 0.7109 - val_accuracy: 0.8411\n",
            "\n",
            "Epoch 00843: val_accuracy did not improve from 0.85670\n",
            "Epoch 844/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3624 - accuracy: 0.8922 - val_loss: 0.7546 - val_accuracy: 0.8380\n",
            "\n",
            "Epoch 00844: val_accuracy did not improve from 0.85670\n",
            "Epoch 845/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.4060 - accuracy: 0.8748 - val_loss: 0.6818 - val_accuracy: 0.8442\n",
            "\n",
            "Epoch 00845: val_accuracy did not improve from 0.85670\n",
            "Epoch 846/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3612 - accuracy: 0.8852 - val_loss: 0.6685 - val_accuracy: 0.8442\n",
            "\n",
            "Epoch 00846: val_accuracy did not improve from 0.85670\n",
            "Epoch 847/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3637 - accuracy: 0.8902 - val_loss: 0.6949 - val_accuracy: 0.8474\n",
            "\n",
            "Epoch 00847: val_accuracy did not improve from 0.85670\n",
            "Epoch 848/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3578 - accuracy: 0.8732 - val_loss: 0.6752 - val_accuracy: 0.8411\n",
            "\n",
            "Epoch 00848: val_accuracy did not improve from 0.85670\n",
            "Epoch 849/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3343 - accuracy: 0.8973 - val_loss: 0.6751 - val_accuracy: 0.8536\n",
            "\n",
            "Epoch 00849: val_accuracy did not improve from 0.85670\n",
            "Epoch 850/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3253 - accuracy: 0.9003 - val_loss: 0.7241 - val_accuracy: 0.8474\n",
            "\n",
            "Epoch 00850: val_accuracy did not improve from 0.85670\n",
            "Epoch 851/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3165 - accuracy: 0.8875 - val_loss: 0.7195 - val_accuracy: 0.8474\n",
            "\n",
            "Epoch 00851: val_accuracy did not improve from 0.85670\n",
            "Epoch 852/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3235 - accuracy: 0.8950 - val_loss: 0.7543 - val_accuracy: 0.8442\n",
            "\n",
            "Epoch 00852: val_accuracy did not improve from 0.85670\n",
            "Epoch 853/1000\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 0.3097 - accuracy: 0.8897 - val_loss: 0.7906 - val_accuracy: 0.8411\n",
            "\n",
            "Epoch 00853: val_accuracy did not improve from 0.85670\n",
            "Epoch 854/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3074 - accuracy: 0.8825 - val_loss: 0.7464 - val_accuracy: 0.8380\n",
            "\n",
            "Epoch 00854: val_accuracy did not improve from 0.85670\n",
            "Epoch 855/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2964 - accuracy: 0.8992 - val_loss: 0.7824 - val_accuracy: 0.8349\n",
            "\n",
            "Epoch 00855: val_accuracy did not improve from 0.85670\n",
            "Epoch 856/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3044 - accuracy: 0.8977 - val_loss: 0.8169 - val_accuracy: 0.8411\n",
            "\n",
            "Epoch 00856: val_accuracy did not improve from 0.85670\n",
            "Epoch 857/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2927 - accuracy: 0.8866 - val_loss: 0.8363 - val_accuracy: 0.8411\n",
            "\n",
            "Epoch 00857: val_accuracy did not improve from 0.85670\n",
            "Epoch 858/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.4181 - accuracy: 0.8864 - val_loss: 0.7965 - val_accuracy: 0.8349\n",
            "\n",
            "Epoch 00858: val_accuracy did not improve from 0.85670\n",
            "Epoch 859/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3728 - accuracy: 0.8672 - val_loss: 0.7936 - val_accuracy: 0.8380\n",
            "\n",
            "Epoch 00859: val_accuracy did not improve from 0.85670\n",
            "Epoch 860/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3202 - accuracy: 0.8930 - val_loss: 0.7639 - val_accuracy: 0.8411\n",
            "\n",
            "Epoch 00860: val_accuracy did not improve from 0.85670\n",
            "Epoch 861/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3401 - accuracy: 0.8952 - val_loss: 0.7302 - val_accuracy: 0.8442\n",
            "\n",
            "Epoch 00861: val_accuracy did not improve from 0.85670\n",
            "Epoch 862/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2929 - accuracy: 0.9036 - val_loss: 0.6787 - val_accuracy: 0.8505\n",
            "\n",
            "Epoch 00862: val_accuracy did not improve from 0.85670\n",
            "Epoch 863/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3279 - accuracy: 0.8927 - val_loss: 0.6996 - val_accuracy: 0.8474\n",
            "\n",
            "Epoch 00863: val_accuracy did not improve from 0.85670\n",
            "Epoch 864/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2968 - accuracy: 0.9112 - val_loss: 0.7076 - val_accuracy: 0.8442\n",
            "\n",
            "Epoch 00864: val_accuracy did not improve from 0.85670\n",
            "Epoch 865/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2723 - accuracy: 0.8983 - val_loss: 0.7187 - val_accuracy: 0.8474\n",
            "\n",
            "Epoch 00865: val_accuracy did not improve from 0.85670\n",
            "Epoch 866/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2793 - accuracy: 0.9063 - val_loss: 0.7015 - val_accuracy: 0.8442\n",
            "\n",
            "Epoch 00866: val_accuracy did not improve from 0.85670\n",
            "Epoch 867/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2922 - accuracy: 0.8967 - val_loss: 0.7309 - val_accuracy: 0.8318\n",
            "\n",
            "Epoch 00867: val_accuracy did not improve from 0.85670\n",
            "Epoch 868/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2798 - accuracy: 0.9018 - val_loss: 0.7218 - val_accuracy: 0.8474\n",
            "\n",
            "Epoch 00868: val_accuracy did not improve from 0.85670\n",
            "Epoch 869/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2752 - accuracy: 0.8789 - val_loss: 0.7418 - val_accuracy: 0.8442\n",
            "\n",
            "Epoch 00869: val_accuracy did not improve from 0.85670\n",
            "Epoch 870/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.2710 - accuracy: 0.9057 - val_loss: 0.7700 - val_accuracy: 0.8442\n",
            "\n",
            "Epoch 00870: val_accuracy did not improve from 0.85670\n",
            "Epoch 871/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2861 - accuracy: 0.9019 - val_loss: 0.8115 - val_accuracy: 0.8318\n",
            "\n",
            "Epoch 00871: val_accuracy did not improve from 0.85670\n",
            "Epoch 872/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3709 - accuracy: 0.8836 - val_loss: 0.7737 - val_accuracy: 0.8255\n",
            "\n",
            "Epoch 00872: val_accuracy did not improve from 0.85670\n",
            "Epoch 873/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.4490 - accuracy: 0.8704 - val_loss: 0.7253 - val_accuracy: 0.8318\n",
            "\n",
            "Epoch 00873: val_accuracy did not improve from 0.85670\n",
            "Epoch 874/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3353 - accuracy: 0.9018 - val_loss: 0.6819 - val_accuracy: 0.8474\n",
            "\n",
            "Epoch 00874: val_accuracy did not improve from 0.85670\n",
            "Epoch 875/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3056 - accuracy: 0.9039 - val_loss: 0.6985 - val_accuracy: 0.8442\n",
            "\n",
            "Epoch 00875: val_accuracy did not improve from 0.85670\n",
            "Epoch 876/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3443 - accuracy: 0.8770 - val_loss: 0.6885 - val_accuracy: 0.8380\n",
            "\n",
            "Epoch 00876: val_accuracy did not improve from 0.85670\n",
            "Epoch 877/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3180 - accuracy: 0.8950 - val_loss: 0.6531 - val_accuracy: 0.8380\n",
            "\n",
            "Epoch 00877: val_accuracy did not improve from 0.85670\n",
            "Epoch 878/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3464 - accuracy: 0.9079 - val_loss: 0.7146 - val_accuracy: 0.8411\n",
            "\n",
            "Epoch 00878: val_accuracy did not improve from 0.85670\n",
            "Epoch 879/1000\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 0.2855 - accuracy: 0.8977 - val_loss: 0.7346 - val_accuracy: 0.8380\n",
            "\n",
            "Epoch 00879: val_accuracy did not improve from 0.85670\n",
            "Epoch 880/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2768 - accuracy: 0.8940 - val_loss: 0.7419 - val_accuracy: 0.8380\n",
            "\n",
            "Epoch 00880: val_accuracy did not improve from 0.85670\n",
            "Epoch 881/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2705 - accuracy: 0.8991 - val_loss: 0.7259 - val_accuracy: 0.8474\n",
            "\n",
            "Epoch 00881: val_accuracy did not improve from 0.85670\n",
            "Epoch 882/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2650 - accuracy: 0.9084 - val_loss: 0.7223 - val_accuracy: 0.8442\n",
            "\n",
            "Epoch 00882: val_accuracy did not improve from 0.85670\n",
            "Epoch 883/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3061 - accuracy: 0.8978 - val_loss: 0.7203 - val_accuracy: 0.8380\n",
            "\n",
            "Epoch 00883: val_accuracy did not improve from 0.85670\n",
            "Epoch 884/1000\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 0.2805 - accuracy: 0.8932 - val_loss: 0.6894 - val_accuracy: 0.8505\n",
            "\n",
            "Epoch 00884: val_accuracy did not improve from 0.85670\n",
            "Epoch 885/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3708 - accuracy: 0.8732 - val_loss: 0.6988 - val_accuracy: 0.8411\n",
            "\n",
            "Epoch 00885: val_accuracy did not improve from 0.85670\n",
            "Epoch 886/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2980 - accuracy: 0.9003 - val_loss: 0.6866 - val_accuracy: 0.8536\n",
            "\n",
            "Epoch 00886: val_accuracy did not improve from 0.85670\n",
            "Epoch 887/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3354 - accuracy: 0.8841 - val_loss: 0.6844 - val_accuracy: 0.8411\n",
            "\n",
            "Epoch 00887: val_accuracy did not improve from 0.85670\n",
            "Epoch 888/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2824 - accuracy: 0.8909 - val_loss: 0.7435 - val_accuracy: 0.8349\n",
            "\n",
            "Epoch 00888: val_accuracy did not improve from 0.85670\n",
            "Epoch 889/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3079 - accuracy: 0.8966 - val_loss: 0.8053 - val_accuracy: 0.8287\n",
            "\n",
            "Epoch 00889: val_accuracy did not improve from 0.85670\n",
            "Epoch 890/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3169 - accuracy: 0.8858 - val_loss: 0.7283 - val_accuracy: 0.8442\n",
            "\n",
            "Epoch 00890: val_accuracy did not improve from 0.85670\n",
            "Epoch 891/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2814 - accuracy: 0.8898 - val_loss: 0.6973 - val_accuracy: 0.8442\n",
            "\n",
            "Epoch 00891: val_accuracy did not improve from 0.85670\n",
            "Epoch 892/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2785 - accuracy: 0.8994 - val_loss: 0.7916 - val_accuracy: 0.8380\n",
            "\n",
            "Epoch 00892: val_accuracy did not improve from 0.85670\n",
            "Epoch 893/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3777 - accuracy: 0.8874 - val_loss: 0.8027 - val_accuracy: 0.8349\n",
            "\n",
            "Epoch 00893: val_accuracy did not improve from 0.85670\n",
            "Epoch 894/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3531 - accuracy: 0.8909 - val_loss: 0.8284 - val_accuracy: 0.8162\n",
            "\n",
            "Epoch 00894: val_accuracy did not improve from 0.85670\n",
            "Epoch 895/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3314 - accuracy: 0.8840 - val_loss: 0.7029 - val_accuracy: 0.8318\n",
            "\n",
            "Epoch 00895: val_accuracy did not improve from 0.85670\n",
            "Epoch 896/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3282 - accuracy: 0.9041 - val_loss: 0.6696 - val_accuracy: 0.8349\n",
            "\n",
            "Epoch 00896: val_accuracy did not improve from 0.85670\n",
            "Epoch 897/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3145 - accuracy: 0.8970 - val_loss: 0.7381 - val_accuracy: 0.8442\n",
            "\n",
            "Epoch 00897: val_accuracy did not improve from 0.85670\n",
            "Epoch 898/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3735 - accuracy: 0.8835 - val_loss: 0.6893 - val_accuracy: 0.8505\n",
            "\n",
            "Epoch 00898: val_accuracy did not improve from 0.85670\n",
            "Epoch 899/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2794 - accuracy: 0.8960 - val_loss: 0.7318 - val_accuracy: 0.8318\n",
            "\n",
            "Epoch 00899: val_accuracy did not improve from 0.85670\n",
            "Epoch 900/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2788 - accuracy: 0.9032 - val_loss: 0.7006 - val_accuracy: 0.8474\n",
            "\n",
            "Epoch 00900: val_accuracy did not improve from 0.85670\n",
            "Epoch 901/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2480 - accuracy: 0.9047 - val_loss: 0.7028 - val_accuracy: 0.8474\n",
            "\n",
            "Epoch 00901: val_accuracy did not improve from 0.85670\n",
            "Epoch 902/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2934 - accuracy: 0.8783 - val_loss: 0.6556 - val_accuracy: 0.8411\n",
            "\n",
            "Epoch 00902: val_accuracy did not improve from 0.85670\n",
            "Epoch 903/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2706 - accuracy: 0.8950 - val_loss: 0.6500 - val_accuracy: 0.8505\n",
            "\n",
            "Epoch 00903: val_accuracy did not improve from 0.85670\n",
            "Epoch 904/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3139 - accuracy: 0.8957 - val_loss: 0.6833 - val_accuracy: 0.8629\n",
            "\n",
            "Epoch 00904: val_accuracy improved from 0.85670 to 0.86293, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 905/1000\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 0.2763 - accuracy: 0.9002 - val_loss: 0.6575 - val_accuracy: 0.8598\n",
            "\n",
            "Epoch 00905: val_accuracy did not improve from 0.86293\n",
            "Epoch 906/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3295 - accuracy: 0.8829 - val_loss: 0.6581 - val_accuracy: 0.8474\n",
            "\n",
            "Epoch 00906: val_accuracy did not improve from 0.86293\n",
            "Epoch 907/1000\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 0.2745 - accuracy: 0.9060 - val_loss: 0.6831 - val_accuracy: 0.8474\n",
            "\n",
            "Epoch 00907: val_accuracy did not improve from 0.86293\n",
            "Epoch 908/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2678 - accuracy: 0.9030 - val_loss: 0.7218 - val_accuracy: 0.8411\n",
            "\n",
            "Epoch 00908: val_accuracy did not improve from 0.86293\n",
            "Epoch 909/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3473 - accuracy: 0.8843 - val_loss: 0.6750 - val_accuracy: 0.8411\n",
            "\n",
            "Epoch 00909: val_accuracy did not improve from 0.86293\n",
            "Epoch 910/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3021 - accuracy: 0.8896 - val_loss: 0.6804 - val_accuracy: 0.8442\n",
            "\n",
            "Epoch 00910: val_accuracy did not improve from 0.86293\n",
            "Epoch 911/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3481 - accuracy: 0.8870 - val_loss: 0.6407 - val_accuracy: 0.8411\n",
            "\n",
            "Epoch 00911: val_accuracy did not improve from 0.86293\n",
            "Epoch 912/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3064 - accuracy: 0.8938 - val_loss: 0.6315 - val_accuracy: 0.8442\n",
            "\n",
            "Epoch 00912: val_accuracy did not improve from 0.86293\n",
            "Epoch 913/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2939 - accuracy: 0.8939 - val_loss: 0.6819 - val_accuracy: 0.8411\n",
            "\n",
            "Epoch 00913: val_accuracy did not improve from 0.86293\n",
            "Epoch 914/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2892 - accuracy: 0.8933 - val_loss: 0.6427 - val_accuracy: 0.8442\n",
            "\n",
            "Epoch 00914: val_accuracy did not improve from 0.86293\n",
            "Epoch 915/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2648 - accuracy: 0.8953 - val_loss: 0.6180 - val_accuracy: 0.8411\n",
            "\n",
            "Epoch 00915: val_accuracy did not improve from 0.86293\n",
            "Epoch 916/1000\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 0.2767 - accuracy: 0.9102 - val_loss: 0.6376 - val_accuracy: 0.8474\n",
            "\n",
            "Epoch 00916: val_accuracy did not improve from 0.86293\n",
            "Epoch 917/1000\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 0.2721 - accuracy: 0.8953 - val_loss: 0.6728 - val_accuracy: 0.8411\n",
            "\n",
            "Epoch 00917: val_accuracy did not improve from 0.86293\n",
            "Epoch 918/1000\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 0.3166 - accuracy: 0.8882 - val_loss: 0.6697 - val_accuracy: 0.8442\n",
            "\n",
            "Epoch 00918: val_accuracy did not improve from 0.86293\n",
            "Epoch 919/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3096 - accuracy: 0.8967 - val_loss: 0.6953 - val_accuracy: 0.8442\n",
            "\n",
            "Epoch 00919: val_accuracy did not improve from 0.86293\n",
            "Epoch 920/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3042 - accuracy: 0.8891 - val_loss: 0.6618 - val_accuracy: 0.8442\n",
            "\n",
            "Epoch 00920: val_accuracy did not improve from 0.86293\n",
            "Epoch 921/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3051 - accuracy: 0.8924 - val_loss: 0.6676 - val_accuracy: 0.8318\n",
            "\n",
            "Epoch 00921: val_accuracy did not improve from 0.86293\n",
            "Epoch 922/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3552 - accuracy: 0.8885 - val_loss: 0.6815 - val_accuracy: 0.8442\n",
            "\n",
            "Epoch 00922: val_accuracy did not improve from 0.86293\n",
            "Epoch 923/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3735 - accuracy: 0.8944 - val_loss: 0.6392 - val_accuracy: 0.8505\n",
            "\n",
            "Epoch 00923: val_accuracy did not improve from 0.86293\n",
            "Epoch 924/1000\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 0.3079 - accuracy: 0.8966 - val_loss: 0.6626 - val_accuracy: 0.8411\n",
            "\n",
            "Epoch 00924: val_accuracy did not improve from 0.86293\n",
            "Epoch 925/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3003 - accuracy: 0.9059 - val_loss: 0.6670 - val_accuracy: 0.8411\n",
            "\n",
            "Epoch 00925: val_accuracy did not improve from 0.86293\n",
            "Epoch 926/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2948 - accuracy: 0.8798 - val_loss: 0.6634 - val_accuracy: 0.8411\n",
            "\n",
            "Epoch 00926: val_accuracy did not improve from 0.86293\n",
            "Epoch 927/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2605 - accuracy: 0.9024 - val_loss: 0.6353 - val_accuracy: 0.8505\n",
            "\n",
            "Epoch 00927: val_accuracy did not improve from 0.86293\n",
            "Epoch 928/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3603 - accuracy: 0.8692 - val_loss: 0.9633 - val_accuracy: 0.7757\n",
            "\n",
            "Epoch 00928: val_accuracy did not improve from 0.86293\n",
            "Epoch 929/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3777 - accuracy: 0.8974 - val_loss: 0.8721 - val_accuracy: 0.8193\n",
            "\n",
            "Epoch 00929: val_accuracy did not improve from 0.86293\n",
            "Epoch 930/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3901 - accuracy: 0.8780 - val_loss: 0.7901 - val_accuracy: 0.8193\n",
            "\n",
            "Epoch 00930: val_accuracy did not improve from 0.86293\n",
            "Epoch 931/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3503 - accuracy: 0.8937 - val_loss: 0.7087 - val_accuracy: 0.8349\n",
            "\n",
            "Epoch 00931: val_accuracy did not improve from 0.86293\n",
            "Epoch 932/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3457 - accuracy: 0.8855 - val_loss: 0.7185 - val_accuracy: 0.8318\n",
            "\n",
            "Epoch 00932: val_accuracy did not improve from 0.86293\n",
            "Epoch 933/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3080 - accuracy: 0.9073 - val_loss: 0.6630 - val_accuracy: 0.8411\n",
            "\n",
            "Epoch 00933: val_accuracy did not improve from 0.86293\n",
            "Epoch 934/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3587 - accuracy: 0.8814 - val_loss: 0.6684 - val_accuracy: 0.8349\n",
            "\n",
            "Epoch 00934: val_accuracy did not improve from 0.86293\n",
            "Epoch 935/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3119 - accuracy: 0.8931 - val_loss: 0.6590 - val_accuracy: 0.8318\n",
            "\n",
            "Epoch 00935: val_accuracy did not improve from 0.86293\n",
            "Epoch 936/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3233 - accuracy: 0.8900 - val_loss: 0.6785 - val_accuracy: 0.8349\n",
            "\n",
            "Epoch 00936: val_accuracy did not improve from 0.86293\n",
            "Epoch 937/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2813 - accuracy: 0.8843 - val_loss: 0.6773 - val_accuracy: 0.8380\n",
            "\n",
            "Epoch 00937: val_accuracy did not improve from 0.86293\n",
            "Epoch 938/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3223 - accuracy: 0.8786 - val_loss: 0.6671 - val_accuracy: 0.8442\n",
            "\n",
            "Epoch 00938: val_accuracy did not improve from 0.86293\n",
            "Epoch 939/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2873 - accuracy: 0.8940 - val_loss: 0.6003 - val_accuracy: 0.8411\n",
            "\n",
            "Epoch 00939: val_accuracy did not improve from 0.86293\n",
            "Epoch 940/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2653 - accuracy: 0.9123 - val_loss: 0.5967 - val_accuracy: 0.8442\n",
            "\n",
            "Epoch 00940: val_accuracy did not improve from 0.86293\n",
            "Epoch 941/1000\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 0.2918 - accuracy: 0.8916 - val_loss: 0.6620 - val_accuracy: 0.8474\n",
            "\n",
            "Epoch 00941: val_accuracy did not improve from 0.86293\n",
            "Epoch 942/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2644 - accuracy: 0.8952 - val_loss: 0.7118 - val_accuracy: 0.8349\n",
            "\n",
            "Epoch 00942: val_accuracy did not improve from 0.86293\n",
            "Epoch 943/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3231 - accuracy: 0.8716 - val_loss: 0.5951 - val_accuracy: 0.8474\n",
            "\n",
            "Epoch 00943: val_accuracy did not improve from 0.86293\n",
            "Epoch 944/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3162 - accuracy: 0.8933 - val_loss: 0.6052 - val_accuracy: 0.8411\n",
            "\n",
            "Epoch 00944: val_accuracy did not improve from 0.86293\n",
            "Epoch 945/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.2628 - accuracy: 0.9004 - val_loss: 0.6528 - val_accuracy: 0.8380\n",
            "\n",
            "Epoch 00945: val_accuracy did not improve from 0.86293\n",
            "Epoch 946/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2756 - accuracy: 0.9043 - val_loss: 0.5988 - val_accuracy: 0.8505\n",
            "\n",
            "Epoch 00946: val_accuracy did not improve from 0.86293\n",
            "Epoch 947/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2685 - accuracy: 0.9012 - val_loss: 0.6117 - val_accuracy: 0.8536\n",
            "\n",
            "Epoch 00947: val_accuracy did not improve from 0.86293\n",
            "Epoch 948/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3277 - accuracy: 0.8824 - val_loss: 0.6292 - val_accuracy: 0.8442\n",
            "\n",
            "Epoch 00948: val_accuracy did not improve from 0.86293\n",
            "Epoch 949/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2469 - accuracy: 0.9092 - val_loss: 0.6362 - val_accuracy: 0.8536\n",
            "\n",
            "Epoch 00949: val_accuracy did not improve from 0.86293\n",
            "Epoch 950/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2441 - accuracy: 0.9078 - val_loss: 0.6311 - val_accuracy: 0.8411\n",
            "\n",
            "Epoch 00950: val_accuracy did not improve from 0.86293\n",
            "Epoch 951/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2995 - accuracy: 0.9001 - val_loss: 0.5769 - val_accuracy: 0.8505\n",
            "\n",
            "Epoch 00951: val_accuracy did not improve from 0.86293\n",
            "Epoch 952/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.2629 - accuracy: 0.8970 - val_loss: 0.6102 - val_accuracy: 0.8505\n",
            "\n",
            "Epoch 00952: val_accuracy did not improve from 0.86293\n",
            "Epoch 953/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2751 - accuracy: 0.8918 - val_loss: 0.6205 - val_accuracy: 0.8380\n",
            "\n",
            "Epoch 00953: val_accuracy did not improve from 0.86293\n",
            "Epoch 954/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2807 - accuracy: 0.8878 - val_loss: 0.6074 - val_accuracy: 0.8442\n",
            "\n",
            "Epoch 00954: val_accuracy did not improve from 0.86293\n",
            "Epoch 955/1000\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 0.2580 - accuracy: 0.8989 - val_loss: 0.6433 - val_accuracy: 0.8442\n",
            "\n",
            "Epoch 00955: val_accuracy did not improve from 0.86293\n",
            "Epoch 956/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.2797 - accuracy: 0.9106 - val_loss: 0.6547 - val_accuracy: 0.8474\n",
            "\n",
            "Epoch 00956: val_accuracy did not improve from 0.86293\n",
            "Epoch 957/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2669 - accuracy: 0.8988 - val_loss: 0.6362 - val_accuracy: 0.8474\n",
            "\n",
            "Epoch 00957: val_accuracy did not improve from 0.86293\n",
            "Epoch 958/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2826 - accuracy: 0.8822 - val_loss: 0.6473 - val_accuracy: 0.8474\n",
            "\n",
            "Epoch 00958: val_accuracy did not improve from 0.86293\n",
            "Epoch 959/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2789 - accuracy: 0.9030 - val_loss: 0.7471 - val_accuracy: 0.8474\n",
            "\n",
            "Epoch 00959: val_accuracy did not improve from 0.86293\n",
            "Epoch 960/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2616 - accuracy: 0.8796 - val_loss: 0.7211 - val_accuracy: 0.8474\n",
            "\n",
            "Epoch 00960: val_accuracy did not improve from 0.86293\n",
            "Epoch 961/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2493 - accuracy: 0.9049 - val_loss: 0.6508 - val_accuracy: 0.8505\n",
            "\n",
            "Epoch 00961: val_accuracy did not improve from 0.86293\n",
            "Epoch 962/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2613 - accuracy: 0.9006 - val_loss: 0.6391 - val_accuracy: 0.8567\n",
            "\n",
            "Epoch 00962: val_accuracy did not improve from 0.86293\n",
            "Epoch 963/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.2523 - accuracy: 0.8970 - val_loss: 0.6112 - val_accuracy: 0.8598\n",
            "\n",
            "Epoch 00963: val_accuracy did not improve from 0.86293\n",
            "Epoch 964/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.2277 - accuracy: 0.9018 - val_loss: 0.6456 - val_accuracy: 0.8474\n",
            "\n",
            "Epoch 00964: val_accuracy did not improve from 0.86293\n",
            "Epoch 965/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2371 - accuracy: 0.9090 - val_loss: 0.6636 - val_accuracy: 0.8505\n",
            "\n",
            "Epoch 00965: val_accuracy did not improve from 0.86293\n",
            "Epoch 966/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2549 - accuracy: 0.8839 - val_loss: 0.6880 - val_accuracy: 0.8536\n",
            "\n",
            "Epoch 00966: val_accuracy did not improve from 0.86293\n",
            "Epoch 967/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2781 - accuracy: 0.9065 - val_loss: 0.6235 - val_accuracy: 0.8380\n",
            "\n",
            "Epoch 00967: val_accuracy did not improve from 0.86293\n",
            "Epoch 968/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2816 - accuracy: 0.8927 - val_loss: 0.5957 - val_accuracy: 0.8598\n",
            "\n",
            "Epoch 00968: val_accuracy did not improve from 0.86293\n",
            "Epoch 969/1000\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 0.2790 - accuracy: 0.8934 - val_loss: 0.6073 - val_accuracy: 0.8567\n",
            "\n",
            "Epoch 00969: val_accuracy did not improve from 0.86293\n",
            "Epoch 970/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2584 - accuracy: 0.9004 - val_loss: 0.6297 - val_accuracy: 0.8536\n",
            "\n",
            "Epoch 00970: val_accuracy did not improve from 0.86293\n",
            "Epoch 971/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3039 - accuracy: 0.8786 - val_loss: 0.6177 - val_accuracy: 0.8536\n",
            "\n",
            "Epoch 00971: val_accuracy did not improve from 0.86293\n",
            "Epoch 972/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2891 - accuracy: 0.8947 - val_loss: 0.6837 - val_accuracy: 0.8442\n",
            "\n",
            "Epoch 00972: val_accuracy did not improve from 0.86293\n",
            "Epoch 973/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.2830 - accuracy: 0.8705 - val_loss: 0.6565 - val_accuracy: 0.8411\n",
            "\n",
            "Epoch 00973: val_accuracy did not improve from 0.86293\n",
            "Epoch 974/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2466 - accuracy: 0.9079 - val_loss: 0.6972 - val_accuracy: 0.8380\n",
            "\n",
            "Epoch 00974: val_accuracy did not improve from 0.86293\n",
            "Epoch 975/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3032 - accuracy: 0.8845 - val_loss: 0.6361 - val_accuracy: 0.8505\n",
            "\n",
            "Epoch 00975: val_accuracy did not improve from 0.86293\n",
            "Epoch 976/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3518 - accuracy: 0.8867 - val_loss: 0.6157 - val_accuracy: 0.8474\n",
            "\n",
            "Epoch 00976: val_accuracy did not improve from 0.86293\n",
            "Epoch 977/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2745 - accuracy: 0.8969 - val_loss: 0.6599 - val_accuracy: 0.8442\n",
            "\n",
            "Epoch 00977: val_accuracy did not improve from 0.86293\n",
            "Epoch 978/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2502 - accuracy: 0.9119 - val_loss: 0.6620 - val_accuracy: 0.8411\n",
            "\n",
            "Epoch 00978: val_accuracy did not improve from 0.86293\n",
            "Epoch 979/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2687 - accuracy: 0.8958 - val_loss: 0.6538 - val_accuracy: 0.8411\n",
            "\n",
            "Epoch 00979: val_accuracy did not improve from 0.86293\n",
            "Epoch 980/1000\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 0.2342 - accuracy: 0.9076 - val_loss: 0.6328 - val_accuracy: 0.8442\n",
            "\n",
            "Epoch 00980: val_accuracy did not improve from 0.86293\n",
            "Epoch 981/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3019 - accuracy: 0.9008 - val_loss: 0.6577 - val_accuracy: 0.8442\n",
            "\n",
            "Epoch 00981: val_accuracy did not improve from 0.86293\n",
            "Epoch 982/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2539 - accuracy: 0.9030 - val_loss: 0.6865 - val_accuracy: 0.8411\n",
            "\n",
            "Epoch 00982: val_accuracy did not improve from 0.86293\n",
            "Epoch 983/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2479 - accuracy: 0.8965 - val_loss: 0.7582 - val_accuracy: 0.8318\n",
            "\n",
            "Epoch 00983: val_accuracy did not improve from 0.86293\n",
            "Epoch 984/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2633 - accuracy: 0.8996 - val_loss: 0.7929 - val_accuracy: 0.8318\n",
            "\n",
            "Epoch 00984: val_accuracy did not improve from 0.86293\n",
            "Epoch 985/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2366 - accuracy: 0.8947 - val_loss: 0.6401 - val_accuracy: 0.8536\n",
            "\n",
            "Epoch 00985: val_accuracy did not improve from 0.86293\n",
            "Epoch 986/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2495 - accuracy: 0.9032 - val_loss: 0.6684 - val_accuracy: 0.8380\n",
            "\n",
            "Epoch 00986: val_accuracy did not improve from 0.86293\n",
            "Epoch 987/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2770 - accuracy: 0.8847 - val_loss: 0.6393 - val_accuracy: 0.8505\n",
            "\n",
            "Epoch 00987: val_accuracy did not improve from 0.86293\n",
            "Epoch 988/1000\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 0.2634 - accuracy: 0.8958 - val_loss: 0.6777 - val_accuracy: 0.8505\n",
            "\n",
            "Epoch 00988: val_accuracy did not improve from 0.86293\n",
            "Epoch 989/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2605 - accuracy: 0.8940 - val_loss: 0.6443 - val_accuracy: 0.8536\n",
            "\n",
            "Epoch 00989: val_accuracy did not improve from 0.86293\n",
            "Epoch 990/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2938 - accuracy: 0.8822 - val_loss: 0.6639 - val_accuracy: 0.8442\n",
            "\n",
            "Epoch 00990: val_accuracy did not improve from 0.86293\n",
            "Epoch 991/1000\n",
            "41/41 [==============================] - 1s 22ms/step - loss: 0.2559 - accuracy: 0.8946 - val_loss: 0.6800 - val_accuracy: 0.8474\n",
            "\n",
            "Epoch 00991: val_accuracy did not improve from 0.86293\n",
            "Epoch 992/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2704 - accuracy: 0.8939 - val_loss: 0.6340 - val_accuracy: 0.8505\n",
            "\n",
            "Epoch 00992: val_accuracy did not improve from 0.86293\n",
            "Epoch 993/1000\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 0.2530 - accuracy: 0.9022 - val_loss: 0.6125 - val_accuracy: 0.8474\n",
            "\n",
            "Epoch 00993: val_accuracy did not improve from 0.86293\n",
            "Epoch 994/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2955 - accuracy: 0.8829 - val_loss: 0.6457 - val_accuracy: 0.8380\n",
            "\n",
            "Epoch 00994: val_accuracy did not improve from 0.86293\n",
            "Epoch 995/1000\n",
            "41/41 [==============================] - 1s 19ms/step - loss: 0.3233 - accuracy: 0.8776 - val_loss: 0.6094 - val_accuracy: 0.8505\n",
            "\n",
            "Epoch 00995: val_accuracy did not improve from 0.86293\n",
            "Epoch 996/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.3076 - accuracy: 0.8924 - val_loss: 0.6176 - val_accuracy: 0.8474\n",
            "\n",
            "Epoch 00996: val_accuracy did not improve from 0.86293\n",
            "Epoch 997/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2704 - accuracy: 0.8867 - val_loss: 0.6149 - val_accuracy: 0.8474\n",
            "\n",
            "Epoch 00997: val_accuracy did not improve from 0.86293\n",
            "Epoch 998/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2605 - accuracy: 0.9036 - val_loss: 0.5884 - val_accuracy: 0.8505\n",
            "\n",
            "Epoch 00998: val_accuracy did not improve from 0.86293\n",
            "Epoch 999/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2450 - accuracy: 0.9053 - val_loss: 0.6272 - val_accuracy: 0.8536\n",
            "\n",
            "Epoch 00999: val_accuracy did not improve from 0.86293\n",
            "Epoch 1000/1000\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 0.2533 - accuracy: 0.9005 - val_loss: 0.6304 - val_accuracy: 0.8442\n",
            "\n",
            "Epoch 01000: val_accuracy did not improve from 0.86293\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_mh1u3ubEALu",
        "outputId": "890a9012-bcbe-4a7f-9856-ca481278c7b6"
      },
      "source": [
        "# PLOT MODEL HISTORY OF ACCURACY AND LOSS OVER EPOCHS\n",
        "# Plot the results\n",
        "train_loss=model_history.history['loss']\n",
        "val_loss=model_history.history['val_loss']\n",
        "train_acc=model_history.history['accuracy']\n",
        "val_acc=model_history.history['val_accuracy']\n",
        "plt.rcParams['figure.dpi'] = 150 \n",
        "plt.figure(1,figsize=(7,5))\n",
        "plt.plot(train_loss)\n",
        "plt.plot(val_loss)\n",
        "plt.xlabel('Number of epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training loss vs Validation loss')\n",
        "plt.grid(True)\n",
        "plt.legend(['Training','Validation'], loc=1)\n",
        "plt.style.use(['seaborn-darkgrid'])\n",
        "\n",
        "plt.rcParams['figure.dpi'] = 150 \n",
        "plt.figure(2,figsize=(7,5))\n",
        "plt.plot(train_acc)\n",
        "plt.plot(val_acc)\n",
        "plt.xlabel('Number of epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training accuracy vs Validation accuracy')\n",
        "plt.grid(True)\n",
        "plt.legend(['Training','Validation'],loc=4)\n",
        "plt.style.use(['seaborn-darkgrid'])      \n",
        "\n",
        "# PRINT LOSS AND ACCURACY PERCENTAGE ON TEST SET\n",
        "print(\"Loss of the model is - \" , model.evaluate(x_test,y_test)[0])\n",
        "print(\"Accuracy of the model is - \" , model.evaluate(x_test,y_test)[1]*100 , \"%\") \n",
        "\n",
        "# PREDICTION LABELS\n",
        "predictions = model.predict(x_test, batch_size=32)\n",
        "predictions=predictions.argmax(axis=1)\n",
        "predictions\n",
        "predictions = predictions.astype(int).flatten()\n",
        "predictions = (lb.inverse_transform((predictions)))\n",
        "predictions = pd.DataFrame({'Predicted Values': predictions}) \n",
        "\n",
        "# ACTUAL LABELS\n",
        "TRUE = y_test.argmax(axis=1)\n",
        "TRUE = TRUE.astype(int).flatten()\n",
        "TRUE = (lb.inverse_transform((TRUE)))\n",
        "TRUE = pd.DataFrame({'TRUE Values': TRUE})\n",
        "\n",
        "# COMBINE PREDICTION AND ACTUAL LABELS\n",
        "finaldf = TRUE.join(predictions)\n",
        "finaldf[10:25] \n",
        "# CREATE CONFUSION MATRIX OF ACTUAL VS. PREDICTION -SGD-MFCC\n",
        "cm = confusion_matrix(TRUE, predictions)\n",
        "plt.figure(figsize = (9,7))\n",
        "plt.rcParams['figure.dpi'] = 150 \n",
        "cm = pd.DataFrame(cm , index = [i for i in lb.classes_] , columns = [i for i in lb.classes_])\n",
        "ax = sns.heatmap(cm, linecolor='white', cmap='Accent', linewidth=1, annot=True, fmt='')\n",
        "bottom, top = ax.get_ylim()\n",
        "ax.set_ylim(bottom + 0.6, top - 0.6)\n",
        "plt.title('Confusion Matrix', size=20)\n",
        "plt.xlabel('Predicted Classes', size=15)\n",
        "plt.ylabel('True Classes', size=15)\n",
        "plt.savefig('Initial_Model_Confusion_Matrix-SGD-SPECTROGRAM.png')\n",
        "plt.show() \n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(TRUE, predictions, target_names = ['Angry', 'Boredom', 'Disgust', 'Fear', 'Happy', 'Neutral','Sadness']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11/11 [==============================] - 0s 7ms/step - loss: 0.6304 - accuracy: 0.8442\n",
            "Loss of the model is -  0.6303622722625732\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.6304 - accuracy: 0.8442\n",
            "Accuracy of the model is -  84.42367315292358 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1050x750 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4sAAAKpCAYAAAAVALnqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAXEQAAFxEByibzPwAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdZ2AUVdcH8P9mk03vBQLpwAbTgYTeEUITAqg0QUFBEFBBkeJL8QFEpdp5EBWQR2mCICglCFITWhKSkAIhIYX03pPdnfdDmGFnd7aF0PT8PpFpe2d3Zpmz595zRQzDMCCEEEIIIYQQQpQYPekGEEIIIYQQQgh5+lCwSAghhBBCCCFEDQWLhBBCCCGEEELUULBICCGEEEIIIUQNBYuEEEIIIYQQQtRQsEgIIYQQQgghRA0Fi4QQQgghhBBC1FCwSAghhBBCCCFEDQWLhBBCCCGEEELUULBICCGEEEIIIUQNBYuEEEIIIYQQQtRQsEgIIYQQQgghRA0Fi4QQQgghhBBC1FCwSAghhBBCCCFEDQWLhJCn3pQpU+Dr64svv/zyoY8VHR0NX19f+Pr6tkDLCPl3yc7O5u6f7OxsbvnixYvh6+uLxYsXG3S8lry3tfnyyy/h6+uLKVOmPNLXIYSQfxrjJ90AQsjT48svv8RXX31l8H5jxozBJ5988gha1KRz586wtraGj4/PQx/L3t4egwYNaoFWEfLkFBUVoV+/fpDJZFi7di3Gjh2r137ff/89PvvsM1haWuL8+fOwsLBokfb4+fmhoqICfn5+LXK8lubj44NBgwahQ4cOT7ophBDyTKFgkRDCYR+oVKWmpiIrKwt2dnbo0qWL2vpH/YA4f/78FjuWVCrFN99802LHI+RJcHJyQv/+/REZGYmDBw/qHSz+9ttvAIARI0a0WKAIAFOnTsXUqVNb7HjN9c033+Dzzz/HqVOn4Obmxi0fMWIERowY8QRbRgghzyYKFgkhHE0PVGvWrMHOnTsp0CLkKfLSSy8hMjISV65cQVZWFtzd3bVun5CQgNTUVG7ff6K4uLgn3QRCCPlHoTGLhBBCyDOoT58+aN26NRiG4TKG2hw8eBBAU3Y9KCjoUTfviaBgkRBCWhYFi4SQFjNw4ED4+vri7NmzOHnyJIYPH47AwEBcu3aN20Ymk2H37t2YMmUKunXrBn9/f4SGhmLixInYt28fGIZRO65QEQzlQhv19fW4efMm5s2bh969eyMgIAADBw7EmjVrUFNTwzuWpgI3bIGO9evXQyaT4bvvvsMLL7yAkJAQdO7cGa+88gouXrwoeN5lZWVYtWoVBgwYgMDAQPTv3x+rVq1CaWkpzpw5A19fXwwcONCg97KsrAybNm1CREQEOnXqBH9/f/Ts2ROzZs1CdHS0xv1kMhl27NiB8ePHIzQ0FMHBwRg1ahS2bt2KhoYGwX2Sk5OxZMkSDBgwAAEBAejZsyfeeecdJCQkqG3Lvnea2qCp0MmjujZYkZGRmDlzJnr27ImAgAAMGjQIq1atQkFBAbfNxx9/DF9fX0yYMEHjcQAgPDwcvr6++P777zVuk5ubi44dO8LX1xexsbEat/vuu+/g6+uL559/nltWU1ODLVu2YNy4cejcuTMCAgLQr18/TJs2Db///rvW81QmFosxZswYAE3dS7Xt19DQgCNHjgDgZxXz8vKwevVqjBgxAiEhIQgICEDfvn2xYMECJCUl6dUOQHuBm6tXr+L1119HWFgYQkJCMGrUKGzfvh0KhULrMWNjY/Hee+9h4MCBCAgIQFBQEMLDw7FmzRoUFxcLvn5paSkAYNCgQbzvDG0Fburr67F9+3aMHz8eYWFhCAgIQO/evTF37lyN9zx7H6SlpSEzMxOLFy9G//79uX2XLFmCoqIivd47ZWlpafjwww8xZMgQBAUFcd9lH374ITIzMzXuV1JSgnXr1mH48OEIDg5Gly5dMGXKFPz5558a99HnngH0KwrG3t8HDhzglql+R3/11Vfo27ev2g8Vj/q7LiIiAr6+vti4caPGY+Xn53P3c3x8vMbtCPk3omCRENLi7ty5g/nz58PExATdu3eHmZkZAEChUGDWrFlYsWIFrly5grZt26Jnz55wdXXF9evX8X//939YsmSJwa93/fp1TJo0CYmJiejYsSO8vb2Rk5ODnTt3Yt68eQYdi2EYvP322/j8889hY2ODwMBAmJiY4MqVK3jjjTd4wQ0AlJeXY/z48di1axfy8/Ph7+8PT09P7Nu3DxMmTEBJSYnB51NYWIixY8diy5YtuHPnDvz8/NC9e3dIJBKcPn0ar776Kn799Ve1/SorKzFp0iR8/PHHSE1NRUBAAPz8/JCRkYENGzZg8uTJqKqq4u3z22+/4cUXX8SBAwdgaWmJbt26wcLCAseOHcP48ePx+++/G9x+bR7FtbFy5UrMmTMH58+fh4eHB0JDQ1FdXY1du3Zh9OjRuHXrFgBg3LhxAICYmBjcvXtX8FjJycnIyMiAWCzGqFGjNJ6Hq6srQkJCAAAnT57UuN2xY8cAgOveXV9fj0mTJmHTpk1ITU2FVCpFjx49YGtri4sXL+L999/HihUrtL2FPOPGjYNIJEJ2djYuX76scbszZ86grKwMEomEO69bt25h1KhR+Omnn5Cbm4ugoCCEhoZCJpPh6NGjeOmll3D+/Hm92yLk9OnTmDp1Ks6fPw+JRILQ0FCYm5tj3bp1WLRokcb9Dh8+jIkTJ+LIkSOQy+XcjwcFBQXYuXMnxowZg/z8fG57Pz8/9OrVi/u7V69eGDRokM6iWOXl5Zg0aRLWrl2LhIQEeHt7o2fPnrC0tMTJkycxbdo0rZVaMzIy8PLLL+P8+fNo3749pFIpSkpKcODAAUybNg2NjY16v1dRUVEYM2YM9u/fj8rKSnTu3BmdOnVCZWUl9u/fjzFjxiA5OVltv6SkJIwaNQrbtm1DVVUVQkND4eHhgcuXL+Pdd9/FypUr1fbR955pKfv378c333wDT09PdO7cmVv+OL7r2Pte2w8xx48fB8Mw6NChAwIDA1v03Al55jGEEKLD6tWrGalUyrzyyitatxswYAAjlUqZgQMHMt9++63a+pMnTzJSqZQJDAxkYmJieOuOHz/OSKVSRiqVMleuXOGte+WVVxipVMp88cUX3LKsrCxu+/79+zNbt25lFAoFt/7gwYPc+qSkJG55VFQUt1zZokWLuGMNHTqUycrK4tZVVVUxL7zwAiOVSpk5c+bw9luzZg0jlUqZsLAwJjk5mVuel5fHREREcO/JgAEDtL53ytj3Ozw8nCkqKuKWy2Qy7vW6dOnCVFVV8fb74IMPGKlUyowfP54pKyvjvVf9+/dnpFIp88knn3DL09LSGH9/f8bX15f5/fffueUKhYL54osvGKlUygQHB/PawL53UVFRgm1n38dFixbxlj+qa2P//v2MVCplunXrxqSkpHDLq6qqmBkzZjBSqZQZO3Yst3zs2LGMVCplPv/8c8H2b968mZFKpcyMGTME1yvbuXMnI5VKmSFDhgiuz87O5tp969YthmEY5ueff+b2KS4u5m0fGxvLhIWFMVKplImPj9f5+qxXX31V8D1XNmvWLEYqlTLz58/nls2ePZuRSqXMxIkTmerqam55XV0d8/bbbzNSqZR5/vnnecdRvu+U7xGhz72+vp7p06cPI5VKmXnz5jH19fXcujt37jD9+vVjQkJC1O7txsZGpmvXroxUKmXWrl3LyOVybl1+fj4zZMgQRiqVMkuWLNGrbQzDcNez6nfYwoULuevyzp07vHXstSWVSpno6GjeOuXvnlWrVjENDQ3cuujoaMbX15eRSqVMZGQko69Ro0YxUqmUefvtt3nHq6ioYCZNmsRIpVJm6tSpvH3q6+u59+Ojjz5iZDIZt+7cuXOMn58fI5VKmdOnT6udl773jKbvTGXs/f3rr79yy5Q/jyFDhqi9hwzzeL7rSktLmYCAAEYqlTKXLl0SbD/7/n733Xcaz5GQfyvKLBJCWpxCocDMmTMF10VERGDatGlcVoY1ZMgQBAcHAwDOnTtn0Ot16NABM2bMgEgk4paNHj0aDg4OAAwbx3Tv3j18+umnvEqKlpaWGD9+PADwuhwqFAocOnQIADBz5kxeN61WrVph06ZNyMvLM+hcAMDFxQUjRozA3Llz4ejoyC0Xi8WYP38+jIyMUFlZyWtLfn4+lwX86KOPYGtry61zc3PjMqyHDx+GXC4HAOzcuRONjY0YPHgwRo4cyW0vEokwd+5ctG3bFrW1tVx2rCW09LXBdhWdM2cOpFIpt9zS0hLLli0D0FTYRTW7ePjwYcEsw/Hjx7m26DJ06FAYGRkhIyNDMBPDHuu5555D+/btAYDr2jlw4EDu+mQFBwdjzZo1WLJkCczNzXW+PovtVnr8+HFUV1errS8pKeHeN+UuqN7e3hg6dCjmzZvHq4xqamqKt99+GwCQmZmJjIwMvdui7MKFC8jPz4eJiQlWrFgBiUTCe+0lS5aodRMHgOLiYgwdOhSDBg3CzJkzYWT04FHFxcUFr732GgDDvydU5efnc11zV6xYAW9vb976cePGYfDgwQCa7hUhVlZWWLp0KUxMTLhlXbt2hb+/PwD9v3vq6urQpUsXDBkyBHPnzuUdz9raGm+++SYA4MqVK6irq+PWRUZGIiMjA87Ozli8eDHEYjG3rnfv3njhhRcAgNc91NB7piUEBQWha9euassfx3ednZ0dV+Wb/b5WVlhYiOvXr+vsTUDIvxVVQyWEtLju3bvzHvBYzz//PG/slip3d3fExcWhsLDQoNdjH4iUiUQiuLu7o6SkhBvHpA8vLy/B4h9spcmysjJu2Z07d7i/+/fvL3isHj16GNyVb8aMGRrXmZubw9HREYWFhbz36eLFi5DL5XB1dRUcWzRixAh0794dDg4O3APl2bNnAQD9+vVT214kEuGXX36BRCKBnZ2dQe3XpiWvjZycHKSlpQEQfv/d3d0RGRkJe3t7WFlZAQBGjhyJTz75BFlZWbh27RpCQ0O57W/fvo20tDTY2tpqbQvL2dkZYWFhiI6OxokTJ9Tm8GODReVA3MbGBkDT51VWVqb23rLBiSEGDx4MOzs7lJWV4dixY1xAzDp8+DAaGxvh5uaG7t27c8sXLlyo8ZjKlVWLiorg5eVlcLvYLtv+/v68QIA1YMAAmJqaor6+nre8VatW+Oijj3S2rTljApWx94ytrS169+4tuM3gwYNx8uRJREVFCa4fMWKE4PXs4eGBhIQEvb97zMzMsHz5co3r2XOWy+UoLS2Fq6srgAcBc8+ePXnBOGvx4sVYsGAB98NEc+6ZlqDcRVjZ4/quGzduHP78808cP34cK1as4Lq/A8CJEyegUCjQt29fuLi4NPcUCfnHomCRENLiWrVqpXX9tWvXEB0djby8PJSWlnKZrps3bwKAzsIXqjw8PASXm5qaAoBB44Y0TT8gdKzs7GwATYGVp6en4H4hISHNGvfV0NCAv//+GwkJCSgoKEBFRQWXCausrATAf59u376ts/1t2rTh/q6trUVOTo7WfXR9js3RktcGe85GRka8c1Omem42NjYYPHgwjhw5gkOHDvGCRTaDOmzYMMEHbyEjRoxAdHQ0IiMjMWfOHG55Xl4e4uLiIBKJeMHi2LFjsXv3biQnJ2PYsGEYNWoU+vTpg9DQUN4DrCHYcYg7d+7EwYMH1YJFtgoqO75RWXV1Nf766y+kpKSgsLAQVVVVahlX9jMwFFuQRdO9IZFI4OHhoTGDlZeXh1OnTuHu3bsoLCzkgko2ADP0e0IVe/34+PgIBnzsOqDpnisoKFALJlryuwdoOrdTp04hLS0NhYWFXOZVOZuo/Hnouu9Vf4xozj3TErTd94/6uw5oClZdXV2Rm5uLkydP8n5gZH/UYYtFEUL4KFgkhLQ45W5BysrLy/Huu+9qrDDYXPo+2Lf0sdgHGXNzc163MWVOTk4GtyE5ORlz5szhglF9lJeXA2jqSqaPiooK7t/67tMSWvLaYM/ZzMyM1/1OlxdffBFHjhzBsWPHsGzZMu4zb85D45AhQ7Bq1SrcvHkTOTk5aNu2LXcshmEQFhaG1q1bc9v7+Phg27ZtWL58OVJSUrB9+3Zs374dEokEPXv2xPjx4w2unMue086dO3H16lXenIvJyclITk6GWCxWCyIvXbqEBQsWNKsIkz7YAiPaMlTW1taCy3/44Qds3LjR4GDLEOz9y2Z7hSi3r7KyUi1YbMnvniNHjmDZsmWCXXM1MfS+b+4987A0vceP47sOaAqOIyIi8O233+LQoUNcsFhSUoKrV6/CxsaG66pKCOGjMYuEkBanmr1gLVu2DBcvXoSFhQU++OADnDhxAnFxcUhJSUFKSsoz98uu0Jg3VZreC03q6uowe/ZsZGdnw8vLC5999hnOnTuHhIQE7n1iAxJlbGZE0/QY2tql7z4toSWvDfacDQ0ounfvjrZt26KiogKnTp0C0FTVMjU1Fd7e3mpjJrWxt7dHjx49APCrorKBp1AX6ZCQEBw6dAg7duzAa6+9Bm9vbzQ0NODMmTOYPXs23nnnHYOzeb6+vggKCgLDMFwmEXgwVq1Pnz687E5BQQHmzp2LkpISBAYG4quvvsKlS5dw8+ZN7j1/WOz9oe0eEMoOnjlzBp9++ikaGxsxYsQI/O9//8OVK1eQnJyMlJQUjeMHHwXle9zQe9kQycnJWLRoEWpqatC7d29s27YNUVFRSEpKQkpKCnedqmLbpO893Nx75mEJZW4f13cdi82sX7x4kevWGhkZCblcjmHDhnHZYEIIHwWLhJDHoqSkhHuY/vDDD/H666/D09OT1/VOuavVs4AtClJXV6fx4V51Pjhdzp49i3v37kEkEmHr1q0YPXo0XFxceJlLofeJzdgpj6nUxtbWlnvQZH+pbwnNCTybe22w59zY2ChY2EUTkUiEsWPHAgCOHj0KAPjjjz8ANK8r2vDhwwE8CBYLCgoQExMDExMThIeHa2xD9+7dsWTJEhw7dgwnTpzAtGnTIBKJcOzYMezfv9/gdrDFa9g5F2UymeDcikDTeVdVVcHKygrff/89Bg8ezBvj1RL3Int/qE7Xokzoet29ezcAIDQ0FBs3bkRoaChsbGy467WlvifY60c5y65KeZ2mrHhL2L9/P2QyGTw8PPDtt9+iT58+sLe35wIj1XGdLLabqb73cHPvGV2ac98/ru86lru7O7p27Qq5XM7NP/kw9z0h/xYULBJCHousrCwui9CnTx+19QqFwqCqpU8DdlyMQqHAvXv3BLfRNmG7ELbypIeHh+BYr8zMTMEAtF27dgCaxlEKZWvq6+sRGRmJyMhI1NTUwNTUlPvVXtOcg0lJSYiMjERCQgK3zNjYmDuetvYbornXBnvOADROWH7x4kVERkZy4zNZY8eOhZGREc6dO4eamhocPXoURkZGGD16tMHtHzx4MCQSCa5fv47S0lJERkZCoVCgd+/eehcH8vT0xOLFizFt2jSu3YYaPnw4LCwskJOTg/j4eERHR6O4uBhOTk5qxUzYzykoKEgwCIqJiTH49VWxFYWzsrIE19fU1Kh9LsCD61FT0ZmWaBsAriDR7du3Nf7Yk5qaCgBwcHAQLNLTUtjPo1u3boJdW69fvy64HzumUtM9nJeXh8jISK4QTnPuGfaeB4Tv+6qqKoN/FAMe33edMrYr9okTJ1BYWIjLly/Dy8sLnTp1Mrj9hPxbULBICHkslMctCT1wHDx4kAu4ZDLZY2vXw2jfvj03xYFQEZvMzEyDH/rZMVKagrGvv/6a+7fyA27v3r1hZGSE8vJyXLhwQW2/ixcvYs6cOVi4cCH38MdWQdU0NcaHH36IOXPm8KYoYIMfoQDgzp07XCEaQzT32mjTpg33wM9mCJRVVFRgxowZmDNnjtoUJm3atEGPHj1QV1eHbdu24fbt2+jRowdvfKEh7e/bty8UCgUuXryIv/76CwDUyvDX1dVh3bp1mDt3rsZugGwAr+nz19WOoUOHAmjKcrKZzoiICN4DP6D9OlMoFPjmm2+4v5tb4Iad7iQ+Pl4w83XixAnB90Fb24qLi7nMI8C/HpS7iepT/KZnz54wMTFBZWWlxmk42HtD6EeMlqTtnOvq6rjpLgD+58HewxcvXhR8j3fs2IE5c+bghx9+ANC8e0b5Bw+h+/7o0aPNKjb0OL/rWOHh4bC2tsa1a9ewa9cuyOVyyioSogMFi4SQx8Ld3Z0rSLBr1y5uOcMw+PXXX7F27VquamR6evoTaaOhJBIJVxRhy5YtvCINBQUFePfdd3nzNeqjY8eOAB5kBFi1tbVYvXo14uPjuV/B79y5w613cnLi5gZctWoVL9OZl5eHTz/9FEDTL+ts5uLVV1+FiYkJYmJisGXLFm57hmHwww8/IDExEWZmZryHqYCAAADA3r17edMCFBQU4P33329WBdWHuTbeeOMNAMD27dtx6dIlbnltbS2WLVsGmUwGX19fdO7cWe112SzD1q1bAeg3t6ImbFfUEydOIDo6GhYWFmqFaszMzHD27FmcPHkSq1evVutiV1BQgJ9//hlAU4apOdjupidOnOCuH9UuqMCD6ywuLg7x8fHc8rKyMixYsABisZgLXJWvM0P07dsXtra2aGhowJo1a3iB3a1bt7B+/XrBwids244cOcLranj79m1MmzaNV4hEuW3KGdLExESd7XNycuK6I69atYoXCDEMgx07duD8+fMwMTHB9OnT9TnlZmPP+fTp07zvkdzcXMycORNBQUFc90zlcx40aBC8vLxQW1uLxYsX866pq1evctfTxIkTueWG3jOenp7c57Rt2zbe5xgbG4tNmzbB2dm52ef8OL7rWGZmZhg+fDgUCgW+//77ZvcmIOTfhKqhEkIeC4lEglmzZmHDhg3cQ5irqytu376NgoICrF69Gk5OTjhy5AgSEhLw0ksvISIiApMnT37STdfq3Xffxfnz55GXl4fhw4cjODgYYrEYMTExeO655/DSSy9h5cqVeh+vU6dO6N27N86fP4958+YhODgYpqamSEhIgLGxMX788UccPXoUMTEx2LlzJ1JSUjB79myEhYVh6dKlSE1NRUJCAsLDwxESEgKFQoGEhATU1dUhODgY7777Lvdanp6eWL16NZYuXYpNmzbh119/haenJ+7evYvMzEwYGxtj9erVvGzbG2+8gbNnzyI5ORnh4eHw9fWFSCRCXFwcOnXqhIEDB+LLL7806D18mGsjIiIC169fx549e/Daa68hICAANjY2SEpKQmlpKRwcHLBhwwbB4iSDBw+Gra0tysvLYWlp2aw5DlkDBgyAubk5N2fb0KFDBafCWLVqFaZNm4bdu3fj8OHDeO6552BtbY2ysjIkJiaisbERXbp0afZ137lzZ7Rv356bXiAsLExwjsRhw4Zhy5YtuHXrFiZOnMg9lMfFxcHJyQk//fQT1q1bh5ycHKxfvx6nT5/Ghx9+aFD1TysrKyxZsgSLFy/GoUOHEBUVBV9fX5SXlyMhIQHPP/88ZDKZWvGWmTNn4rfffkNWVhbCw8Ph7++PsrIy3Lx5E7169cLy5cvx999/o7CwEK+//jqCg4Px1VdfwcrKCr6+vkhJScHChQvxxRdfwMfHh5ehUvXBBx8gNTUVMTExGDZsGKRSKaytrXHnzh0UFBRALBZjxYoVXGDzqEyePBk7duxAcXExXnjhBQQHB6Ourg7x8fGQSqX46quvkJ6ejhs3bmDx4sUIDAzEpk2bYG1tjc8//xyvvvoq/vrrL/Tv3x/+/v4oLS3lAuZJkyZhyJAh3GsZes8YGxtj+vTp2Lx5Mw4ePIjo6Gj4+Phwn+OcOXNw7do1g+fHfZzfdcpefPFF7NmzB42NjejRowc3ZyUhRBhlFgkhj82MGTOwcOFCeHl5ITMzEykpKfD19cX27dsxbtw49O3bFxMnToS1tTXS09Mfe8W+5nB3d8fevXsxdOhQWFhYIC4uDgUFBZg5cyZ+/PFHLhug2h1Km82bN2PChAlwdHREQkIC99C8b98++Pn54fXXX0fPnj1hbGyMW7ducQ911tbW+OWXX/Dee++hXbt2SEhIQHx8PDw9PfHee+9h165datMYREREYM+ePRg2bBhqa2sRFRWFqqoqhIeHY8+ePWrVPMPCwrBt2zZ07doVMpmMO98ZM2Zg69atGuer0+Vhro3//Oc/2LRpE7p3747s7GxcuXIFFhYWeOWVV3Do0CGu250q5czwsGHDuC7FzWFhYYEBAwZw3fGU51ZUFhISgt9++w3Tp09H27ZtkZaWhnPnziEjIwMhISFYuXIlduzY8VBTMrz44ouC/1YmFovx/fffY+TIkbC0tERsbCwKCgowYcIE7NmzB23btsWCBQsQFBQEuVyOjIyMZk21MGbMGGzduhVdu3ZFVVUVLl++jOrqarzzzjvYuHGjYEDt5uaG7du3o3v37mhoaEBsbCwUCgUWLVqEb7/9FqamplizZg3atm2LsrIyFBUVcft++umnCAgIgEgkQnFxsc6Ml5WVFXbu3ImlS5fCz88Pd+/exbVr1yAWizFq1Cjs379fMDPb0qysrPDTTz9hwIABEIvFiI2NRWVlJWbNmoWffvoJNjY2WL58Odq3b8+N9WTv+44dO+LIkSOYMmUKrK2tcfnyZWRkZKBr167YvHkzVqxYofZ6ht4zs2fPxrJlyyCVSlFcXIzY2FgYGRnhs88+w7x585p93o/zu44VFBTEZc2pCyohuokYfWq/E0IIaZbvvvsO69evR0hICPbs2fOkm0OUyOVyhIeHIysrC/v27UNQUNCTbhIh5BHLzMxEeHg4bGxscPbsWZoygxAdqBsqIYQ8hBs3biApKQlubm7o1auX2vqoqCgAgL+//+NuGtHh0KFDyMrKQqdOnShQJORf4ptvvoFCocCECRMoUCREDxQsEkLIQzhz5gy+/vprODs7Y8eOHbzS9Pv378f58+chEomou9NT5urVq1i1ahUAYMGCBU+4NYSQx2H79u04ePAg7OzsHnnRIkL+KShYJISQhzB9+nScPXsW8fHxGDlyJFcsIj09nZunbO7cuQgMDHzCLSUA8Oabb6K0tBQ3btwAwxzztHMAACAASURBVDB444030LVr1yfdLELII5KcnIzNmzcjIyMD6enpMDY2xtq1awXnFyWEqKMxi4QQ8pCqqqqwfft2nDx5EpmZmWhoaICdnR0CAwMxceJEbi408uSFhISgvr4eHh4emDJlCl555ZUn3SRCyCN0/fp1TJkyBSKRCH5+fpg/fz569OjxpJtFyDODgkVCCCGEEEIIIWpo6gxCCCGEEEIIIWooWCSEEEIIIYQQooaCRUIIIYQQQgghaihYJIQQQgghhBCihoJFQgghhBBCCCFqKFgkhBBCCCGEEKLG+Ek34FlWWFj5pJvAY29vAQAoLa15wi0h/wR0PZGWRNcTaUl0PZGWRNcTaUlP6/Xk7GzdrP0os0gIIYQQQgghRA0Fi4QQQgghhBBC1FCwSAghhBBCCCFEDQWLhBBCCCGEEELUULBICCGEEEIIIUQNBYuEEEIIIYQQQtRQsEgIIYQQQgghRA0Fi4QQQgghhBBC1FCwSAghhBBCCCFEDQWLhBBCCCGEEELUULBICCGEEEIIIUQNBYuEEEIIIYQQQtRQsEgIIYQQQgghRA0Fi4QQQgghhBBC1FCwSAghhBBCCCFEDQWLhBBCCCGEEELUULBICCGEEEIIIUQNBYuEEEIIIYQQQtRQsEgIIYQQQgghRA0Fi4QQQgghhBBC1FCwSAghhBBCCCFEDQWLhBBCCCGEEELUGD/pBjSHTCbD9u3bcejQIdy9exdisRj+/v6YNm0aBg0apNcx/v77b+zYsQPx8fGoq6uDm5sbIiIiMG3aNEgkkkd8BoQQQgghhBDydHsmM4sLFizAunXr4OXlhY8++giLFi1CbW0t3nrrLfzyyy8699++fTtmzpyJ1NRUTJ8+HatWrYJUKsXGjRvxzjvvPIYzIIQQQggh5PFiGAY/XcnCpjNpKKlpeNLNeaYxDIPKOhlvWVW9DAoF84Ra9Gg8c5nFyMhIHD9+HCNHjsSGDRu45RERERg1ahQ+/fRThIeHw8HBQXD//Px8rF+/HlZWVjhw4ABcXFy4/VevXo2ffvoJf/zxB4YPH/5YzocQQgghhPwzxOWU42J6CYb7tYKngwW3XKZgYGwkatYxFQwDEQCRqHn7K/vrVhG+OJt+/7jAewPaPfQxhURllCAupwKjA1ujtY0Zb51cwUDczPfC0ONo2uZSRgni71UgItAVLtamBr+2TMFg5u5YJOZVYm4fb0wJc8fvCXlYc/IWPBzMceitngYf82n1zGUW9+/fDwCYNm0ab7mZmRnGjx+P2tpaHDlyROP+58+fR2NjI0aMGMEFiqy33noLYrEYBw8ebPmGE0IIIYSQh5JeXIM913NQWFX/pJuipry2Ee8cSMAP0VlYeiSJW/591F30++I8lv2RDIYxLOtUVtOICTuuYdDXl3A1s0xtfW5FHX65noO7JTV6HW/Fnyncv3dfzzGoLfrKq6jDuwcTsS0qE59E3uaWN8oVmLk7FoO/uYQzt4oe6jUiUwrx/DcXMXtvHGRyBW8de418fS4d/b+8gA+PJPHe93vldZh/MBHfXcrEZ6du8/aNyS7H9uhM7Lichbicco2v/8fNfMTnVkLBgAu+/3M8FXIFg/SiGuy+kv1Q5/c0eeYyi7GxsTA1NYWfn5/aus6dOwMAYmJiMHXqVMH9CwsLAQAeHh5q6xwcHNC6dWvExcW1YIsJIYQQQsjDUDAMzqUV4/1DNwEA60+nwcbMGBV1Mng7WGDNyI7o4Gz1UK+RX1mP+HsV6O5lDytTwx+RL2WUorpBDgBILaxGdYMMDANsuXAXAHAsqQARga3Rxd1O4zFO3yrC5jNp6OJuh2XhUpxMLUR6cVMgOHvfDUQv6AMjkQgMw+B6djlm7b0BANhlJcGB17vC1Fh7Hqhexg+sZu2NQ0WdDKtHdISPoyVvnUzB4P+OJiGloAqLn++Abp72er0PvyfkQ36/K+aF9BJu+aH4PMTkVAAAFh6+iSvv9dV5rMS8SlTVyRDmaQcjpczqkvvB+NWschxOzMfYIFcAQG2jHG/uiUNpbSO37YmUpmf/69nlGOzrDAXDcO37O62Y2y69uAaz9sZBuRfp232bsobJ+ZUorGpAD28HGBuJEJPNDySPJubz/o7PKccYP35S6ln1TAWLVVVVKC0thaenJ4yM1G+GNm3aAAAyMzM1HsPKqumLpKSkRHC9RCJBeXk5KisrYW1trbU99vYWWtc/bmJx03vytLWLPJvoeiItia4n0pLoevr3iLpTjHUnUpFRXINypQAAACrujxdLL6nBkqPJODVfd/AhRCw2Qm2DHK/+LwbF1Q0Y1NEF/32ls8HHqVYZq1ahAHLKannLzmaU4vmgNhqP8eHRJDTKGdxLzMeozm2RWszPGCYU1aBPeycsOhCPg7H3uOUFVQ3IqWlEFz0DOta1rKagZ/mfKTg6rzdv3a7oTJxKbcoAfnrqNk6/1w8XbhdhY+Qt9PBxxPtDpLzty2sbkZxXCYWY3+3T2FwCazNjJBZU8ZYL3b+VdY1IvFeBTu52uJFTjtf+FwMAWD3aHxPC3AXPYe3JW4jKLMO6cYE4fCOPFyiy2IDxl+s58HLkv+7XF+/iRk458srroDrc8Iuz6Qhr54Sp/4sBwwDvD5aiv68zjqgEhyuPpfD+lhgb/WO+n56pYLG6uhoAYG5uLrieXV5VVSW4HgC6du0KkUiE48ePY/78+TAxMeHWxcXFIT29KZVcU1OjM1gkhBBCCHlUckpr4WApgblE/KSbopfy2kas+SMJxxPz4dfGBjP7eGOAr+7sSlW9DPfKatHBxUptXN6K328irbBa5zHuFtdg2/l0vNHbG9X1Mnx6PAX1jQosGuoLuYKBkQhwtNI8Nu3v1EIUVzcVfDmVXIAGmQISYyOcTinAT1GZ6NnOESMCXeFqa6a2b0ZRNVztzHFbJRjKLKnBpTv85MSZ+0GLEJlcgUb5g2jltMC2h+Lu4aMjScgU6HaalFcJaStrFFXVw8vRAiKRCPkVdRAbiWBqLMZvsZq7nabkV6Goqh4NMgXa2DU9T++/9qArZVZpLZYfTsTPl7MAAHHZ5RgZ5Ip2zpbILKlBG1tzDPviPAoq1bsHn0kpwNCA1pCoZD3rGuUwM3lwbWeW1CDim4uoqJNhqH8rJN6r4Nb936FEWErEeCG4DWrvZ2+VnU4pROjHf2k8P2UZKgH49kt3tW4/5ccr3L/Xn0xFwj3N3VNZ+RVPXzfp5nqmgkVdA3v16QculUoxZswYHDhwALNmzcIHH3wAW1tbREVFYcOGDXBzc0N2djYviNSktFS//uGPC/sLxtPWLvJsouuJtCS6nkhLelaup9pGObbff7ie1tWd92CsDcMw2HklG1+dS4etmTH2TwuDnUXTc0lmaS12Xc1CgKsNRgW01ngMBcNge3QWyusaMa2bB+zMdT/XPKxvL2TgQExTtutKRilS8ipxfHYPrYVdahvlePnHq8irrMe4YFcsfr4Dt65eptArUGR9ciwFTqZipBXVcEHNzXvluFVYDQXDYNOYAFzPLoeJkQivKn0e9vYWqK7nV7VMzCiBq60Z5u+NQ1W9HGdvFeGTYykYF+wKM2MxTMQivBjSBr/dyMW2qEy0sTGFqTH/803ILMXNbP44w3vldUjPKec+T2V5FXW8v+8WVqNSpV2H43I1nv/K32/i02PJqG1UYFYvT/i6WGH+wUQd79oD3T85DQBYP9of/do7IqeUnxVl31PWphMpiMupQFF1AxwtJVywrWr+vhvYeTED7vb8ZM/VW4Xwd7UB0NT99oPDN7l1x1Qyd+xxglwsUVYrU1v3OAm1TVV2ac1T9/3k7Ny8JNgzFSyyXUhraoTffDbzqCsjuHz5cjAMg0OHDmHUqFEAgFatWmHRokX4448/kJubS1lFQggh5Cl0KaMEqddy8HKoG5QfPetlChy4kQsTIxEiAlvD+H5X1YepQvmw9sfeww9RTUNjbEyNMTnUTWebZAoGb/zSVGURAMrrZBj87SUcmdkNraxNseH0bVxML8XBG3n4K7UIy4dK4WChPj/0saQCfHshAwBgbCTClFB37Iu9hza2Zhj6nEuLVKNUxZ4rq6JOhi/P3sHbfX00vl50Riny7mejfo3LRZ92jujl3VTRPkPPoi3Ktl68i1SlADMp/0G2750DCdy/98Xew5bxwWjv1DROr0xlGom7pbXIr6pHVT0/i/WrUrC2XSl4uieQSWLHKqpKKahCNy/17qI/RvODMeXxfvqqbVRofW19fHwyFX3bdRfszqmM7aIKQGOgyIrJqUCVSkbwtZ9j8XJIGywc1B6LlAJFbVafuAUHgUD7aXOvvA4KhuGNs3xWPVPBooWFBZydnZGXlwe5XA6xmP8LTnZ2U7rc29tb63HMzc3xySefYNGiRbh79y4sLS3Rrl07GBkZ4auvvoKnp6demUVCCCGEPD55FU1VDOUKBom5Ffhs5HPcut9u5GLj6TQAgIVEjOF+rfDRsRScTCnEjB6eeLWr8HinR4mtkggAm/++g8mhbvgk8haOJOZjejcPTO+uXmzvj5v5XKCobOTWaHz7UhAuppdyyy6kl2DzmTsY5ueCnLI6jPRvxWXLlKte7rySjfJaGQ4l5AEArmSVYeVQ3xY7T21+vpaD61nlGBPUGsP8WsFcKbt6Mb0EC1WChDO3ihDkaoM/buYjrVj/rCLrrko2TJPyOhnePZCA314Pw9lbhfj6TBpvfWZpDUprtAdLzZUsECwm5FbgwA3NWcPHqaSmEW/tu9Hix70lkCXeG3sPAW2soW+N2NMPWUX1cVEomoroGImf/WDxmZs6o3PnzmhoaBCsWHr58mUAQFhYmF7Hsre3R0hICDp06AAjIyOkp6cjPT0dffr0adE2E0IIIeTh/Rafx1UxVB3Ptf70g4f9FX+m4HZRNY4k5qNepsBX59Ihewomys4orsGvcbmolynw7YUMKASGz8Rmax4PNVvgAf7PpAK8/WsCPj11G5//fUfjvmygCDRVbszUM6jSpbCqHlN3XcfIrdEat0kuqMLayNv4r0q2a82JVLVt43IqMPDri1h/Og0Hb+SprddFtdqnNvmV9Xhz7w1M33FNLTC8mlWG48kFBr++PoSmuTh/x/AsIgBM6+aOhQNbfq7Eq1m6x+W1lOV/pOje6CFZmxpjfCfNhYU0eau3F5yt1DP32thbmGDugHYwET9zYZagZ+4sJkyYAAD4/vvvecsrKyuxd+9e2NnZYfjw4dyytLQ0XuXT2tpajBw5EiNHjkRDw4OUOcMw+Oyzz2BiYoKJEyc+hjMhhBBC/t2uZZXhtf/FYNOZNI11ByJTCjF55zVsPJ3GTUvAkmsJAFULTAgV3tDlVmGVWjEM1rZLdzF113X8fbtYcP3hePVA557KmLS6RvXApkhHdz5t9sfloq5RrlfAdONeOYqq6nE9u0zvQJphGMTfq0BeRR3kCgYx2eV450ACkvKrkK/H+/u/a9n45nw6FAyDukY5CqrUzzW9GV1PH8YNpSIqyi6mlwq2Tx+trU3Rv72jxvWNAu93cz93J0sJ+rbT/FotTepsqXujx2xcsCsWDWqPuX2EexZ297THnte6YMGAdujkZqv3cT8a5otp3Tzwx5vdMVVDJVZVvbwdcGXpIMwd0F7v13naPVPdUAGgZ8+eePHFF7F//37Mnj0bQ4YMQU1NDX755RcUFRVh48aN3NjGkydPYsmSJZg+fToWLVoEoKkLar9+/bBt2zZMnToVY8eOhUgkwuHDh3H58mUsXbpUZzdWQgghhDy8tSdv4W5pLRLzKhHmYYfePvyH3ka5AmtOpqKqXs4bh8aqrJMJFgoBgIp6fqYoo6QGO69kobSmEe8NaAcXa82VMYGm7pBsF8ktLwfx5sa7U1yN/15sypK9fyhRbb642kY5VglkzZQrXbLbWahUOn2YYBEALmaUoo2N9nMDgNO3irHuVBpqGuUIcLXGF2MDYW2m/bHw52s52Pz3HRgbiTDY1xl/JhmeefsxOgvOVqbo4NSyQYeDhQlKHlG30dEBrbFkcAcsPZKEv/ToBlnVIINfa2uc0fBDgtCPHKrVTfe+FgoAmLjjKuRaYnlHSwlaWZvCUiJW+zHFEK92dcfsXl6I2HaZG0MqZHKoG6+Ls5Ce3vbwsLfAsOdckJBbgXV/pWnd/mHsmNwJfq0f1BkxEgFfn0uH1MUKAzo4wcHCBC8EtObGDm4Y7Y+fr2VjW5TmafZ8HC0woXNbhHd8UMl3end32Jkb87qWq5rWzR0vhRievXzaPXPBIgCsWrUKfn5+2Lt3L1asWAGJRILg4GAsX74cXbt21bn/+++/j9atW2Pfvn1Yu3YtRCIR/P39sXXrVvTr1+8xnAEhhBDyZJXVNsLWzFhnpfFHZX/sPd74sqOJ+VywWFUvg0RshIS8CrUCI8q2X85qejBvpT4Ze5FKVmjrxbvcWECRCPjkBT+t7Vv3123u3+/9logz83pxf8fl8LNRVfUy3iTueRrK5tfL+OdS2yjn9jczNoKx2Ag5ZXVCu+rtamaZXtmTs0qTkSfkVuKb8+lYpFSJVMjm+91cZQqmWYEia3t0Job7tWr2/qomdm6Lq1lljyRYDHW3xTv9mgr0TOzcVq9g0b+1NToKXJMsoe7HyvfC5jEB8L4/F+Bno/1x/k4xLtwpEcx0mhmLIRKJIHWxUpsoXsic3l74+nyG2vJxwa4QG4ngbCXRGiza6ygu08bGFBsiArgCTg0GdAtW9k4/HzhYmGgNTFUDRQCYEuaOMUGusJSIBb/brM2M8WYvL5y7U4KUAuGp9jZE+MPNjl+51VJijClh7ujbzhFTdl1Hg0yhFsS/1fufmWx6JoNFIyMjTJ48GZMnT9a63dixYzF27Fi15SKRCFOmTMGUKVMeVRMJIYSQp9b3UXfx3wt3EeBqg+8mBLd4ZUwFw+BQfB4q62R4MaSNWvYsJrscn566zVvGZtSiMkrw/qGbenWl/N/9eeAOxauvU80AKBeNOZVapBbgKZPJFbwHc9WMjWqGMLusFh1bWUOuYCASae7yWqUyDUJtoxwX0kuw6PBNWErE2DYhBDWNzc8OAcDlu6U4qkdpf1W/J+ZjVi8v2GqYYkMowNEkvKMzIlOLNHYTLqhqwE9XsgTX6dLDyx6XMh4U+XGwMMGCAe0wb388bsHwgjiqXG1M8f7A9vg17h66edpjfKe23P0R4maLad3c1aqWKjMSAfP6+KhNE6FM+X05lVqIX+NyeYGu1OVB1rVvO0f0beeItSdvCRbAaX+/W+hIv1Zag0VnKwl2v9oFNmYmcLCQqGW+be5nlXVNsWKhMv1LqLstb3zjvL4+vEq/wW1tEOhqjfhc9aJN2vT2doCXo4XGYPG5VlYaA3JN97WykhrNGXzVQFGZp4MF/pzVHTUNckzccQ3ldU92Go/H4Zkbs0gIIYQQw8gUDI4k5iEypRAKhsGWC3fBAIjPrcCpVM2ThGtTVtuIX67nICFXfczXubQSfHzyFr48l46flSb2Zn11Tr0r1+2iavx8LRvzfk0wqEhJcykHHMpOJBdg0NeX1Jb/72o2KuqaHugLqvjBYHZZHf6+XYR+X17A5J3XcUfDuDvVB8vaRgWW/p6EepkCJTWN+PBoksb2hnd0VlsW3MZGbdnd0tpmBZz1MgWS8jU/0OszJpE1JsgVf7zZDdsmBMNVQ5dYNt42NhJhWjft48HWjfLDuGBXhHrYYV5ffvaGDXIcLB+uin1ESBt8Nz4YP0/tgr7tHPH52EBM6uKm9kPK7F5egvs7Wkqw57UuOPRGV/i2soKFRIy1I58Du3cbWzNuWzZYvHGvAot/T8KVzAdzMXo5mMPJUr2gilCRlYUD26HV/e7Uw/xcuGykqrFBrvhlalOgCACjAltjVAA/s8sGgULTsLCGPecC/9bW3Ll087RT++Gkt48D72+RSIQ3enjylpkaaw8/5vbxhtf9c5nVy1Nt/axenvhuQshDTUtRoqG7d09v9SlNVFlKjOFsZYq6x/A99TR4JjOLhBBCCNHf3pgcbDrT1IVwrdJ0EwCQUlCNIR0NP+aaE6k4c7sYpsZG2D8tFK1tHjwMrzr+IBvw34t31R4WcyvUu1pW1cu5Nj4O2WUPuv01yhU4l1YMD3sLfHg0WXD7zX/fwe7rOfjv+GC1wGnJkQdB3u2iam4KD1Wq3VNrG+W8wE55TkBVAa42OJ7MD+y3TQxBYVU9YnMqsPSI5kBTX/UyzdnDdA2FfoT4OFrA3kICBwsJfpjUCTfuVaCrhx3e2B2LtCL+cZ5rZY3npc5q2bpunnbIKKnF2CBX9O/ghP4dnARfiw0YHLUEOUBT19B+7R3xjUAXTABwsTZFiB7ddzV127aUiOHjyB+H+byvM1xtzVBR14is0jquazObWNxyQb0tb/f1EXwN1WDRy8EcL3dqy/1tIjbCf18OwuGEfLUfY/q0c1DLGA99zgWHEx5koNnXFOpm2sHZEtamxninnw+MxUbYMakTYnPKEeZph4M38hB3v0iQpUTMTd2izEcliB3YwQmV9TKNFWCVp7l5rasHTt8q5nUZ7ePjqDPg1GWYXyscuZ+BtzY1hpeDOQARlg2R6n2Mwb7O3DE8tGSSn3UULBJCCCHPmOoGGf5zLBVltY1YFi7V2m0KAC8I26ASyLDZMkPkVdRxxTvqZQrM2B0HazNj9PZx0DluR6Zg1MYTPgnKk4h/fS4D/7uWzes+JySvsh4r/0zWe044VcrTVwDApjP6F/6w0VB8xtnKFIN9nbHlQsZDT4ch19LVNMOAKqX2SoGbk6UEA+8Hem1tzdWCRTc7M7VuygDwf0OkvB8glM3s4Ymtl5oKDL3TzwdAU3fHn65qbtPYIFf09HHQGCwGttW/SmZ4R2e1wF21eybL//6Yunvl97hlcgUDBcPgpsB8mj28hDNbzlb8DK25wOvZW0gQEdhaLVi0F+haGupuh6HPueDCnRK8rZStVQ0WX+3qrlZl1M7ChAveR/q3wh8381Fa04jPRgmPA26lUkzKRCzSu1uz2EiEfu0cecGirkJM+pjZ0xMJuRVolDPYPCaAy2QaYk5vLyTnV6GmUY5PXnhO9w7PKAoWCSGEkGfMHzcLuEIbS48k4YtxgahrlAs+XDfK+V2lVKttGlp9M7eiDi/9yH8qz6usR15lPW4VVqNfO0eN84tV1smw+PebzQ62WlJx9YMgmR37qM8UEjE5wlMt6EN1DJ9q4KSNtakx5vf34QL/RYP4pfk1BZOvhLrBwcIEu65mo1HOYEhHZ/waJzz5u7apSPQNFscEtda4TiJwXbjZmQlmo5ysNFd0fSXMDVZmxrAzN+aCq77tHPHRMF/cuFeBzm628HWxwuSfrqNepoClRIz+HRwFX18sAjp72GOIXytUlOsXbC8Y0E49WBQIePmv8+CHCDnD4F55nWD1UmMN945qdq5BLtwFUmi8ntA4VJFIhFXDO0LBMLzunKo/mAz3c1HdlcfO3AT/m9KZO6YQkUiEvu0cuaJKL4W0ESyyw65TpRpYWusxJlEXVxszruJsc4t8OVmZ4uep2s/9n4CCRUIIIeQZsz/2QZYiKb8KQ7dEgWEYbIjwV5t+QlPFP9b5OyX4ISoTr3Vz12sM0Jdn07WOKTyeXKgxQ7cnJgeXlcZnPUnaClw8jSxNxRgb5IqaBjlEIuCFAH5QJhQkbIzwR5/7c/BN7OIGmVyB6LtlGoNFmYL/uf51qwhn04rxckgbjfNNutmZoZ2jJf5OK4aLlQRv9dKcWe7b3gGRKmNk3ezM1bJyIqgHLcrMTcSY2Lktb5lIJMJwv1a8Kqtbxwfj94Q8DOnoAhszE7W5PCd1aYuZPT3R1sXaoId9BwsJpoS64aerD8bj6goWjZTOR8EwglngN3uqj89jtbYxw6iAVlzX0VClqVyUCRWr0lbBVPWeD27zIMPq42ih1rVWiD7v3fsD28HVxhQdW1mhYytrtc9i4cD2yKuowythbmr7qn7b6Hqv9dUSAd4/OUhkUbBICCGEPGM87M1xR+nhnc0I/edYKk681YO3rT5jzb69kAE3OzMM6ag9i9AoVyAuR3t5/pt5lTAW8x+gGIaBSCTi5iY0xNw+3jASqVc3tbcwQamOqRIsJWIM7OCE3wWqg7LBor7d4To4W+KWwFyPj4tYJIKZiVht/CfLRiVYnNvHmwsUgabgy9hIrDEDCfAzi6U1DfjwSBJkCgZxOeUapzD55AU/+LpYIbeiDg4WEq1jyZ6XOiP6bhmvWquTpQRmJvx9WioY8GttzZtaQfXBXgQRLCXNmz7G0pTfRk3dUFnKmUWZnMFnKtWAxwW7YnKoeqCkbOHA9rAyNUZZbSNvXJ8qFysJV83X1NgIlhL9H/d9W1nh3X4+SMitwOsarrXmcLUxw/sDH2TDVaedeLmT5vkJFSoZ74cpbEMMR8EiIYQQ8pSRKRgcis9FbkU9+rd3RIArv+qlpkxBaa168KRvafdPT93WGCzWyxSYvTcOt4uqUduovQJgSkEVXFW6w9Y0yg16YGU5WkrwUkgbGImaCseU1TbiBf/WGBXqDlNjIyw7EI9frudo3L+NrRle7+GB4poG3Cuvg5eDBTfWkp2q4Fya8MTpyr4bHwx/V2uM+G807z3u4+OAcxqKdABNlTOPJOYhqxlzJ/Zv78ib1F25mqYQ1XFcmsZ16QoWbxdVIyqjFAoFw3XLzdbSfof716LqZy7ERGyElUN9UVrTgIvppXCxkiC4ra3aw39LBYu6hHkKZ+f0oXo96+yGqpTxYwvCsF4MdtU5xyUAmJmIMb9/O53b9fJxwMEbeTAzNsK2CSE6t1elK2htCc9LnXD1fi8DXdN1dHG3xfbLzZtqhTw8ChYJIYSQR+TGvQoUVdWjX3sn7mGxpKYB8w8morpehnWj/QXL3f8YlckV8PjlWjYOvdGVN4arTkfAxjqbVozP/9avwmhF3NqGDAAAIABJREFUnQwvbI1GG1szrB/tzws2frmWrfc8aXUyhVqhlPJaGSwlxrCUiNXGaalm7No5WWD7pE6IvlsG/9ZW3EP4R8MelGxls1e6Jgj3drBAW1tzfD42EEDTeEs2AKuokyGztBbvH7qp9Rg2ZsZclUxPB3OU5jwIFod0dEFsTgUq64UDcmcrCQZ3dMEPUZlaX0OIsZEISwd3wK6r2RgV0FqtwIkq1XFcts0IFivr5Ziz74ZBk9vretAX8vHI53A1swyBbWwEM5G6snQP4/OxAdj89x10drNFTw3FZPRhqRIc6uyGqiUZ5uFgeHEVbT4Y2B69vB3h7Wjx1FbpHB3oiquZ5bhbWoMlOgLlbp72eDHYFdeyy/FOX5/H1ELComCREEIIeQTicsoxc08cFEzTvGCvd2/q0rUv5h5XBXHJkZvY/Woob7/qBhkvW9YgZxCfWwkLSQ3aO1nC0VKCWi3z6JXVNnIP8O/9lmhQm9lCNV+fT8dipQc4tpiOvgpV5iGsqGtEG1szWJka84LFsUGuWDK4A8I2nOWWFVU1wMxEjH7t+WMvhegKVLp58oMB1TnktkfrDuKUgzDV+i9dPe1gb2GiMVi0kIjhqfKwrm93Vr/W1hgT5IoxQa46t1Vtp9DfupYDwNnbRQYFigA0FjPSxlJijH7thafCAB5tZrGntwN6ejvo3lAHf1dr3t+BrupzXirTNgazsx5TdhjCWGyk1/3zJBkbibBWzwqiIpFIr8wreTQebpISQgghhAh650ACF1x8d+lBUPJb/IPpE4SqYX57PkMt+Pjg8E3M3R+P0dsu46/UQq3B4ozdsahrxqTsyn6Ny+VVUVWdH1AX1a6qbFdY1SwS+xomSmMcO2so3CFEdUqADs78YhxdVboZmhob8bJWt4v4QZtYBOyfxg/elYOr4Db8gMDBQsJ1wxRibiJGG5Xumd5askgbI/xhamyEtrZmagVsdFHtdmprJtwuocqjrEwd3WUdLExwYHoY2I8r1KP53Ti1Uc3aPY18HC2xeWwAXg5pg5VDfTFAwzyQLE3j7D4b1TTmk5CnFQWLhBBCSAurlyl4GTTlwiFudvzgIU9pgvrqBpnGSpXscRf9noSaBs3dUDNKanHgRi5qBMryGyLtfiDFMIzgWEhDlN/fX7UCJDvObdOYAIhFTd0PZ/XSv6iGamYx1N0Ooe5NWZrBvs6CU4koB1VJ+fxKsXKmaU445WBlsK8z9+/xndtyweOq4U3dYu21TAZvbiJGBxdLLkC1NTPWOp9bn3aOODWnJ/ZPDzO4e6dqgNWcueiKdUyjEuZhB3d7c3w88jlM6NwWS1sw29Pb50G2b0qY5uItT5Ne3g5YOKg9Rvi3EqxCqsxIYP3cPt46g0xCnjTqhkoIIYS0oKOJ+Thzm99t09XmwXgz1QxDYl4lF9TkVtTrNddfVYP2ojUnUwofuqvdlF0x2Do+WOe4QH3k35/MXtX4zk0VELt52uP47B4QG4kEp4DQxE6lbRYSMb5+KQi5FXVqGT2WlakY+RqGX9qaGcPMRIz/DO+Io4n5GNDBCeEdHwSLraxNcfTNbqhpkMPRsilItDPX3F4LEzEsJcb4z/CO+DMpH6MDWyOzRPtcftqqiRpC29jE5gq6P63CQKkzBkqddWxtmAX928HWzBg+jpYaJ6Z/lgkFk/3aPd1dRQkBKFgkhBBCWkxMdjlWHktRW64cAKpm6bKUsm26MjusEh3bFVU1qI0bbI6Ze+LUunY2x+XMMkRllPKW7XstFDZKXSWFJg7XRTX7Jlc0TTDe1lZzUQ9tY/Y+uD/Rfd92juir4UHe3EQMc6WunGbGmrtMslNC9GvvyI0hq20UHv85v//DFe5QnXBeW1fOqWHu2HklC6bGRghpa4Pou/rNfTnEt2UDRGXu9uZYqVTE6J9GLJB4tNHyQwMhTwu6SgkhhJD75AoG59KKYWduwlXANITq3Gms6vtz1O2Nuac272Fe5YOgTt9gUdd0GLWNchRWtcyk89qKsXS53+Wzul6OkpoGbm43VaqBIgC0ttFe3VMfqtmzBrnuKrFCmUtvRwv83xApAlWKluhDW4EXoUItfX0cMNjXGdF3S+Hf2hpv9vJCXaP8oYucdPeyh4OFCUpqGtHVw07r3IFv9fZCVw87eDqYY6uec19OCXVTy+QS/QmNWRTTfIHkGUDBIiGEEIKmyphfn8/g/t46Phid9HiA3xuTgwM3cjG+U1sUaQj2ahrlWHgokTdvHute+YMxi0XNCPB+ebULJu64xltWXifDij/VM5wbI/yxQEOFVF8XK6QUVAmuEzK9uwdm9/Li/l75ZzKO3izQe/+W6G6p+gBeL9MdLAplFhcObIegNtqrWWoiEUoZ3WcuUEzGWGyEj0fqVwXSEGYmYnw/MQTXs8rRV0clTLGRCN3ud/XUNdYOAJ6XOmNOH+8Waee/ldD7bKzl2iHkaUEFbgghhPzr5ZTX8gJFAJi974ZaQRZVRVX1WPdXGtKKavDxyVso01IIRihQBIBLGaVg7s9LqBxsulhpLpyizNxEv//KXW1M0dPbAetH+2N+fx/08eGPadw1pTPc7XRPrM5S7QJqo6H6pibaMl/N1VbHxPWAerDYwdkSYR7NHyPnrmUeO22VRx8FNztzjApsbVBxHH2CxfcG+Oi1HdFMKItobPRsPoabJeyC7W8vQ5IR+aSbQh6DZ/MqJYQQQlqQatdQoKlL6rgfruBYkuZsWWKefhPV6/LthQwA/GCxnZN+YwX1mcDc1cYUn7zgB7GRCP3aO2JSFzcsGdwBtmbGEBuJsG6UHwDNXSq9HSwwOpA/lYPqtBXNqb7ZEhYObA8RgDa2ZngppI3O7a1M+e/X+E6699FmSEcXjeM6tc2t97TQ1cbl4VI4WT18l+F/u/9n77zDpKiyNv5W6BwmMwwwQxxyVkABBRMgKGBYkVVBVIzrurq6q+unsqtrXHXVNa64KioCJjCiIgYUkJyz5Dixc6yq74+aDpW6qyeH+3seHrqqblXd7ulQb51z3qMmtluiAKf85bD/9H8wHv0FWZ9fC0RS31AjtHyIWCQQCARCmyfVRdvXO7XF4uE0fen0smTrSQC1E4sWA6Po/5dMcbYZH18/HH3bS+vxCuwmfH7TGfjyphEYW2PfLzdJidE514LRMndVeUQtk2jW9WeU6B6bjiuGdMAXN5+BD68bpiuSJ69ZrKsQYmkK71wzFF/cNKLOwrMpSCdYLupX2Egzad2otc5oiVmojPsgKD5RM208uKwJZ6MDQYB5y5uwrn4KVMgFyl8O28rHYdqxoKln1mIgNYsEAoFAIKTAncJM5nCaNFW9+EJR/LK/EhuOuOLrTi/Oxjtrj6Td18TSuO+CUjz/42/4Zb/USCbbYsCTU/ppCgITS8PEJtJdtSKLViODsaX5eGpyXyzaeAwDOjjRTyY+2zv0ia5/X9ofI+u5NUK+TV/KLqAUi3rTfVNBUxQK7CbYMmj70VxIF1lsiHThtohcGLI01SJfWzpQKVk2/fYlwj0uaqLZpMe0+0M4fvw/AADFR0AFq2DZPh8A4LLkI9zlvKacXouARBYJBAKB0CbgBQGrDlTil/2V4AVpL8NARNsYxR2SisVghMNXO05hx0kP9ldoO4WmwsTSePeaoYljRnnc8dFWyfahxVl49pJ+KY9jNTCgKArd82147tIBCtOYudMHo4fOCCUAGDRCHTGjlrGl+XjxdwNxc5KxTYwiHfWCADAijVNnQyPvYllQjymW04d0jP8NWkpEriWkymYCFaiAaeci0N5jTT0VCfIbNi0xBRUA6IC09QvjPtxEM9GH89s/xR9b178UF4oAkPX5zKaYUouj5d0CIxAIBAKhFizfU457P90BAPjnpN4Y17sd5q05jE+3nYw3WFfDI4ssvrjiAN5ffxQsTUn6J2aCiaWRnyKidVa3XFgMDDql6BcIAH1lrR7kl5/y+rx0aKWh6q2LlNO/yIGtxxN1nVlmFmyKVhONQUTmmJpVj7WW2VYD5l09FDtOejC2R369HbchSSVarj69UyPOpH7I+uJ6GE6sBecoRuXVPwF087jUlTv3tlSRTgWkRl10QN24qzlA+dV7mkoI+wBj3XvJtmZIZJFAIBAIrZK95T6U+8LYW+bDnz7aGheKAHD/5ztxwh3E8z/ux/4KP9Ye0m5K7g5KHU7fX38UAGotFAHAzNKwG7UvYq8/ozMAwJ5CyPzhrK74x4W9JOvkEVNbinOooWXlb0nR4D35XPJG8EM6SluPZFLX2FCc1zM/fqE+tFNWvUc5u+ZZMbFvoWqPxeaIlli8+5zuuOHM+qstbRQifhhOrAUAMJ7DYMu2ptmh8ZC7oWqKRUEAU74diChNtxoCyl8O2nVA93i5OKQCOgRZPUMFq8CUbQNTsQNUWLvdj6Fss2RZYJXZD5atb6Y/IRcW30uCACrsBXtqMyCofP8LvPi3Cyj7yrZkmsftFgKBQCAQ6pH31x/F08v3wWZkEIryqsJub7m+FNIwJyAY4WA2MPEWF3XFbGBgZGkYGQphTnrM83rmo0eNu6ZaT8AYM4cXK9ZxsueZaS/DukQWAUCuuyb2K8S8pLrLg/VU41kX8u0mPDWlL9YcqsZlg1qeIU19o9a+4YzOOZg2tGMTzKZuyFMkQTWfmIjeNFTbyn/CuuEVcPYiVE7/vkGjXkzlbuQsGA+Kj8A14VWEu09Ku4/8NaYjPiAaANjUWRD1BeUvQ+7740AHygAAvDkXlVevgGBSmnwxlbul+0aVhmT2lY8hmt8PkZKx6icUeOQsmgS2YgdC3SeCKd8B1rUfgT5XwnvuvyRDrWufh+3Xf0EwZ4G7ZQ0Aa62eY3Oj+XyKCAQCgUCoJxZsEKN/vjCnGQFMZVwjx1NTt5jJPqmIiTi52QogbUmRqdjj6qhlNWsWdUbJzu6eaAY/uX+hol5Sq8VErYgG1e/u62B0tzzcObY7SlL0SGwrqIkWW4bpyw1GNLObC7Q87ZALqw9saFTmLdfkWpFF64ZXAACM9zgs2+Zpn0MQMn595DiW3QmKFzMnsr66SXsgH42/lmppp3LTm5Qkz1lFvKXDtvrJuFAEADpYCdvqJ8Q5ymArd+k6pnnXRwAXAgRl7brh6EqwFWJWimnfF2Bd+wEAlh3vJ6K/0QDAhWD7VRSPVNAFavvHGT2v5gwRiwQCgUBoNRx3B/Hm6kM4oqOlxQl3KOX2ZKHmqhGJJz2p9wGk7ppje+Th/J7K2rVY/ZKaWHTqqKG7+5zuacfUBk03VJ2RxevP6IxRXXMxpX973H1uDwDAfy4bEN8+Y5gyGlobqB2LwTzdAzkLxpE+b3VETbTo/Xs3JPblf0X+qz1h//5e3fsoUiSjjZPKGUcQ4PzqRuS/1hvWNc9KNsnTUOU1jLH9k9FMo+WjyPr4cuS/1huWjf+t1VQt6/4Dw6lNaccxFTuQ97+hyH37TDBV+xQ1i4BKRFcD+/f3Iv+1XrD9+ADsy/4sPl75WEbzNu/8QLHOsuUt5L49QpFOK48samE8+B3y3hqBvLkDwVTslGyjItoZKAWv9UTBi52Q/3p/FLwi/U6mPMd1nbslQMQigUAgEFoNf/tsB15ccUDX2GOu1IIyWbR5MhCLM4cXY0CRE2d2ycED43uiZzu75lh1sZi6ru/1Kwfhigbq56eVhmrRKR5Kciz496X98X/je8b3GdElB+9eMxRvTB+MCX3a1cs8mQ9ngYr4wVbsgHkn6ZdWF9Qii01db0kFKmDZ/i4oCLBse0f3Rb9CLDZS3V8MtnwrTPu+ACVwsP36NMAl6p3lr7OaVqRCLskyHVSP2BmOrIDx+GpQAgf7z3/P/IaJIMC+6nFdQ7O+uAF0sBKM/yRsq58A7S9TjFFEdFWgPUdh2fYOKIGHdcv/YNm5AJTAwbr+RYDndM2FCnvjkVA5jO8kzEm9E6lgNdjy7bqOS4eqQQfKQYeqkfX5LNlJ038WKE7ld6EV1S2SmkUCgUAgtAoCEU7ivJmO3WXaxgiAWC9Y5hVTr9wZiMXu+Ta88ftEvZeaAIvVPtpVLsodKSKL2RYDBslMY+oTrTRUq7Fu95ZTCeaMkV1YsrJIQKtCEGD/8X4Yjq2Gd9SDiJSMqfdTqKahNrFYZDzS/qK5889FoN818I55VF1l1SA3W2k0schF4Pj2jzDv/VSymnHtB5fbE4A0kliAarwYeRHZH1rgHv8SeHsHgIsga/GVkv2Nh38Ee3IDooVDJOsNp7ZIlgteK0W4eAxo3wlEC/rDc+7TgCDA8c3tYKv3wTP2cUTbnwYAsK56Auadi3Q/NcZ9MP7YtO8L1TGO7+5CxXVJUUpBgP2n/4PhyEr4Rt6PcJfzwFTt0T4JHwFo9fcce2oTHN/dA7ZiOwSF37MU47FVMC6cKM6Zj2oKy1QwnsNSh1Q1IagHT/Nq3VIXSGSRQCAQCK2CdGmlcnacTC0Wk1sqxBxR9+kwxZHXGWqldgLqETtnClObCKfdD7I+qGsaamOQfPEKALy9qIlm0vAYD34Hy9a3wVbuQtaX1zfIOdTSUI0Z1srWN2o9Ei3b5sFwbFXq/ZooDdW8Y4FCKALSNMhkUT6d+Q5DhW0wnFgLx3d3i8fYNg+GcmXaqf2nhxTr1NxLjYd/AFu5C+ZdH8Ky+Q0YD30P877PwFbsQPbHl8f3s617AYzvhPoTkdd4qtTwqUEHKkQX0BoMR3+BZctbYKt2w/HN7QAANlV0OMV5spZcBbZCPDal6JIqxXB8DQxlm0GHXKLxTi0xHfw2/ri2Nxwo99Fan7+5QSKLBAKBQGgVHHNnbpagxROT++KzrYkLKm+YA8cLWL43fU8xueA6u3sunvpOfeyBSuWFiNOi/dPcPb9h+4F1D2zG84Z38QU3Al/xw+PrTWwzEovySKKKsUVjYNr1AYwHvkNg0A2Ith/aIOcwHvgm/piKBuH89BoIJif8w+4El9OjdgeNBGBb/STAR+EfcbeqWDSoOKQ2JOZt78BwdCX8Q28Dl9UFWV/OVh2X/cnv4B96K3zD7gJU2iDIa+fU3C/1z+ldGI6sQGDorWCPr4Xh+K+IthsMw9GfIRgd8A+7E8b9S8FW7obhyArVY2QtvRll3Q4ANCupWZzJLo0/Nh7+EdZfn4ZNVuMYw3ByPWj3YfDORL1vOuMW+8//QKjr+PgyxUfAVO0DU2POooXjuz+D9h5HuGQsAkNvAy2L8KYid8E48JY8cPaOkpYVdNiN7IUXwlC2RXNfio8qZKDh2GrYVswBHdJua6QH3uhEYMgtsK55GpTsu4I32FRFpW3VEzDt/VQUz4x2P9yUELFIIBAIBELz4niaGkS93H5WV5xbmo/vdidqcwJhDqsPVqHCl95d0SQTi+2dZvxzUm/c/3lC5MQujAodJkU7CadJWrP4ryl9cc/i7WAZCvePK0157hnDivH2msMAgCkD2qedq5xZ+/4AMMBkZiUGBV+DC2L6aCNrh5TITT8auy4NAGj3YTiW3QVK4MFW7kLV9GUNch55LZTp0HJxfcQH96Q3a3VM68ZXYd0kmqII1gIwtisVYwyNGFlkKnbCUWNiw7gPI9xpVMrx1vUvIZrdA6E+Vyi2yV05a/veoF0H4fj+rwAgjRgmPTYe+FZX9Mq4/2uEu0+UfIaOCAXIoxIp81pCMYZp76cIDL1VXIgGdbl8mvYvlSwb938FwZQ6hd28W3TwNB5bhWi7gaA47TROzlqIaLuBMCXd0KADFapuqamEIgBAkNUsCgIc3/wRjLd2gos3ZcM1ZT4ACtHs7oDBgkC/3yP/jUHScfYOoFXSYxn3ITDuQxmft3rqImR/8jsAoiMquBDAmGr1HJoTRCwSCAQCoUWx4rcKHKwMYHL/9nCYWYSjPIwsjeMZpqFqUegQf9yTTT58YQ7vrdN3l10thW9c73YSsRhj5vBi/HpIeufcLmtbMKZHPhbPHg4zSyPHmvou96wRxagOhBHhBPxhdFdd840jEyZ96YNYyfdDaYENXXOl/cKMB5aBqd6HYO8rIJizMztPLWCPr4Hx6CoEe18O02/SuqlUboUNQiSA7I+mgqpJnWMrd2V0UciWbYHxwDIEe04Fn9Ul9WCN1g96jTvUiNn7A2IbAvaC6YoxBq2G8Q2AecfCxHlProfh5Pq0+7DV+xDxHIN5x3yA5xDsOx28szizmsVoEOadCyEYbMCIq8SejIIA094lMG97N+0c9KY5Gk5tBuM5CsrSHoAo1nKhv7YaENNcwRhBe44BjAFULVpm2FY/hUyqzwzH14K35Glup8MeRIqGI1ks1hqeAyIBmHfMh2DORaTD8FoLRQAIDJiJaMEAyTpB5blECwaATVVLmSGRDmcgUjAQhrLNEAoHtAqhCBCxSCAQCIQm5kClH5uPuTG2R15aJ9Bdp7y48+NtAIBvd5chwgnYdcqLPoV2XS0n9MDXxP2S6wkr/WH8ejAh6mYOL8Zbvx5W3T+Teq/hnXPwzjVDcfU88QK5c44F7RzKC4wipzLlTg27icUD43vpPn8yVEh6ARsQTPj7hb1wTmk+qKQUOqZ8O7I+nyk+dh0QTUcaEMp3CtlLfg8qGoB529tgvFJLeiqcuva0vrGufxGM76RkHe09AT6rc9p9qWAVshZPBx2qhmnvp2kjknRQ3VFRa31tkLd0ALRdcRsCiq/FTZ6IH45vb4fx2GoAgOnAt6iatlTZwiFFzaJl0+txR1AuNx9CzwthPLQczq9vy3w+KbCu/w8AwA5gBPUA1gi9UEhl0JcQoji2r5ijWB/qPgnhTqPh+OG+tMeQp2CmPWflLnApbmbwljxwebX7rpFDCVFYNr4iOsgC8A+8Lu0+nLUQjP+k6jb/sLt0nTfU4yKYd3+kf6I1VE5fDipUjZyPLpFuoChUT12EXPcGCJ2GAfVXGdGkNKPEEgKBQCC0NbyhKGa9twEPL92Nf3ylbYBwqCqAX/ZX4r+/JMxNth73YNcpUSjsOOnF6oOZ1baYEMbv7FtRBGnalC8kpkQlO0J+tu1kPHXUzNK4eWRnjO2RByMVxdn0JrRPOoZRw1FUi17t7Pjy5jMwZ0IvvDptkHr/tUaACkvFYgQszuqWpzDhsa77T/yxZevbtT+hIIA9sQ5sUq83KlgF4/5vJI27LVvfikdS5EIRaPw0VNvafyvWMSqGLGpYtrwVr8ESI5LqaX6U75QYvVUxMgEAKhoAU5E+FZEt2wrjgWUw7v8GlIbAVHNDZTN8D6siCDAcWw22bIv4+MjPYMq2gSnfDsORnxM9BaOZi0XDqU1xoQgAbMV2mHe8r0iBNB5eoehdGCO5dQT9/T8BAI5v/5TxXDJhgelhFKECRip9qwjX+FcQzU0txoI9pyJUOqW+pieBqdytajQUwzv6QUQKh4I3Out+Mp6PC0UAsG5+I+0uwb5XgnMo+7aGOp+r6awqJ6ziLpzOcRUAuNxSRIuGqW802iCUjgMsObrm0BIgkUUCgUAgNBnL95TDWyPOfthXAUEQ4lGsl38+gC3H3Jg6oD0eXrobwWj9OoE+zP4PV0R/QNRmwVDfc3DDDpamMLaHmK6k1Vuwa54VLEPjqSn9YFuxCNZNryMgGDEy9Dyq4NQVlZFfv+bbjJjUr7DOz6ku0DKxyIBTb6Uhdy4UhJTtDLQw7vscWUtvBgC4Lnob4eKzkbPoIjDugwiVnAP3xfPEeWgIphhUpHEji2qkuqhOxihL2aOiAQiMNJpOhb3InX9uWmOP3PfPQ/m16yHY1HtXGo6uRNbiafF0Wc7ZGZW//14yRmBMqsKwPiKLpl0fwLnsTgBAsPtFMO/7TLLdO3oOAoNu0IyS+ofcgnDxWbD/9JAiVVAtVdWx/B7FOrZqN0x7l6QXVDW99LT6GtYnbxsTIpU3OiSfO4G1wnP2IwBrQrj7RLDV+8Cufkr1OLzBjnDJOQ2W6shU/wbBqN7yxj3uJYS7TgAoCq6pC2Da+znARyAYrPGbN4LRDioaAOcsidekxvAPmh2vmxUH186kyjX5XRj3fw37L48kDmXJ138AxgTO3kFys8d10dswHlkBKuKHZdu8Ws2rtUEiiwQCgUBoMuSiyRMSLxp+PViFN1YdwppD1bj/8531LhRz4MYV7A8AAJYLYPF5fswYVoynp/ZDvl28+NLqNdclqX7Puul1AICFCuPaGodDrTTUcb0K4o9nj0yfsqgF5S8Tm3BH/KBUzCRqfVyZWGTBqT8Xg7R+0XBsFWjvcUDgQXv01xnFhCIA2JffA9Puj+NtMUyHlsf7KTJpjklFfKC9x0CFPeqiLRoA5S8D7T6syzmVCrkUzdERDYKuST3lnMq/Ha0S8RQHRxJzEgSw5Tuk+8nTJgGY9nyi2wHSsu0dzW3OL2+IC0VAbDkiF6uC0QFLuAoOSKOzWv02MyEmFAEohCIAWH99GrT7sOrfTGBM8I28H5HisxEYrO6Mqhf78r8q1lGyJvJCdmfAp2w2X1sE1qK5rTudeK9w2d3gH/qH+LJv2J0I9blCFLcUjVCPizWPE+42XnSErWMmQrDnJarrKYGD4eQGxfpAn2kIlU6OnzdaMAC+M++Fb9QD8A//M3yjHhAfD7sTvjP/hmC/qxXH8I1+CEJSs3tKozYXEG8aqBEuHgMuuxsCQ25GuGPCFMk/6AbNY3nGPJYYN/gmcd25iYhmqOQcRDqfI87/9NtVjxHsnTBW8oxNCH/f6XdonrelQyKLBAKBQGg6ZNc5p7xhOM0GfLdHeRFdFxwmFgtnnY5FG47ijdWHMZ5ZK9meZ6Fw+2CpIYxFQyyWFqi3r7DVFKhopZHeObYbsiwGtHeY4tHLTDH+9hWcS2+O1x8JNAv3hXMR7nJerY6XjJpYVHsuAiUVkDH3vxj+QbPhG63sDZcKxndSIi4AUQQKJmda+37DqU3IeyvR5sM76qG4wKB8pyRRukh+P1Rftli17QIgNgDP/vgyAED11A8QLRwMKlAzhqxAAAAgAElEQVSJ3PnnggpUwHPeM6DCbuX8VQQPFfYi5/3zwXiOwDt6DkLdJoLipRfFue+ejcorl0lqv+S1o6lgPOp1swj7QMsFL8RoUTJ0oBznLhuHdaYorgg/hI2C2I6DbYSaRTrsQd68M1W3CUk3JHhT3QyUaJXIs9xNlDrwA9hntVM+Q10ugF4jl0C/q8Fb8lXTleWEu46Df9CNABcEQCHQf4ZkO5fdTXtOPSbrmg8AcI5O4JzFoP0V4JzFiBSfBaZ6P3hbO4S6Toi7oOqCqqc2OjQLcOINodz3xqoOEWgWwd5XwLrh5fg6zlmCQP+ZkjRQ79mPwLLhFUSLhoHL76t5ymCfaaD9p0CFPfCfJor0SPFZ8Jz9TxhObYqvAwDeWgiBYkAlObUKrBW+MxI3H4K9p4H2HgcV8SGQQqS2dIhYJBAIBELjIwgQINYsJlPmDaFHvq3e6vYm9GkHVyCCG0d2Rr7NGE8tHUBJ+42p1b2pNaJnaApnda8RerIebgHUpINxIYBixboZgRddFgHk2034y3m17I1XQ9aX0gsSio8i6/OZKLs1STTU8rWTi0WGUo/m0ipiKRnrpv8mxGIsdExRYqSQCwOMQWmVrzEfwWCLR/T0Yv/57wgMnAXQLOwrH5VE6Qzl22DZ9i4Cg9Qb3Du/vDHem8/59W2ovOZnWNe9EI8AOpfdqRDLgNgMXI513QtgaoSufcUczQv/rM9nonJGUrP5DP5+8ghZDLZ8m+71DB8CQwFvGx/DwNBcAJnX3SrmpSJUM0EwJNIf07V74OwdQQfKFW1G4vuDSqRK1/zPyMViCoHuHfUgAoNvRO7bZ8T/nprzpo3wjnkUlg2vphwXI9R1AmCwwDd6juYY34h7apxMk87DmBAuPkvXOQDANektbTMaPgqBNipuZGhSX2JR5XMkJ9JptOJzU33pR+Bt0rZAXG4pvOc9jbQwRviH/1mxOjhgptKLhmbA2wolN4Lc5z8L3pZULsAY4B+hTH9ubRCxSCAQCIRGxbx9Pugf/oFl3BC8QUmdB8s84gVLfTn3335WV4m7qNUo/uxZKOmFpVwoiWOlF0Xt7Ea8fMUglOSIKWbynm4BwYgH2HnIf20GeHMuBKMdtL8c/uF/1hQn9UXO/HPAVu0FAPgHXg/fWX/Xv7MgwPH1bTDvXSJZbYB6yiYV1JEiyUVgOLYazm9uA+fohMCg2bD/eD/okAu8wY7ggBlpD8F4jiBn0SRQinbd6TEc+RmRkjFgT21WbDPt+lDz75Fs1x9LiZULLEpeswmArdgBpmovuJzEzQB5o3YtQxrGc0TSekOrhi/ccRSMR3+WnrdS3RRKq+2ApGegDCcVgAN+eGCFoQ6NNU17lsD59a213h+QRhYFjShwYgAHztEJbPU+1c0UBOS+Mzr+9/SdfgdoDZGtRiyy6R73Iuw/PQTemg/TgW9Vx0ZzewIUnX7OsWNbctOO8Q++EWz5dtDe4+CtBWDch+Ab/ueMmsWnbG9Ds+AcHcCmqQ1OjK+fqLNAs2mtZII9JgM0A/f5z8Oy8VWEel2uEIoNCS+rZ0y+idGWIDWLBAKBQGhwwlEe3+08hTJvCI7l98DGezCZ+hF9w9KL+TKfKOKoeoosOmTtNKxG8WfPAh1iURZZPL9XQVwoAsp6s05UOa5nvwTFR8H4T4Gt/g102A37isxSMmtDTCgCgHXzXLGuUSdM5W6FUATENFQ19ESNqIgXzi9vAB2ogOHUJji/+UM8LZKOeGFd/1LaY9hWPaFa06cH46Efaiai4vSZrkG4DCGFgUg0p2f8seHYKsk2eRSKrdJ2+43PF1D0CgQAz9gn4Jq6AKHO0nRjxntU9b2rWUOZhoG0KLgMGbR/kWPVMGTJBMGQSPXmrQUpRgKh7hPB24tSjokJRQCwrX1ONRKsOZeayGa0/Wmo/t1ncE96E1WXK2swASDYt6ZnJavTdEZPlI61wD3hVVRfvgTuiXNRdeU3CHebIBkS7jgy5SH4NNFZSbQsDZGCQekHyQh3TKQbR9qfLj5I89wFUGJdJoBQr0tRPW1pnetXM4VzlkjnpEPct0aIWCQQCARCg/Pgkm248Z31mPbmOsn63tQhyXKZN7PI4p1jtWt6AMDCeeH4+g9wfjkbtO9kIrIIacpVLLWSdh2E87MZcCy7EzZGGkHKtshcK2XmMr9nv9OeiEaLBL0YDq9AVk0tnR4Y3wn1DXwU9uV/RdbiK8FU7AQA0Bq9yvoUmEEFq+FYeiucX90YF6BqtXBycuafp1orlgmG479qbhOylJb5yVg3vQb78r8qatMAMdKU8/4FMOuw5wegGcHhDXZwOYn3n+P7e5HzzmjYv78P7MkNijYOqVpdmPYsgWXdf5D3ej9YdixQbI+lHPpG3g9OdmHPqEQX9bbyUMwD4vvUUJvQvsDD/t3dYF37NYdw9o6qabyKQyW5cPLOEgT6XaM51n/aH8HbO2Q01VTCXTEXs1JoRdsNQqDvVRBoFrwpS0wL7TgSwb5Xivsw+iKLels8pMNzzpNiXaK9CIGYYK2Bsxdp1ujGSBetC/SeBt5gQ7jjKIR66f8eiuEd+wQ4e0dw9iJ4zqm5maDx3AXGBIFm4R/xl7QpyA1NYOB14GvcVUNdLkA0v3+TzqepIGmoBAKBQGhwPlgvpsV5Q2Eg6bqFhlSQVQf0i6of/zgKG46kFi62tf+Gec8nAMS0J2svsZ+aMg3VWzP+OZgOiqKvxNgeQOKOuN0k/cmUi4FUUBEfBKb2Rh3ZS67MaLyWS6plwyuwbH8XAGBd+xw841/W7EN3xaB2sK1+Kh515E1Z8J7zlK40VMZ/KqP5ZoqQ3wuUS8PcpYbY81SDrdgBx08PItx1AnhHaqERe28o5mDOVrhesq4DYF0HVC33UwkU855PgD2am8HXRDi43J6onLEa2R9OheHURvG4lbsQbX+aZHxtI4uxaHJtWmcYDv0Ay473Jevc416SpKRyzk6gwm5JNNQ18Q1QYQ+c3ybcJAWZ46537GMI9p2OnEUTJetdk96EYM0XBVESnrMehuOnBzJ+DgAQzSmVtOrgTSr98igK3nOegPfsR8QaXC4suamgNw1VoOrnMpzP6oLKa34BBB6Go7/Asn1+fBuXplcjAETbDQb2LNbcHhh4HbxjHxefay3gsruJ8wPiIlHtuYdLxsB18buK17OpiBYORsXMNeL3d6pU3lYOiSwSCAQCodGQR/RYmVgM1bTICEZSt8rommuFxcComtDEuOq0TpJeXua9n8YjiybZPGIGF+adC+PrCje/gF41kc8CVGH0wRdg3vpOXFxlkiJJRXyq6017PoXtpwdBy+qFqLAX1tX/gmXdf8R6tgzRmltyI3Lz3k/h+Po2ZH96lerYThufhmXrW/Fly/b5AB+tU8QwmttLV9PrtOSXQsjtXufDMFUpFBoA66onFXWCMXhTlm5RACBunJMprgvnSlfQLKJ5veOLjuV/gfOL65H18WWwrn0B4DndfR/lMDWfR7Xei5pwIVh/fQbZn0mjfwJrQajbBETzEu6Uwd5XKPp5hovPUqSaqtWG8SZl83feLAo5XtZbL1I0XDFWL4HBNyaOUzAQXG5P7cEx8SQXNnrfF/UUWQQgGsbQrEIcctb0KaaBflfHG9z7hyrrTQVzdq2FYhyakT5flece/zs2A6EYhzG0aaEIkMgigUAgEBqYKJcQflZZrSAjq4uL9VMMRFK7ZZ5TKjqSyk1oAODuc7pjROccdM61ADLzx5i4lItWKqLuhvis4WVMDD+Gew3zMfDICuCIaGIR7TAcdAZ1gWpikanaC+fXYg8xtmofXJMTkTDz1rcS1vu1uHCi/crIIqVinGJOEU1IrvOKHyOU2gk1HeEu5yNw8TtgqvZCYC2IthsExrUf9hVzYDz8o+7jCM5OQJ+poH5OOCBm5OgY2ye56bhKhNW27nntfU1ZKfvp1QeuiW8g3HWcYr1cEJj21/T4PLYavDlb0psy3OEMGGX1lFrExGImkUXL1ndgW/OMYn00txfAGFH1u09hOLkRnK0QfFYXCN/fF/878aZsgLWAN0tbySTXLMbXsVbluhrzGfl4Lq8XBNacsUDnTVkI9p2OcMeRoH0nEW0/tFbuwqnqXCXQ9X8ZzlvbSZftOgxhDBZU/n45GM8RcDk9FDXFDZIOqlKzWNc2KYSGgUQWCQQCgVDvbD3uxpItJ+APc/CFE8LPQkkv3oyU1HEzVCMS5WJxAPUbLmd+gBVBmFkakweIF0Bysdi3vQPThnZElzyrqklOLGKiMLjRsM7vSx+EAVFcxiScLW2//gu0+zCsG/XZ4wMysSgIMBz6HlmfTIuvMh7+AeypTbBsmgvLxtdgX5loHm3/+R+6zxNDEVnko7Cu+0/Gx1EcV2ezeC0Egw28vQiR4rMQLTodYAzgcnsiktQzTRc5XcD3kzYT57JKEMy0nopPvM+YJJMgPXC5pUADikXOWohwyRjVbZHCIZr7OX64D3Qw4dTrHfMYeJ0ujgw4lFAn0W7bKzDtWAhEA2n3kRv7xIhHqBgTIh1GgM/qAgDwDb8LgNiv0zVRrBsVrDKxqFbXaFCKxZhxS7jbhPjjUPeJQE0tYabwFnEefFZnRDsMr7WYU4s4y2tNAdRfGwrJMSkE+tTUTrIWBPtr13tKYM0SN99k1MR7XRFUIotNXaNIUIdEFgkEAoFQL5T7wvjL4u04WOWHOyiKwIe/3o3TixMXAPLIonw5GOWx/YQHKw8komAdUYZPjA+AoQTc0LUa1aP+gY5Z4kW6XCwOK0l9Z9pZ445qpqS1kbHUOM5eBEZW79XP5oEkAEqzyF6cYQ1hOCEWDUd+QvanVyvGZH84FRRfeyMc/8DrYK0xbaFkbT3M29/PSNxqkVyvKDAmeM57FtGcHshdoIx+qaF10RnqPgm2X9X7pEXaDQYdrJJEOoWCPkB2Z+ncuAg8Yx4H+GjKiKlkn9jrLfDIWXShrn2S52w4pm3CU1s4WyF8Z9yHSKdR8XYacqLth+o6Fm/KBpfTA1XTliLvnVFpx1uoMBYa/oGCdeLnz1+9D74z70u5j7xnIQB4Rz2EcDf11zMw5BZwOaXgrQXx58GbpS6TFKeMCKpFcWPiQjA5UXXFlzCc3IBw53Nr1mUDGfboFCx56QfpOY7KXHlHMZik+XCga90TNR3esx5GpHgMovl96qfVREPMUy2y2MbTPZsrJLJIIBAIhFrBlm2R1EY9u3wfthx3x4VijLWHXaDAYzC1FwWU1JAmCz4MpXbDXCMa95T5MPPdDfHaRQC4lV0ChhJTBHsfWYDu+QnBIa9ZNKex/M+1GnHVaZ0UkUXGfRCIBhRCEQDemiCNyhgP/6iaopmKeGSRiyB7ye/Vx9RBKLomvhE3QQGUkUXHD/fW+tjJmJOcOjl7B4RKJ4PL74uIzGAFEKND8otmLbHI5fbUjJa5x70I3iqtSUN2iWgyMvL/4qv8g2cDBguCffQLecOJtTAe+BZM9W9pUxZ5oyMeMeKcnREpGpGyZjFcNCJeU5cJ/mF3IdT78tTtICgavtPv0N5eQzS3F0BR4LM6I9A7Ecl2TXxDdW49qSNoTyVu1BgPfAvacxRM2TYxTVcQwJ7aFDfQoYLVYKt/kxyDs7ZDYMBMbYFBMwh3Gy8VvLJUa9W/hVp9X1IdHe8sQah0CgSjA0DtolSRdtoR24xQiyw6OkmW+Ya8BDdYECq9WDNS2CxQidqSyGLzhEQWCQQCgZAx5s1vwPHTgxBYK6p+9zm43FJ8vUu7hu9Bdh5msUsV66ex32Ma+z328UUYF34SHJQXhPK6xmRMMnEoX1bjT2O7wb4jApm3DgpeLVUdn/X5zLTHTAdVYwrj/OYPdT6WHO+Z9yPcdRxMuz+Jr6ttf8J0JDuMJps+uM9/XhG5ck2eD9vKR2E4tSm+jjdqp0O6x72MvHlnSNdd8AL4rM6gPbIm8zVpioFBs8UIhcDHRaLcSTMVNp09ASPtBsFz7jOggxUwHliGYJ9pAM2oR5DMOQj2vgKBgdch+6NLAChrRVOh1zTHf9rtAGOCwFrAm5xwfvdnxRguL1Hb6Bv5N/D2InA5PRDuOg6ui9+BeccCWLa+HR/TjpLOla3chby3RwAAPGMeAxXxwf7LIxBoIyqnL0POR5dK5zToRoR6Tq2zQYmeWsNIYeroqvx9wJuy0rZ98Q9LL8D1IK9ZFEApehmqfde1KVQiiwKpWWyWELFIIBAIhIyxrRHNV6ioH86vZmP7RV+pj0MAPphVhWIy3enjOJ9ej6W8snYtAG2zCHldYp4tcZGq1fIAXAQUH1XfVkcE1opAv6th3fSaZD0V8QNhH0z7Pq/3cwYGXgtA2rycqd4PCHxcVDUEyVEAPqszorm9JH0NI51GxaM8cVIIOd7ZCa4L5yLry+vF/QuHINRTrEv0jbgnLoaC3S9KXLzQjKJRd0OYzrjHvQg+qws4AJGkBuhq5/Kc+3SSKU3m6XuRDmemHwQArBn+0/8YXwwe/ineJiZGNK9PYq6WPPhH3J3Y1m4QvO0GgXEfgvHQ9wCAdpR2Tarjh0Q6KsWHkf3pVaADiRtEkfanwzf6QX1zVyFSMACGsi0AgEBf9eh7pN2g+M0H3xl/TXk8eRSbt3dMKRb5rmPrLbIlF/yCwaacTwN+NlsCajWLXHbXJpgJIR1t+51KIBAIhFqRbKDBVu3F4k1HFGOmM8uwwXQjPjPer+uYRZR6b0CFWJSZbkzqJ96xL3SYcH5PUTAZ932OvDcGKY7l+PYO1Xqo2sLLapx4az4CQ25EsHSKZD0V8WXUCDwjahqAJ6ct0mE3ct4bC0QCNfPMV9uzTiicCzmlE6kgiySmM1oJdz4X/kGzEeo+Ee5xL8fXh3pMRmDATAR7XgLv2Q+nPIZaZJG3FMA/8PqU+6U8ptbrpxIFTBYFVNSf0Xk8Yx9P2/dRC/l+AiiEu5yfdj8hKR2wHfQbGDHuQ5LldH+XdHgueAGh7pPgO/1PiJSMVR3jPesfCHU+D97Rc8SazhTI32u8yaExsobsktTbM0BgpO8L3lkM0NLWEySyKH3+nK09uOxuTTQZQipIZJFAIBAIGXOSaY9C7kR8eeXmrQCkJhWPGcT+cP2pA7qO6YT6hXVQkKa00SEX+KSIzgPjemJy/0L0LLDDWJOGal37AiiV/oTmXR+KKYT1QPUlH4I3OZH7/gXxdby1ALytPTzjXgRoA8y7PgAgRjmZygYSizXRVc4mrXFjq3+Decf7CA6cBQipW5HUBsEsjcKESqeArWn3EevZJhilvfHSuioyBvhGP6Rcb7DAe/Y/9c1L1mKBNzpRcd0GAIDpt6/AeI+q7aZ9PMakOW9V0xWJWEzvJppMsJ/S+EgvnF0qFiNFw1PXPcZIumgvpDJLmY3hOfsRRAsG1GrfGFxOD7gnpDZhirY/De6L3ko5Job8poEiyi0f33OiruPqgpXe4OKyOktEOQDwzVgsBrtfBPO+zwBA05G3zshej8DgmxrmPIQ6QyKLBAKBQMiYqoj0LnkolNlFsRp3GT5AKaWMUMq731FBaSoZQ1MY2ikb2a5tyJl/HrI+vQqG8q2a58n+5ArJcrSWd7OjuT0VwiTcaXRi3saEaLCt/bdqTVltCXccBc7RCe7zk/oAGiyKaIp146vInTcKtEqPxboijyz6h9yCcKezEM3tBfeF/xXHyCKLmdQT1hrFORLvoNi8MoG35GmataQXi/UXxU4HL7tZECq9WN+OSemAFiqzPpUAEOp8bkamQo2FPKqtJhbd414G5+gEfshMCD0uUGyvNTIhxDk7K5racw3RNqOe8I1+CJHCoWKt7pjHG+Qcguz5C7LXh9B8IJFFAoFAIGSMjeEkKo6RucUYUTtnz7+wCzA7IhVV8l6MdKha1fLGsvG/Ys2cipW/FgJrBpfbS+HoCACBATNh2aIexeCs7SCouEmGuk9KHLsBepPFcF08T9VERJ5iy3iU4jtcPAbGwz/UfRLytg5GG1xT5kvXyVLv5BfwDYFCwAmJN2q03UCEuo6PN7HXQ6oUXjUzmuSbBGpEs7qAdR3QfX69yN02k9+LqZBftGeC66K3460qmhvyz59gdCCaUwq2ag8AINL+NIRKL0ao9GLk5DTsTYxI0emgvSck62iaTWHd1bTw9iJUX76kYU8ir1msoykSoeEgkUUCgUAgZIxBJgZjYvGCXgW4/owS5MJdq+NewKyLP57NfIaXDc9iELVPMobSMKmQm3voQWAtivS9GLxJu+1BrE2FYM5BsHQqACDY6zJw+X0Tx9bZCF3XPJMu6P1Db9O8sNJj3OMfcgv4ehCyVERHPZ4sIteQAjqO7CKUEqQ3MoQML0rldamSY6WJLKrhGz0HnKNY7FM55jFwtvYQWDNck97MaF5yuPy+CHcU6/j8g26EkGR4lBKdYpGTpbSGS8YgXNxAKYr1gFoaque8Z8AbHeBNWfCcq97Xs77wDbsTgJgFEO46XnHjxGpu4+JIFn0V6Db+ejRjSGSRQCAQCBnhCkSQI8jFoniPfHS3XEzsW4hVq+sWuRpM7cX9hvdUtyU3hk+GsxVKml7rQWAtmuYlQooG0ckC03PBC/Ce/bAi0liXlEvelIXKa34B+CjoQCV4az4EUzaokCvlvOSOpIrjGh2IFI9GxbXrkbtgXNp+ke7zn4fz2z+qbtPVQFvu+NgATqXpkSUypxGLya6cQJpG7YbUYpE3ZYMOSd+vnL0DKq9eASrqh2B0INh3OqhosO5RV4qCa8r7oELVqlFvTVT63ckRKAaV16wEFXJDsOSCClSK52igpvL1gfxmDW90IFo4BBXXrhNvKMgj4/WMf/ifERh4veiwSlGK15lm2vgluPy7gaShNltIZJFAIBAIuvnPT/tx/ksrYRCktU2z2S9gQhhFjBvWNc9iOvNdrc8xmNqLacxyze2WHfNFA5tgFRD2wbLxNZh2LgJv75jxuQTWDN6qLgYUbp/J25KjLBSlenGuFbHUg3vCaxBMWRAseeByS+MX5qmEIpDekTLeGsBoE1NZ5dvl/eFUxBAgitmgRnsDKbLLjCYRF1KxKNCpL0qj+f0ky6kji7IWCTQrEQXu8S8p9zE6xB6NsRo6mq2/9FyN92Iq9KShcs4ScZ4W0cRKsOQ2a6EIpDC4MVgbXCjGz2nOjr9Oglwc6hDprRm54U+6zyWh6WiR79RoNIo333wTixcvxsGDB8EwDPr164dZs2bhvPPO03WMjz/+GIsWLcLOnTsRDodRUFCAkSNH4qabbkJJSf3ZJxMIBEJrIRjh8NavhwEoaxKnML9gK98Fg3dVw3b4C1xdh1+XN4xPYgWv7axoOL4GhuNrQHuPgrcX6W6srobAWsCb1cVAqp5relwmubzeGc/Hfe4ziBadXmsL+UjHkfCOngP7ijmq2/mk58Rld4NrwmvI+urG+DrBYJO6yKqkhlVdthhcdjcIJqdimxwtsdmoCPLIYmqhwMtEfuqaRdnzkwmvSPHZcE14FVlfJZweGyUVNxNU+t3J4XJ7NsJE6helwU3D18umRC6GmrHBTaMgf/6kZrHZ0iLF4l133YWlS5di3LhxuO666xAKhbBo0SLceuutmDNnDqZPn55y/0ceeQTz5s1D//79cccdd8DpdGL79u1YuHAhvv76ayxYsADdupFeLwQCofWz7nA1oryAEZ1TRyPKfWG8uTrWV02AEcrauPsN7wGH6z6nXMqLc+kNacdZtr1T53MJBjt4q7oYSJVmyZtzNbfF4JydM55PtP3QOvcaixQN19zGZUmbXsubYAtGO5DUQ1Ne38fZOyLa/jTdcwn0uwbWdS+AigYR7KHTnbOBSVezKH8/aL0/AGVkkbe2U4wJdx0PztkZjPsgorm9Mo78NTg6Ily8rbARJlK/KA1u0t/caEjkkbQ2LxZpuRsqEYvNlRYnFr/99lssXboUF110EZ5+OlGcPHXqVEyePBlPPPEExo8fj9xc9R/yw4cPY968eejYsSPmz58Po1F8c15yySUoLS3FAw88gNdeew2PP94wVsEEAoHQXPhhbznuXrwdAHDfBaW4dKB6tCzC8bhm3nqU+8TUUxYcaEre0KJ+sVON03JAMGdrphmmiiym2hZHJWLDOUsUzcyTSZX6qpdUaZPh7tJecvLm4Yo6S7lYdBZnNBfBkouqSxfDcHI9Qk0lFhWRxTRiUXYjQEh1Y0D2+oU7n6McQ7OonjIfxgPLEO46rvmlb8prx1TQc3OkuaEUi80rsqgQj20MgZKn5ZI01OZKi6tZ/OADscHxrFmzJOvNZjOmTZuGQCCAzz77THP/I0dEG/GBAwfGhWKM004T75YeOqT9Q04gEAithS93nIo/fuybPYhwvOq4Xw9Vx4UiAFjReL3jGhqxLlAZOQr0vUpTuAm0AZGiYbqO7x94ffyxa/wrCPaW9niURx91idA08NZ24C2iE6bAWuJ1iLwpC6Eu50sHy9JE5Y6EAmOUtGDwnXFvxvPhCvoh2P+atPWWDUfqmsVIUjN534i/QsggsgiKQjSnR81xWfiH3Kw6jHeWIDhwFnhH5nW1DY2aaBEoBpF2g2q2GxDsmzpjqznS7MSiPJKoI/23VSO7SUEii82XFndbY+PGjTCZTOjbt69i29ChQwEAGzZswIwZM1T379atGxiGwYEDBxTbYkKyR48e9TdhAoFAaKZU+KQmNWsOVWNkVzGCcKDCj/fWH8HQTtlwmBI/FTR4LDPd06jzbEh4U5ZqDZlvxN2Kmjz/0D+AClYh1GOSrno9APAP+xNAMeCteQh3uxDs+helA5LrA4H6cQRkDHBPeAWmXR8i1PMSgI/CtGexKFTlph+KmjtZqwvaCO/IB8Bb8xHN749o0el1n19jI2udIa9ZDPa/BmF/GRANIjBwFmhZ5FerpjWG54IXYN76NsJdx8dbqrQoVNIhBaMDnnOfhmXLmwgXn90sRW465O/tps4armUAACAASURBVI7kKZrOt/HIouL5k8his6VFvVO9Xi+qqqrQuXNn0LQyKNqhg1iUnioyWFhYiBtvvBEvv/wy/v73v2PmzJlwOp3YtWsXHn/8ceTn52P27Nm65tPQTVwzhWHE16S5zYvQMiHvp9aPySj9CSgPRZGTY8WXW0/gT++vAwcGH28+gQcv6gNAbI9xAb0OBZR6n8OWiCm7AMZcqViMXr8c2UXKekPjyBuA7BJkdkljBS4WyxrMAND3AmD1k/GtNC8Vi/X2ecs5B+h3TmKuA8erzzsqFQqsQTrKmesE8nsCnZ+FAUAzsKsBkP77ie9xAei93wAAhDNvl4yjHNK/tzWvPYRRNwAATACQJRWTWR2KVVtkxMkZAfQcAQOAZmZdowvaalaso8xOOHsMBXoMbbHPC472kkVnpx6AWf390hi/d5RLGtlkDYY2/ftKm6WfM0eOE2glr0dru35qUWLR5/MBACwW9S/t2Hqv15vyOH/6059QVFSERx99FO+9l+jjNXjwYLz66qsoLs6sJoNAIBBaIvLI4tHqILYePIlOH03GetMx3BW5Bcv40/C/nw/gacNLuJBegzJBX5qkYM0D5a9oiGnXLxYxNZK76mPQPzwOvttYoGhQfDP3u3dAr3wOfJ+pQHY9RI06ngZuzH2g930Hfsy9oBfoaT/RgMhTvxQOhY3TYqC+4S98GvjqHsBoBz/qTulG+XOWpyeas8BNeg70xnngT78htVBsDchrxwDA3LRmMPUCawY35VXQa/8LfsgMwFz3FO+6IG+d0dSRziZHnoZL0lCbLS3qnUqlKQoX5EXsGrz66qt47rnnMHLkSEyaNAkFBQX47bff8L///Q8zZ87Eyy+/jN6901ueV1X5dZ2vsYjdwWhu8yK0TMj7qfniCkSw6kAVTivOQr699hfz5R5pVGv/KS9273gBV9B7AQDPGl7CwNBc5Hl24TJ2BQCgM3VKcRw5kaJhqL70Y1g2va7ZwqGxCPa6DOZdH8aXwx3OgPHYqviyj7MiVOUHsocBU2rGJb/n240FpoxVrq8L/W8T/wEoiAYkm5ri81aQ9DhkL4EZq+PLLm8UPJrfd0D676dcYNxc8aEfgD8xzhwCHEkj3SEGUflxulwm/gPq7+/eTLGGOEXkMELb4GoNz7vTJPEfkPLv2Bi/d6yPQ7IPbpSjWsdrXEvsYUGSqeDycuDp1vF6NNfrp4ICR/pBKrQogxu7Xbz75/erv/ixyKPDof1irFq1Cs888wzGjh2L119/HZdccglGjx6NGTNm4K233kJZWRn++te/1v/kCQQCoR4QBAG3LNqM//tiJ25dtAVRDVOadHC8AFdA2ivxuCuIEYGf4stOShQy2XwlMiFmqCJv8A4AkYKB4C158J75t0ynnNkcaCM4WyECA2bBNekt8JY8hDucAf/pd0jG8fVgKNPS8Zz1MHijA4He0xDN7y/ZpvY3bOnIn5NgaGLjk6ZGzeCmqc1gWiMKN9Q2bnCjqCUmNYvNlRYVWbRarSgoKMCJEyfAcRwYRvpBixnUdO3aVW13AMBPP4kXQhdeeKFiW0lJCXr27Ilt27ahsrJSs/0GgUAgNBXVgQj2lIk3xvZX+rHusAsjumj3bVt7qBpvrzmMMT3ycNmgRLNxVzACeS7GcXcQeVAKw3CGPxWx3nOKi3JzNqqv+ALgOTCVu4CVj2Z03EyovGYFeFv7uONexawNAEWDLdsqnVMTi8VoXl+wFWL7EnnPvsYiOHAWggNmAhQNy6bXpRtbY2qY3IVRxeCoLaHqhmqsXQSCoI1CHKql/7YlBE66SLfC75pWQouKLAKi42k4HMamTZsU23799VcAwLBh2pbmgYB4pzwUCqXcHvufQCAQmhOekPQHdv1RbbMZQRDw0Jc7kX3oK2R//xc89f5iVPvFaOKhSuV3nCsYhV2RcijAAvXvS83zxnrPsbKoVKx1As00uAgRaKNUFNQ8lvcRbLp2DiLu854V21vQRrgufrfpJhJ7rWR3+1ulnT0vu0g1tm2xqNZnkYjFBkDu9qli1NimUPQ/JZHF5kqLe6deeeWVAIC5c+dK1ns8HixcuBDZ2dmYOHFifN2+fftQWZm4Uz5kyBAAwJIlSxQ1jtu2bcP+/fvRsWNHdOzY8myiCQRC68cTlKaOrjlYrTn2YFUABu9RvGx8Dley3+P3ZU/jrTWH8fXOU5i9QHnDTSkUAStCsGYoFmMiUZHCaEkIswYXIRoXHvIoiqIJfSPDFfRDxcw1qJi1DpEOI5p0LgCUqWGt0M6e4qXGTm09skjSUBsHxXdPG48sUvLIYmu8MdVKaHHv1JEjR+Lyyy/HBx98gFtuuQXjxo2D3+/H/PnzUV5ejmeeeSZe2/jNN9/gvvvuw3XXXRevQ7zwwguxaNEirF69GtOnT8eUKVPgdDqxf/9+vPnmm6BpGn/7W8PW0hAIBEJt8YSikuWdpzwIRXmYWOW9v83H3LiISZi5DKZ/w6xtJ/HOWjFlfzC1FwPpffiEGwU37MimfIpjnEVvgYWqZWRR9uMv2NolFhpYhGilNPGOYkTy+8FQvg2RdoPBWwsbdB56aOropgS5WFSJOrV4OOkNl1aZapsJKn0WOXsHlYGEOiH/zktj2tjqaQM3ploLLU4sAsDDDz+Mvn37YuHChXjooYdgNBoxaNAgPPjggxg+fHjKfVmWxdy5c/Huu+/i008/xZNPPolwOIycnByMGjUK119/PQYOHNhIz4RAIBAywx2UisUIJ2DnSQ8GdRRr7zhewC/7K+EwsdhyzI2eMgFYZGdRFYigHaqwwPgPmKgohtB7cWfkNpggjbgAwKvGZ/F8dGpGc9SqWYQzkbGh9y5yNLsb2OrfMjo/AO2UJoqCa+pCGI7+gkjHUeSCTY78Aq4VIo9otHXUjFa4vF5NMJNWjjyCq9PBv9Ui/xy2xhtTrYQWKRZpmsZVV12Fq666KuW4Sy+9FJdeeqlivcFgwLXXXotrr722gWZIIBAIDYNXFlkExAhiTCx+sPEY/rV8X3zbI6xULOabxB/o69kvYKLEY13C/Iw7I7dp1iZOoX/JbJKxNFSZYYuQJBb13kXmnSVAbcRiih5mgikL4W5KkzMCQLWBC9hgr8tgW/kYKC6EcMnYpp5O06OSDhnNJWKxvhFk33mUwmKsjdEGbky1FoiMJxAIhBaEPLIIAIerE2Y1yUIRALJkkUWGE5dtCErWv3j5AJhVIosAEEVmFu+JNNS6RxY5R3FG5ybUldZ/ASeYc1A95X34RvwFnnOebOrpND0yoxXekg/BktdEk2nFKCKLrf+zlgqqjT//lgQRiwQCgdDMEAQh7loq56RHGf2r9EWwv8KPB7/YqdiWB7dk2RAVTWwMkKYAtbObkEt5VM9potTnooWeNFS9kcVoO1IW0JiEuk6IP+ZbsWCIFg2D//Q/gie1eQqjFS5bu/0YofYoW5SQyCKhZdAi01AJBAKhtSIIAm5auBkbjrgw+8wS3DiyS3zbnjIvPth0XLFPpT+Mx77dgw1HlG00iqgKyfKx8goAWWApqVjsGNiG14zPqs4pB+oiUpOYSJT3s3MmXZjrbEjNW/LgmvQmzDsXItjnSiDih3nPJwj0uwbZn6YuRSBkDpfXC56xj8Nw5BcEht7a1NMhNAayz2JTOwS3WlKkxrdJiFhsMZB3LoFAIDQTft5fiU82H4+Lvv+uPITZZ3bGd3vK4Qtz2HzUrbpfhT+CY66g6rZCStpaw1ZTl8jKIovtv5ypOS9bpm6oNZFF3pIr3eAoAryZ3U0XWAsixWch3OX8+Lpwj4sAAP4Bs2Dd8r+MjkdIT7Df1Qj2u7qpp0FoLGRuqAJraaKJtHLk2RRtoD44JcRoqsVAxCKBQCA0IRwvYNXBKhys9OPZ75VGLj/uq8C9n+4AALRDFT4xPgMjorglcgcOCu0BABU+9VpDIyKwyoSejQoAAmCAtPaRDqsLUTmn7H2Qx1eC8Z/UHBNPQzXnwHvm32DePh/UyNsBgwVQ6eWYCrlJTjK+kX8D4zkKxnMYbMWOjI5LIBBEFP3/iFhsGOTOy21dLPJELLYUiFgkEAiEJmTJ1hN49Js9mtvvXrw9/vhBwzwMpkUDm38ZXsHvwnMAAKGoejpPFpR9E2PGNnYEFNv0cLzzZaDG3iweY/lfYNn+nmJMcq1iYOitCAy9FTk5tUxtS3XhylrgnvQGACD/5S6geKX5D4FASIM8DTXFDRpCfdK2xSLVBsy0WgtELBIIBEITcMoTAstQKYWinIuYVfHHw+jdacc7KaVYvJtdiBvxGQbQB3SfN5mu7fMTDTZUmnkDSC3wMkR3lINiABCxSCBkDElDbSLatlhs85HVFgQRiwQCgdCIVPsj2HnKgzs+2gq6jg3hs8wsXCqtNGJkw6tY15k+VadzSswvNExq6jMyoftYWsKVQCCkRv7ZIZHFxqGNiyXOVtTUUyDohLTOIBAIhEbig43HMP6Vlbj9w63gBSDKq18sjKK34F72PXSllM6nyXTLt6XYKuBm9rM6zFaDpP6ISiv4mvXylhl1QG+UQ2suBAIhNaRmsalo22LRP+xO8AY7AMA78v+aeDaEVJBfVwKBQGgENhxx4Ylle9OOy4YHcw3/gpmK4Ax6O6aGH9Ec+8ezu2LWextVt42mt+ICZl2t56sJl2SYoxXNSxKUdUV/Giq590kg1AqShto0tPHIIu/shKrfLwcdKEe0YEBTT4eQAvLrSiAQCLVkx0kPLp37K66fvxHekHY66HF3ELcs3KSxVcB4eg1G0lsBACPonTBTEQDAYPo32FO4h/YvcuL1KwepbruNWazvSWRIpHhMYqExonmsziilzr6NBAJBBjG4aRKoNh5ZBADeXkSEYguAiEUCgUCoJS/8uB+Hq4PYfMyNf6u0vYgxb80RcBrXBdcyS/Gq8Vm8Z3wUZ9ObEJYlfJRSR+OPo4LyK9tmUhdsIRhU19eFyt//AMFojy8LmnWC9XgRpDNiKFAkUYZAqA3yzzGJLDYWRCwSWgZELBIIhFYJ7T4E2ntMsV4QBOwt8yGs0W4iHd5QFAcrxWjfmkOJhveLt57Q3CfKK8/VAeXIhwtzDG/H1z1teEXR0qKUPhJ/zEEmzgQBdmNinQFRnEFvx81F++r9MoSztQeX0126UiWaJ7AWRHN71vPZ0+Md88/4Y/+g2Y1+fgKhxSL/HBOx2DgQrUhoIZBbsQQCodVhOPQ9sj6bAYCCa+oCRDqcEd/21Hf7sGjjMXTOseD9a08HS+t3JK30h3Hp3DXwhTNrJix3PT2L3ow3DU9AgHS9A344KKlY7EUlxGIUNCRJmRE/7CZxDQUeHxjnYBD9G1AFyHVlpgigJGlSvCVfOUiWhhouGQvfaX9skovNcNdx8Ix5FLTvJAKDbmj08xMILRaFwQ1JQ20UBNJnkNAyIJFFAoHQ9CSbptQD1o3/BSXwoAQO2R9fLtm2aKMYbTxYFcDyPeUZHfelFQc0haIREXg02ljIBelzhv+AoQSwlPRigQcNh6xGsRNVFn/Myb6y6YgH1prIYh/qkCgU6wt5HZMlVzFEnr7mOfufiHYYrvsUkfan125ualA0gv1nwD/iHgjmnPo7LoHQ2iFpqE0ECS0SWgZELBIIhCbFtmIO8l/rDduKOfV2TPbkeskyFRTTRQWZ+1yZNzOReqQ6oLJWwCuGZ7HFdD1cPz2vup88sphLKfsfAgAPCnZZZDFZPLKQiksq5IkfuzQpAiknYnBgXOgJ/MgNwHvRc3AV8xTCJWMg0KlcS6U/D7wpWzlE3icyQ8Mb9/n/RqjreAT6z8hoPwKBUH8IxOCGQCCkgIhFAoHQZFDBKlg3vQ6Kj4j/Byrr5bhcXh/JsnH/UgBAROYyk2ndolrC6pn0dkxg1sBERTFk9zOq+/E6LdJ5UIrIYkw8UuBhpaTilgp74o970dpiccuI57BbKMaMyH34W3Q29tLd4Lr4XbgvfE1zn0jHMyXLgllFLMqfV4aOpHxWF7gnzoV3zKMZ7UcgEOoRuTkUiSw2CvLvWAKhuULEIoFAaDKoiDSKRoVc9XPcJBEFAOa9SwAAgYg0hTRZPIaiPH7eXwlXIJLiwAm5eBvzCZYa/4I72Q8kQ+TRSwAIRvSJUicVwLXs15J1MfFoRlgxPufDyTAcXQkgdWSRlgm9WFYsZ++gOj7UbQKCvS6VrONNWaknD0Cg69+BlUAgNDCKyCIRiw1F9cXvgrfkI1I0DIGB1zX1dAgEXRCDGwKB0HTQ0vtVFK/dqzAT5KLTcOQXgOcUYjHMJUTcnz/ZitUHq9E114r3ZgwFyyjvpcWkYil1BPcYFqqeu8LtRX6WQ7LOLxepAgMDpc8kJxZZtEI9ZTb7k98BeFfSYkMOa80BcDy+TNWIXt5epBjrHfkAAkNugnHf55L1gloaqhzNVhoEAqGlQNJQG45IyRhUXLexqadBIGQEiSwSCISmQ95Sgk8R1csAuVik+AjAhRQRPl+Yw2fbTuBvn+3A6oPVuIr5Fnd4nsT2rWviYwwHl8Px9W0wHP4pLhZH0Vs1z320XJlKGxOp3ahjeIp9RbdQBAAnAujgNGHGYKXBTIznDC+iC31Scztrkxq+MDVPRDBlKy4MBVON0GXk65WRRUqRhkruPxIILQ5OmrUgMCaNgQQCoS1CftkJBELTIUgjiVR9iEUuAjriU6ymuBACUelXXswZFRCF3D8NbwAAqtccRGTgKpxyeVD6+WwYhSDMexZjU/BNAEYUURWapz9RWYVB3TvHl8u8Iaz4TRSQ/za8iIH0/oyejomKoEcui2sGZwE71cdMYX7R3D8q0DBapEIvFlkERYGzdwBbnXBRFQyiWBQYqfkNr1azKEMgYpFAaHlQsrgBk8r4ikAgtDVIZJFAIDQZirTTaN1baGjVPdp/uB+dNjyJa5mvYEVQsb0/lRBx2aGjYCp24I1la2EUEmOLqVMApO0s5JyqrJIsP/9j4riZCsUYhcYIqIg//UAVypEFs1GaHprcyYPL6iLZxscji9ILRrXIosL6vQ5i0TfiL4p1rvGv1Pp4BAJBH1xOKaJ5fQEA4Y4jIZicTTwjAoHQnCC3gQkEQtMhE4sUpxRxmUJriEXz3iXoBmCOASikqvBEdLp0P5nwWfD+q1gTHg0kZWTlU27sFZCyPtDtcUuWv9pxquZR7Xtq5RtCoKL6U1eTOS7koZOs/jK5lQeX2ws4+F18WTDWPrJYl5pF/2m3I1I4FLytUDxUNIBou4G1Ph6BQNAJRaHq0o9hOLEGkQ4jmno2BAKhmUEiiwQCoemQi8V6iSxWpx1zC/upYp2DkkbuCvmTCgfSIlSgE1WGnrS2WGSiCYfX/2fvzsOjqNI1gL9V1Vs6e0LYQwCDIMgOoigCgoCIigzIJhejjo64jOMdx1HHfdfBdRjnujKjqCAKKqgIOooggw6bC7LvOyFrp/fuun900umqrl5T2cj7ex4fU6dOnXOA6jz58p2lOOQcx3RondEYn1YGV1x/Li1OS+uwstDjEb053RX3aoJF9UEh2pnFKA0nShDgyb8Avpxu8OV0Y6BI1JBMqfB0GsFjM4goDINFImo0gqzMlgnexDOLu05W4fYPf8YL3+yBLMsQnckFVepgLh12mKFcQzlI3IF/m+6I2o5YHSz+eKQCl/zf+mB5rpD8sSA5BifEJM+g7J4ffjyGIrOY1UVxTzamAgjP8vrNyk1yqmsnNSYiIiJqHjgNlYgaj3rNos+JcocHL6/dh/2lDozpnocr+4Qf7xDqzo9/waEyJ9buLUH/PAGXlHwbV9ftcApHkRu8VmcW0wVHWGZxpuHLmO0eOHkKg+euDivPQaVG7ci2+fPRQzwIAOjh/glSafg5i1oqhz2M9G/vD15b0rJQBWBkt1b4985iAMB153YK3vfm9oQsSBBkH/zmLPitrYLlNWRBBLS209c4U5KIiIhOHwwWiajx+NWZRRfe2XgYH2wJnAn43wNl6N8hE51zrRGbOFQWyID1EvZhwtdFMMvxTWVdZ7kVr3kvwaPeWQCANI3MokWIL0ALFek8xFYJZhYrUTsd7KydL8f1jDe7G5w9ZyiCxZpppX8ceQZyrEa0TTfjom6tah8ypqD8srdg2fY+nN0nA9Xb5svmDJSPfwPmXcvg6HV1hCmmDBaJiIhOZwwWiahhyHJYwKE+KuPt/+zEO1WdFWW/HKuMGizWuFL6Nu5Ascb1hs/wpHc6vDCEZRbTEJ5ZjIdV0B5DrlChWR5JlZz42qHKi+aGZQDd+cMBAK3Tzfjz6G6az3nyL4Qn/8KwcneXMXB3GZPwOIiIiOj0wDWLRFTvjEf+g5x/nYOsDycBnkAGb1dxFdbvLVbUq7TZ4PT6FWUHSpVB3K7iKiz98ShsLuUU1hwhsWmewfYs/4N/m/6AiaqzCgvEE3jV9GzC7aVEyCwmOg3VichnnXla94M3twdkVWBYM4W0/NL58Ob2hH3ALfC2G5RQvwnhNFQiIqLTGjOLRFTv0lfMgWQ/Acl2FKn/fQEH+tyB2W9vxLnyPowNiYnMGtM+95c64PT4cO/ybVi9+1Sw/Jvdp/DclWcHrzNRlfT4uojHk35WLdI01N7pNmgc76jJYWkLZ5Ux4n37oNvg7jIGhmMbkP3BFcFyf0ogWHR3Hg1359HxDzpJvuzCeu+DiIiIGg8zi0RUL8TyfchYXoS0f98FyX4iWG7e9Qne+uEQ3D4ZEpRZRDM8aIVyvGr8K140voR02PH9/jI8/80eRaAIAGv2lMAdkoXMFJIPFvUUaRrqeekn427DefGz6NOpTcT7/pTAxjzeNgPgOGsaZEGCve8NgDH2dF09uc4YD0+7cyBDQOWFjzZo30RERFT/mFkkonqRser3MB7bEFYuuMpQ5Q5MITVAucGNBW48aXwFo6VNAIBN/kK86bokuOGNWom9NhOZBVvYfbcswSQkd5h9slI00od/HnUG0jfsiut5b3Y3eDtdiHb7vgAiHOdYEyxCEGC76K+wDX8suDFNgxINKLvyg8CutlLkTCgRERE1T8wsElG90AoUAUBwVcDrD6x1U2cWM4WqYKAIAFdJ3wAARoib8JDhTZwpHFTUr9kJteZZtaNyblhZfZttWIkLxJ8UZe0NlRCdpXE9L1dnB+UowZ/fqso6NkagWEMQGCgSERGdphgsElGDEiDDVx0sqjOLI8QtiutDcitkwob/Mz6H2YaVeN34VwghAeahsprjLmRkamQWS5Ch7+Dj9A/jc0hH7cY8bd37439YCiziVG9eU0MWTYAx8Z1SiYiIiBLFYJGIdCGW74fllwUQHKdi1vX5AgGfOljMFpQBXxqc6CochVkITFvNF09isLA9eP+b6nWMKXCFTTf91d8JJ+XMxP8gOkgTnHjL9AT6CzsD144I80k1yGIgSycbtANCmYEiERERNRAGi0RUd14nspZORvrXdyHzs+tjVk/xlQEADDHWE+YK5ZBUAeV4aX3w6zV7SgCE74R6p+cGXO2+G1rHyDeUfuJuLDE/gMGpJ9BRKon/wZopnRGmlsrGVB1GR0RERBQbg0UiqjPToTWQbIFNaIxHfwC8jqj1M9yB3VHVaxbVzhQPI1W1u+hg496welkh6xXtshnv+0bgFDIBJH4OoEvQnv6ZrKf7V8Bo196gR4ssBoLEiNNQG3jHUyIiImq5GCwSUdKOV7rg9flx4phy4xmxKvq5hccP7wYQPg1VyxvGpxXXXXFIsW4RUGYWy1CbeROTCBbLDHkJPxNNntEZDKTjItVMQ40ULDKzSERERA2DR2cQUVLe/u8hvPDNHnTItGC6Zxu6hdyTqo5FfbadUAJARkbIJjCRSIIy4EuRHeggnMIhuTaoSxdq26mUazNvYozMpZZTUh7aeA7Grhgn0VkCqVx7gxtZNELwe8LKAESchurod6NuYyMiIiKKhplFIkrKC9/sAQAcLnfC6C5T3BNt0YPFfOEElprux13G95Lqe6XpTsV1CmqnqjpQG2Qls2bxpNAqqTFFYt30D0gVEYJFs8ZurVF2Q7UPmANX4WW6jo+IiIgoEgaLRFRnbQXlGYJfbvwpQs2A6w2foZ+4O+n+UgQ3CoTagNQiuINfO2EKfq3OLHpa94vZ9klB+2zGb3x9Eh1mTH5LdliZHCFYtJ1/P6rOuydwriERERFRA2CwSNSIBPtJZC75DbLfGwPp1PbYDzRBnYTjuEL6TlFWcvxAvfebBmfwawtqg0WHbEKONTCVUx0sVo58Gt7sM6O2a83tqFlebm4L28Dbwsq92WfC3f7cuMYsS2ZUDbkTvtQ2sA29D7IpPbxOhGmocoRpqURERET1hcEiUSNKXf8MTEfWw3BqKzJW3tzYw0nK/0hfhJW1FWKftVhXJtSu9VNPQy2xB+79IndWPONr1ROlM75CxZh5Edsd2KuXZvmAPoPgOPdPijJZMqN0xlcov3JxXGP2p7aFfdDvUXLNBjj63whva41spai9wU2kDW+IiIiI6guDRaJGZNn+QfBrw6ltAADTvi+R8dn1MO0ND8Iam1S2B+mf/w7W/76AmmMp2qimoAJAB6G43sdihBcA0Fk4inuM7wbLnTChf8dMAMBL3itx0J8Hr2BExZi/hzwd+VufMSs8s7jT3wHmwddGHc9t+FPU+wDgS2+vuK4achdkQVJWqp5mKkuq4JDBIhERETUwBotEjUgWVRsSe53IXD4b5j2fI/PTa2OeV9jQMj6/AZbdy5C6/hkMEHYCUGb1ajREsDgkPw0A8LTxFUW5UzbhxqEFAAAbrBjufg6PdPsQrm6XB+vIYuRvff7UNorr37gewBj3U9rBmly7U+tyVz8865kcdczqYy9kcwZKZq9XVhIDwaNsUE9DNYGIiIioITFYJGpMqmBRqlCu9RMdJQ05mqjE8v3B7CcAnCv+CgCwagSLeUKFZhu7/e10G89vuzmwZuB3OEdUrvVslZWBgflZEKv3cP6ABQAAIABJREFUgfFDxKBuBcqHhcjf+mRLNtwdzgMAbPF3xQb5TMgRv1XWBos+GahCjHWFcvi5j+FrEasHrg5O1RlIIiIionrGcxaJGlPNZiY1l/aTyvty7EPrG4p57wrFtbv624dVCA8WI1nkG4G7xXdjV4xDxtoHoXHwBFJSAhnHl6/qg7+t3ou+HTJxbuccZaUYgVf5ZW9j63+/wo1rDAAEPH15z7jG5I3xLVW2ZIUXqsYiVweyYdNQiYiIiBoYg0WiRqSehipWHVVcC974A7F4HSx14ECZA0MKsmEQtY9h2HnSBl+JA+d2rQ2yRJtybJlCFQDtaahafvJ3DgaY9UkwWQEAAzpm4Y0Z/SNUijGpQjLjrHPG4W8dK+CTZfTvkBmhojJTuMR3Pv5keA+pEQJo+8Bbw1tQ/cKgZmzqaahEREREDY3BIlFjUgUKUqUqWPTpGywer3Rhyvz/wueXce2QfNx0QZewOluPVWL2gk0AgEcu74lx3QKH1At+j6JeJgLBotY0VC12WOCGMXbFOhKNKXHUin1WoSAI6BsxSKymmlZagTRMcT+AC8Uf8Wfje4p75Zf+E77swvA2RHWWs3pszCwSERFRI+OaRaJGFJZZtB1RVtA5WPz7t3uQLx8BIOON9Qc169z3ae26xPs+3lp7w+9V1LtI2oQBwo5ghjEWp2xqkMyiVJ1ZjEYOC9DiZ+/72+DXtuGPh93fKnfGfOGKsHJ3wUXaDao3OarJegoC/JbsYLGn3eDEB0tERERUB8wsEjUm9ZpFVbAoeJ3Q0w1H7kY/83+xzHcubvGEHzAPACdtEQJUVWaxo1CMD80Pxt13RkYmXKXx7+gpS+akMquiOXawGHMaahT2wbcDkhGyMR3OHlM066RbjPCmdoGhfG9InxGymeqxhFyXX/Y2LL+8DXeXcZBDAkciIiKihsDMIlFjUmW4RIfyyAk9p6GK5fvRz/VfAMAE6T/IgEZG0O+D1x++Y2dgLO469d+jQ2vcdlH3uOr6zZnwm2NMAY1ANMYxfbMOO4vK5kxUnXcP7INuBUKOs+jXoXa7nWn9O8A+5M7gtad13/g7CAkqva37wjbyGbg7j0p6vERERETJYrBI1IjUm5sIPmX2Ts9pqIJHGRxmC5W191wVyFo4FrnzB2GA/Kui3t5TdljXPwPLjiV1G4DRirxMrf1LA9ahDzytzoY3pztsFz4KhB0poXEupQbRGE9mMfaaxUTdfXE3DOqUhUt7tcGMgR3gKrwM9v6/g6dNf1Sdd08CLfHbMhERETUNnIZK1JjUa+dUUz313A1VdCvPPsxF7XXqusdhLP4FAPCc8W8Y6vpb8N5DC1dhufxCnfuXjdaoB8v/IPZB4dQng9fW7+eGt2FKh+AsjdqPGMeaxfo4s7BrbipentJHUVY19C8JtyOLDBaJiIioaeBPJUSNKSyzqJrqqWdm0VmmuM4VKiBX7+Zp3vlxsLy9UKKoN9S9Rpf+ZUOKxgH0oQNU/e5KfaQEANkUOTNZo32uxlmG6nbqsGax/umf9SQiIiJKRrPMLHq9XsyfPx8fffQR9u/fD0mS0KtXLxQVFWHUqOhrez788EPcfffdMfv48ssv0bFjR72GTKRJPa1S8NiU13oGi65yxXWuUAGvX4ZREsKyjqGGiT/p0r9ssCjW+IWNT1IHi+HfnvymdMTKCUrmVPhiDaYJB4v+1NaNPQQiIiIiAM00WLzjjjuwYsUKjBkzBtdeey1cLhfef/99zJkzBw8++CCmT58e8dkhQ4bghRe0p9TJsoxHH30UAJCTk6NZh0hX6syiWxUs6jkNVR0sogJOjx9GKTxwes44D696L8VWuTNaCdqBpFM2wiJ4NO9pEqSo01DVwWHYYfUAfFldYSz+OXo/caxrbGrBor3vDbBueQXezM5wFV7W2MMhIiIiAtAMg8VVq1ZhxYoVmDBhAubOrV3TNHHiRFx++eV46qmnMHbs2IjBXocOHdChQwfNewsWLEBxcTGee+45WK1xrHsiqqOwzKI6k6hjZnHHgUMYEHLdSiiH0+tDusa3gSultRgg7MQI97NIgz3s/ub82fjfXWfjS/OdYfcikoyam9bUENRBnurab8mGP61dHB3FMY2ziQWLVeffB2evGfCltov6d0RERETUkJrWT0xxWLx4MQCgqKhIUW6xWDB16lQ4HA4sW7Ys4XaPHDmCuXPnYuTIkRg/frwuYyWKKUYWTM9zFn/ee1BxnSNUwunywLL1Xc36BeIJDBB2Il1whN3b4GiH/XKbhPqXRUPUNYvqaajqzKI3p3v0zCQAb/aZ8GUXxh5MhA1uKkf+Nfaz9UEQAuM2pTZO/0REREQaml2wuHnzZpjNZvTs2TPs3oABgbzJpk2bEm73scceg8/nw/3331/nMRLFTfZHvZ3smkVZlvHg59txxWvfY/XuUwCATEF5dEYrlCP3x78j/d+Rs4Pjpe+RhvBgceMRO7wwoEJOiX9QgiFqsCeGZRaVAZ0vt7vmpjc1PG0HomzSB3Edi6G1wU3ZxEVwnjU15rNERERELUWzmoZqs9lQWlqKgoICiBrby7dv3x4AcODAgYTa3bx5M1atWoXf/e53wTbikZ3dtKaqStVrz5rauAiAuwo4uhnoMAjwuYHjPwMdz4m5vM5i9MOUxL/nyp8Ponjr1zgln4H/XfoLdj06DgPFHYo6GUIVCra+GLWd3uIeGIXw7WK81dvM/Nb9Ryw0PwIAWOgdgauM30KQtbeXsaZbkRJlp1Kj2ax4d0WzMgtpat0V8EfeukbsPx1Z7bSnmIfxKP9O5YyOSDt7dHzPUlL4/Yn0xPeJ9MT3ifR0ur1PzSpYrKoKZEZSUrSzGTXlNptN834kzz77LFJTU3HdddfVbYBEWvw+SK+NhFCyC/5uYyGc+BVC+QH4e08F/N7ozya5wc0ZX92Iheb/4Bd/AS51Pw5h95foKBQr6vQW98Vsp7twULPcUx0srpfPwo3u21EoHMHbvtG4KnMrUHVCuzHRCBiiZBbDdkNVZRFNaYAnfP1kkDGBb8rqzKL6vEsiIiIial7BohBjelnNmXGJ+P7777F+/XoUFRUhIyP2GW6hSkuj/ODaCGp+g9HUxtXSGY5vRnbJLgCAuHNFsFz8aSHcHS9AtFV4npIjqCipqp1a6fNA8Dogm6O8qx4Hzqz4DwCgl7gfQ4Rt8K1dHfPICS2Zgva75A1pbYX/HNT8qXyWHBgiBItlWQPgr/AhL0JfPllUvLsZPgGhucUqjwTBBaRHeN7mluCO892XKt0I3QLL7+fnpr7x+xPpie8T6YnvE+mpqb5PeXmRfoKKrlmtWUxLSwMA2O3af/k1mcf09Pj/Mt577z0AwOTJk+s4OqIkRJiyWcO87wtkvzca8LkgOMuQs2AYct/oC/POTzTrr99firfXKI+WWGh+BKYD3+g1YgCAR+P3TLcO6wJ/SitFmaPnTLi6XoKKUc/Dn94BEKWwHWBreEWL4lq9wY1ssAZ2VI1ANiSfWdRaw0hERETU0jWrzKLVakVeXh6OHTsGn88HSVLmSg4dOgQA6NKlS1ztOZ1OfPnllygsLERhYRw7KBIlw+eOfM8ffYMbADCUbEfK5lch+L2QKgPveMYXN+FkN+V5fMVVbvxhyc/o4j+AP9Tz6QteufazN6Vfe1x2dhuc1SYd/pXKA+XdBSPg7nqJ8mHRpDn91i1YVPWUn2/ZaIXsjjLFPIFpqGHBIaehEhEREYVpdr9OHzBgANxuN7Zs2RJ27/vvvwcADB48OK621q9fD6fTiaFDh+o6RmqZTPtWIWf+IGQsvyYYIEolO5G9ZFLEZwQ5xprFasYTmyGd2qYsVO2keuDf/8Bqw814yvhqQuNORug01DNaWXFWm0A2351/obKixlEZkXZEdQqq8kQzi3VZsxjP2YxERERELUyzCxanTZsGAHj99dcV5ZWVlVi0aBGysrKC5yRWVlZi9+7dKCkp0Wzrxx9/BAD06NGjHkdMLUXm8msgVR2Ded8qWLZ/CABIX3lL9Ifi3MBGcJUHpnGGECsPAwAqnV5sOFCKsfufRjuhBP3FXQmPPVGekGAxx1ob5Lm7jFHU81tyECbC1Fu3oAwsw6arGlOiHr2R2DRUdSaRwSIRERGRWrMLFocOHYrJkydj1apVuOmmm7BkyRIsWLAA06dPR3FxMR566KHg2saVK1di/PjxePVV7UzL3r17AQAdO3ZssPFTy2A49gMAwFj8S9R6xuKfo96vITrLwvso2QGX148Z/9qAP73/n8QHWQehaxZzU2sDONmcgaohd0KGAHf7IfC27hP2rOiu1GwzfBqqRmZRjBYsJnLmI4NDIiIiolia1ZrFGo888gh69uyJRYsW4YEHHoDJZELfvn1x//3345xzzom7nfLycgC1G+cQ6UffYERwlUNQBVlSyXZ8XtkTxypd6CxU6NpfLF5FZlEZ1NkH/R6OPtdBNqYmFJS5hchTTAFANqZAjjoNNZFgkWsUiYiIiGJplsGiKIqYOXMmZs6cGbXepEmTMGlS5PVi6qmsRLrROXMluMoheKoUZaL9JPb7HACAXMQfLNpkC9IEZ9Q6JXIafBCRFyEIjZRZrCGbEv8FTFhmUbUxUCCzqM+aRe5+SkRERBQbf2IiagZET1VYZlF0FOOELbDmsVUCmUUHYm+V6oeIo3JuxPuhu6GmGPXJ0rlUJ04KflWwaLRGXbMYbYpqGGYWiYiIiGJisEhUL/RfEye4VZlFRwmKqwIBVU6cweI73ovgkGMHVbGCxdANbhJl73uD9g318RU+j/JaMsGfkR+54USyuVyzSERERBQTg0WieqF/MCK6y5U9OIpx0hYIFuOZhvqQZxYe9V4NOywx6/og4ki0zGJ1sDi2R17MttSqzv0TKkY9H1Z+/bkFimvB7wmr409tm3B/mjgNlYiIiCgm/sREVB/qIXMl2k8qruWqkzhZPQ01N47M4tu+i2GHBS712kANn7b/PSoQeQ3gIxN6Y84FnfHHkYUx2wpjsMDVYzL85kxFcX62aoMa1ZrFGpXDnwwr87QdmNgYOA2ViIiIKKZmucENUdMnALJf3xZdyswi7Kfg8PgACDGDRT+E4NRRr2QBogytctjDGHbGDJz4Yj9wRLvOkK6tMSSR3Uc1B+WNelsrswgAzl4zIHhsEJ1l8GZ1gaF4Kxy9r0moa25wQ0RERBQbg0Wi+uKNvuNoogRVcGUSfMiAHQ6YkQVb1Gc9ghk1U2PDdh0N8XXWZPTqcy2yAXS95Grg9Te0K4p1/9ah/vOEUa9ZDD4owtH/d8FLV1KdM1gkIiIiioXBIlF9EISwoy7qw58M72GKtBpmIUJgVc0t1G5q4xZTAF+EilLITqnt+uFVwwz0dm9CK5SjUAxJM+oQLCJC5rCGejdUXYUFi3L99UVERETUTPHX60R6CJtyKkDw2Ou926sNX8YMFAHA5qsN7txi5MyiYFCeYzjfMBnT3PfhP/6zVBXrviZTiDFN151/YZ37iNw5v/URERERxcKfmIj0oJ5SKaBBMovxcsq1QaA3SrCoPsfQX51wk+thd9dY7ANuhrvdEPjS2qPsyg/0bTxsgxsepUFERESkxmmoRHrwq+d1ChC8jkYZihZnyIH3HilysOgX1cFiIFpsjGARRivKJ30AyLL+u8uGtcdpqERERERqzCwS6UCQwzdraUqZRRdqM4tVsjliPVmVcauOFeFvzMxbPRxDQkRERESxMVgk0oNqGqoM7Q1u7ANuhi+jIKy8vrlCMoslHmPEeuqwrD4zi7KhjkdvEBEREVG9YrBIpAdVsGjZvhiWre+GV7PkQJYiZ/bqi1OuDRZPuSPPPg8PFutpQADKx78e8nWEIzqIiIiIqNFwzSKRDtQHyIvuSpj3f6VRUUBjrI8LnYZ6ym0ATBEqqqJFf3W06K+H3yt58i9EydQvIMg+ePN6694+EREREdUNM4tEegjb4CacbLDA2WOKxjEb9S90g5tOrXMi1hNV0WLNNNT/806ARw6sZ3R2u0K3cfla9WSgSERERNREMVgk0oP66AwNZVcshGzJRn1nFvcNfhju9kMUZaHTUC/t2yXis+kW5WSDmpGeQDZmuO+Fbeh9sA17RLexEhEREVHTxWmoRDqQKg9Hve/oNQvetgMDF3L9BouO7pPhyGkN05H1wbISZAAA5k7shTbWPRGf7ZaXCmfItT9krD/IPeDof6Hu4yUiIiKiponBIlEdpX/5B1i2vR+1jmy0Br8W6nEaql8WYDGnQPC5FeWrfP0BALlWI2SDVevRwNhUx1T4G37GLBERERE1EQwWieKlcTi84KqIGSgCymCxPrlgRIrJAF9WV0X5BvlMAECGxQgIkY+s8LQZoLj213MWlIiIiIiaLq5ZJIqD4dgG5Lw1FFkfTgLctecnCh5bXM/LxtTQqzqNxSlHPidRhgBJFOBt3ReOXldjFzrhavfdkKs/6tlWY1jg6mk7CN7cs2AfcDO8bRksEhEREVEAM4tEccj89FqIjlOQKg8i9YdnUXX+fQAAwZ14sFjh9CC7DmM5hQx0wCnNe1bBhSoAEATYRjyJF5zbseaX4wCASX3aIc1sgAxlsOguuAj2QbfVYUREREREdDpiZpEoDqKjNjgz7/k8+LXgrozredkYmPq5/YQNVS6PZp2f/J3hlI24y/PbqG2dkjPi6hMAbh/RFbcP74pnJ/bCn0cXBsZiUE1DjbKG0udnZpGIiIiopWJmkShRIcdkxB8sBjKLvxyrRJcI01Anux8EALhgwlPGVyO2VSxnxjnQwBrFmYM6Kgsl1TTWKMEiY0UiIiKilouZRSINxsPfIXXNg5BO/Rp+UxEsJjYN1eeXIUQIFn0Q4YJJ816oNX6dD7GPEiy2y7To21eTxaiYiIiISI3BIpGK4K5E1tKrYN3yGjKXXRN+3187jVR0V8TVZs1xFYFgUZsvjo/j6+IUVEDfnVVlQ+SA8MVp/YJfPz7hLF37JSIiIqKmjdNQiVSMIYfZS7bDgSMzQiWVWawNFkVoZ/LkOILFEn8qXFF2Q42Xs/tkWLYvhmywwnn2rIj1+udn4f2iQXB6fOjRJr3O/TZdkUJ4IiIiopaLwSKRmjo4lH2Ky9DMouCKM7NYHSy6fX7NsMQrx5fkt/kkuFD3YLFy+ONwdxoBb+s+kM3R10B2zmmYMyIbF6ehEhEREalxGioRALHiEETbUe2bPtXupX4vIPthOLEForM0rvZr1ixWuX2423NdeBdxfhSr/IawdY3f+s6uvT/o93G1A6MVrjMnwpfVNb76RERERNTiMLNILZ7x4GpkfjwTEESUTfow7L7gcyoL/F5krPgdzLs/jbuPmmDR5vLiK39/fO3rixHSltom4wwWXbIxLLP4lu9i9Bk5EwZXCRy9i+IeExERERFRNMwsUouX9fEMCJAhyD5kfH4D1FMS1cdjCJATChQBANWbyFS5fZAhYoFvlOJ2vJlFF4xwy8rf8RyWW8Hdexbsg34P2Rz/GYxERERERNEws0gUQqo6HlYmuOI7S1GLO384HL2vAYRAMGhzBTbHUQeHcWcWYYJZUE6LPSrnJj0+qsENboiIiIjUGCwSqanOHRTd5Uk14zzzSlRe/JKirMod2CxHHRwmklk8JmcrykpwOu9S2lC4wQ0RERGRGqehEqmFHI0BJJ9Z1Dq/sCaz6IWkKI87WJSN2Ce3w2veS3BczqreLIdZMSIiIiLSHzOLRCqCz628dsd3PIZalS/8iIuazKI6OEwkswgAj3pn4VFv5PMRiYiIiIjqiplFIhV1sCjGeZai2ge/lOCnI7XPyrKMckdgvaFfda6iVzDH1aYeZywSEREREcWDwSKRml+5gYx6N9R4OWHCvct/BRAIFJ/7ek8ws+hVf/QMDBaJiIiIqGlhsEikos4smg58nVQ7TtmEoxUuAMCaPSV4d+Ph4L2wDW5EZbD49zaPaLbpkhksEhEREVHDYLBIFEKGEJZZNB77b1JthWYBv9l1SnEvbM2ipAwWd2VegL+0egnr/T3C2kw1Seiaa01qTERERERE8WKwSBRKlMIyi8lywgSDGNiptNypDEB9qt1Q/arMYpt0M45au+NXfydFuQsmDCnI5kEPRERERFTvGCwSKYiAXsGibIRJCnzEDpQ6FPfUmUX1MRvtMs0wSiIkKM98dMOAFKPIYwGJiIiIqN4xWKSWyeeBWHkkvFwUIaimoSbLCROMkgCfX8ahstpg8Z8z++P6oZ0VddXBYvsMC4yiAAk+ZT2IsBglyIwW68zVZWzwa/uAWxpxJERERERNE89ZpJbH60TOOyMhVR6Ebeh9qpsi4EsuWHR1vhjmfStrr2GEySDihM0Ft682uOuSa0VvcztgQ+2z6g1u2mZYYDKIkDSCQqtRQus0M/aVOMLuUfwqRzwJv7U1/Glt4TpzYmMPh4iIiKjJYWaRWpyUH9+EVHkQAJD2nXLXUVmUIPhdSbVbee5diutAZlFEhcMbLEs1SUgxSpAF5UfPodrltFVq4FmDoMwsAkCKUcLdF3eDFFgOibtHFyY13pZOtubBNuIJ2Af9HhD5ezMiIiIiNf6ERC2OVHEg8k0h+czi75dsw4KQa6dsgkkSYPfUBnyppuqNbUTlBjcZaWnKMYoCTFL4NFQAsBhFdMxKwce/HYJTdjfOapOe1HiJiIiIiKJhsEgtj+yPclNIas3iPmMhDlW4gZDZpDWZxdBgMcVYHSQKyo9e26x0XNqzNTYdKscfRpwBAJob3IS20TrdjNbp5rD7RERERER6YLBILVCUzWFEKeHdUH1p7fC7U9eHHYfhghFGUYDdXRssWoOZRdUMcMmIBy9RnqloihAsitXHcRARERER1SeuWaQWKHKwKAuJnbP4ecql+PGyf2Ob3Ak+Wflx8sAAj0+GQyNYlAVlYAlRuWYRAIySgINyXlh5lcsbVkZEREREpDcGi9TyRJuGKghAAtNQ7y2dgCvf3AgAkFSb0XhlCR6fH1Va01DVG6poBosi/ua9EsVyBgDgL54iZRtERERERPWI01Cp5Yl2RKEMCHFucPMXTxFOITPifTeMkH1+RWYxuMGNajdUWWM3TpMkoBJWnO96EXlCOQ7Jeci0GHBprzZxjY+IiIiIqC6YWaQWR4gSLQp+D+CPbxpquZyquD4k5+FXfz4AYLO/K04iE1VuHz7YciRYp3aDG1V2UNLOLAKACyYckvNwdrt0fHjdYGYWiYiIiKhBMLNILU+0aah+b9yZRTfUAZ6Aqe77cIH4M9b4zwYgoNypXF8YXLOoOjpD1piGapKUv8s5tyAbGZbwekRERERE9YGZRWq+fC4YjnwfOBfR6wh87Q/f/EWsPAypZEdcTQp+b9y7obo0ftdSgTR86j8XFUjTeAKwRsosakxDNRqUH8/gTqpERERERA2AmUVqnmQZWR9OgvHEFrg7jYBoOwpDyXa4ul6CikteDVaTircie9E4CLIfFWP+Dle3yxF10aLfCyHOaaieCB+fv17RE3/8aKvmvWDApwoWZckUVteoOiKD00+JiIiIqCExs0jNklS6C8YTWwAApgNfw1CyHQBg3vOZYppp+jf3QKi+zvhiTqDQr9y1VMHvCWQq4+CWtaeEZqVEnipqjbDBjVZmUT0NlZlFIiIiImpIDBapeYp2vIXXFfxStB0Ouy1EeVaADMHrjGsI7giZxfiCRWXWUGvNotHAzCIRERERNZ5mOQ3V6/Vi/vz5+Oijj7B//35IkoRevXqhqKgIo0aNiqsNl8uFV199FZ988gmOHDmC9PR0DBw4EDfffDN69OhRz38CqjONaZs1BK8dsjEFACCbMgAcVVbwucIfCn3eY4trCJGmoWZYIn+s5AgzYH05Z4aVhWUWGSwSERERUQNqlpnFO+64A8888ww6d+6Mhx56CHfddRccDgfmzJmDd999N+bzTqcTs2fPxrx58zBkyBA8+uijmDFjBtatW4cZM2Zg27ZtDfCnoLrQOpewhuCx19YzZ4Tf90YPFkVXeVxjcIXthhpglCJ/rJye2imwFaOegy+jAFUDb9MMFtXtpHAaKhERERE1oGaXWVy1ahVWrFiBCRMmYO7cucHyiRMn4vLLL8dTTz2FsWPHIicnJ2Ibr7zyCjZt2oSHHnoI06ZNC5b37t0bd999N7766itmF5s4IcrxF6HBot+kChZ9bggxMovxijQNVZ0RrGGUBAwvbBW8dvWYAlePKRHbZ2aRiIiIiBpTs8ssLl68GABQVFSkKLdYLJg6dSocDgeWLVsW8Xmv14t33nkHnTp1wtSpUxX3hg8fju+++w5z5szRf+CkryjBYtZHU2H56Z+BaqZ0xT3RWRJzGmokbllSXWtnFg2Scq1hmlnCDecV4KXf9EZuauTps2qSajdUi7HZfVyJiIiIqBlrdj99bt68GWazGT179gy7N2DAAADApk2bIj7/yy+/oLS0FMOGDYNQvcmI2+2G1xt+Ph81YVGCRdFRjPTV98Jw9AdAVAZ4gv1U3BvYqPmgbEtrzeJtF3aBqNq8pktOKn47tAAD87MS68+vXOAYKWNJRERERFQfmtU0VJvNhtLSUhQUFEAUw39wbt++PQDgwIEDEdvYuXMnAKBTp05477338Oabb2Lfvn0QRRG9e/fGbbfdhgsuuCCu8WRnW5P4U9QfqTqYaGrjqhee2Bm6zM0vAhZlgJYpVUKU4zsaQ82rChZDp6F+e+cI+Px+dNT4u89MNSb1b2JQ7apa0C4Dlgacitqi3ieqd3yfSE98n0hPfJ9IT6fb+9SsgsWqqioAQEpKiub9mnKbLfJulmVlZQCApUuXwuFwoKioCG3btsXWrVvx6quv4re//S1efvlljBgxQt/Bk76iZBZriHv+DX/3CcpCezGQdGZR+QsKd8gGN1kpxogb0KSak/uYpVuMePLKs7FowyHMPKdTgwaKRERERETNKlgUVNP71ORI5xKEcLuIgsdVAAAgAElEQVTdAICTJ0/i448/Rm5uLgBgxIgR6NOnD6677jo8/fTTcQWLpaX2mHUaUs1vMJrauOqDodyO7DjqeZwOmEOu7WWlSPU4Ef1N0qbOLHpCrh02J5wR3k8Dkv83GdU1B6O6BjZrauh/15b0PlH94/tEeuL7RHri+0R6aqrvU15eeuxKGprVIqi0tDQAgN2u/Zdfk3lMT4/8l5GamgogsJlNTaBY44ILLkC7du2we/duFBcX6zFkqi+yL3YdIGznU8HnSnqDG3VmUQ65jvaLjFRmBImIiIioGdItWFy3bp1eTUVktVqRl5eHY8eOwecLDxYOHToEAOjSpUvENvLz8wEg4oY2eXl5AIDKysq6DpfqUxzTUAFAcFUoC3yepI/OUGcWozm3c23ec3K/9kn1R0RERETUmHQLFouKijB27Fi88sor9ZqVGzBgANxuN7Zs2RJ27/vvvwcADB48OOLz/fr1gyRJ2Lp1q+b9I0eOQJKkYNBITVScwaLoKldcCz4nBH9yO9/6ZO2PS2Gr1LCyu0YVYmr/9njs0h7oknt6LHAmIiIiopZFt2Dx0ksvxYkTJ/Dss89ixIgRuPXWW7F69eq41hEmYtq0aQCA119/XVFeWVmJRYsWISsrC+PHjw+W7d69GyUlJcF6OTk5GD16NHbu3Bl2HuMnn3yC4uJiDBkyJDjllZqoeDOLbmWG2HAi/JcMkXzl66e4/tbfR3F950WFGH1mKzw4rnvYsx2zUvDHiwoxpkfruPsjIiIiImpKpAcffPBBPRoaO3YsZs+ejcLCQjidTqxevRoff/wxPvjgA9hsNuTn50ddSxiv/Px8HDt2DMuWLcPWrVvh8XiwceNGPPjggzh8+DCefPLJ4BmMy5cvx7XXXgtZlhXHYfTr1w+ff/45Pv74Y9jtdpw8eRIffPABnnvuOaSlpeH5558PW8+oxW531/nPo6eU6qMWnM7kjoZoTqTKQ7BsWxS7ot8DISSwNJTtiat9tyzhT54bMdXwdbDMes71MHU6B/B7UHnRszirey+M7p6HVmmxj/FojlrS+0T1j+8T6YnvE+mJ7xPpqam+T6mp5tiVNOi6G2pKSgouu+wyXHbZZSgrK8Nnn32GZcuWYd68eXj55Zdx/vnn46qrrsKoUaNi7mwazSOPPIKePXti0aJFeOCBB2AymdC3b1/cf//9OOecc2I+365dOyxevBgvvfQSli1bhlOnTiErKwsTJkzALbfcElzXSE1YvBvcxDnldI+/LbqKx4LXv/P8AWVQZpdbZ6XC0X02HANviX+cRERERETNlCDrPU9Uw969e3HPPfdg8+bNAID27dvjuuuuw4wZM+q763p18mTT2gSnqW7VWx+Mh9Yi66OpurW3ztcT50m161inu+/FQTkPa8y3B8sqLv4bXGdO1K3Ppq4lvU9U//g+kZ74PpGe+D6Rnprq+9Qkj87YsmULHnroIcycORObNm2CyWTC+PHjYbVa8fDDD2PWrFmw2Wz1OQQ6XcWZWYyHT0rBEeQoyuyyGW7ZqO5Utz6JiIiIiJo6XaehAkB5eTmWLl2KxYsXY9euXZBlGV26dMENN9yAK6+8EpmZmZBlGe+88w4ef/xxPPbYY3jiiSf0Hgad7uLc4CZmM6IRWy58E0dXvqsot8MCt/rjUf9JeCIiIiKiJkO3YHHdunV4//33sWrVKng8HkiShHHjxmHatGkYMmSIoq4gCJg5cyb27NmDjz76iMEiJUzQIVgsnfIpKq35mPR/P+FqSZlZdMAMT9jHQ58AlYiIiIioOdAtWCwqKgIAdOzYEVdddRUmT56MnJycqM8MHDgQ7777btQ6RJp0CBY/O2LBv37aCwAolZXzuO2yGW6opqEys0hERERELYhuweKoUaMwdepUDBs2LO6dTocMGYK3335bryFQS6JDsHj/l4fgrf4IlKp2PrXDDA8kVZ8MFomIiIio5dBtg5t58+bhggsuwBdffIGSkhLFvS1btmD58uVQb7yam5uLAQMG6DUEOs0IzlIYD60F/Bqb2ag2uHGcPTuhtp2CORgoAsAG/5k4LmcBAPaKneCECYDylx56TH0lIiIiImoudAsWHQ4HioqKcPvtt+Pw4cOKezt27MD//u//4pprroHb3bQOsqcmyuNAzoLhyPpoKtK+vS/8vipwqzr3Twl2oAwEXTDhGvddeM43FU9l/CXsfgCDRSIiIiJqOXQLFt98802sX78eU6ZMQYcOHRT3LrzwQlxzzTX4/vvv8dprr+nVJZ3GUrYugOgMZKhTfv5XoNBjh+AOHLUi+GsDN0/rvpDNmQm1b5GdYWW/ygVYlXs1qqydgmVVsjn4tbvjsIT6ICIiIiJqznQLFpcsWYIpU6bg4YcfDtvYpk2bNvjzn/+MKVOm4MMPP9SrSzqNCc4yxbVUvBW58wciZ/4gGE5sgTLLF98a2Xj8YURXpFtqp6dOd/8Fe9uMRcXoF+DPyNetHyIiIiKipk63YPHo0aMYPHhw1DoDBw7E8ePH9eqSTmvK9a0ZK26C6K6E6LEh47PrldNQxcBGNJ5WverUY9GQfPTtkIl0c22w+KN8Bjb0exqu7r+pU9tERERERM2NbsFiVlYWSktLo9Y5fvw40tPTo9Yh0mIo2x38WrIdVW5wIwRe48oxf4en7cCk++iWF9gRNTRYBIBUk6RVnYiIiIjotKZbsDhkyBD885//DNvcpsaPP/6IN998E4MGDdKrS2rJQnbWlauDRV/2GSj7zUdYZhwX8/H9hi5hZenmQFAYOg0VAKwMFomIiIioBdLtnMU5c+Zg0qRJuOSSSzB48GB06tQJZrMZ5eXl2L59O3799VdYLBbccsstenVJzYjh2Eakrn8a3tZ9UXXun4FYZ3HGONNQ8IdnFmssSLkavV0bUSCeiPj8vPTbAZuyLN1iDPzfzGCRiIiIiEi3YPGMM87AggUL8NBDD2Ht2rVYu3at4n7Pnj1x//3348wzz9SrS2pGsj6aCsHrgOnQGrg7nAdPpxF1bDFkzaKgDOZsUhZGuJ/F9dKnuNf4TtiTVef8Edt3nQGgQlGeUR0kmg3K4JPTUImIiIioJdItWASAs88+G++//z4OHjyI7du3o6qqCmlpaSgsLERBQYGeXVEzI3gdwa/N+1bGESxGzywqNrhRZRZFAZAh4l++MbhaWhWWYfRbsuHxh7dfk0E0iIJmORERERFRS6JrsFgjPz8f+fnhxwysW7cOH3/8MZ544on66JaaixhxIAAIocGgZhuhwaIyuKsJBF0wYaz7KVwo/ohXTM/VPmq0wuNTtn92u3TkWAPTUM1GZXCYYmSwSEREREQtj+7BotfrxalTp+Dz+RTlTqcTS5cuxWeffcZgkWLzeaLfDwkWZdU0VLe39p4TZmzyd1M+K5kUweKUfu1xy7AuEKqDzsH5WWidZsIJmxuD8jMhxlpfSURERER0GtItWJRlGXPnzsWCBQvgdDoj1unWrZvmPWpJYqcWBZ8r+n3VBjdurx/3fboNRyuc2FVcpajrVr3me0vdcPtqxzC8MFcx1dRkEPHa9H7YcLAMw7rmxhwrEREREdHpSLdg8V//+hdee+01pKWloVu3btixYwc6d+4MWZZx4MABZGRk4NJLL8X//M//6NUlnc682r9wqBUScAoSVmw7ga92FmvWVAeLL649hCP+NsFrkxR+gky7DAsm9Gob93CJiIiIiE43up2z+OGHH6J///749ttv8fbbbwMAHnnkEaxYsQIrV65E79694fP50LlzZ726pOYqxrEYACD4YgSLisyigE9+OR6xqhtGxbVHFTwaJU4zJSIiIiJS0y1Y3LdvHyZOnIiUlJTg2q8aHTt2xLx587Bp0ybMnz9fry6p2ar7NNRVWw+GVJaQazVFrOtTvea/+pU78xpF3T4GRERERESnDd1+Svb5fEhLSwMAmEyBH9xtttpTz81mM6666iosXrxYry6puYonsxhjGurEsvnBrw+Vu7Bqx8loraHIfSe+9Z2NOz034CSyFHeNBmYWiYiIiIjUdFuz2Lp1a+zcuRNAIDC0Wq3YunUrRo4cGayTmpqKw4cP69Ulnc5iZBZD/XK8KuK9s9ulw2IQ8e+D/fFvf3/NOswsEhERERGF0+2n5CFDhuDNN9/EW2+9BQDo0aMH3nrrLWzevBkAUFpaioULFyInJ0evLqnZiiezGH+wqJ5mGmruxF7IsBgj3ge4ZpGIiIiISItuweKcOXOQkpKCr7/+GgBw7bXXoqysDNOnT8fAgQNx/vnnY8uWLRg/frxeXdLpLIHMoh+Rgz2TJMJijP6aGzV2QyUiIiIiaul0m4aan5+PTz/9NDgVdfTo0XjyySfxyiuv4NChQ2jXrh0mTJiAm2++Wa8uqbkIW6NY9zWLofxy5GDPYhBhMUgR7wPMLBIRERERadEtWASAnJwcDBkyJHg9ceJETJw4Uc8uqDmS/Qk/Ems31FD+CAlyUQAkUWBmkYiIiIgoCbr9lHzddddhzZo1ejVHpxPZq7hM2fouzNsWK89KVElkzWKkaahGSYQgCLAYY2UWGSwSEREREanp9lPy1q1bceLECb2ao9OJPzyzmPHl7TDt+SzyM74EpqFGeI2zUgIb21gM0V9zzkIlIiIiIgqnW7A4e/ZsvPHGGzh+/LheTdJpQlBlFmukrXs88jM6ZBbbZ5gBIGZmURAYLRIRERERqem2ZtFqtaKgoAAXX3wxBg8ejI4dOyI1NTWsniAIuPPOO/XqlpqDSNNNwza+qSn3Q/C7424+0tEZbTIsAGJnFomIiIiIKJxuweLjjz8OQRAgyzLWrl0bsR6DxRZI1g4WfWnttesnsLkNAMgRMouZlsDrnRIjs0hEREREROF0CxafeOIJvZqi002kzKIxRbM4kWMzgMiZxTRz4PVmZpGIiIiIKHG6BYtXXnmlXk3RaSbSmkXBbdMuTzCzGGmDm7w0EwDEPDqDiIiIiIjC8adoqn8au6ECgOCuDC9zlCD7nZGJNa8xDTUrxYhxZ7UGAFgMymmoKQweiYiIiIhi0i2zOGrUqLjqCYKAVatW6dUtNQcRM4vhwWLa2ocgapRHE5pZHFGYi9Fn5uHs9ulINVVPQ1UFhzdd0AUvfrMHXr+MS3u1SagvIiIiIqKWQrdg8fDhwzHrZGVl6dUdNRd+L9K/uUfzltY0VPP2DxPvIiSzmG01Ymx1RrGG+uiMTtkp+L+pfbHtuA3jzspLuD8iIiIiopZAt2Bx48aNmuVOpxP79u3D/Pnz4fP58Pzzz+vVJTUDpr0rYDq4WvOe4K4EZD8g1Gb+BEQ4TiOK0A1u1FNOA2XKzKJRFNCnfQb6tM9IuC8iIiIiopZCt8VbVqtV87+cnBwMGDAAL774IpxOJ1588UW9uqRmwLx3ZcR7AmQIHnvwWiremlQfoUdnmDR2PlVnFomIiIiIKLYG3elj7NixWL58eUN2SY1MFqMHaoK7Ivh1xhc3J9WHT659jUWNIxd5dAYRERERUeIa/KfokydPNnSX1JiE6MFiyk//BLwOCPZiGEp3JtVF6AY3GrEizKpgsX2mJal+iIiIiIhaEt3WLMZy7NgxvPfee9zkpqWJESxaN86DLBrg6TA06S5Cp6EKQni4KAgC/jy6EG/85wAm9GqDjlkpSfdFRERERNRSNMjRGXa7HeXl5ZBlGTfeeKNeXVJT4vfBcGIzvK16AYaQzF2MaagAkPrfF1CZ0irprn0xMosA8Ju+7fGbvu2T7oOIiIiIqKVpkKMzDAYD2rZti3HjxmHOnDl6dUlNSPoXN8Oyexm8uT1QOnUlUJ3hk2NkFmsYSrYn3Xfo0RmiRmaRiIiIiIgSp1uwuG3bNr2aouZG9sOyexkAwHBqGwzHNsDbblDgXtzB4o6kuw9dsxgxtUhERERERAlpkA1uPB5PQ3RDjcXjUFwKPlftRRzTUAHAcPLHpLsPzSxaeUwGEREREZEudA0W16xZg8suuww7diizREuXLsW4ceOwbt06PbujJkL02BTXsmSqvYgzsyh4nUn3f1bbTABAqknCxD5tk26HiIiIiIhq6RYsbt68GTfeeCP27t0blkls1aoVjh07huuvvx4///yzXl1SEyF4qlQFgdfKeOAbWDf+LaG2fNbWCfd/cY82eOrynnhv9kCkmhpsg18iIiIiotOabsHivHnz0KFDB6xcuRK9evVS3Bs5ciRWrVqF/Px8PP/883p1SU2EOlgU/F4AQNYnMxNuy5fTPeFnDCJwUbdWaJvB8xOJiIiIiPSiW7C4ceNGzJo1C+3atdO836pVK0yfPh2bNm3Sq0tqIsIyi77k16g6+l6feP+yL+n+iIiIiIhIm27Bot/vR1ZWVtQ6mZmZ8Pn4g/3pRnCrM4vupNpxFVwEd+fI53VGJMtJ9UdERERERJHpFix26dIFa9eujVpnxYoVyM/P16tLaiL0yix62w5KbgDMLBIRERER6U633UAmTpyIxx9/HCaTCVdeeSUKCgpgMplQXl6O7du3Y+HChVi9ejXuvPNOvbqkJiIsWPQnFyz6MrskNwAGi0REREREutMtWLz66quxYcMGLFq0CO+//37YfVmWMXr0aMyePVuvLqmJCN/gxgOpZGdCbfiNqXB3HIqnv9yFnuJkFPkXx9+/359QX0REREREFJtuwaIoinjhhRfwzTffYPny5dixYweqqqqQlpaGM844A+PHj8dFF12kS19erxfz58/HRx99hP3790OSJPTq1QtFRUUYNSr2mrfu3aPvuPnggw9i+vTpuoy1JVAHi6LtKLK/+mPcz7u6jEXV4DvwS7kJ728+AjMm4GexFe67ahSylk6J3QAzi0REREREutP9ULrhw4dj+PDhejercMcdd2DFihUYM2YMrr32WrhcLrz//vuYM2dO3IFeYWEhbr31Vs176qM/KDrBbVNcWze/AsHnivt5e/+b4MvrhZ0/HQUAuGDCB/4LcanQC3H9ekFmZpGIiIiISG+6BotVVVVYuHAhLr30UrRp0yZY/t133+Hnn3/GrFmzkJKSUqc+Vq1ahRUrVmDChAmYO3dusHzixIm4/PLL8dRTT2Hs2LHIycmJ2k5OTg7GjRtXp7FQgOCxK69dFQk9LxsC74QAQVF+7bubsS+eoxOZWSQiIiIi0p1uu6GWlpZi6tSpeOaZZ3D8+HHFvcOHD+PZZ5/FlClTUFlZWad+Fi8OrGUrKipSlFssFkydOhUOhwPLli2rUx+UGMGjzCxC9ibWgDEQLJY6wjfGOSS3Cn7tkSXt53l0BhERERGR7nQLFl955RXs27cPt99+O7p27aq4d8kll+Dee+/FgQMHMG/evDr1s3nzZpjNZvTs2TPs3oABAwAAmzZtSqhNu90OPzdJSVrYBjcJTguVpUD6sMQefj7jDe47sNbXC//0XowPfcO0+2dmkYiIiIhId7oFi5999hlmzZqFG2+8EWlpaYp7aWlpmDVrFmbOnInPPvss6T5sNhtKS0vRtm1biGL40Nu3bw8AOHDgQMy2SktLcc8992DQoEHo378/+vTpg1mzZmH9+vVJj6+lEjyOOj0vV2cWyzQyi1vlzpjpuRcPeIvgi/S6MlgkIiIiItKdbmsWi4uLNbN9oXr27Im33nor6T6qqgIZrEjrHmvKbTab5v1QO3fuRNeuXfHwww/DZDJh48aNeOutt3DNNdfgpZdewujRo2O2kZ1tTWD09U+SAsFUQ49LlBKbBirnnwfh4LrgdVarbMBoRaUnekbSr1rTWMNilmBqYv8Wp4PGep/o9MT3ifTE94n0xPeJ9HS6vU+6BYt5eXk4evRo1Dp79uyJufFMNIKgHSzUkONcu/aPf/wDOTk56Nu3b7Bs9OjROO+883D99dfjsccew6hRo2L2RwGCP7HMnu/iR2F4I+SIE0NgGuopW/g01FD+CJlFOb1dQv0TEREREVFsugWLF1xwAd544w0MHjwY/fv3V9zz+/1YsWIF5s+fX6cdSGumt9rtds37NZnH9PT0qO2MHDlSs3zYsGHo3r07tm/fjt27d6OwsDBqO6Wl2uNoLDW/wWjocWV5PDAmUL/UciYyO5wH0+F1cPScDluZEwBQXOmM+pzWNFRfWgeUdJ4CNLF/i9NBY71PdHri+0R64vtEeuL7RHpqqu9TXl70+CgS3YLFW265BV988QVmzJiBTp06oaCgAGazGWVlZdi9ezdKS0uRlZUV8WzDeFitVuTl5eHYsWPw+XyQJOXumIcOHQIAdOnSJek+8vLysH379jrv2tqi+BPc/VQQUH7FQoiVh+DP6AQgkBXW2g01lKyahursPhm2Cx8FTKmJ9U9ERERERDHptsFNmzZtsHTpUowdOxbHjh3D6tWrsXLlSvzwww+oqKjA6NGjsXDhwuAmNMkaMGAA3G43tmzZEnbv+++/BwAMHjw44vPbt2/H4sWLcfDgQc37e/fuBQB06NChTuM83Uilu5Gy5TWItiPhN5PZYEYQg4EiAFS5ffD4ok8jVq9Z9GV1gWxKi1CbiIiIiIjqQrfMIgC0a9cOzz//PJxOJ/bt2webzYa0tDR07twZFosF69atwzPPPIOXXnop6T6mTZuGFStW4PXXXw8elQEAlZWVWLRoEbKysjB+/Phg2YkTJ5CdnR1cK7l161bce++9GDt2LF588UVF24sXL8bhw4cxaNAgtG7dOukxnnZ8bmQunQLJfgLmHUtRNkV1jmWCR2VoKbFHzyoCWmsWdftdBxERERERqegaLNawWCzo0aMHgEDAtnDhQrz33nvYt29fndseOnQoJk+ejMWLF+Omm27CmDFjYLfb8e6776K4uBjPPvtscG3jypUrcffdd+Paa6/FXXfdBQCYMGECPvnkE6xYsQKzZs3CxRdfDKvVig0bNmDJkiXIzs7Gww8/XOdxnk6MxzdBsp8IfH1ic2DaqVj76iS6wY2WUo0zFhVjkAQYDcppxzI3ICIiIiIiqjf1EiwCwC+//IJ33nkHn376KZxOJ2RZRt++fVFUVFTnth955BH07NkTixYtwgMPPACTyYS+ffvi/vvvxznnnBP1WaPRiJdffhmLFi3C4sWLMXfuXPh8PrRt2xYzZ87EDTfcgDZt2tR5jKcTWVAGaYLXqZz+qcM5h6UxMouvTuuHwXvWAJtCB8LMIhERERFRfdE1WHS73Vi+fDneeecd/Pzzz8GjLIYOHYpbb701bJfUZImiiJkzZ2LmzJlR602aNAmTJk0KKzebzZg1axZmzZqly3hOe5JJee11AIpgMf5pqPb+vwsrK7W7URIjs5huNgCiKjhksEhEREREVG90CRYPHDiAd999F0uWLEF5eTlkWUZ+fj6GDx+OBQsWYNq0aboFitTwZFH5mgheBxRb0SSQWbQPvE1x/cp3+/DqugMxn8swG8KDQwaLRERERET1pk7B4pdffol33nkH69atg9/vh9FoxLhx43DVVVfhvPPOw4EDB/D222/rNVZqLLJyl1LBqzwPMd41i7ah90E2Z4Q0K8cVKAJAmllisEhERERE1IDqFCzefPPNEAQBZ511Fi6//HJcccUVyM7O1mts1EQIqsyh4HUEvpBlpK/6PaSK/fE1JCrXPsazA2oNgyRqBIfc4IaIiIiIqL7UOTUjCALS0tJgtVphMNTbfjnUmCIEi8aj62HZ8WH8zaiCvYOljsTGoXpe3R4REREREemnTj9tz5s3D+eddx5++OEHPPDAAxg2bBjuvvtubNy4Ua/xUVOg3sCmehqqVPxrYu2odlU9WBZfsPinUYXVX3EaKhERERFRQ6lTKnDUqFEYNWoU9u/fjwULFmDp0qVYsmQJli5disLCQgwfPhwCz8Jr/vzamUUhgV1QAw/EDha75aWiTboZa/aUAAAeuqQ7xvcMHGUSdq4ig0UiIiIionqjy7zRgoIC3HPPPbjjjjvw8ccfY8GCBdi+fTt27doFAPh/9u49Tsa68f/4e3b2vGgJOcQussQicqgs3ZFjREIrOXV2iDvVTzpQqftLom8qdwdKDmGTcriVb9wIdYccUt0UKqzDhsUexh5mr98f287O7MzsrjW7szP7ej4e9+OeuT7Xdc1ndj8PXe/9nFauXKmoqCg1adLEEx+HMlZwzmKlrVOUEhQhOa6JWowbOYY9V8NQB95QRzdHV1XVsD9U56pQ9by+pt31jmGz4P0AAAAAeI5Hu2ZCQ0M1ePBgrVq1SkuWLFGvXr1kNpu1efNm9e/fXw888IC2bdvmyY9EWSjQg2hOPanI1fcqID3p8u7j1LPouKrqs90a664WtVS7Sqim9GyiB2+OUoB9IGQ1VAAAAKDMlNqKNDfeeKNuvPFGnTlzRsuXL1dCQoK2b9+ub775Rv/972XOdYN35WS7PBzyy6rLuo1htxqqYRgOPYsL7r1BzWtXcXVZPqdwSFgEAAAASkupP21Xr15dY8eO1b///W+98cYbat++fWl/JDys4DBUmwJbYRR9o/zmdjY9S+lZ+fetVzWsGNc7Djt1msMIAAAAwGPKbK8Ls9msHj16qEePHmX1kfAUNwvZGAXnEBbhVGq2gjKyVSkk0KFX8arQQFUJDSq6Gk5zFulZBAAAAEoLT9soWo5nehbnfP27Bn24S+ctWTpxIX++4rWRxehVlFzMWaRnEQAAACgthEUUzd0w1MvsWbQqQGfSMjX/P0cdhqBWCS1mBzdzFgEAAIAyw9M2iuZuP8XLDIs5fzW3f//yp7Ks+fcMNhezGbLPIgAAAFBmeNpGkdwucOPuuBvWv5pbUmqmMrLzw2JQscMicxYBAACAssLTNormbs6iNfOybmO1a24XLPnbcQQHFm/uoVEgHBZ8DwAAAMBzeNpG0dwMQzVdZlg0lB8Kz1/Ksr0ufs8iC9wAAAAAZYWwiKK5GW5qsl5yedwdx57F/LDInEUAAACg/OFpG0Uy5WS7Pp5lcXncHfuweN5i37NYzB5CpwV1aCtfxMwAACAASURBVL4AAABAaSnmngWoaEyWcwo9uELZNVq4Xw01+/LCYo6bnsWSD0MlLAIAAAClhbAIlyptf1GhBz+VYTLL0voRl+eYZDgdM0wBMrkJl1bDvmfRboGb4vYsFuxJJCwCAAAApYanbbgUevBTSbnbZoTvnlvs64zgym7L7IehpmTkh8Xi9iwaTnMWWeAGAAAAKC2ERXiUERThvkyuw13xF7hh6wwAAACgrPC0DY8ygsLdllndNLeSL3BDzyIAAABQWgiL8CgjsCRhkQVuAAAAgPKGp204M5wXrimu7IBgt2U5bppbSYehEhYBAACA0sPTNpy52VexOE5czHRbduXDUFngBgAAACgrhEU4MVkvlfja06nug2bOFS5wYxScs0jPIgAAAFBqeNqGs+ySh0V3vYeS+2GoQYElXA2V5gsAAACUGp624cSUnVHia90FQqmQYagBxR2GypxFAAAAoKzwtA0nVzIMtbCeRasCVDkk0Ol48Re4Yc4iAAAAUFYIi3BiKqVhqIZh0uqH2qtL4+oOx4s/DJU5iwAAAEBZ4Wkbzq4gLBY2DLVP7DWqFBKoJjUrORwPLuZqqAbDUAEAAIAyw9M2nJisJZ+zWFjP4sj29SRJ4cGOPYRB7LMIAAAAlDs8bcPJlQxDLaxnMW9uYlhQgMvjRXPsgWQ1VAAAAKD08LQNZ9mWEl/qbi/FXIYk557EoGIOQ1VAwTmLLHADAAAAlBbCIpwUthqqUXCRmQIK3WcxrIYkKbDAVhkMQwUAAADKH5624aTQfRbNwYVe624Y6sVub0lBYZKkQHPJhqE6DzulZxEAAAAoLYRFOClszqJRRFi0Gq6bVEZMf9vroAI9i8VdDdV5n0WaLwAAAFBaeNqGoxyrKm2b6rbYMIcWenlhw1Dz1LnK8R7mgOKGRfZZBAAAAMoKT9twEHTyu8JPKOEwVHuNqkeof4taCgkM0Ji4aJmKu1CN05xFhqECAAAApSXQ2xVA+WFOPqTIzwcXek6Rw1CL+feHZ7vHaNLtjZ0WuylUgbBo0LMIAAAAlBqetmFT5ctHij7JHFRocXHDouS8KmqRmLMIAAAAlBmetmETeO5gkeecuVR4wHNesVS60Ov9EtfJ8d4FP5vmCwAAAJQWnrZxWY6lWAstvyo8xOH9paaDldmwl2c+3KlnkTmLAAAAQGkhLOKyZBqFD0O9unKYw/usGrGlWBvCIgAAAFBaCItwK/uqaF1q3M/hWGYRayJdHeHYs8i8QgAAAMA38SQPt6xXNZCl9aMOxzJVeM9i5bCyDItGKd4bAAAAqNgIi3AvIFCG2TH8FdWzWCms4NYanmxiDDsFAAAAygphEe4FmF2ExcJ7FkODCoRFFqEBAAAAfBJhEblysp0OGaZAKdAxLOYYhYc/U4C5wAHCIgAAAOCLCIvIZc10PuaiZ7Gw7JeicBlOcxQ918SMkCqO74MiPHZvAAAAAI4Ii5AkmawZLg66CItuFpU5b0To11vfk0yOPYvO4bHkjNCqSm95vwxTgNJbPiAjNNJj9wYAAADgqPDVSlBhuAyLAYGS2XEOYqCsLq//1+1b1b1pTWnvLwVu7Nm/R6R1eklpnV7y6D0BAAAAOKNnEblcDEM1Asy5gdFOFaU5X2o/j7FgOGTOIgAAAOCTfDIsZmdna968eerbt69atmyp1q1b67777tPGjRtLdD/DMDR06FA1adJEb775podr6xtMruYsFhhSKknBcl4Ix6oABZlzm5LhdA1hEQAAAPBFPhkWJ06cqJkzZyo6OlovvviiJk2aJIvFojFjxmjp0qWXfb+FCxdq165dpVBTH+JmgZvsHMc5iruMJk6nGaYAdWxQLfeNU8+iTzYxAAAAoMLzuSf5DRs2aP369erTp4/efPNN3XXXXYqPj9eSJUsUFRWlGTNm6Ny5c8W+39GjR/X6668rNja2FGtd/rmas2iYApVlzXE6/mTWIw7vgwIDFRz4V1Mq2LNIWAQAAAB8ks89ya9YsUKSNGrUKIfjoaGhuueee2SxWLR27dpi3cswDD377LOKiIjQo48+6vG6+hJ3C9xkZudoqzU/SC/P/pv+NAqsQmofCAMcm5QnV0MFAAAAUHZ87kl+7969CgkJUbNmzZzK2rRpI0nas2dPse718ccfa8eOHZo6daqqVKlS9AX+zM0w1CxrjiZmjdac7P4amfn/dELVZS3YbOx6E53mLLLADQAAAOCTfCospqamKjk5WbVq1VJAgHPV69SpIyl3aGlRjh8/rtdee009e/ZU9+7dPV5XX+NqgRvDZFaGNUd/qqpmZw/W5pwbJMlFWLRfDZUFbgAAAAB/4FP7LKal5W7bEBYW5rI873hqamqh98kbfhocHKwpU6aUuD5Vq4aX+NrSYP5rRdKS1Mt0yvlYWHiowiJCnI7nGI5h0RRgtn2mqZLj76ZS5TAZ5eznhOK5kvYEFER7gifRnuBJtCd4kr+1J58Ki6YihjQahlFoeZ5ly5bpP//5j1577TVdffXVnqia78t2scDNX3MWC8op2FsYYNebWLDHlzmLAAAAgE/yqbBYqVIlSVJ6errL8ryex8qVK7u9R2JiombOnKnbbrtNffv2vaL6JCe7roe35P0FoyT1Cr2YooI/NUuGobMu7tWjWS3pcP77HMNk+8zgdKuusjs3NS1LmeXs54TiuZL2BBREe4In0Z7gSbQneFJ5bU81arjPR4XxqbAYHh6uGjVq6NSpU7JarTKbHefHHT9+XJLUoEEDt/d4/vnnZTKZNHbsWJ06lT/2Mm+7jdTUVJ06dUqVKlWyhdMKIcfFnEUFaMoXBx2OTe0Zo96Rxx3CokPvoVNPInMWAQAAAF/kU2FRyl3xdP369dq3b59t9dM8O3bskCS1a9fO7fXbt2+XJA0cONBl+YIFC7RgwQKNGzdOjz32mIdqXf65WuBm38k0HU222N5fGxmqPs1rKTDpdIGL7cOiY4Bn6wwAAADAN/lcWIyPj9f69es1f/58h7CYkpKihIQERUZGqnfv3rZjSUlJqlq1qqpVqyZJeuedd1ze95dfftHs2bPVp08f9enTR9HR0aX+XcoVF/ssfv3bBYf3QX9N2HVa8dRhn0W2zgAAAAD8gc+FxVtuuUUDBw7UihUrNHr0aHXv3l3p6elaunSpzpw5o9mzZ9uGj3711VeaPHmy7r//fk2aNEmSdNttt7m8b3h47vji6Ohot+f4I5PlrML2L1DIr6udytKtjkEv+K+w6NRb6BAeC4RDehYBAAAAn+RzYVGSpk2bpmbNmikhIUFTp05VcHCwWrVqpSlTpqh9+/berp5PifjPqwr7eYnLspwC+ykGm/8KggUCoGHXe2gU7Fn0ra08AQAAAPzFJ8NiQECAhg4dqqFDhxZ63oABAzRgwIBi3bNDhw46ePBg0Sf6GXdBUZKyCwS9gLxQ6DQM1ez6tcQwVAAAAMBH0e0Dt6yGY/DLtP6156LTvMRCVkNlGCoAAADgk3iSr8gMo9Digj2LGdm5YdF5ziIL3AAAAAD+hrBYgZkyLhRabpVj8MsLi4UNNTUKbp1BEwMAAAB8Ek/yFVjApXOFllsLNA/bMFSnoaV2vYcMQwUAAAD8Ak/yFZgp/Uyh5U5hMdtdWLQbzsoCNwAAAIBfICxWYAGWwsNidoFhqJdscxYLBEL7uY+FLX4DAAAAwGfwJF+BBVgch6Eeyqnj8N7tnEWnvRTzOQVJwiIAAADgk3iSr8DsexYvNe6n57NHOZQXHIbaonbl3BeFBcDC5jMCAAAA8BmExQrMlHHe9toSeJWshmNzsA+LEcFmPdcj5q8LLyMs0rMIAAAA+KRAb1cA3hNgt3XGRUU4zVHMNszqF1tL429tIHOASRHBfzWXgkNN7RXcOoOwCAAAAPgkwmIFZrqU37OYnBPhNOzUqgDd27auqoQGORx3mpfoUFawZ5FhqAAAAIAvotunArPvWTyTHe7Us9i0TqQaXh3h4sICzaaw1VCZswgAAAD4JMJiRWLNUtDRLTJdSpYkmezC4unsMKfVT9vXr+76Pk49i4XsswgAAADAJzEMtQKpvGG8Qg+tkbVSXZ2772uHYahnc8KVrQyH89tGX+36RpezwI2RU9LqAgAAAPAiehYrkNBDayRJ5tREhRxaI3P6aVvZmaxwp57F8NAQ1zcqJCwWNp8RAAAAgO8gLFZQVTb83eF9kjVc2QWbQ0AJOp4Lzlm0n88IAAAAwGcQFiuKnOxCi09nhcpqlLRX0H7OomOTMomwCAAAAPgiwmJFYc0stHjPqQzllHTlUqOwBW4IiwAAAIAvIixWECZrhtuydIVJkgxPbHNRcF9FhqECAAAAPomwWEGYsi+5LZuRNdiTn1TgPWERAAAA8EWExYrCTc/if1q8oo+sPSRJWQV2UjHMblZDLYRRYIEbwxx62fcAAAAA4H2ExQrClO06LB5JDba9Pqcq2m5tLknKrNNBOZXrFvPudr2HgWHKiOoqScqqeYOs1WJKVF8AAAAA3lWCvRHgi0w5rhe4OXzR8f2orP+n/wyuKmuN5sW/eYF5iRd7zVPgmR+VXa2p8xxGAAAAAD6BsFhRuOlZ/D3F8X2mgmSt1ebKPsscpOxrWl/ZPQAAAAB4FcNQKwh3q6EeTaXnDwAAAIAzwmIF4W411NQcx0VspvRgjiEAAAAAhqFWHG56Fi3KXeCmRqVgff5AewUHluTvB2yPAQAAAPgbehYrCHfDUC3K7Vm89qrQEgZFyWQQFgEAAAB/Q1isINxtnZGhIElS7avYDxEAAABAPsJiReGmZ1HKXeCmekSwm3IAAAAAFRFhsYJwNww1T9VwwiIAAACAfITFisKaWWhx1bCgMqoIAAAAAF9AWKwg3G2dkadqOGERAAAAQD7CYgVR1DDUalcUFlkNFQAAAPA3hMWKgjmLAAAAAC4DYbGCcLd1Rh7mLAIAAACwR1isIFwNQ/2frCGSpIhgs4IDr6ApGAxDBQAAAPxNoLcrgDJiFxYza3fQi4lttMLaQZJ0bWSYt2oFAAAAoJwiLFYQJrutMywNemjJb01t78d3bnCFd6dnEQAAAPA3DEOtIOyHoWbKcX7i9ddULuvqAAAAACjnCIsVhV3PYobh2KEcFkQzAAAAAOCIlFBBmNyExWCzSYHmK2wGLHADAAAA+B3CYkWRk2V7eckuLIYFmUt0O8OU33Syru1Y8noBAAAAKJcIi34u6NhWRa4coKCkfbZjl3Lyw2J4cMnC4oU7lyonuLKyr2qgtJv+3xXXEwAAAED5wmqofi5y9RCnY5ac/IBY0p7FrGs76uxD/y1xvQAAAACUb/QsVkD2YTGihD2LAAAAAPwbYbECSvdAzyIAAAAA/0ZYrIDSrfkBsaRzFgEAAAD4N8JiBZRmpWcRAAAAQOEIi/7MyHF5OI2eRQAAAABFICz6M7u9Fe2lZOf/2ulZBAAAAOAKYdGfWbNdHk61C4vhhEUAAAAALhAW/ZgpJ9PlcYeeRYahAgAAAHCBsOjPclz3LKZk2Q9DpQkAAAAAcEZS8GMmN3MWz2fm/9orBQeWVXUAAAAA+BCfTArZ2dlasGCBVq1apT/++ENms1nNmzfXqFGj1LVr1yKvNwxDa9euVUJCgo4cOaILFy6oevXq6tChgx5++GE1atSoDL5FGbA6h0VDJl3MNGzvI0IYhgoAAADAmU/2LE6cOFEzZ85UdHS0XnzxRU2aNEkWi0VjxozR0qVLi7x+6tSpevLJJ2W1WjVmzBi99NJL6ty5s9auXauBAwfqwIEDZfAtSp/J1TBUc7BSM/O31KBnEQAAAIArPpcUNmzYoPXr16tPnz6aNWuW7Xj//v115513asaMGerRo4eqVavm8vpvvvlGy5cv1y233KL58+crICA3Lw8YMEBRUVF69dVXNW/ePL322mtl8n1KlYsFbgxzsNIs+SGSnkUAAAAArvhcz+KKFSskSaNGjXI4HhoaqnvuuUcWi0Vr1651e32VKlX0+OOP6/HHH7cFxTydO3eWJJ04ccLDtfYOlz2LRo4sWXY9iyE+9/cCAAAAAGXA55LC3r17FRISombNmjmVtWnTRpK0Z88eDR8+3OX1sbGxio2NdVl25MgRSVLTpk09VFsvszr3LAZkpTm8j2DrDAAAAAAu+FRYTE1NVXJysqKiopx6BSWpTp06kqSjR48W635ZWVmyWCw6f/68tm7dqlmzZikmJkZjxowp1vVVq4YXv/JlwGzO/ZnY6pVS9K/32muqyBxgKs1qwUc5tSfgCtCe4Em0J3gS7Qme5G/tyafCYlpabq9YWFiYy/K846mpqcW635YtWzR27FhJUlBQkOLj4zVx4kSFh/vHL9fkomfRXniwmaAIAAAAwCWfCosmU+HBxjCMQssLatOmjRYuXKiLFy/q+++/1/Lly/XNN9/ojTfeUOPGjYu8Pjk5/bI+r7Tl/QUjr15BF1IVWcj5EcHmcvcdUH4UbE/AlaA9wZNoT/Ak2hM8qby2pxo1KpfoOp8Ki5UqVZIkpae7/uHn9TxWrly8H0a1atXUoUMHSVK3bt3Uq1cvDRkyRE8++aRWrVrlgRp7lynHeZ9Fe8xXBAAAAOCOT62GGh4erho1aujUqVOyWq1O5cePH5ckNWjQoET3b9Wqla6//nodOHBAp0+fvqK6lgtFhEVWQgUAAADgjk+FRSl36GhmZqb27dvnVLZjxw5JUrt27dxeP2PGDHXo0EHbt293WX7x4kVJlz+ktTxyuXWGHXoWAQAAALjjc2ExPj5ekjR//nyH4ykpKUpISFBkZKR69+5tO3b48GGdO3fOdl7jxo11/vx5ffDBB06BcMeOHTp27Jjq1aunWrVqlfI3KQNW557FtKBqttcRwfQsAgAAAHDN59LCLbfcooEDB2rFihUaPXq0unfvrvT0dC1dulRnzpzR7NmzbXMbv/rqK02ePFn333+/Jk2aJEm68847tWbNGm3btk333HOPevfurcjISB04cEDLli1TQECAnnnmGW9+RY8pOGfRWqm2Pq39vLQ/931okM/9rQAAAABAGfG5sChJ06ZNU7NmzZSQkKCpU6cqODhYrVq10pQpU9S+fftCrw0MDNT777+vpUuXavXq1ZozZ44yMjJUtWpVde7cWQ8++KBatmxZRt+klNmFxcz6t+pCn8U6tPU3SblzO0MDGYYKAAAAwDWfDIsBAQEaOnSohg4dWuh5AwYM0IABA5yOBwYGatiwYRo2bFhpVbFcMNkNQzUCgiSTSRnZObZjIYH0LAIAAABwjbTgz+yHoQYESZIuERYBAAAAFANpwZ/ZrYZq5IXFrPwtR5izCAAAAMAd0oIfM1kz89+Yc8Oi4zBU5iwCAAAAcI2w6M8cehZzp6faD0MNZRgqAAAAADdIC37M5GLOIgvcAAAAACgO0oI/yymwGqocw2JoEMNQAQAAALhGWPRjrnoW7Re4oWcRAAAAgDukBX9mt8+iqwVumLMIAAAAwB3Sgh8zFbHADT2LAAAAANwhLfgz+60zbHMW7fZZZOsMAAAAAG4QFv2YyXrJ9toIDJMkXcqy61kM4tcPAAAAwDXSgh8zZVtsr42gMFlzDGXnGLZjzFkEAAAA4A5pwZ9l2fUsmkMdFreRGIYKAAAAwD3Coh+zH4aqwDBdspuvKDEMFQAAAIB7pAU/ZsrKH4aabQ7VFz8nOZSzGioAAAAAdwK9XQGUHvuexX//lqb/3XvE9j7YbFKAyeSNagEAAADwAXQt+TH7nsWP951xKAsNYr4iAAAAAPcIi/7MbjVUi0IciupUCS3r2gAAAADwIYRFP2Y/DNWiYIeyhtXDy7o6AAAAAHwIYdFfWbNkysm2vTUFhjkUR1cjLAIAAABwj7Dop0x2Q1AlqXLlyg7vq0c49jQCAAAAgD3Cor/KvuT4NsBxjmLnRleXZW0AAAAA+BjCop+y71k0ZFK6NX/100c7RumqsCBvVAsAAACAjyAs+imHYaiBocrMyX/bsk6Vsq8QAAAAAJ9CWPRTJrthqEZgmLKt+WkxKIBfOwAAAIDCkRr8lMMw1MBQZVoN2/ugQH7tAAAAAApHavBTjmExTFkOPYsmb1QJAAAAgA8hLPqrAsNQHcKimV87AAAAgMKRGvxUwWGoWfbDUM30LAIAAAAoHGHRTzkscGMOkWFXRs8iAAAAgKKQGvyVNcP2Mscc6lAUTM8iAAAAgCIQFv2UKTs/LFoDgh3K6FkEAAAAUBRSg58y5WTaXhcMi4GshgoAAACgCIRFf0XPIgAAAIArEOjtCsBzTHsWKWDfYoU0HSaT3ZzFbFOI7bXZJJnpWQQAAABQBMKiv8iyKGD90zJlW1Tl+E5lNLrDVnTofLbtNb2KAAAAAIqD5OAnAjIvOOytGHL4X7bX35/M30aDsAgAAACgOEgO/sKa7bYowwiyvc4xDLfnAQAAAEAewqK/yMlyW5Sh/LCYlmkti9oAAAAA8HGERT9hKmZYBAAAAIDiICz6i5xChqEq2G0ZAAAAALhCWPQThfYsGvQsAgAAALg8hEV/UWjPImERAAAAwOUhLPoJ5iwCAADAn508eUJxcW01btzDJb7HwIF9FRfX1oO18m+B3q4APKSQrTMyCYsAAADwkPnz39WHH75f7PPnzHlHbdpceUCrWrWapk2brsjIqiW+xxNPPK1LlyxFnwhJhEX/Ucw5i1eF8isHAABAyXXp0k0NGzZyOPbll//S9u1bNWDAILVufaNDWYMGjueWVGhoqG677fYrusfNN3f0SF0qCpKDnzAVc87ijDublUV1AAAA4KcaNGioBg0aOhz76acfJW1V06bNrjjQofxgzqK/yMl0W5QXFp/p1lg31ossqxoBAAAAeuWVFxQX11Y//rhfU6ZMVrdunfXRR/Nt5bt379JTT01Qnz7ddOutHdSjx6167LFH9M032xzu42rO4vz57yourq2+/nqztmzZpIceGq5u3TqpW7fOmjBhjA4fPuRwj4JzFnfv3qW4uLZ6441ZOnz4kJ56aoJ69eqi2267WSNH3qvNmzc6fZ8fftirceMeVrdundSz59/09NMTdfz4Mb322v+oefNm2rFjh6d+dF5Hz6KfKE7PYhWGoAIAAJSKS1lWZVkNb1ejSEFmk0KDzF757CVLFshqteqpp55RVFS0JGnXrh2aOHGcqlevoXvvHa4aNWooKem0Pv00QZMmPa7p02erY8dORd578+aN2rt3t+66a5AGDKiuPXu+17p1a/Tkk+OVkLBKQUGFr+Fx4sRx/f3vY9Sz5x3q0qWbEhOPa9myxZo69RnNn79Y113XWJJ08OAB/f3vYxQQEKB77hmqqKho7dmzW2PHPqhGjRpf4U+o/CE9+ItC5ywGS5Iigr3zDwMAAIA/m7XpsBL2JCqn/GdFBZikwa3r6onbPDOP8HKcOJGo+fMXKzAwP4L89tsRtWx5gx56aLRatWptOx4b21Jjxz6khISlxQqL27Z9rY8//lTVq1eXJPXq1UcnTiRq797d2r9/X5EL7GzfvlUzZrzu8Fkmk0kffvi+tmz5ty0sLlw4X5mZmXr22RfUq1cfSVL37r20cGFtvffe3OL/MHwEw1D9hKmQ1VDzehbDg/nbAAAAgKd94iNBUZJyjNz6ekOXLt0cgqIkDRoUr7fees8WFNPT05SSkqJrrqktSTp16kSx7t21a3dbUMzTrFmsJOnMmT+LvP7aa+s7hVJX13///U4FBwera9fuDufec8+9Cg+PKFZdfQnpwV8UYxhquJeGHAAAAPizQa3r+kzPotmUW19vqFPH+XOtVquWLVusL7/8lxITjyszM9OpvDjq1avvdCwkJESSlJ3t/jk5T/36RV9/8eIFpaamql69+goODi5wbqhiYppo797dxaqvryAs+ovChqH+FRbDgulIBgAA8LQnbmuksXHRzFksgquet5kz/6G1a1cpOrqhxowZr7p16ykkJEQZGRl66qkJxb53SEhw0ScVomD4c8Viyd2fMSwszGV55cqVr6gO5RFh0U+4W+AmyzArW7n/IITRswgAAFAqQoPMCi18DRUUcPbsGa1bt0bVql2tuXPfV5UqV9nK/vwzyYs1cy04OLensWDvZ560tLSyrE6ZoKvJX7jZOiNVYZJMkhiGCgAAgPLj5MmTysnJUdOmzRyCopS7Smp5ExkZqZCQEJ0+fcppeGxWVpZ++eWgl2pWenwyLGZnZ2vevHnq27evWrZsqdatW+u+++7Txo3O+6C485///EejRo1S27ZtFRsbq1tvvVWTJ0/WsWPHSrHmpcddz2Kqkd9NHhLok79uAAAA+KG8BWkKLmJz6tRJffzxQpnNZmVkZHijai6ZTCbFxraSxWLRt9867gH5ySfLlJaW6qWalR6fTA8TJ07UzJkzFR0drRdffFGTJk2SxWLRmDFjtHTp0iKvf/vttzVixAidOHFCo0eP1rRp03Trrbdq9erVGjhwoBITvbNC1BWxup6zmKpQ22uTyVRWtQEAAAAKVatWbbVo0VJHjhzWtGlTtH79Oi1YME8PPjhcw4aNUr169ZWcfE6LFi3Q4cOHvF1dSdLQocNlMpn0yisv6oMP3tO6dWs0Y8YrWrPmM7Vrd5O3q+dxPjdnccOGDVq/fr369OmjWbNm2Y73799fd955p2bMmKEePXqoWrVqLq8/ffq03nrrLdWtW1crVqywTUS96667VLduXc2ePVsffPCBnn/++TL5Pp7itmdRrifgAgAAAN720kvTNWfObH333bfatm2LGjZspMmTp6hjx04KCQnVrFnT9dFH81S5cmV16HCzt6ur9u1v0ksv/Y8++ugDLV68QJUqVVa7dh305pvv6fXXZ0iSzGaf7I9zyWQYRvlftsnOo48+qk2bNunTTz9VbGysQ9n8+fP16quv6tlnn9Xw4cNdXv/zzz9rwYIFateunQYNGuRQduDAAfXr10833nijPv744yLr8uefKSX/oqgVvQAAIABJREFUIh4WsX2awve+63R8k7WVRmVNkiTtfKJzWVcLPqxq1XBJUnJyupdrAn9Ae4In0Z7gSbQneMqYMQ/qhx/2as2atapatZa3q+OgRo2SrdTqc7F37969CgkJUbNmzZzK2rRpI0nas2eP2+ubNWumV1991SkoSlJqau44Y59c9tZNz2KKwsu4IgAAAIB/2rx5o554Yry2bPm3w/Hff/9NP/20X9WrV1d0dLR3KlcKfGoYampqqpKTkxUVFaWAAOecW6dOHUnS0aNHS3T/RYsWSZL69etXrPPz/hJVHgS4Wao51cifs1ie6ovyL28IBe0GnkB7gifRnuBJtCdcjpYtm2n69Gnav3+v/vjjsBo1aqhTp05r0aKFslqtmjhxooKCAv2mPflUWMzbu8TdRph5x/N6CC/HP//5T3355Zfq3LmzevfuXfJKekuO6wVuThu5czdZ2wYAAAC4Mo0aNdLixUs0f/48rVmzWmfOnFFYWJiuv/56vfjiS+ratYu3q+hRPhUWi1rNsyTTL7OysjRt2jQtX75c7dq10xtvvFHsa8vT2PbKFovduqe5Lhrh+tDaU1LuTovlqb4o/5jDAU+iPcGTaE/wJNoTLlf16nU1adJUl2VWa46k8teeSjpn0afCYqVKlSRJ6emuf/h5PY/FnXOYnJys8ePHa8eOHerTp4/+53/+R8HBwZ6pbFmz2zrjp4YPa9aBKvo5J0oXFSEpNywCAAAAQHH5VFgMDw9XjRo1dOrUKVmtVpnNZofy48ePS5IaNGhQ5L2SkpI0bNgw/fHHH3riiSf08MMPl0qdy4zdAjcZplD9O6eNYznjUAEAAABcBp9bDbVNmzbKzMzUvn37nMp27NghSWrXrl2h9zh37pxGjhypxMREzZkzx/eDoiST3ZzFLMP510pUBAAAAHA5fC4sxsfHS8rdU9FeSkqKEhISFBkZaVugJiUlRYcPH9a5c+cczp00aZIOHz6s//3f/1X37t3LpuKlza5nMUtmp+IGV/vHikwAAAAAyoZPDUOVpFtuuUUDBw7UihUrNHr0aHXv3l3p6elaunSpzpw5o9mzZ9vmNn711VeaPHmy7r//fk2alLsx/ebNm/X111+radOmys7O1pdffunyc3r27Flm38kTTPZh0XD8tZpN0ku9mpZ1lQAAAAD4MJ8Li5I0bdo0NWvWTAkJCZo6daqCg4PVqlUrTZkyRe3bty/02v3790uSDhw4oAkTJrg97+DBgx6tc6mzH4Zq12F8XfUIvXl3rKpXCvFGrQAAAAD4KJNRkv0mIEn6888Ub1fBJnLlAAWdzJ2z+WroBM0930GS1KNpDb18x/XerBp8FEuJw5NoT/Ak2hM8ifYETyqv7amkW2f43JxFuGHNtL08ftFqex1k5lcMAAAA4PKRJPyF3ZzFTLvRxcGERQAAAAAlQJLwG/mjie3DYpCZTTMAAADgO1555QXFxbXV7t27bMfi4tpq4MC+xbp+3bo1iotrq/nz3/VovXbv3qW4uLZ65ZUXPHrf8oyw6Ccyo7pIkpKNSvo+J8Z2nJ5FAAAAeNKkSY8rLq6tNm78vyLP/fTTBMXFtdU//vHiFX3mtGnT9cQTT1/RPS7H0aO/O4XNBg0aadq06br77sFlVg9vI0n4ifQO/0+v1pur2zNm6oIq2Y4HBfIrBgAAgOcMGJAbllatWlnkuatX555z9933XNFn3nbb7br55o5XdI/LsWXLZn344fsOx6pWrarbbrtdTZs2K7N6eBtJwl+YTPrBaKSzusrhcDDDUAEAAOBB7dvfpGuvrafdu3fp6NE/3J73448/6PDhQ2revIWaNPGtPb9//nm/t6tQLvjkPotw7WxaptMxhqECAADAk0wmk+66a6DefPN1rV79mcaN+7vL81av/kySNGDAIKWnp2nx4o+0detmnTiRKKvVqho1aqpjx8564IFHVLly4Vs7xMW1Va1atbVixRrbsaSk03r77Te0c+d3unTpkqKiojRkyHC399i9e5eWLl2k//73Z6WkXFRoaKhiYppqyJBhuuWWOEnSyZMnNGjQnQ6fK0nbtu3S7t27NH78o+rVq4+effYF2znJyclatOgDbd++VUlJpxUUFKT69aPVq9cduuuuQQoICHC433XXxWjOnHf0z3++qW++2aoLF87r6qurq0+ffhox4gGH872NsOgnfjqVov+edN73ka0zAAAAykCWRaYc5z/clzdGQLAUFHbF9+nd+069//4/9cUXa/Tww2MUHBzsUJ6SkqKNG/9PkZG5QzcnThynvXt3q1u3nrr33uEyDEO7du3QihXL9PPPP+qddz64rJB06dIlPfbYI0pMPK7evfuqZcsblJx8Th988J5q167tdP6uXTs0ceI4Va9eQ/feO1w1atRQUtJpffppgiZNelzTp89Wx46dVLVqNU2bNl2zZs3Q+fPJmjZteqH1uHDhvB5+eKSSkk7pjjvuVNu2bXTpkkVffLFer78+UwcO/NchWEpSdnaW/v73MapXr74eemi00tPTlJCwVPPnv6sqVa4qV3MiCYt+Yu7W31weZxgqAABA6YrYOlVh+z+UycjxdlWKZJgCZGkxSmmdrmzBmcqVK6tbt55as+Zzbd78b3Xv3tOhfP36fykjI0ODB9+rtLRUhYWFOfXI9e7dV2fPntH33+/U/v0/qFWrG4r9+evWrVFi4nH16zdATz31jO34nXfepXvvvdvp/N9+O6KWLW/QQw+NVqtWrW3HY2NbauzYh5SQsFQdO3ZSaGiobrvtdr399huScudKFubDD9/XyZOJeuyxx3XPPUNVtWq4JKlHj34aM+ZBffHFWvXrd7diY1vYrvn9998UH3+fQ4/sddfFaPz4R7Vp04ZyFRbpdvIT10a6/gsRPYsAAAClK2z/Ap8IipJkMnIUtn+BR+41YMAgSfmL2Nhbvfozmc1m9et3t6pWraaZM9+wBcXs7GylpKQoJSVF9epFSZJOnTpxWZ+9c+d3kqTu3Xs7HL/qqkjdemsXp/MHDYrXW2+9ZwuK6elpSklJ0TXX1C7R5+fZtGmjAgMD1a+fY0A1m83q27efJGnr1s1O18XHD3V437x5rCTpzJk/S1SP0kLPop8Y16mBdh47r2PJFofjzFkEAAAoXZYWI32oZ9EsS4uRHrlX48ZN1KJFK+3du1t//PG7oqKiJUn79+/TkSOH1anTrapVq5Yk6dChX/Xhh+9p797dunjxogzDcLiX1Wq9rM8+ceK4JKlevXpOZQ0bNnI6ZrVatWzZYn355b+UmHhcmZmZTuWXKyUlRWfPnlG9evUVGhrqVB4d3VBS7jYc9sLCwlS9eg2HYyEhuddnZ2dfdj1KE2HRT1QODdTK0Tdr6Y5jmr3hV9txcwDDUAEAAEpTWqcXlXbT0xVqzmKeAQMGaf/+fVq16lONH/+EpPwtNfK22Pjjj981evT9ysjIUN++/dWuXQdVrlxFJpNJn3/+qf79768u+3MtltwOkpCQEKcyV8Ft5sx/aO3aVYqObqgxY8arbt16CgkJUUZGhp56asJlf35uHdIl5YY/V/ICYF5d8xSc31meERb9SNXwYI26JdohLCZbsrxYIwAAgAoiKEyGPBfCfMXf/tZVb775ur744l965JFxyszM1KZNG1S/fpTatm0vSfrkk2WyWCx66KHRGjHiAYfrv/rqyxJ9bl5IzMzMVESEY1laWprD+7Nnz2jdujWqVu1qzZ37vqpUyd9q7s8/k0r0+ZIUHp77wenpFpfleWEy7zxfxBhFPxMWbHZ4f1Uofw8AAABA6QgKClLfvv2VknJR27Z9rY0b/08ZGRm6665BMplyR7idOJEoSerQ4RaHa61Wq/bs+b5En1u7dl1JUmLicaeyw4cPObw/efKkcnJy1LRpM4egKOWuklpSlSpVUs2a1+jkyUSlp6c7lR85kluP6OgGJf4MbyMs+qHHOuU2yAZXh6tL4+perg0AAAD8Wb9+A2Q2m7Vhw5fasGG9beXTPNWr5z6PnjyZ6HDdggXzdPHiRUlSRkbGZX3mjTfm7n9YsGfy7Nkz+vrrTQ7H8j6/4CI2p06d1McfL5TZbHb6fLPZ/Fe9LhVaj9tv7y6r1arPP1/hcDw7O9s2HLdLl27F+UrlEt1Ofmh4+3q6o/k1igwLYs4iAAAASlXNmtcoLq6zvvlmm6xWq/r27a9KlSrZym+/vYfWrVujOXNm69y5swoNDdOWLZuUlHRajz32uF555QWtW7daERER6t69V7E+s0+fflq+/GOtXPmJMjOzFBvbQufOndWaNZ+rZcsb9M0322zn1qpVWy1atNT+/T9o2rQpat/+Jp08eUIrVizX+PETtXDhB/r999+0aNEC3XJLnBo1uk516tRVYuJxvfrqK2rUKMZpa5A8I0Y8oO3bt+qdd97SiROJatu2jVJSUrR27b/066+/6N57h+m66xpf2Q/YiwiLfurqCN+ZOAsAAADfNmDAYG3Zssn22l779jfpmWem6uOPF2nu3DmKjKyquLjOev75lxQSEqING/5Pe/Z8r/fff6fYYTEiopLefPNdvf32G9q06SutX79O9erV16hRDykyMtIhLErSSy9N15w5s/Xdd99q27YtatiwkSZPnqKOHTspJCRUs2ZN10cfzVPlypXVqNF1euSRsfrzzyRt3PiVvv9+lzp1utVtPf75z/n66KP52rp1i9auXaWQkBA1bHidpkyZVuzvU16ZjILr1qLY/vwzxdtVcJC3CWhysvOYaeBy0Z7gSbQneBLtCZ5Ee4Inldf2VKNG5RJdx5xFAAAAAIATwiIAAAAAwAlhEQAAAADghLAIAAAAAHBCWAQAAAAAOCEsAgAAAACcEBYBAAAAAE4IiwAAAAAAJ4RFAAAAAIATwiIAAAAAwAlhEQAAAADghLAIAAAAAHBCWAQAAAAAOCEsAgAAAACcEBYBAAAAAE4IiwAAAAAAJ4RFAAAAAIATwiIAAAAAwAlhEQAAAADghLAIAAAAAHBCWAQAAAAAODEZhmF4uxIAAAAAgPKFnkUAAAAAgBPCIgAAAADACWERAAAAAOCEsAgAAAAAcEJYBAAAAAA4ISwCAAAAAJwQFgEAAAAATgiLAAAAAAAngd6uAK5cdna2FixYoFWrVumPP/6Q2WxW8+bNNWrUKHXt2tXb1YMXpaSkaN68eVq3bp1OnjypoKAgxcTEaODAgRo4cKBMJpPD+QcOHNDcuXO1c+dOpaSkqGbNmurSpYvGjBmjatWqOd1/w4YNWrBggX7++WdlZWUpOjpa/fv318iRI2U2m8vqa8KLtm/frvvvv1+SdPDgQYeyY8eO6e2339b27duVnJysyMhIxcXFady4cbr22mud7rVz5069++67+uGHH5Senq66deuqZ8+eeuSRRxQeHl4m3wdla8+ePXrnnXe0Z88eZWZm6tprr1W/fv30wAMPKCDA8e/ZtCcUJTExUe+88462b9+upKQkBQcHq0mTJhowYIDTf/NoTyho5cqVeuWVV5SamqqNGze6bAel3W4++eQTLV++XIcOHZIkNWrUSEOGDNHAgQM9/4WLyWQYhuG1T4dHjB8/XuvXr1f37t3VpUsXZWRk6JNPPtGPP/6oF154QUOGDPF2FeEFp0+fVnx8vJKSktSvXz+1bdtWFy9e1PLly3XkyBHdf//9mjRpku38ffv2acSIEYqIiNCIESNUu3Zt/fzzz1q0aJHq1q2rTz/9VJUqVbKdv3jxYk2bNk3NmzfX3XffrYiICG3atElffvmlevfurddff90bXxtlKDU1VX379tWJEyckOYbFY8eOafDgwcrIyNCIESPUsGFD/fHHH/rwww8VGhqqhIQE1a1b13b+hg0bNH78eNWtW1dDhw5VtWrVtGvXLn3yySdq3bq1Fi5cqMBA/r7pT7766itNmDBB9evX17333quIiAitXbtW33zzjfr3768ZM2bYzqU9oSi///677rnnHl26dEmDBw9Ws2bNdPHiRa1Zs0b79+9XfHy8XnzxRUm0Jzg6e/aspkyZoo0bNyosLEzp6ekuw2Jpt5sZM2bogw8+UIcOHdS3b18FBATY/k186KGH9OSTT5bZz8SBAZ/21VdfGTExMcbEiRMdjlssFqNbt25Gq1atjLNnz3qpdvCm559/3oiJiTE++ugjh+MXLlwwbr75ZuP66683zpw5Yzver18/o1mzZsavv/7qcP7y5cuNmJgYY/r06bZjSUlJRosWLYxu3boZ6enpDudPnDjRiImJMTZt2uT5L4Vy5fnnnzduuOEGo2fPnkZMTIxD2ejRo42YmBhj27ZtDse3bdtmxMTEGI899pjtWEZGhnHLLbcY7dq1M/7880+H82fPnm3ExMQYixcvLr0vgjKXnJxstGvXzujevbuRkpJiO261Wo377rvP6NOnj5GUlGQ7TntCUSZNmmTExMQYy5YtcziekZFhdOnSxYiJiTGOHj1qGAbtCY7+9re/GR07djS+/vpr47777jNiYmKMY8eOOZ1Xmu3mp59+Mpo0aWIMGTLEsFqttuNWq9W49957jaZNmxoHDhzw1Fe+LMxZ9HErVqyQJI0aNcrheGhoqO655x5ZLBatXbvWG1WDl9WsWVM9evRwGrpQpUoVtWnTRlarVb/88osk6aefftJ///tfderUSdddd53D+QMGDFCVKlX02WefKScnR5K0du1aZWRkKD4+XmFhYQ7njxw5UlJ+24R/+vbbb5WQkKBHH31U1atXdyg7e/asNm/erJiYGHXs2NGhrGPHjmrcuLE2btyo5ORkSdLmzZt15swZ9e3b1+leI0aMkMlkoj35mc8//1wXLlzQ6NGjHUYsBAQEaNGiRVqzZo1q1KghifaE4jl69KgkqW3btg7Hg4OD1aJFC0nS8ePHaU9wcsMNN2j16tXq1KmT23NKu92sXLlShmFoxIgRDkPwAwICNGzYMOXk5GjlypWe+LqXjbDo4/bu3auQkBA1a9bMqaxNmzaScueEoOIZN26c5syZ43JMfEpKiiTZHtL27t0rSWrdurXTuYGBgWrZsqWSk5P122+/ScpvU67Ob968uUJCQmh3fiwtLU3PPvusmjVrpgceeMCpfP/+/bJarS7bh5T7b1N2drb2798vqfD2VK1aNUVFRenAgQNKT0/34LeAN23btk2S1LlzZ9uxS5cuuTyX9oTiiImJkSTbf6fsHT9+XGazWQ0bNqQ9wcnrr7/ucl0Ge6Xdbgo739vP84RFH5aamqrk5GTVqlXLaSEASapTp46k/L+2AVLuvLKdO3eqcePGat68uaTccfiSVLt2bZfX5B3PO+/48eOS8tuYvYCAANWqVUtnzpzhP55+6rXXXlNSUpL+8Y9/uJynU9L25O78OnXqKCcnR4mJiVdcd5QPhw4dUpUqVWSxWDR+/Hi1atVKrVq1UocOHfTyyy8rLS3Ndi7tCcXx8MMPq2bNmnrllVe0adMmnT17VkePHtXrr7+u/fv3a+TIkbrmmmtoTyiR0m43x48fV1BQkG1Ehb0aNWooKCjIa8/zzMb1YXn/MS04DDBP3vHU1NQyqxPKt5MnT2rs2LEKCAjQCy+8YPsjQ15bcreiW8G2dDltj1Xi/Mt3332npUuXavTo0WratKnLcy7336bLbX/wfefPn1dwcLCGDx+ujh07avbs2UpNTdVnn32mRYsW6ccff9SSJUtkNptpTyiWOnXq6JNPPtFTTz2lRx991HY8JCRETz/9tG26Du0JJVHa7SYtLU2hoaFOq9RLkslkUmhoqNfaGGHRh7lqUPYMFrqFnX379mns2LE6f/68Zs2a5TCvw9NtibbnnywWi5599lk1btxYo0ePdnteUe3pcs+nPfmfzMxMWSwWDR8+XOPGjbMdv/POOzVkyBDt2bNH69evV+/evWlPKJZjx45pzJgxOnXqlCZMmKDrr79eWVlZ2rBhg6ZPn67ExEQ999xztCeUiLfbjTfbGWHRh+XNN3M31C/vrxqVK1cuszqhfFq9erWee+45hYWFaf78+erQoYNDeUREhCQ5DP2yV7At2be9KlWqFHk+/MOsWbN04sQJLVu2TMHBwW7PK+rfpry/juadd7ntD74vIiJCFy9e1N133+1w3GQyaeDAgdqzZ4++++479e7dm/aEYnnmmWd06NAhffLJJ4qNjbUd7969u4KCgrRo0SLddNNNtCeUSGm3m0qVKik1NVWGYTgFzZycHF26dMnl81ZZYM6iDwsPD1eNGjV06tQpWa1Wp/K88dINGjQo66qhHJk/f76eeuopRUVFacWKFU5BUZKioqIkybZfXkEF21Le+a7maGRnZ+v06dOqVauW2+Ea8D27du3S4sWLNWjQINWsWVOnTp2y/S8zM1OSbO/r168vyX17yms3DRs2lFS89hcYGKh69ep59DvBe/J+l9nZ2U5leXN28h6+aE8oSnp6unbu3Kn69es7BMU8Xbt2lSRt376d9oQSKe12ExUVpaysLCUlJTmde/LkSWVnZ3vteZ6w6OPatGmjzMxM7du3z6lsx44dkqR27dqVdbVQTixZskSvvvqqbrrpJi1dutTtf8xuvPFGSdLOnTudyi5duqT9+/frmmuusV1f2Pl79uxRVlaW0/Ll8G3ffvutDMPQsmXLdOuttzr8L2813bz3LVu2VFBQkMv2IeW2m5CQENty9oW1pxMnTigxMVEtWrRQSEhIKX07lLW83/lPP/3kVJb3cHXNNddIEu0JRbp06ZIMw1BGRobb8rz/pz2hJEq73eSteJr37F7w3pL3nucJiz4uPj5eUm7vkb2UlBQlJCQoMjJSvXv39kbV4GW7d+/WK6+8otatW+vdd9912MusoMaNG6tNmzb69ttvnR7elixZIovFovj4eNvQiDvuuEOVKlXS8uXLnSZc57XFIUOGePgbwZv69Omjd955x+X/8pasz3t/1VVXqWfPnvr999+1YcMGh/t8+eWXOnbsmPr27Wtrk3Fxcapbt67Wrl2rU6dOOZw/b948SbQnfzNw4EAFBATo3XfflcVisR3PzMzUxx9/LCm/N4j2hKJUq1ZN0dHROnnypL777jun8rz9ptu2bUt7QomUdrsZOHCgAgMDtWDBAocRF1lZWfroo48UFBTktG92WTEZzMz1ec8++6xWrFihLl26qHv37kpPT9fSpUt15MgRzZ49Wz179vR2FeEFd999t3788Uc9/vjjio6OdnnOddddp+uuu06S9Msvv2jo0KEym826//77Vbt2be3du1dLly5V8+bNtWTJEod5ap9//rmefvppxcTEKD4+XmFhYfriiy+0ZcsWDRs2TM8991xZfE2UA8OGDdOOHTt08OBB27GkpCQNHjxY58+f18iRI9WoUSMdOnRICxYsUM2aNbV8+XKHfa2+/fZbPfzww6pRo4aGDx+uqlWratu2bVq9erW6du2qt99++7IXGED59uabb+qtt95S8+bNNWTIEFksFn322Wf6+eefNXjwYE2bNs12Lu0JRfn66681ZswYmc1mDR06VM2aNZPFYtEXX3yh7du3q3Xr1lq4cKGCg4NpT7BJTEy07Y0o5f67dOjQIU2dOtXWBurWrasWLVqUeruZO3eu3njjDbVt21b9+/eXJH366afas2ePJk+erJEjR5bND6UAwqIfyMnJ0dKlS5WQkKDffvtNwcHBatWqlR555BG1b9/e29WDlzRp0qTIc8aNG6fHHnvM9v63337TW2+9pW+++UYpKSmqU6eOevbsqUceecQ2Wdve9u3b9d5779k2q23UqJHi4+M1aNAg/sNZgbgKi5J0+vRpvf3229q8ebPOnTun6tWrq0uXLho7dqyuvvpqp/v88MMPmjt3rnbv3i2LxaKoqCj169dPI0eOVFBQUFl9HZShdevWaeHChTp48KBycnIK/TeE9oSiHDhwQO+//7527typc+fOKSgoSNHR0erVq5dGjBjhMFSU9gRJWrlypSZPnlzoOXfddZemT58uqfTbzdq1a7Vo0SIdPHhQJpNJ119/vUaOHKnu3bt75guXAGERAAAAAOCEOYsAAAAAACeERQAAAACAE8IiAAAAAMAJYREAAAAA4ISwCAAAAABwQlgEAAAAADghLAIAAAAAnBAWAQAAAABOCIsAAAAAACeERQAAAACAE8IiAAAAAMAJYREAUGGsXLlSTZo00ZtvvuntqpSIYRiaOXOmOnTooObNm+v999/3dpU8rkmTJurZs6e3qwEAEGERAHAFvvvuOzVp0kRNmjTRli1bijzPV0NaefH1119r3rx5qlq1ql5++WXFxcV5u0oAAD9GWAQAeMTUqVOVmprq7Wr4tYMHD0qShg0bprvuukvXX3+9l2sEAPBnhEUAwBWLi4vTyZMnNXPmTG9Xxa9lZGRIksLCwrxcEwBARUBYBABcsTvuuEO33nqrli9frp07dxbrmsLmDy5evNipbNiwYWrSpInOnTunGTNmqFOnTmrZsqX69u2rjRs3SpLWrFmjfv36qVWrVurSpYtefvllZWVlufz8rVu3Kj4+Xq1bt1br1q01atQo/fTTT07n/fnnn5o2bZq6du2q2NhYtWvXTsOGDdO//vUvh/OOHz+uJk2aaMyYMdqyZYtuv/12xcbGFvlzSE9P15w5c3THHXeoVatWuuGGG9S3b1/NnTvXFg6l3Ll8b731liRp8uTJxRrWaxiGli9frkGDBql169Zq2bKlevbsqVmzZunixYsO5+b9fP/44w+9/vrr6tKli2JjY9W5c2dNnz5d6enpTvffuHGjRowYoXbt2tnOffLJJ3X48GGnczMyMvTWW2/pjjvuUMuWLdW+fXtNmDBBv/76q8u6p6Wladq0aerUqZNiY2PVpUsXzZ07V4ZhOJy3efNm3X///YqLi1NsbKw6deqkcePGae/evYX+bAAARQv0dgUAAP7hxRdf1B133KHnnntOq1evVkhISKloWPUaAAALPUlEQVR8zssvvyyLxaIJEyYoMTFR8+bN04QJEzRx4kQtW7ZMQ4cOVUhIiD766CMtWrRItWrV0oMPPuhwjx9++EHLly/XwIEDNXjwYB04cEAff/yxhg8frlWrVunaa6+VJJ0+fVqDBg1Senq64uPj1bhxYyUnJ+vzzz/XxIkTdeTIET322GMO905JSdGUKVM0atQoRUZGFvpdMjMzNXz4/2/v/mOirOM4gL9Pfp1CeSOCqA1J5UuQNtJSrKuWLBaZSU0QjR/tgtTmSJ1lOY2tYlbrx2B5aUSnMu5a7DjimBCZ+KsyJ/6Bm9uphaxM0XIThh4e8O2P2/Pow3PgafCX79fG2H2+n+d73+d7DPbh+T7fpxDHjh3DggULUFBQACklfv75Z1RUVOC3336DzWbDhAkTUFFRgebmZrS0tODll1/GnDlzMH369FH737BhA+rr65GRkYHc3FwAwJEjR1BdXY22tjZ89913mDRpkuaY9957D16vFxaLBZGRkWhsbITNZkNnZye2bdum5tlsNnz44YeYPn06SkpKEBsbi99//x21tbXYs2cP7HY7HnjgAQCAz+dDUVEROjo6sHTpUixfvhznzp3D9u3bkZubC4fDoeYC/iJ35cqViImJwRtvvIH+/n5UVVWhoqICd955J/Lz8wEAzc3NWL16NWbMmIEVK1bAZDLhzJkzcDgcKCgogN1ux8yZM0edIyIiGoUkIiK6RYcOHZJCCOl0OqWUUtbW1kohhPz4448D5lVWVqoxp9Opiylqamp0bfn5+VIIIV999VVN7qZNm6QQQqalpckLFy6o8aNHj0ohhFy2bJnuPVNTU6XH49H0880330ghhHz//ffV2OrVq2Vqaqrs6OjQ5Pb398uFCxfKlJQUeebMGSmllH/++acUQsjk5GTpdrtHn7hR3lNRWloqhRCyqalJjVVWVmrmezT79u2TQghZXl6ua9u2bZsUQsgvv/xSjSnzm52dLX0+nxofGBiQL7zwghRCqPNw/vx5+eCDD8onn3xS9vb2avreu3evFEJIi8WixpSfC6vVqsltb2+XQghZUlKixoQQUgghP//8c03u4cOHpRBCFhUVqbEVK1ZIIYT8559/NLldXV2ysLBQulyuG00TERGNgstQiYhozCxduhSPPPIIbDZbwCWdYyEnJ0fzWtnkZf78+YiJiVHjqampAPzLSIebM2cOhBCa2IIFCwD4d24FAK/Xix9//BEpKSmYMmUKenp61C+v14vMzEwMDg7iwIEDmn6MRiMyMzODOpcffvgBgH8J6HB5eXkAgN27dwfV13ButxsAsHDhQs3Ye3p61PHt3btXd1xOTg5CQ68tPAoJCUFWVhYAoL29HQCwZ88e+Hw+ZGdnIyoqSnP8U089hfj4ePz666/q0lVlye5LL72kyZ01axbsdjvWr1+viRsMBt3VYOXz7O7uVmNhYWEArn1mioSEBOzYsQPZ2dkB54aIiILDZahERDRmDAYDPvjgAyxatAgbNmyA0+nUFB5j4b777tO8Vpa7jhQfGBjQ9ZGUlKSLxcbGIiIiAn/99RcA4PTp0/D5fDh27BgeffTREcej5Cvi4uIQHh4exJkAp06dQnh4OKZMmaJrmzZtGgDgjz/+CKqv4ZR7ARcvXjxizvCxA9AV0QBwzz33ALhWeJ86dQpA4HkE/GM/e/Ysurq6kJKSAo/Hg4iICMTFxelyZ8+erYvFxMToitDIyEgA0NzHWVxcjIMHD2LNmjWw2Wwwm81IT0/H7Nmzx/znjojodsTfpERENKbuv/9+rFq1Cp9++imqqqqwcuXKMe1/pEJMucoUDKXwGM5oNKqP/1C+p6WlYe3atSP2FR8fH1TfgVy+fFlXFCmUHU+vXLkSdH/X6+vrAwBs2bIFd9xxR8CcQAVVoPEosd7eXgBQrxiOtCur0WjU5PX19Y14noEEW2w/9NBDaGhogM1mw+7du2G1WmG1WmEymWCxWPDaa6/BYDAE/b5ERKTFYpGIiMacxWJBc3MzrFZr0Esyr+f1esdhVDfu3+v1qgWQUtwMDg5i7ty54zKOyMhIXL58GVJKXVGjFFo3U3xeTxl/YmLiDTfCuV6guVGKxMmTJ2vGFGiH1OvjSl5UVBR6e3sxODiIkJCQoMcSjISEBJSVlaGsrAwnTpzA/v374XA48Nlnn2FoaGjM/1lBRHQ74T2LREQ05kJDQ1FeXo6hoSFs3LgRQ0NDAXOAwAXH6dOnx3V8gR7tcO7cOfT39yMhIQGA/wppWFgYTp48iUuXLunyL126FHCJ681ISkqCz+dDZ2enrs3j8QC4thz1ZinLSQM9ykRKiYsXLwY8LtDcdHV1AfAv1VXGDQAnTpwI2PfJkycRGhqKxMREAP5zUOLDud1uuFyuIM7oxoQQKC4uRl1dHcLCwtR7QomI6NawWCQionGRmpoKi8WCo0ePwm6369qV+9eOHz+uiXd3d+ueYTjWfvnlF12B1tjYCAB4/PHHAfjveczMzITX68WOHTs0uQMDAygtLYXZbB6x6AqGsqlOTU2NJi6lRG1tLQCom8vcrOeffx4AsHPnTt3Vwvr6epjNZtTV1emOq6urw+DgoPp6YGAALS0tAPwbAwFARkYGjEYjXC6XetVR0dLSggsXLuDpp59Wl6M+99xzAACHw6HJ9Xg8WLdunboZz824cuUKcnJy8Oabb+rajEYjJkyYEPRyViIiCozLUImIaNysWrUKra2taG1t1bU9/PDDiIuLw6FDh/Duu+9i1qxZOH/+PGpqavDss8+ivr5+3MaVnp6OV155BTk5Obj33ntx/PhxOBwOmEwmFBYWqnnr16/HkSNHYLVa8ffff2PevHno7e3F999/j46ODpSUlCA6OvqWx7FkyRLs2rULdrsdPT09SE9Px9WrV9HW1oYDBw4gKysLGRkZt9T3E088gRdffBEulwtLlixBbm4uJk2ahPb2drhcLiQmJuKZZ57RHRcZGYmioiJkZmYiKioKjY2N6OzsRFZWFpKTkwEA0dHReOedd1BWVoa8vDwsXrwYJpMJHo8HDocDd911F95++221z7y8PDQ1NeHbb79Ff38/5s2bh+7ubuzcuRNGo1G3G2owJk6ciJkzZ6K2thYXL17E/PnzYTKZ8O+//6KhoQFXr14NuMssEREFj8UiERGNm4iICJSXlyM/Px9SSk1beHg4tm/fjs2bN8PtdqOxsRHTpk1DWVkZQkJCxrVYNJvNKCoqwhdffAGPxwODwYDHHnsMb731lrrUEvBf/XQ6ndi6dSva2trQ1NSEsLAwJCcn46OPPvrfj2YIDQ1FdXU1qqqqsGvXLrS2tiIkJARTp07Fxo0bsWzZsv/V/+bNm5GWlgan04lPPvkEPp8P8fHxKCgowPLly2EymXTHrFu3Dj/99BNqampw9uxZREdHo7i4GKWlpZq8vLw8xMfHo7q6Glu2bIHX68Xdd9+NRYsW4fXXX1d3UAX8n7XNZsNXX32F5uZmNDU1YeLEiUhPT8eaNWswderUWzq/TZs2ISkpCQ0NDaisrERfXx9iY2ORlJSEr7/+Gmaz+Zb6JSIiP4Mc/tebiIiIbjsFBQU4fPgw3G53wMdnEBHR7Yf3LBIREREREZEOi0UiIiIiIiLSYbFIREREREREOrxnkYiIiIiIiHR4ZZGIiIiIiIh0WCwSERERERGRDotFIiIiIiIi0mGxSERERERERDosFomIiIiIiEiHxSIRERERERHpsFgkIiIiIiIiHRaLREREREREpMNikYiIiIiIiHRYLBIREREREZEOi0UiIiIiIiLSYbFIREREREREOiwWiYiIiIiISIfFIhEREREREen8B3rMAdVCetblAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 1050x750 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1350x1050 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Angry       0.96      0.95      0.96        85\n",
            "     Boredom       0.85      0.93      0.89        43\n",
            "     Disgust       0.00      0.00      0.00        27\n",
            "        Fear       0.61      0.95      0.74        41\n",
            "       Happy       0.90      0.90      0.90        40\n",
            "     Neutral       0.81      0.85      0.83        46\n",
            "     Sadness       0.95      0.92      0.94        39\n",
            "\n",
            "    accuracy                           0.84       321\n",
            "   macro avg       0.73      0.79      0.75       321\n",
            "weighted avg       0.79      0.84      0.81       321\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wnHMAL2vJDId",
        "outputId": "aad26372-080b-40ca-d3a8-d9216c6f6764"
      },
      "source": [
        "model = tf.keras.Sequential()\n",
        "model.add(layers.Conv1D(256, kernel_size=(8),strides=1,dilation_rate=1,padding=\"same\", activation='relu', input_shape=(x_train.shape[1],1)))\n",
        "model.add(layers.Conv1D(256, kernel_size=(8),strides=1,activation='relu',dilation_rate=1,kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
        "model.add(layers.MaxPooling1D(pool_size=(2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.Dropout(0.25))\n",
        "model.add(layers.Conv1D(256, kernel_size=(8),strides=1,dilation_rate=1,padding=\"same\",activation='relu'))\n",
        "model.add(layers.MaxPooling1D(pool_size=(2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.Dropout(0.25))\n",
        "model.add(layers.Conv1D(128, kernel_size=(8),strides=1,dilation_rate=1,padding=\"same\",activation='relu'))\n",
        "model.add(layers.MaxPooling1D(pool_size=(2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.Dropout(0.25))\n",
        "model.add(layers.Conv1D(128, kernel_size=(8),strides=1,dilation_rate=1,padding=\"same\",activation='relu'))\n",
        "model.add(layers.MaxPooling1D(pool_size=(2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.Dropout(0.25))\n",
        "model.add(layers.Conv1D(128, kernel_size=(8),strides=1,dilation_rate=1,padding=\"same\",activation='relu'))\n",
        "model.add(layers.MaxPooling1D(pool_size=(2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Conv1D(256, kernel_size=(8),strides=1,dilation_rate=1,padding=\"same\",activation='relu'))\n",
        "model.add(layers.MaxPooling1D(pool_size=(2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Conv1D(64, kernel_size=(8),strides=1,dilation_rate=1,padding=\"same\",activation='relu'))\n",
        "model.add(layers.MaxPooling1D(pool_size=(2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(7, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='Adam',metrics=['accuracy'])\n",
        "model.summary()\n",
        "checkpoint = ModelCheckpoint(\"SER_best_initial_model.hdf5\", monitor='val_accuracy', verbose=1, save_best_only=True, mode='max', period=1, save_weights_only=True)\n",
        "model_history=model.fit(x_train, y_train,batch_size=32, epochs=1000, validation_data=(x_test, y_test),callbacks=[checkpoint])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_39 (Conv1D)           (None, 155, 256)          2304      \n",
            "_________________________________________________________________\n",
            "conv1d_40 (Conv1D)           (None, 148, 256)          524544    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_34 (MaxPooling (None, 74, 256)           0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_34 (Batc (None, 74, 256)           1024      \n",
            "_________________________________________________________________\n",
            "dropout_43 (Dropout)         (None, 74, 256)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_41 (Conv1D)           (None, 74, 256)           524544    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_35 (MaxPooling (None, 37, 256)           0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_35 (Batc (None, 37, 256)           1024      \n",
            "_________________________________________________________________\n",
            "dropout_44 (Dropout)         (None, 37, 256)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_42 (Conv1D)           (None, 37, 128)           262272    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_36 (MaxPooling (None, 18, 128)           0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_36 (Batc (None, 18, 128)           512       \n",
            "_________________________________________________________________\n",
            "dropout_45 (Dropout)         (None, 18, 128)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_43 (Conv1D)           (None, 18, 128)           131200    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_37 (MaxPooling (None, 9, 128)            0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_37 (Batc (None, 9, 128)            512       \n",
            "_________________________________________________________________\n",
            "dropout_46 (Dropout)         (None, 9, 128)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_44 (Conv1D)           (None, 9, 128)            131200    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_38 (MaxPooling (None, 4, 128)            0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_38 (Batc (None, 4, 128)            512       \n",
            "_________________________________________________________________\n",
            "dropout_47 (Dropout)         (None, 4, 128)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_45 (Conv1D)           (None, 4, 256)            262400    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_39 (MaxPooling (None, 2, 256)            0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_39 (Batc (None, 2, 256)            1024      \n",
            "_________________________________________________________________\n",
            "dropout_48 (Dropout)         (None, 2, 256)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_46 (Conv1D)           (None, 2, 64)             131136    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_40 (MaxPooling (None, 1, 64)             0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_40 (Batc (None, 1, 64)             256       \n",
            "_________________________________________________________________\n",
            "dropout_49 (Dropout)         (None, 1, 64)             0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dropout_50 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 128)               8320      \n",
            "_________________________________________________________________\n",
            "dropout_51 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_52 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 7)                 455       \n",
            "=================================================================\n",
            "Total params: 1,991,495\n",
            "Trainable params: 1,989,063\n",
            "Non-trainable params: 2,432\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/1000\n",
            "54/54 [==============================] - 4s 36ms/step - loss: 5.6884 - accuracy: 0.1818 - val_loss: 4.4174 - val_accuracy: 0.2430\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.24299, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 2/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 4.7730 - accuracy: 0.1898 - val_loss: 4.0173 - val_accuracy: 0.2196\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.24299\n",
            "Epoch 3/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 4.1351 - accuracy: 0.2050 - val_loss: 3.6352 - val_accuracy: 0.2710\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.24299 to 0.27103, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 4/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 3.6288 - accuracy: 0.2192 - val_loss: 3.2924 - val_accuracy: 0.3178\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.27103 to 0.31776, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 5/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 3.2602 - accuracy: 0.2364 - val_loss: 2.9865 - val_accuracy: 0.3551\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.31776 to 0.35514, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 6/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 2.9252 - accuracy: 0.2452 - val_loss: 2.6171 - val_accuracy: 0.3785\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.35514 to 0.37850, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 7/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 2.5611 - accuracy: 0.2998 - val_loss: 2.3566 - val_accuracy: 0.3855\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.37850 to 0.38551, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 8/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 2.3330 - accuracy: 0.3247 - val_loss: 2.1183 - val_accuracy: 0.3879\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.38551 to 0.38785, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 9/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 2.1493 - accuracy: 0.3200 - val_loss: 1.9603 - val_accuracy: 0.3949\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.38785 to 0.39486, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 10/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 2.0384 - accuracy: 0.3405 - val_loss: 1.8331 - val_accuracy: 0.3808\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.39486\n",
            "Epoch 11/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 1.8626 - accuracy: 0.3608 - val_loss: 1.7485 - val_accuracy: 0.3949\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.39486\n",
            "Epoch 12/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 1.8148 - accuracy: 0.3277 - val_loss: 1.5943 - val_accuracy: 0.4486\n",
            "\n",
            "Epoch 00012: val_accuracy improved from 0.39486 to 0.44860, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 13/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 1.6913 - accuracy: 0.3681 - val_loss: 1.6037 - val_accuracy: 0.4019\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.44860\n",
            "Epoch 14/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 1.6127 - accuracy: 0.3822 - val_loss: 1.5227 - val_accuracy: 0.3972\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.44860\n",
            "Epoch 15/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 1.5799 - accuracy: 0.3850 - val_loss: 1.4927 - val_accuracy: 0.4836\n",
            "\n",
            "Epoch 00015: val_accuracy improved from 0.44860 to 0.48364, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 16/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 1.5366 - accuracy: 0.3918 - val_loss: 1.4305 - val_accuracy: 0.4065\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.48364\n",
            "Epoch 17/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 1.5387 - accuracy: 0.3963 - val_loss: 1.3743 - val_accuracy: 0.4486\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.48364\n",
            "Epoch 18/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 1.4908 - accuracy: 0.4229 - val_loss: 1.3986 - val_accuracy: 0.4603\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.48364\n",
            "Epoch 19/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 1.4986 - accuracy: 0.3923 - val_loss: 1.4099 - val_accuracy: 0.4252\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.48364\n",
            "Epoch 20/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 1.4801 - accuracy: 0.3948 - val_loss: 1.3259 - val_accuracy: 0.5023\n",
            "\n",
            "Epoch 00020: val_accuracy improved from 0.48364 to 0.50234, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 21/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 1.3836 - accuracy: 0.4283 - val_loss: 1.3637 - val_accuracy: 0.4182\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.50234\n",
            "Epoch 22/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 1.3814 - accuracy: 0.4350 - val_loss: 1.2836 - val_accuracy: 0.4696\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.50234\n",
            "Epoch 23/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 1.3973 - accuracy: 0.4299 - val_loss: 1.3098 - val_accuracy: 0.4836\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.50234\n",
            "Epoch 24/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 1.3752 - accuracy: 0.4480 - val_loss: 1.2153 - val_accuracy: 0.5023\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.50234\n",
            "Epoch 25/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 1.3216 - accuracy: 0.4409 - val_loss: 1.4743 - val_accuracy: 0.3621\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.50234\n",
            "Epoch 26/1000\n",
            "54/54 [==============================] - 1s 22ms/step - loss: 1.3003 - accuracy: 0.4644 - val_loss: 1.2493 - val_accuracy: 0.5023\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.50234\n",
            "Epoch 27/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 1.3624 - accuracy: 0.4307 - val_loss: 1.8758 - val_accuracy: 0.3668\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.50234\n",
            "Epoch 28/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 1.3570 - accuracy: 0.4480 - val_loss: 1.1502 - val_accuracy: 0.5514\n",
            "\n",
            "Epoch 00028: val_accuracy improved from 0.50234 to 0.55140, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 29/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 1.2324 - accuracy: 0.4773 - val_loss: 1.1430 - val_accuracy: 0.5421\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.55140\n",
            "Epoch 30/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 1.2440 - accuracy: 0.5083 - val_loss: 1.1595 - val_accuracy: 0.5164\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.55140\n",
            "Epoch 31/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 1.2686 - accuracy: 0.4758 - val_loss: 1.0826 - val_accuracy: 0.5374\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.55140\n",
            "Epoch 32/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 1.2079 - accuracy: 0.5015 - val_loss: 1.0902 - val_accuracy: 0.5748\n",
            "\n",
            "Epoch 00032: val_accuracy improved from 0.55140 to 0.57477, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 33/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 1.2218 - accuracy: 0.4932 - val_loss: 1.0205 - val_accuracy: 0.6005\n",
            "\n",
            "Epoch 00033: val_accuracy improved from 0.57477 to 0.60047, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 34/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 1.1735 - accuracy: 0.5042 - val_loss: 1.1161 - val_accuracy: 0.5117\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.60047\n",
            "Epoch 35/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 1.1779 - accuracy: 0.5128 - val_loss: 1.0335 - val_accuracy: 0.5678\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.60047\n",
            "Epoch 36/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 1.1155 - accuracy: 0.5517 - val_loss: 1.0104 - val_accuracy: 0.5701\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.60047\n",
            "Epoch 37/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 1.1322 - accuracy: 0.5333 - val_loss: 1.0372 - val_accuracy: 0.5561\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.60047\n",
            "Epoch 38/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 1.1240 - accuracy: 0.5479 - val_loss: 1.1019 - val_accuracy: 0.5631\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.60047\n",
            "Epoch 39/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 1.0705 - accuracy: 0.5615 - val_loss: 1.0266 - val_accuracy: 0.5771\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.60047\n",
            "Epoch 40/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 1.0963 - accuracy: 0.5741 - val_loss: 1.3144 - val_accuracy: 0.5210\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.60047\n",
            "Epoch 41/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 1.0573 - accuracy: 0.5758 - val_loss: 1.3815 - val_accuracy: 0.5023\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.60047\n",
            "Epoch 42/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 1.0563 - accuracy: 0.5561 - val_loss: 1.2829 - val_accuracy: 0.5724\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.60047\n",
            "Epoch 43/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 1.0941 - accuracy: 0.5433 - val_loss: 0.9460 - val_accuracy: 0.6355\n",
            "\n",
            "Epoch 00043: val_accuracy improved from 0.60047 to 0.63551, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 44/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 1.0238 - accuracy: 0.6038 - val_loss: 0.9022 - val_accuracy: 0.5701\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.63551\n",
            "Epoch 45/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 1.0298 - accuracy: 0.5867 - val_loss: 1.0961 - val_accuracy: 0.5771\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.63551\n",
            "Epoch 46/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 1.0580 - accuracy: 0.5867 - val_loss: 0.8392 - val_accuracy: 0.6963\n",
            "\n",
            "Epoch 00046: val_accuracy improved from 0.63551 to 0.69626, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 47/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.9922 - accuracy: 0.5924 - val_loss: 0.8995 - val_accuracy: 0.6402\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.69626\n",
            "Epoch 48/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.9183 - accuracy: 0.6214 - val_loss: 0.9063 - val_accuracy: 0.6308\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.69626\n",
            "Epoch 49/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.9694 - accuracy: 0.5939 - val_loss: 0.8464 - val_accuracy: 0.6682\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.69626\n",
            "Epoch 50/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.8811 - accuracy: 0.6271 - val_loss: 0.9366 - val_accuracy: 0.6051\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.69626\n",
            "Epoch 51/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.9558 - accuracy: 0.6077 - val_loss: 1.1688 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.69626\n",
            "Epoch 52/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.9286 - accuracy: 0.5819 - val_loss: 0.8562 - val_accuracy: 0.6729\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.69626\n",
            "Epoch 53/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.8437 - accuracy: 0.6354 - val_loss: 1.0985 - val_accuracy: 0.5280\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.69626\n",
            "Epoch 54/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.8908 - accuracy: 0.6047 - val_loss: 1.0211 - val_accuracy: 0.6121\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.69626\n",
            "Epoch 55/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.8791 - accuracy: 0.6601 - val_loss: 0.8122 - val_accuracy: 0.6565\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.69626\n",
            "Epoch 56/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.8861 - accuracy: 0.6277 - val_loss: 0.9232 - val_accuracy: 0.6495\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.69626\n",
            "Epoch 57/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.8519 - accuracy: 0.6342 - val_loss: 0.7792 - val_accuracy: 0.6776\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.69626\n",
            "Epoch 58/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.8294 - accuracy: 0.6494 - val_loss: 0.9409 - val_accuracy: 0.6262\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.69626\n",
            "Epoch 59/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.8632 - accuracy: 0.6069 - val_loss: 0.8594 - val_accuracy: 0.6589\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.69626\n",
            "Epoch 60/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.8846 - accuracy: 0.6265 - val_loss: 0.7175 - val_accuracy: 0.7243\n",
            "\n",
            "Epoch 00060: val_accuracy improved from 0.69626 to 0.72430, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 61/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.8007 - accuracy: 0.6259 - val_loss: 0.7269 - val_accuracy: 0.6869\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.72430\n",
            "Epoch 62/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.8455 - accuracy: 0.6394 - val_loss: 0.9282 - val_accuracy: 0.6449\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.72430\n",
            "Epoch 63/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.8746 - accuracy: 0.6362 - val_loss: 0.7427 - val_accuracy: 0.6822\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.72430\n",
            "Epoch 64/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.8394 - accuracy: 0.6533 - val_loss: 1.0555 - val_accuracy: 0.6729\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.72430\n",
            "Epoch 65/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.8345 - accuracy: 0.6455 - val_loss: 0.7868 - val_accuracy: 0.6846\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.72430\n",
            "Epoch 66/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.7643 - accuracy: 0.6638 - val_loss: 0.7745 - val_accuracy: 0.6963\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.72430\n",
            "Epoch 67/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.7224 - accuracy: 0.6531 - val_loss: 0.7540 - val_accuracy: 0.6752\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.72430\n",
            "Epoch 68/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.7547 - accuracy: 0.6639 - val_loss: 0.9235 - val_accuracy: 0.6262\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.72430\n",
            "Epoch 69/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.7703 - accuracy: 0.6512 - val_loss: 0.7278 - val_accuracy: 0.6939\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.72430\n",
            "Epoch 70/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.7118 - accuracy: 0.6807 - val_loss: 0.6524 - val_accuracy: 0.7033\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.72430\n",
            "Epoch 71/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.7636 - accuracy: 0.6763 - val_loss: 0.7172 - val_accuracy: 0.6986\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.72430\n",
            "Epoch 72/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.7153 - accuracy: 0.6826 - val_loss: 0.6946 - val_accuracy: 0.7079\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.72430\n",
            "Epoch 73/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.7184 - accuracy: 0.6980 - val_loss: 0.6229 - val_accuracy: 0.7617\n",
            "\n",
            "Epoch 00073: val_accuracy improved from 0.72430 to 0.76168, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 74/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.6926 - accuracy: 0.6807 - val_loss: 0.7117 - val_accuracy: 0.7360\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.76168\n",
            "Epoch 75/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.7001 - accuracy: 0.6955 - val_loss: 0.8720 - val_accuracy: 0.6776\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.76168\n",
            "Epoch 76/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.7927 - accuracy: 0.6726 - val_loss: 0.5788 - val_accuracy: 0.7360\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.76168\n",
            "Epoch 77/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.6994 - accuracy: 0.7075 - val_loss: 0.6197 - val_accuracy: 0.7523\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.76168\n",
            "Epoch 78/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.7143 - accuracy: 0.7017 - val_loss: 0.6865 - val_accuracy: 0.7126\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.76168\n",
            "Epoch 79/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.6320 - accuracy: 0.7002 - val_loss: 0.6236 - val_accuracy: 0.7336\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.76168\n",
            "Epoch 80/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.6423 - accuracy: 0.7208 - val_loss: 0.5635 - val_accuracy: 0.7874\n",
            "\n",
            "Epoch 00080: val_accuracy improved from 0.76168 to 0.78738, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 81/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.5978 - accuracy: 0.7225 - val_loss: 1.0578 - val_accuracy: 0.6822\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.78738\n",
            "Epoch 82/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.6612 - accuracy: 0.7188 - val_loss: 0.6009 - val_accuracy: 0.7196\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.78738\n",
            "Epoch 83/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.6213 - accuracy: 0.7369 - val_loss: 0.6772 - val_accuracy: 0.6542\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.78738\n",
            "Epoch 84/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.6235 - accuracy: 0.6969 - val_loss: 0.5737 - val_accuracy: 0.7383\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.78738\n",
            "Epoch 85/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.6522 - accuracy: 0.7151 - val_loss: 0.5505 - val_accuracy: 0.7477\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.78738\n",
            "Epoch 86/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.5678 - accuracy: 0.7244 - val_loss: 0.5620 - val_accuracy: 0.7477\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.78738\n",
            "Epoch 87/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.6256 - accuracy: 0.7068 - val_loss: 0.8569 - val_accuracy: 0.6729\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.78738\n",
            "Epoch 88/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.6281 - accuracy: 0.7253 - val_loss: 0.6101 - val_accuracy: 0.7500\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.78738\n",
            "Epoch 89/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.5654 - accuracy: 0.7280 - val_loss: 0.6220 - val_accuracy: 0.7547\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.78738\n",
            "Epoch 90/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.5945 - accuracy: 0.7152 - val_loss: 0.5475 - val_accuracy: 0.7523\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.78738\n",
            "Epoch 91/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.5915 - accuracy: 0.7271 - val_loss: 0.5802 - val_accuracy: 0.7313\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.78738\n",
            "Epoch 92/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.5483 - accuracy: 0.7410 - val_loss: 0.7510 - val_accuracy: 0.6963\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.78738\n",
            "Epoch 93/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.5656 - accuracy: 0.7165 - val_loss: 0.5379 - val_accuracy: 0.7664\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.78738\n",
            "Epoch 94/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.5613 - accuracy: 0.7280 - val_loss: 0.5652 - val_accuracy: 0.7593\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.78738\n",
            "Epoch 95/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.6264 - accuracy: 0.6981 - val_loss: 0.5758 - val_accuracy: 0.7360\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.78738\n",
            "Epoch 96/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.5477 - accuracy: 0.7418 - val_loss: 0.5492 - val_accuracy: 0.7547\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.78738\n",
            "Epoch 97/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.5935 - accuracy: 0.7282 - val_loss: 0.5205 - val_accuracy: 0.7570\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.78738\n",
            "Epoch 98/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.5861 - accuracy: 0.6982 - val_loss: 0.6244 - val_accuracy: 0.6986\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.78738\n",
            "Epoch 99/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.5587 - accuracy: 0.7299 - val_loss: 0.5231 - val_accuracy: 0.7430\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.78738\n",
            "Epoch 100/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.5246 - accuracy: 0.7509 - val_loss: 0.5113 - val_accuracy: 0.7757\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.78738\n",
            "Epoch 101/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.5469 - accuracy: 0.7121 - val_loss: 0.5174 - val_accuracy: 0.7664\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.78738\n",
            "Epoch 102/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.4640 - accuracy: 0.7363 - val_loss: 0.5128 - val_accuracy: 0.7640\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.78738\n",
            "Epoch 103/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.5559 - accuracy: 0.7082 - val_loss: 0.5787 - val_accuracy: 0.7336\n",
            "\n",
            "Epoch 00103: val_accuracy did not improve from 0.78738\n",
            "Epoch 104/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.5210 - accuracy: 0.7357 - val_loss: 0.6037 - val_accuracy: 0.7336\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 0.78738\n",
            "Epoch 105/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.5430 - accuracy: 0.7452 - val_loss: 0.5111 - val_accuracy: 0.7477\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.78738\n",
            "Epoch 106/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.5118 - accuracy: 0.7432 - val_loss: 0.5542 - val_accuracy: 0.7407\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.78738\n",
            "Epoch 107/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.5297 - accuracy: 0.7420 - val_loss: 0.5935 - val_accuracy: 0.6893\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.78738\n",
            "Epoch 108/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.6432 - accuracy: 0.7155 - val_loss: 0.5745 - val_accuracy: 0.7617\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 0.78738\n",
            "Epoch 109/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.5614 - accuracy: 0.7254 - val_loss: 0.5642 - val_accuracy: 0.7687\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.78738\n",
            "Epoch 110/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.5251 - accuracy: 0.7445 - val_loss: 0.5200 - val_accuracy: 0.7523\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.78738\n",
            "Epoch 111/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.5172 - accuracy: 0.7382 - val_loss: 0.5780 - val_accuracy: 0.7477\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 0.78738\n",
            "Epoch 112/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.5001 - accuracy: 0.7312 - val_loss: 0.5010 - val_accuracy: 0.7523\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.78738\n",
            "Epoch 113/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.4870 - accuracy: 0.7355 - val_loss: 0.4685 - val_accuracy: 0.7103\n",
            "\n",
            "Epoch 00113: val_accuracy did not improve from 0.78738\n",
            "Epoch 114/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.5271 - accuracy: 0.7396 - val_loss: 0.5242 - val_accuracy: 0.7617\n",
            "\n",
            "Epoch 00114: val_accuracy did not improve from 0.78738\n",
            "Epoch 115/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.4947 - accuracy: 0.7433 - val_loss: 0.4628 - val_accuracy: 0.7734\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.78738\n",
            "Epoch 116/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.4767 - accuracy: 0.7401 - val_loss: 0.5073 - val_accuracy: 0.7547\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.78738\n",
            "Epoch 117/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.5342 - accuracy: 0.7277 - val_loss: 0.5761 - val_accuracy: 0.7407\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.78738\n",
            "Epoch 118/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.5298 - accuracy: 0.7286 - val_loss: 0.4700 - val_accuracy: 0.7780\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.78738\n",
            "Epoch 119/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.5135 - accuracy: 0.7188 - val_loss: 0.4641 - val_accuracy: 0.7593\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.78738\n",
            "Epoch 120/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.4758 - accuracy: 0.7284 - val_loss: 0.5428 - val_accuracy: 0.7360\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 0.78738\n",
            "Epoch 121/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.4806 - accuracy: 0.7488 - val_loss: 0.5001 - val_accuracy: 0.7523\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.78738\n",
            "Epoch 122/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.6334 - accuracy: 0.7058 - val_loss: 0.5184 - val_accuracy: 0.7664\n",
            "\n",
            "Epoch 00122: val_accuracy did not improve from 0.78738\n",
            "Epoch 123/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.5346 - accuracy: 0.7367 - val_loss: 0.4815 - val_accuracy: 0.7734\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.78738\n",
            "Epoch 124/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.5172 - accuracy: 0.7558 - val_loss: 0.4485 - val_accuracy: 0.7710\n",
            "\n",
            "Epoch 00124: val_accuracy did not improve from 0.78738\n",
            "Epoch 125/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.4952 - accuracy: 0.7367 - val_loss: 0.4932 - val_accuracy: 0.7734\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.78738\n",
            "Epoch 126/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.4801 - accuracy: 0.7227 - val_loss: 0.4736 - val_accuracy: 0.7780\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.78738\n",
            "Epoch 127/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.4836 - accuracy: 0.7419 - val_loss: 0.4845 - val_accuracy: 0.7196\n",
            "\n",
            "Epoch 00127: val_accuracy did not improve from 0.78738\n",
            "Epoch 128/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.4779 - accuracy: 0.7636 - val_loss: 0.4859 - val_accuracy: 0.7360\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.78738\n",
            "Epoch 129/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.4655 - accuracy: 0.7447 - val_loss: 0.5197 - val_accuracy: 0.7313\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.78738\n",
            "Epoch 130/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.5165 - accuracy: 0.7549 - val_loss: 0.5640 - val_accuracy: 0.7617\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.78738\n",
            "Epoch 131/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.4799 - accuracy: 0.7332 - val_loss: 0.4570 - val_accuracy: 0.7850\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.78738\n",
            "Epoch 132/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.4733 - accuracy: 0.7523 - val_loss: 0.4763 - val_accuracy: 0.7687\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.78738\n",
            "Epoch 133/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.4685 - accuracy: 0.7477 - val_loss: 0.5159 - val_accuracy: 0.7804\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.78738\n",
            "Epoch 134/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.5049 - accuracy: 0.7699 - val_loss: 0.6844 - val_accuracy: 0.7453\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.78738\n",
            "Epoch 135/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.4898 - accuracy: 0.7328 - val_loss: 0.5510 - val_accuracy: 0.7523\n",
            "\n",
            "Epoch 00135: val_accuracy did not improve from 0.78738\n",
            "Epoch 136/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.5004 - accuracy: 0.7473 - val_loss: 0.7857 - val_accuracy: 0.7266\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.78738\n",
            "Epoch 137/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.4929 - accuracy: 0.7330 - val_loss: 0.5019 - val_accuracy: 0.7664\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 0.78738\n",
            "Epoch 138/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.4700 - accuracy: 0.7422 - val_loss: 0.5827 - val_accuracy: 0.7383\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.78738\n",
            "Epoch 139/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.4708 - accuracy: 0.7383 - val_loss: 0.5638 - val_accuracy: 0.7500\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.78738\n",
            "Epoch 140/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.4573 - accuracy: 0.7464 - val_loss: 0.5535 - val_accuracy: 0.7500\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.78738\n",
            "Epoch 141/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.4920 - accuracy: 0.7206 - val_loss: 0.4753 - val_accuracy: 0.7640\n",
            "\n",
            "Epoch 00141: val_accuracy did not improve from 0.78738\n",
            "Epoch 142/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.4533 - accuracy: 0.7593 - val_loss: 0.5559 - val_accuracy: 0.7477\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.78738\n",
            "Epoch 143/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.4510 - accuracy: 0.7665 - val_loss: 0.4473 - val_accuracy: 0.8061\n",
            "\n",
            "Epoch 00143: val_accuracy improved from 0.78738 to 0.80607, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 144/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.4553 - accuracy: 0.7560 - val_loss: 0.5368 - val_accuracy: 0.7664\n",
            "\n",
            "Epoch 00144: val_accuracy did not improve from 0.80607\n",
            "Epoch 145/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.5042 - accuracy: 0.7516 - val_loss: 0.4871 - val_accuracy: 0.8084\n",
            "\n",
            "Epoch 00145: val_accuracy improved from 0.80607 to 0.80841, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 146/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.4225 - accuracy: 0.7834 - val_loss: 0.5074 - val_accuracy: 0.7874\n",
            "\n",
            "Epoch 00146: val_accuracy did not improve from 0.80841\n",
            "Epoch 147/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.4738 - accuracy: 0.7706 - val_loss: 0.5167 - val_accuracy: 0.7804\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.80841\n",
            "Epoch 148/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.4990 - accuracy: 0.7438 - val_loss: 0.5025 - val_accuracy: 0.7734\n",
            "\n",
            "Epoch 00148: val_accuracy did not improve from 0.80841\n",
            "Epoch 149/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.4851 - accuracy: 0.7448 - val_loss: 0.5094 - val_accuracy: 0.7547\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.80841\n",
            "Epoch 150/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.4952 - accuracy: 0.7486 - val_loss: 0.5841 - val_accuracy: 0.7944\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 0.80841\n",
            "Epoch 151/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.4838 - accuracy: 0.7561 - val_loss: 0.5196 - val_accuracy: 0.7757\n",
            "\n",
            "Epoch 00151: val_accuracy did not improve from 0.80841\n",
            "Epoch 152/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.4525 - accuracy: 0.7792 - val_loss: 0.5194 - val_accuracy: 0.7897\n",
            "\n",
            "Epoch 00152: val_accuracy did not improve from 0.80841\n",
            "Epoch 153/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.4598 - accuracy: 0.7691 - val_loss: 0.5530 - val_accuracy: 0.7757\n",
            "\n",
            "Epoch 00153: val_accuracy did not improve from 0.80841\n",
            "Epoch 154/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.4802 - accuracy: 0.7676 - val_loss: 0.5020 - val_accuracy: 0.7967\n",
            "\n",
            "Epoch 00154: val_accuracy did not improve from 0.80841\n",
            "Epoch 155/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.4423 - accuracy: 0.7577 - val_loss: 0.5119 - val_accuracy: 0.7617\n",
            "\n",
            "Epoch 00155: val_accuracy did not improve from 0.80841\n",
            "Epoch 156/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.4328 - accuracy: 0.7469 - val_loss: 0.4250 - val_accuracy: 0.8154\n",
            "\n",
            "Epoch 00156: val_accuracy improved from 0.80841 to 0.81542, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 157/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.4192 - accuracy: 0.7798 - val_loss: 0.5707 - val_accuracy: 0.7874\n",
            "\n",
            "Epoch 00157: val_accuracy did not improve from 0.81542\n",
            "Epoch 158/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.4106 - accuracy: 0.7756 - val_loss: 0.5177 - val_accuracy: 0.7921\n",
            "\n",
            "Epoch 00158: val_accuracy did not improve from 0.81542\n",
            "Epoch 159/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.4329 - accuracy: 0.7878 - val_loss: 0.5141 - val_accuracy: 0.7874\n",
            "\n",
            "Epoch 00159: val_accuracy did not improve from 0.81542\n",
            "Epoch 160/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.4408 - accuracy: 0.7966 - val_loss: 0.5072 - val_accuracy: 0.7991\n",
            "\n",
            "Epoch 00160: val_accuracy did not improve from 0.81542\n",
            "Epoch 161/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.4555 - accuracy: 0.8066 - val_loss: 0.4686 - val_accuracy: 0.8131\n",
            "\n",
            "Epoch 00161: val_accuracy did not improve from 0.81542\n",
            "Epoch 162/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.4510 - accuracy: 0.7872 - val_loss: 0.5375 - val_accuracy: 0.8248\n",
            "\n",
            "Epoch 00162: val_accuracy improved from 0.81542 to 0.82477, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 163/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.4124 - accuracy: 0.8161 - val_loss: 0.4732 - val_accuracy: 0.8318\n",
            "\n",
            "Epoch 00163: val_accuracy improved from 0.82477 to 0.83178, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 164/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.4288 - accuracy: 0.8093 - val_loss: 0.4063 - val_accuracy: 0.8271\n",
            "\n",
            "Epoch 00164: val_accuracy did not improve from 0.83178\n",
            "Epoch 165/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.4447 - accuracy: 0.8143 - val_loss: 0.4166 - val_accuracy: 0.8294\n",
            "\n",
            "Epoch 00165: val_accuracy did not improve from 0.83178\n",
            "Epoch 166/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.4111 - accuracy: 0.8129 - val_loss: 0.4525 - val_accuracy: 0.8318\n",
            "\n",
            "Epoch 00166: val_accuracy did not improve from 0.83178\n",
            "Epoch 167/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.3737 - accuracy: 0.8215 - val_loss: 0.7505 - val_accuracy: 0.7780\n",
            "\n",
            "Epoch 00167: val_accuracy did not improve from 0.83178\n",
            "Epoch 168/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.4836 - accuracy: 0.7902 - val_loss: 0.4275 - val_accuracy: 0.8178\n",
            "\n",
            "Epoch 00168: val_accuracy did not improve from 0.83178\n",
            "Epoch 169/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.4223 - accuracy: 0.8022 - val_loss: 0.3599 - val_accuracy: 0.8318\n",
            "\n",
            "Epoch 00169: val_accuracy did not improve from 0.83178\n",
            "Epoch 170/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.3724 - accuracy: 0.8274 - val_loss: 0.3822 - val_accuracy: 0.8388\n",
            "\n",
            "Epoch 00170: val_accuracy improved from 0.83178 to 0.83879, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 171/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.3687 - accuracy: 0.8067 - val_loss: 0.4755 - val_accuracy: 0.8107\n",
            "\n",
            "Epoch 00171: val_accuracy did not improve from 0.83879\n",
            "Epoch 172/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.3893 - accuracy: 0.8037 - val_loss: 0.4165 - val_accuracy: 0.8224\n",
            "\n",
            "Epoch 00172: val_accuracy did not improve from 0.83879\n",
            "Epoch 173/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.3831 - accuracy: 0.8117 - val_loss: 0.4681 - val_accuracy: 0.8201\n",
            "\n",
            "Epoch 00173: val_accuracy did not improve from 0.83879\n",
            "Epoch 174/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.3747 - accuracy: 0.8188 - val_loss: 0.4759 - val_accuracy: 0.8131\n",
            "\n",
            "Epoch 00174: val_accuracy did not improve from 0.83879\n",
            "Epoch 175/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.3757 - accuracy: 0.8227 - val_loss: 0.4196 - val_accuracy: 0.8248\n",
            "\n",
            "Epoch 00175: val_accuracy did not improve from 0.83879\n",
            "Epoch 176/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.3540 - accuracy: 0.8077 - val_loss: 0.4422 - val_accuracy: 0.8458\n",
            "\n",
            "Epoch 00176: val_accuracy improved from 0.83879 to 0.84579, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 177/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.3215 - accuracy: 0.8318 - val_loss: 0.3916 - val_accuracy: 0.8201\n",
            "\n",
            "Epoch 00177: val_accuracy did not improve from 0.84579\n",
            "Epoch 178/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.3582 - accuracy: 0.8278 - val_loss: 0.7040 - val_accuracy: 0.7921\n",
            "\n",
            "Epoch 00178: val_accuracy did not improve from 0.84579\n",
            "Epoch 179/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.3219 - accuracy: 0.8368 - val_loss: 0.4218 - val_accuracy: 0.8248\n",
            "\n",
            "Epoch 00179: val_accuracy did not improve from 0.84579\n",
            "Epoch 180/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.4183 - accuracy: 0.8019 - val_loss: 0.4877 - val_accuracy: 0.8294\n",
            "\n",
            "Epoch 00180: val_accuracy did not improve from 0.84579\n",
            "Epoch 181/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.4475 - accuracy: 0.8229 - val_loss: 0.5112 - val_accuracy: 0.8271\n",
            "\n",
            "Epoch 00181: val_accuracy did not improve from 0.84579\n",
            "Epoch 182/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.3952 - accuracy: 0.8226 - val_loss: 0.3815 - val_accuracy: 0.8224\n",
            "\n",
            "Epoch 00182: val_accuracy did not improve from 0.84579\n",
            "Epoch 183/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.4536 - accuracy: 0.8153 - val_loss: 0.4659 - val_accuracy: 0.8248\n",
            "\n",
            "Epoch 00183: val_accuracy did not improve from 0.84579\n",
            "Epoch 184/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.4110 - accuracy: 0.8288 - val_loss: 0.4375 - val_accuracy: 0.8271\n",
            "\n",
            "Epoch 00184: val_accuracy did not improve from 0.84579\n",
            "Epoch 185/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.3627 - accuracy: 0.8373 - val_loss: 0.4121 - val_accuracy: 0.7991\n",
            "\n",
            "Epoch 00185: val_accuracy did not improve from 0.84579\n",
            "Epoch 186/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.3753 - accuracy: 0.8328 - val_loss: 0.4997 - val_accuracy: 0.8528\n",
            "\n",
            "Epoch 00186: val_accuracy improved from 0.84579 to 0.85280, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 187/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.3321 - accuracy: 0.8352 - val_loss: 0.4683 - val_accuracy: 0.8224\n",
            "\n",
            "Epoch 00187: val_accuracy did not improve from 0.85280\n",
            "Epoch 188/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.3403 - accuracy: 0.8296 - val_loss: 0.7492 - val_accuracy: 0.7383\n",
            "\n",
            "Epoch 00188: val_accuracy did not improve from 0.85280\n",
            "Epoch 189/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.4103 - accuracy: 0.8298 - val_loss: 0.4943 - val_accuracy: 0.8411\n",
            "\n",
            "Epoch 00189: val_accuracy did not improve from 0.85280\n",
            "Epoch 190/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.3898 - accuracy: 0.8278 - val_loss: 0.4731 - val_accuracy: 0.8248\n",
            "\n",
            "Epoch 00190: val_accuracy did not improve from 0.85280\n",
            "Epoch 191/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.3470 - accuracy: 0.8338 - val_loss: 0.4738 - val_accuracy: 0.8037\n",
            "\n",
            "Epoch 00191: val_accuracy did not improve from 0.85280\n",
            "Epoch 192/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.3214 - accuracy: 0.8570 - val_loss: 0.4654 - val_accuracy: 0.8084\n",
            "\n",
            "Epoch 00192: val_accuracy did not improve from 0.85280\n",
            "Epoch 193/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.3216 - accuracy: 0.8629 - val_loss: 0.4232 - val_accuracy: 0.8505\n",
            "\n",
            "Epoch 00193: val_accuracy did not improve from 0.85280\n",
            "Epoch 194/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.3287 - accuracy: 0.8447 - val_loss: 0.3612 - val_accuracy: 0.8364\n",
            "\n",
            "Epoch 00194: val_accuracy did not improve from 0.85280\n",
            "Epoch 195/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.3229 - accuracy: 0.8643 - val_loss: 0.4635 - val_accuracy: 0.7921\n",
            "\n",
            "Epoch 00195: val_accuracy did not improve from 0.85280\n",
            "Epoch 196/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.3693 - accuracy: 0.8341 - val_loss: 0.3391 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00196: val_accuracy improved from 0.85280 to 0.86215, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 197/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.3307 - accuracy: 0.8613 - val_loss: 0.3223 - val_accuracy: 0.8668\n",
            "\n",
            "Epoch 00197: val_accuracy improved from 0.86215 to 0.86682, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 198/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.3262 - accuracy: 0.8459 - val_loss: 0.4396 - val_accuracy: 0.8061\n",
            "\n",
            "Epoch 00198: val_accuracy did not improve from 0.86682\n",
            "Epoch 199/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.3131 - accuracy: 0.8390 - val_loss: 0.3641 - val_accuracy: 0.8271\n",
            "\n",
            "Epoch 00199: val_accuracy did not improve from 0.86682\n",
            "Epoch 200/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.3181 - accuracy: 0.8268 - val_loss: 0.4266 - val_accuracy: 0.8061\n",
            "\n",
            "Epoch 00200: val_accuracy did not improve from 0.86682\n",
            "Epoch 201/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.3635 - accuracy: 0.8319 - val_loss: 0.3924 - val_accuracy: 0.8388\n",
            "\n",
            "Epoch 00201: val_accuracy did not improve from 0.86682\n",
            "Epoch 202/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.3461 - accuracy: 0.8273 - val_loss: 0.3513 - val_accuracy: 0.8668\n",
            "\n",
            "Epoch 00202: val_accuracy did not improve from 0.86682\n",
            "Epoch 203/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.3408 - accuracy: 0.8361 - val_loss: 0.5470 - val_accuracy: 0.8154\n",
            "\n",
            "Epoch 00203: val_accuracy did not improve from 0.86682\n",
            "Epoch 204/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.3229 - accuracy: 0.8425 - val_loss: 0.4066 - val_accuracy: 0.8364\n",
            "\n",
            "Epoch 00204: val_accuracy did not improve from 0.86682\n",
            "Epoch 205/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.3339 - accuracy: 0.8413 - val_loss: 0.3418 - val_accuracy: 0.8178\n",
            "\n",
            "Epoch 00205: val_accuracy did not improve from 0.86682\n",
            "Epoch 206/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.3178 - accuracy: 0.8428 - val_loss: 0.3418 - val_accuracy: 0.8551\n",
            "\n",
            "Epoch 00206: val_accuracy did not improve from 0.86682\n",
            "Epoch 207/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.3172 - accuracy: 0.8423 - val_loss: 0.3794 - val_accuracy: 0.8318\n",
            "\n",
            "Epoch 00207: val_accuracy did not improve from 0.86682\n",
            "Epoch 208/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.3225 - accuracy: 0.8452 - val_loss: 0.3543 - val_accuracy: 0.8178\n",
            "\n",
            "Epoch 00208: val_accuracy did not improve from 0.86682\n",
            "Epoch 209/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.3190 - accuracy: 0.8429 - val_loss: 0.2874 - val_accuracy: 0.8505\n",
            "\n",
            "Epoch 00209: val_accuracy did not improve from 0.86682\n",
            "Epoch 210/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.2934 - accuracy: 0.8443 - val_loss: 0.3837 - val_accuracy: 0.8388\n",
            "\n",
            "Epoch 00210: val_accuracy did not improve from 0.86682\n",
            "Epoch 211/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.2982 - accuracy: 0.8488 - val_loss: 0.3587 - val_accuracy: 0.8364\n",
            "\n",
            "Epoch 00211: val_accuracy did not improve from 0.86682\n",
            "Epoch 212/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.3323 - accuracy: 0.8538 - val_loss: 0.5399 - val_accuracy: 0.8364\n",
            "\n",
            "Epoch 00212: val_accuracy did not improve from 0.86682\n",
            "Epoch 213/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.3549 - accuracy: 0.8551 - val_loss: 0.3204 - val_accuracy: 0.8551\n",
            "\n",
            "Epoch 00213: val_accuracy did not improve from 0.86682\n",
            "Epoch 214/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.2918 - accuracy: 0.8534 - val_loss: 0.3292 - val_accuracy: 0.8224\n",
            "\n",
            "Epoch 00214: val_accuracy did not improve from 0.86682\n",
            "Epoch 215/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.3324 - accuracy: 0.8370 - val_loss: 0.3692 - val_accuracy: 0.8598\n",
            "\n",
            "Epoch 00215: val_accuracy did not improve from 0.86682\n",
            "Epoch 216/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.3207 - accuracy: 0.8320 - val_loss: 0.4080 - val_accuracy: 0.8411\n",
            "\n",
            "Epoch 00216: val_accuracy did not improve from 0.86682\n",
            "Epoch 217/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.2926 - accuracy: 0.8665 - val_loss: 0.4806 - val_accuracy: 0.8411\n",
            "\n",
            "Epoch 00217: val_accuracy did not improve from 0.86682\n",
            "Epoch 218/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.3533 - accuracy: 0.8397 - val_loss: 0.3661 - val_accuracy: 0.8481\n",
            "\n",
            "Epoch 00218: val_accuracy did not improve from 0.86682\n",
            "Epoch 219/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.3592 - accuracy: 0.8506 - val_loss: 0.4054 - val_accuracy: 0.8061\n",
            "\n",
            "Epoch 00219: val_accuracy did not improve from 0.86682\n",
            "Epoch 220/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.3161 - accuracy: 0.8614 - val_loss: 0.3349 - val_accuracy: 0.8341\n",
            "\n",
            "Epoch 00220: val_accuracy did not improve from 0.86682\n",
            "Epoch 221/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.3189 - accuracy: 0.8372 - val_loss: 0.2968 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00221: val_accuracy did not improve from 0.86682\n",
            "Epoch 222/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.2931 - accuracy: 0.8507 - val_loss: 0.3864 - val_accuracy: 0.8178\n",
            "\n",
            "Epoch 00222: val_accuracy did not improve from 0.86682\n",
            "Epoch 223/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.3294 - accuracy: 0.8455 - val_loss: 0.3926 - val_accuracy: 0.8435\n",
            "\n",
            "Epoch 00223: val_accuracy did not improve from 0.86682\n",
            "Epoch 224/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.3494 - accuracy: 0.8500 - val_loss: 0.4048 - val_accuracy: 0.8575\n",
            "\n",
            "Epoch 00224: val_accuracy did not improve from 0.86682\n",
            "Epoch 225/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.3334 - accuracy: 0.8400 - val_loss: 0.3876 - val_accuracy: 0.8435\n",
            "\n",
            "Epoch 00225: val_accuracy did not improve from 0.86682\n",
            "Epoch 226/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.3092 - accuracy: 0.8549 - val_loss: 0.3073 - val_accuracy: 0.8505\n",
            "\n",
            "Epoch 00226: val_accuracy did not improve from 0.86682\n",
            "Epoch 227/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.3161 - accuracy: 0.8438 - val_loss: 0.3272 - val_accuracy: 0.8762\n",
            "\n",
            "Epoch 00227: val_accuracy improved from 0.86682 to 0.87617, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 228/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.3499 - accuracy: 0.8563 - val_loss: 0.3144 - val_accuracy: 0.8505\n",
            "\n",
            "Epoch 00228: val_accuracy did not improve from 0.87617\n",
            "Epoch 229/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.2997 - accuracy: 0.8514 - val_loss: 0.3042 - val_accuracy: 0.8668\n",
            "\n",
            "Epoch 00229: val_accuracy did not improve from 0.87617\n",
            "Epoch 230/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.2949 - accuracy: 0.8654 - val_loss: 0.4087 - val_accuracy: 0.8248\n",
            "\n",
            "Epoch 00230: val_accuracy did not improve from 0.87617\n",
            "Epoch 231/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.3085 - accuracy: 0.8398 - val_loss: 0.3707 - val_accuracy: 0.8575\n",
            "\n",
            "Epoch 00231: val_accuracy did not improve from 0.87617\n",
            "Epoch 232/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.3111 - accuracy: 0.8593 - val_loss: 0.3019 - val_accuracy: 0.8294\n",
            "\n",
            "Epoch 00232: val_accuracy did not improve from 0.87617\n",
            "Epoch 233/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.2742 - accuracy: 0.8811 - val_loss: 0.3813 - val_accuracy: 0.8598\n",
            "\n",
            "Epoch 00233: val_accuracy did not improve from 0.87617\n",
            "Epoch 234/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.3152 - accuracy: 0.8501 - val_loss: 0.3895 - val_accuracy: 0.8692\n",
            "\n",
            "Epoch 00234: val_accuracy did not improve from 0.87617\n",
            "Epoch 235/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.3193 - accuracy: 0.8651 - val_loss: 0.4834 - val_accuracy: 0.8061\n",
            "\n",
            "Epoch 00235: val_accuracy did not improve from 0.87617\n",
            "Epoch 236/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.3393 - accuracy: 0.8401 - val_loss: 0.3674 - val_accuracy: 0.8808\n",
            "\n",
            "Epoch 00236: val_accuracy improved from 0.87617 to 0.88084, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 237/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.3277 - accuracy: 0.8601 - val_loss: 0.3236 - val_accuracy: 0.8318\n",
            "\n",
            "Epoch 00237: val_accuracy did not improve from 0.88084\n",
            "Epoch 238/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.3504 - accuracy: 0.8332 - val_loss: 0.2994 - val_accuracy: 0.8575\n",
            "\n",
            "Epoch 00238: val_accuracy did not improve from 0.88084\n",
            "Epoch 239/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.3299 - accuracy: 0.8462 - val_loss: 0.2782 - val_accuracy: 0.8551\n",
            "\n",
            "Epoch 00239: val_accuracy did not improve from 0.88084\n",
            "Epoch 240/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.3400 - accuracy: 0.8372 - val_loss: 0.4175 - val_accuracy: 0.8598\n",
            "\n",
            "Epoch 00240: val_accuracy did not improve from 0.88084\n",
            "Epoch 241/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.3530 - accuracy: 0.8542 - val_loss: 0.4173 - val_accuracy: 0.8505\n",
            "\n",
            "Epoch 00241: val_accuracy did not improve from 0.88084\n",
            "Epoch 242/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.3221 - accuracy: 0.8547 - val_loss: 0.4604 - val_accuracy: 0.8435\n",
            "\n",
            "Epoch 00242: val_accuracy did not improve from 0.88084\n",
            "Epoch 243/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.3290 - accuracy: 0.8651 - val_loss: 0.3994 - val_accuracy: 0.8411\n",
            "\n",
            "Epoch 00243: val_accuracy did not improve from 0.88084\n",
            "Epoch 244/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.3175 - accuracy: 0.8455 - val_loss: 0.5247 - val_accuracy: 0.8481\n",
            "\n",
            "Epoch 00244: val_accuracy did not improve from 0.88084\n",
            "Epoch 245/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.3143 - accuracy: 0.8590 - val_loss: 0.5983 - val_accuracy: 0.8505\n",
            "\n",
            "Epoch 00245: val_accuracy did not improve from 0.88084\n",
            "Epoch 246/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.3561 - accuracy: 0.8630 - val_loss: 0.4261 - val_accuracy: 0.8458\n",
            "\n",
            "Epoch 00246: val_accuracy did not improve from 0.88084\n",
            "Epoch 247/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.2985 - accuracy: 0.8579 - val_loss: 0.5673 - val_accuracy: 0.8341\n",
            "\n",
            "Epoch 00247: val_accuracy did not improve from 0.88084\n",
            "Epoch 248/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.2943 - accuracy: 0.8549 - val_loss: 0.4003 - val_accuracy: 0.8551\n",
            "\n",
            "Epoch 00248: val_accuracy did not improve from 0.88084\n",
            "Epoch 249/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.3499 - accuracy: 0.8356 - val_loss: 0.3518 - val_accuracy: 0.8388\n",
            "\n",
            "Epoch 00249: val_accuracy did not improve from 0.88084\n",
            "Epoch 250/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.3033 - accuracy: 0.8669 - val_loss: 0.4088 - val_accuracy: 0.8598\n",
            "\n",
            "Epoch 00250: val_accuracy did not improve from 0.88084\n",
            "Epoch 251/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.3229 - accuracy: 0.8659 - val_loss: 0.3829 - val_accuracy: 0.8505\n",
            "\n",
            "Epoch 00251: val_accuracy did not improve from 0.88084\n",
            "Epoch 252/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.3102 - accuracy: 0.8664 - val_loss: 0.4052 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00252: val_accuracy did not improve from 0.88084\n",
            "Epoch 253/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.2835 - accuracy: 0.8673 - val_loss: 0.4106 - val_accuracy: 0.8505\n",
            "\n",
            "Epoch 00253: val_accuracy did not improve from 0.88084\n",
            "Epoch 254/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.3317 - accuracy: 0.8535 - val_loss: 0.3914 - val_accuracy: 0.8692\n",
            "\n",
            "Epoch 00254: val_accuracy did not improve from 0.88084\n",
            "Epoch 255/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.2655 - accuracy: 0.8831 - val_loss: 0.3939 - val_accuracy: 0.8692\n",
            "\n",
            "Epoch 00255: val_accuracy did not improve from 0.88084\n",
            "Epoch 256/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.2885 - accuracy: 0.8730 - val_loss: 0.2892 - val_accuracy: 0.8855\n",
            "\n",
            "Epoch 00256: val_accuracy improved from 0.88084 to 0.88551, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 257/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.2742 - accuracy: 0.8710 - val_loss: 0.3343 - val_accuracy: 0.8785\n",
            "\n",
            "Epoch 00257: val_accuracy did not improve from 0.88551\n",
            "Epoch 258/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.2597 - accuracy: 0.8694 - val_loss: 0.3236 - val_accuracy: 0.8972\n",
            "\n",
            "Epoch 00258: val_accuracy improved from 0.88551 to 0.89720, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 259/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.2834 - accuracy: 0.8619 - val_loss: 0.3282 - val_accuracy: 0.8528\n",
            "\n",
            "Epoch 00259: val_accuracy did not improve from 0.89720\n",
            "Epoch 260/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.2820 - accuracy: 0.8562 - val_loss: 0.3579 - val_accuracy: 0.8925\n",
            "\n",
            "Epoch 00260: val_accuracy did not improve from 0.89720\n",
            "Epoch 261/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.2832 - accuracy: 0.8727 - val_loss: 0.3542 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00261: val_accuracy did not improve from 0.89720\n",
            "Epoch 262/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.2573 - accuracy: 0.8571 - val_loss: 0.3891 - val_accuracy: 0.8575\n",
            "\n",
            "Epoch 00262: val_accuracy did not improve from 0.89720\n",
            "Epoch 263/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.2957 - accuracy: 0.8868 - val_loss: 0.4726 - val_accuracy: 0.8318\n",
            "\n",
            "Epoch 00263: val_accuracy did not improve from 0.89720\n",
            "Epoch 264/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.3288 - accuracy: 0.8668 - val_loss: 0.3727 - val_accuracy: 0.8832\n",
            "\n",
            "Epoch 00264: val_accuracy did not improve from 0.89720\n",
            "Epoch 265/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.2902 - accuracy: 0.8841 - val_loss: 0.4615 - val_accuracy: 0.8692\n",
            "\n",
            "Epoch 00265: val_accuracy did not improve from 0.89720\n",
            "Epoch 266/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.3343 - accuracy: 0.8667 - val_loss: 0.4184 - val_accuracy: 0.8738\n",
            "\n",
            "Epoch 00266: val_accuracy did not improve from 0.89720\n",
            "Epoch 267/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.2764 - accuracy: 0.8737 - val_loss: 0.3879 - val_accuracy: 0.8738\n",
            "\n",
            "Epoch 00267: val_accuracy did not improve from 0.89720\n",
            "Epoch 268/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.2960 - accuracy: 0.8812 - val_loss: 0.2912 - val_accuracy: 0.9065\n",
            "\n",
            "Epoch 00268: val_accuracy improved from 0.89720 to 0.90654, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 269/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.3456 - accuracy: 0.8666 - val_loss: 0.3236 - val_accuracy: 0.9112\n",
            "\n",
            "Epoch 00269: val_accuracy improved from 0.90654 to 0.91121, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 270/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.3077 - accuracy: 0.8683 - val_loss: 0.3709 - val_accuracy: 0.8481\n",
            "\n",
            "Epoch 00270: val_accuracy did not improve from 0.91121\n",
            "Epoch 271/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.3021 - accuracy: 0.8692 - val_loss: 0.4433 - val_accuracy: 0.9042\n",
            "\n",
            "Epoch 00271: val_accuracy did not improve from 0.91121\n",
            "Epoch 272/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.3626 - accuracy: 0.8908 - val_loss: 0.5471 - val_accuracy: 0.8879\n",
            "\n",
            "Epoch 00272: val_accuracy did not improve from 0.91121\n",
            "Epoch 273/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.4474 - accuracy: 0.8646 - val_loss: 0.4584 - val_accuracy: 0.8575\n",
            "\n",
            "Epoch 00273: val_accuracy did not improve from 0.91121\n",
            "Epoch 274/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.3224 - accuracy: 0.8883 - val_loss: 0.3465 - val_accuracy: 0.8902\n",
            "\n",
            "Epoch 00274: val_accuracy did not improve from 0.91121\n",
            "Epoch 275/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.3037 - accuracy: 0.8843 - val_loss: 0.3608 - val_accuracy: 0.8925\n",
            "\n",
            "Epoch 00275: val_accuracy did not improve from 0.91121\n",
            "Epoch 276/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.2907 - accuracy: 0.8845 - val_loss: 0.3403 - val_accuracy: 0.9229\n",
            "\n",
            "Epoch 00276: val_accuracy improved from 0.91121 to 0.92290, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 277/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.2882 - accuracy: 0.8883 - val_loss: 0.3417 - val_accuracy: 0.8949\n",
            "\n",
            "Epoch 00277: val_accuracy did not improve from 0.92290\n",
            "Epoch 278/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.2973 - accuracy: 0.8934 - val_loss: 0.3708 - val_accuracy: 0.9042\n",
            "\n",
            "Epoch 00278: val_accuracy did not improve from 0.92290\n",
            "Epoch 279/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.2540 - accuracy: 0.9087 - val_loss: 0.3587 - val_accuracy: 0.8925\n",
            "\n",
            "Epoch 00279: val_accuracy did not improve from 0.92290\n",
            "Epoch 280/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.2508 - accuracy: 0.9074 - val_loss: 0.3383 - val_accuracy: 0.8879\n",
            "\n",
            "Epoch 00280: val_accuracy did not improve from 0.92290\n",
            "Epoch 281/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.2642 - accuracy: 0.9031 - val_loss: 0.3886 - val_accuracy: 0.9136\n",
            "\n",
            "Epoch 00281: val_accuracy did not improve from 0.92290\n",
            "Epoch 282/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.3381 - accuracy: 0.8821 - val_loss: 0.4168 - val_accuracy: 0.8995\n",
            "\n",
            "Epoch 00282: val_accuracy did not improve from 0.92290\n",
            "Epoch 283/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.2979 - accuracy: 0.9018 - val_loss: 0.3635 - val_accuracy: 0.8972\n",
            "\n",
            "Epoch 00283: val_accuracy did not improve from 0.92290\n",
            "Epoch 284/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.2719 - accuracy: 0.9050 - val_loss: 0.3438 - val_accuracy: 0.9322\n",
            "\n",
            "Epoch 00284: val_accuracy improved from 0.92290 to 0.93224, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 285/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.2581 - accuracy: 0.9009 - val_loss: 0.3368 - val_accuracy: 0.9299\n",
            "\n",
            "Epoch 00285: val_accuracy did not improve from 0.93224\n",
            "Epoch 286/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.2590 - accuracy: 0.9124 - val_loss: 0.2606 - val_accuracy: 0.9276\n",
            "\n",
            "Epoch 00286: val_accuracy did not improve from 0.93224\n",
            "Epoch 287/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.2268 - accuracy: 0.9211 - val_loss: 0.2911 - val_accuracy: 0.9369\n",
            "\n",
            "Epoch 00287: val_accuracy improved from 0.93224 to 0.93692, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 288/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.2451 - accuracy: 0.9197 - val_loss: 0.2611 - val_accuracy: 0.9439\n",
            "\n",
            "Epoch 00288: val_accuracy improved from 0.93692 to 0.94393, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 289/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.2336 - accuracy: 0.9106 - val_loss: 0.2840 - val_accuracy: 0.9533\n",
            "\n",
            "Epoch 00289: val_accuracy improved from 0.94393 to 0.95327, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 290/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.2265 - accuracy: 0.9233 - val_loss: 0.3512 - val_accuracy: 0.9416\n",
            "\n",
            "Epoch 00290: val_accuracy did not improve from 0.95327\n",
            "Epoch 291/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.2278 - accuracy: 0.9237 - val_loss: 0.2535 - val_accuracy: 0.9393\n",
            "\n",
            "Epoch 00291: val_accuracy did not improve from 0.95327\n",
            "Epoch 292/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.2337 - accuracy: 0.9297 - val_loss: 0.2923 - val_accuracy: 0.9299\n",
            "\n",
            "Epoch 00292: val_accuracy did not improve from 0.95327\n",
            "Epoch 293/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.2286 - accuracy: 0.9287 - val_loss: 0.2691 - val_accuracy: 0.9369\n",
            "\n",
            "Epoch 00293: val_accuracy did not improve from 0.95327\n",
            "Epoch 294/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.2244 - accuracy: 0.9302 - val_loss: 0.2330 - val_accuracy: 0.9369\n",
            "\n",
            "Epoch 00294: val_accuracy did not improve from 0.95327\n",
            "Epoch 295/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.2000 - accuracy: 0.9258 - val_loss: 0.2332 - val_accuracy: 0.9463\n",
            "\n",
            "Epoch 00295: val_accuracy did not improve from 0.95327\n",
            "Epoch 296/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.2168 - accuracy: 0.9372 - val_loss: 0.2437 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00296: val_accuracy did not improve from 0.95327\n",
            "Epoch 297/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1956 - accuracy: 0.9441 - val_loss: 0.2759 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00297: val_accuracy did not improve from 0.95327\n",
            "Epoch 298/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.1904 - accuracy: 0.9400 - val_loss: 0.2326 - val_accuracy: 0.9393\n",
            "\n",
            "Epoch 00298: val_accuracy did not improve from 0.95327\n",
            "Epoch 299/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.2625 - accuracy: 0.9375 - val_loss: 0.2671 - val_accuracy: 0.9369\n",
            "\n",
            "Epoch 00299: val_accuracy did not improve from 0.95327\n",
            "Epoch 300/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.2116 - accuracy: 0.9543 - val_loss: 0.4256 - val_accuracy: 0.9019\n",
            "\n",
            "Epoch 00300: val_accuracy did not improve from 0.95327\n",
            "Epoch 301/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.2805 - accuracy: 0.9347 - val_loss: 0.2474 - val_accuracy: 0.9463\n",
            "\n",
            "Epoch 00301: val_accuracy did not improve from 0.95327\n",
            "Epoch 302/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.2250 - accuracy: 0.9507 - val_loss: 0.2409 - val_accuracy: 0.9439\n",
            "\n",
            "Epoch 00302: val_accuracy did not improve from 0.95327\n",
            "Epoch 303/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1961 - accuracy: 0.9592 - val_loss: 0.1748 - val_accuracy: 0.9603\n",
            "\n",
            "Epoch 00303: val_accuracy improved from 0.95327 to 0.96028, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 304/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1909 - accuracy: 0.9485 - val_loss: 0.2513 - val_accuracy: 0.9463\n",
            "\n",
            "Epoch 00304: val_accuracy did not improve from 0.96028\n",
            "Epoch 305/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.2384 - accuracy: 0.9434 - val_loss: 0.1769 - val_accuracy: 0.9509\n",
            "\n",
            "Epoch 00305: val_accuracy did not improve from 0.96028\n",
            "Epoch 306/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1981 - accuracy: 0.9549 - val_loss: 0.1907 - val_accuracy: 0.9579\n",
            "\n",
            "Epoch 00306: val_accuracy did not improve from 0.96028\n",
            "Epoch 307/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1853 - accuracy: 0.9563 - val_loss: 0.2547 - val_accuracy: 0.9533\n",
            "\n",
            "Epoch 00307: val_accuracy did not improve from 0.96028\n",
            "Epoch 308/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.2243 - accuracy: 0.9510 - val_loss: 0.1850 - val_accuracy: 0.9579\n",
            "\n",
            "Epoch 00308: val_accuracy did not improve from 0.96028\n",
            "Epoch 309/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1911 - accuracy: 0.9475 - val_loss: 0.2928 - val_accuracy: 0.9369\n",
            "\n",
            "Epoch 00309: val_accuracy did not improve from 0.96028\n",
            "Epoch 310/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1633 - accuracy: 0.9604 - val_loss: 0.2564 - val_accuracy: 0.9416\n",
            "\n",
            "Epoch 00310: val_accuracy did not improve from 0.96028\n",
            "Epoch 311/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.1935 - accuracy: 0.9534 - val_loss: 0.2376 - val_accuracy: 0.9509\n",
            "\n",
            "Epoch 00311: val_accuracy did not improve from 0.96028\n",
            "Epoch 312/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.2172 - accuracy: 0.9546 - val_loss: 0.2667 - val_accuracy: 0.9463\n",
            "\n",
            "Epoch 00312: val_accuracy did not improve from 0.96028\n",
            "Epoch 313/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1568 - accuracy: 0.9702 - val_loss: 0.1713 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00313: val_accuracy improved from 0.96028 to 0.96963, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 314/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1541 - accuracy: 0.9652 - val_loss: 0.1940 - val_accuracy: 0.9603\n",
            "\n",
            "Epoch 00314: val_accuracy did not improve from 0.96963\n",
            "Epoch 315/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1895 - accuracy: 0.9671 - val_loss: 0.3121 - val_accuracy: 0.9556\n",
            "\n",
            "Epoch 00315: val_accuracy did not improve from 0.96963\n",
            "Epoch 316/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1811 - accuracy: 0.9578 - val_loss: 0.2661 - val_accuracy: 0.9486\n",
            "\n",
            "Epoch 00316: val_accuracy did not improve from 0.96963\n",
            "Epoch 317/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.2250 - accuracy: 0.9509 - val_loss: 0.2521 - val_accuracy: 0.9626\n",
            "\n",
            "Epoch 00317: val_accuracy did not improve from 0.96963\n",
            "Epoch 318/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.1668 - accuracy: 0.9710 - val_loss: 0.2219 - val_accuracy: 0.9486\n",
            "\n",
            "Epoch 00318: val_accuracy did not improve from 0.96963\n",
            "Epoch 319/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1462 - accuracy: 0.9736 - val_loss: 0.1846 - val_accuracy: 0.9603\n",
            "\n",
            "Epoch 00319: val_accuracy did not improve from 0.96963\n",
            "Epoch 320/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1344 - accuracy: 0.9718 - val_loss: 0.1967 - val_accuracy: 0.9579\n",
            "\n",
            "Epoch 00320: val_accuracy did not improve from 0.96963\n",
            "Epoch 321/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.1245 - accuracy: 0.9812 - val_loss: 0.2135 - val_accuracy: 0.9556\n",
            "\n",
            "Epoch 00321: val_accuracy did not improve from 0.96963\n",
            "Epoch 322/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.1312 - accuracy: 0.9749 - val_loss: 0.1594 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00322: val_accuracy improved from 0.96963 to 0.97196, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 323/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1262 - accuracy: 0.9770 - val_loss: 0.2611 - val_accuracy: 0.9579\n",
            "\n",
            "Epoch 00323: val_accuracy did not improve from 0.97196\n",
            "Epoch 324/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1258 - accuracy: 0.9743 - val_loss: 0.1998 - val_accuracy: 0.9509\n",
            "\n",
            "Epoch 00324: val_accuracy did not improve from 0.97196\n",
            "Epoch 325/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.2172 - accuracy: 0.9621 - val_loss: 0.3040 - val_accuracy: 0.9509\n",
            "\n",
            "Epoch 00325: val_accuracy did not improve from 0.97196\n",
            "Epoch 326/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1703 - accuracy: 0.9594 - val_loss: 0.3146 - val_accuracy: 0.9416\n",
            "\n",
            "Epoch 00326: val_accuracy did not improve from 0.97196\n",
            "Epoch 327/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1746 - accuracy: 0.9750 - val_loss: 0.2334 - val_accuracy: 0.9626\n",
            "\n",
            "Epoch 00327: val_accuracy did not improve from 0.97196\n",
            "Epoch 328/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1581 - accuracy: 0.9673 - val_loss: 0.2771 - val_accuracy: 0.9603\n",
            "\n",
            "Epoch 00328: val_accuracy did not improve from 0.97196\n",
            "Epoch 329/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.1359 - accuracy: 0.9768 - val_loss: 0.2192 - val_accuracy: 0.9533\n",
            "\n",
            "Epoch 00329: val_accuracy did not improve from 0.97196\n",
            "Epoch 330/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1309 - accuracy: 0.9700 - val_loss: 0.3456 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00330: val_accuracy did not improve from 0.97196\n",
            "Epoch 331/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1216 - accuracy: 0.9750 - val_loss: 0.3101 - val_accuracy: 0.9626\n",
            "\n",
            "Epoch 00331: val_accuracy did not improve from 0.97196\n",
            "Epoch 332/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1773 - accuracy: 0.9657 - val_loss: 0.2972 - val_accuracy: 0.9626\n",
            "\n",
            "Epoch 00332: val_accuracy did not improve from 0.97196\n",
            "Epoch 333/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1722 - accuracy: 0.9662 - val_loss: 0.3801 - val_accuracy: 0.9509\n",
            "\n",
            "Epoch 00333: val_accuracy did not improve from 0.97196\n",
            "Epoch 334/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.1545 - accuracy: 0.9768 - val_loss: 0.3116 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00334: val_accuracy did not improve from 0.97196\n",
            "Epoch 335/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1413 - accuracy: 0.9776 - val_loss: 0.3633 - val_accuracy: 0.9603\n",
            "\n",
            "Epoch 00335: val_accuracy did not improve from 0.97196\n",
            "Epoch 336/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1769 - accuracy: 0.9631 - val_loss: 0.3208 - val_accuracy: 0.9486\n",
            "\n",
            "Epoch 00336: val_accuracy did not improve from 0.97196\n",
            "Epoch 337/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1483 - accuracy: 0.9787 - val_loss: 0.2680 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00337: val_accuracy did not improve from 0.97196\n",
            "Epoch 338/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1331 - accuracy: 0.9721 - val_loss: 0.2128 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00338: val_accuracy did not improve from 0.97196\n",
            "Epoch 339/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1325 - accuracy: 0.9760 - val_loss: 0.2334 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00339: val_accuracy did not improve from 0.97196\n",
            "Epoch 340/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1793 - accuracy: 0.9722 - val_loss: 0.3692 - val_accuracy: 0.9393\n",
            "\n",
            "Epoch 00340: val_accuracy did not improve from 0.97196\n",
            "Epoch 341/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1654 - accuracy: 0.9660 - val_loss: 0.3205 - val_accuracy: 0.9486\n",
            "\n",
            "Epoch 00341: val_accuracy did not improve from 0.97196\n",
            "Epoch 342/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1380 - accuracy: 0.9745 - val_loss: 0.3760 - val_accuracy: 0.9603\n",
            "\n",
            "Epoch 00342: val_accuracy did not improve from 0.97196\n",
            "Epoch 343/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1389 - accuracy: 0.9749 - val_loss: 0.1889 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00343: val_accuracy did not improve from 0.97196\n",
            "Epoch 344/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.1056 - accuracy: 0.9818 - val_loss: 0.2233 - val_accuracy: 0.9603\n",
            "\n",
            "Epoch 00344: val_accuracy did not improve from 0.97196\n",
            "Epoch 345/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1222 - accuracy: 0.9789 - val_loss: 0.2129 - val_accuracy: 0.9626\n",
            "\n",
            "Epoch 00345: val_accuracy did not improve from 0.97196\n",
            "Epoch 346/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1232 - accuracy: 0.9814 - val_loss: 0.2030 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00346: val_accuracy did not improve from 0.97196\n",
            "Epoch 347/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1106 - accuracy: 0.9797 - val_loss: 0.2630 - val_accuracy: 0.9579\n",
            "\n",
            "Epoch 00347: val_accuracy did not improve from 0.97196\n",
            "Epoch 348/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1194 - accuracy: 0.9775 - val_loss: 0.2849 - val_accuracy: 0.9579\n",
            "\n",
            "Epoch 00348: val_accuracy did not improve from 0.97196\n",
            "Epoch 349/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.2109 - accuracy: 0.9634 - val_loss: 0.1925 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00349: val_accuracy improved from 0.97196 to 0.97430, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 350/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1471 - accuracy: 0.9768 - val_loss: 0.1849 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00350: val_accuracy did not improve from 0.97430\n",
            "Epoch 351/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1640 - accuracy: 0.9694 - val_loss: 0.1877 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00351: val_accuracy did not improve from 0.97430\n",
            "Epoch 352/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.2147 - accuracy: 0.9658 - val_loss: 0.2230 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00352: val_accuracy did not improve from 0.97430\n",
            "Epoch 353/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1729 - accuracy: 0.9762 - val_loss: 0.1365 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00353: val_accuracy did not improve from 0.97430\n",
            "Epoch 354/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1256 - accuracy: 0.9825 - val_loss: 0.1596 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00354: val_accuracy did not improve from 0.97430\n",
            "Epoch 355/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1492 - accuracy: 0.9772 - val_loss: 0.1815 - val_accuracy: 0.9626\n",
            "\n",
            "Epoch 00355: val_accuracy did not improve from 0.97430\n",
            "Epoch 356/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1322 - accuracy: 0.9809 - val_loss: 0.2083 - val_accuracy: 0.9556\n",
            "\n",
            "Epoch 00356: val_accuracy did not improve from 0.97430\n",
            "Epoch 357/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1442 - accuracy: 0.9684 - val_loss: 0.1777 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00357: val_accuracy did not improve from 0.97430\n",
            "Epoch 358/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0954 - accuracy: 0.9823 - val_loss: 0.1791 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00358: val_accuracy did not improve from 0.97430\n",
            "Epoch 359/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0970 - accuracy: 0.9849 - val_loss: 0.2382 - val_accuracy: 0.9626\n",
            "\n",
            "Epoch 00359: val_accuracy did not improve from 0.97430\n",
            "Epoch 360/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1435 - accuracy: 0.9752 - val_loss: 0.2010 - val_accuracy: 0.9626\n",
            "\n",
            "Epoch 00360: val_accuracy did not improve from 0.97430\n",
            "Epoch 361/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1060 - accuracy: 0.9823 - val_loss: 0.1865 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00361: val_accuracy did not improve from 0.97430\n",
            "Epoch 362/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0945 - accuracy: 0.9810 - val_loss: 0.2500 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00362: val_accuracy did not improve from 0.97430\n",
            "Epoch 363/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1103 - accuracy: 0.9817 - val_loss: 0.2176 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00363: val_accuracy did not improve from 0.97430\n",
            "Epoch 364/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0914 - accuracy: 0.9848 - val_loss: 0.2473 - val_accuracy: 0.9626\n",
            "\n",
            "Epoch 00364: val_accuracy did not improve from 0.97430\n",
            "Epoch 365/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.0898 - accuracy: 0.9867 - val_loss: 0.4490 - val_accuracy: 0.9159\n",
            "\n",
            "Epoch 00365: val_accuracy did not improve from 0.97430\n",
            "Epoch 366/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.1487 - accuracy: 0.9752 - val_loss: 0.3105 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00366: val_accuracy did not improve from 0.97430\n",
            "Epoch 367/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1113 - accuracy: 0.9810 - val_loss: 0.2878 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00367: val_accuracy did not improve from 0.97430\n",
            "Epoch 368/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1499 - accuracy: 0.9739 - val_loss: 0.2941 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00368: val_accuracy did not improve from 0.97430\n",
            "Epoch 369/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1083 - accuracy: 0.9805 - val_loss: 0.3185 - val_accuracy: 0.9486\n",
            "\n",
            "Epoch 00369: val_accuracy did not improve from 0.97430\n",
            "Epoch 370/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1802 - accuracy: 0.9658 - val_loss: 0.3007 - val_accuracy: 0.9509\n",
            "\n",
            "Epoch 00370: val_accuracy did not improve from 0.97430\n",
            "Epoch 371/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1041 - accuracy: 0.9902 - val_loss: 0.1864 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00371: val_accuracy did not improve from 0.97430\n",
            "Epoch 372/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1111 - accuracy: 0.9813 - val_loss: 0.3350 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00372: val_accuracy did not improve from 0.97430\n",
            "Epoch 373/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1268 - accuracy: 0.9772 - val_loss: 0.3369 - val_accuracy: 0.9486\n",
            "\n",
            "Epoch 00373: val_accuracy did not improve from 0.97430\n",
            "Epoch 374/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1326 - accuracy: 0.9798 - val_loss: 0.1889 - val_accuracy: 0.9626\n",
            "\n",
            "Epoch 00374: val_accuracy did not improve from 0.97430\n",
            "Epoch 375/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.1404 - accuracy: 0.9784 - val_loss: 0.1778 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00375: val_accuracy improved from 0.97430 to 0.97897, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 376/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0730 - accuracy: 0.9921 - val_loss: 0.2045 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00376: val_accuracy did not improve from 0.97897\n",
            "Epoch 377/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0916 - accuracy: 0.9915 - val_loss: 0.2774 - val_accuracy: 0.9626\n",
            "\n",
            "Epoch 00377: val_accuracy did not improve from 0.97897\n",
            "Epoch 378/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1335 - accuracy: 0.9690 - val_loss: 0.2684 - val_accuracy: 0.9533\n",
            "\n",
            "Epoch 00378: val_accuracy did not improve from 0.97897\n",
            "Epoch 379/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1403 - accuracy: 0.9774 - val_loss: 0.3153 - val_accuracy: 0.9603\n",
            "\n",
            "Epoch 00379: val_accuracy did not improve from 0.97897\n",
            "Epoch 380/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1107 - accuracy: 0.9833 - val_loss: 0.4838 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00380: val_accuracy did not improve from 0.97897\n",
            "Epoch 381/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1436 - accuracy: 0.9873 - val_loss: 0.4329 - val_accuracy: 0.9369\n",
            "\n",
            "Epoch 00381: val_accuracy did not improve from 0.97897\n",
            "Epoch 382/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1319 - accuracy: 0.9890 - val_loss: 0.1951 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00382: val_accuracy did not improve from 0.97897\n",
            "Epoch 383/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1075 - accuracy: 0.9878 - val_loss: 0.2437 - val_accuracy: 0.9603\n",
            "\n",
            "Epoch 00383: val_accuracy did not improve from 0.97897\n",
            "Epoch 384/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1747 - accuracy: 0.9741 - val_loss: 0.1919 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00384: val_accuracy did not improve from 0.97897\n",
            "Epoch 385/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1876 - accuracy: 0.9747 - val_loss: 0.1751 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00385: val_accuracy did not improve from 0.97897\n",
            "Epoch 386/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1441 - accuracy: 0.9801 - val_loss: 0.1792 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00386: val_accuracy did not improve from 0.97897\n",
            "Epoch 387/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1159 - accuracy: 0.9856 - val_loss: 0.2314 - val_accuracy: 0.9603\n",
            "\n",
            "Epoch 00387: val_accuracy did not improve from 0.97897\n",
            "Epoch 388/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1060 - accuracy: 0.9858 - val_loss: 0.2023 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00388: val_accuracy did not improve from 0.97897\n",
            "Epoch 389/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0906 - accuracy: 0.9896 - val_loss: 0.1761 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00389: val_accuracy did not improve from 0.97897\n",
            "Epoch 390/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0891 - accuracy: 0.9901 - val_loss: 0.3358 - val_accuracy: 0.9299\n",
            "\n",
            "Epoch 00390: val_accuracy did not improve from 0.97897\n",
            "Epoch 391/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1200 - accuracy: 0.9738 - val_loss: 0.2670 - val_accuracy: 0.9603\n",
            "\n",
            "Epoch 00391: val_accuracy did not improve from 0.97897\n",
            "Epoch 392/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0855 - accuracy: 0.9911 - val_loss: 0.3285 - val_accuracy: 0.9533\n",
            "\n",
            "Epoch 00392: val_accuracy did not improve from 0.97897\n",
            "Epoch 393/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1516 - accuracy: 0.9764 - val_loss: 0.3378 - val_accuracy: 0.9626\n",
            "\n",
            "Epoch 00393: val_accuracy did not improve from 0.97897\n",
            "Epoch 394/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1415 - accuracy: 0.9812 - val_loss: 0.2475 - val_accuracy: 0.9603\n",
            "\n",
            "Epoch 00394: val_accuracy did not improve from 0.97897\n",
            "Epoch 395/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1208 - accuracy: 0.9841 - val_loss: 0.2632 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00395: val_accuracy did not improve from 0.97897\n",
            "Epoch 396/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1106 - accuracy: 0.9827 - val_loss: 0.2620 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00396: val_accuracy did not improve from 0.97897\n",
            "Epoch 397/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0926 - accuracy: 0.9841 - val_loss: 0.2180 - val_accuracy: 0.9603\n",
            "\n",
            "Epoch 00397: val_accuracy did not improve from 0.97897\n",
            "Epoch 398/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1244 - accuracy: 0.9810 - val_loss: 0.2440 - val_accuracy: 0.9579\n",
            "\n",
            "Epoch 00398: val_accuracy did not improve from 0.97897\n",
            "Epoch 399/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1109 - accuracy: 0.9848 - val_loss: 0.2016 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00399: val_accuracy did not improve from 0.97897\n",
            "Epoch 400/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0727 - accuracy: 0.9911 - val_loss: 0.3172 - val_accuracy: 0.9603\n",
            "\n",
            "Epoch 00400: val_accuracy did not improve from 0.97897\n",
            "Epoch 401/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1282 - accuracy: 0.9834 - val_loss: 0.2851 - val_accuracy: 0.9556\n",
            "\n",
            "Epoch 00401: val_accuracy did not improve from 0.97897\n",
            "Epoch 402/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1166 - accuracy: 0.9776 - val_loss: 0.2510 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00402: val_accuracy did not improve from 0.97897\n",
            "Epoch 403/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0941 - accuracy: 0.9854 - val_loss: 0.2057 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00403: val_accuracy did not improve from 0.97897\n",
            "Epoch 404/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1146 - accuracy: 0.9818 - val_loss: 0.2760 - val_accuracy: 0.9556\n",
            "\n",
            "Epoch 00404: val_accuracy did not improve from 0.97897\n",
            "Epoch 405/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1214 - accuracy: 0.9831 - val_loss: 0.2405 - val_accuracy: 0.9603\n",
            "\n",
            "Epoch 00405: val_accuracy did not improve from 0.97897\n",
            "Epoch 406/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1322 - accuracy: 0.9784 - val_loss: 0.2298 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00406: val_accuracy did not improve from 0.97897\n",
            "Epoch 407/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1291 - accuracy: 0.9774 - val_loss: 0.3465 - val_accuracy: 0.9509\n",
            "\n",
            "Epoch 00407: val_accuracy did not improve from 0.97897\n",
            "Epoch 408/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1460 - accuracy: 0.9695 - val_loss: 0.3354 - val_accuracy: 0.9556\n",
            "\n",
            "Epoch 00408: val_accuracy did not improve from 0.97897\n",
            "Epoch 409/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1258 - accuracy: 0.9864 - val_loss: 0.3599 - val_accuracy: 0.9533\n",
            "\n",
            "Epoch 00409: val_accuracy did not improve from 0.97897\n",
            "Epoch 410/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1011 - accuracy: 0.9840 - val_loss: 0.2798 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00410: val_accuracy did not improve from 0.97897\n",
            "Epoch 411/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0844 - accuracy: 0.9896 - val_loss: 0.2866 - val_accuracy: 0.9626\n",
            "\n",
            "Epoch 00411: val_accuracy did not improve from 0.97897\n",
            "Epoch 412/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0702 - accuracy: 0.9929 - val_loss: 0.2326 - val_accuracy: 0.9579\n",
            "\n",
            "Epoch 00412: val_accuracy did not improve from 0.97897\n",
            "Epoch 413/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0906 - accuracy: 0.9860 - val_loss: 0.3290 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00413: val_accuracy did not improve from 0.97897\n",
            "Epoch 414/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0940 - accuracy: 0.9872 - val_loss: 0.4721 - val_accuracy: 0.9393\n",
            "\n",
            "Epoch 00414: val_accuracy did not improve from 0.97897\n",
            "Epoch 415/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1652 - accuracy: 0.9843 - val_loss: 0.3883 - val_accuracy: 0.9439\n",
            "\n",
            "Epoch 00415: val_accuracy did not improve from 0.97897\n",
            "Epoch 416/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1482 - accuracy: 0.9855 - val_loss: 0.2469 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00416: val_accuracy did not improve from 0.97897\n",
            "Epoch 417/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1821 - accuracy: 0.9756 - val_loss: 0.2772 - val_accuracy: 0.9556\n",
            "\n",
            "Epoch 00417: val_accuracy did not improve from 0.97897\n",
            "Epoch 418/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1426 - accuracy: 0.9791 - val_loss: 0.2042 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00418: val_accuracy did not improve from 0.97897\n",
            "Epoch 419/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1263 - accuracy: 0.9842 - val_loss: 0.2791 - val_accuracy: 0.9533\n",
            "\n",
            "Epoch 00419: val_accuracy did not improve from 0.97897\n",
            "Epoch 420/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1318 - accuracy: 0.9799 - val_loss: 0.3182 - val_accuracy: 0.9579\n",
            "\n",
            "Epoch 00420: val_accuracy did not improve from 0.97897\n",
            "Epoch 421/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1722 - accuracy: 0.9833 - val_loss: 0.2327 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00421: val_accuracy did not improve from 0.97897\n",
            "Epoch 422/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1250 - accuracy: 0.9807 - val_loss: 0.3156 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00422: val_accuracy did not improve from 0.97897\n",
            "Epoch 423/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1384 - accuracy: 0.9861 - val_loss: 0.3172 - val_accuracy: 0.9626\n",
            "\n",
            "Epoch 00423: val_accuracy did not improve from 0.97897\n",
            "Epoch 424/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1109 - accuracy: 0.9857 - val_loss: 0.1278 - val_accuracy: 0.9883\n",
            "\n",
            "Epoch 00424: val_accuracy improved from 0.97897 to 0.98832, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 425/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0851 - accuracy: 0.9908 - val_loss: 0.1314 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00425: val_accuracy did not improve from 0.98832\n",
            "Epoch 426/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0899 - accuracy: 0.9895 - val_loss: 0.1497 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00426: val_accuracy did not improve from 0.98832\n",
            "Epoch 427/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1321 - accuracy: 0.9817 - val_loss: 0.1364 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00427: val_accuracy did not improve from 0.98832\n",
            "Epoch 428/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0823 - accuracy: 0.9880 - val_loss: 0.1431 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00428: val_accuracy did not improve from 0.98832\n",
            "Epoch 429/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0740 - accuracy: 0.9868 - val_loss: 0.1581 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00429: val_accuracy did not improve from 0.98832\n",
            "Epoch 430/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0774 - accuracy: 0.9916 - val_loss: 0.2352 - val_accuracy: 0.9579\n",
            "\n",
            "Epoch 00430: val_accuracy did not improve from 0.98832\n",
            "Epoch 431/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1091 - accuracy: 0.9832 - val_loss: 0.2271 - val_accuracy: 0.9579\n",
            "\n",
            "Epoch 00431: val_accuracy did not improve from 0.98832\n",
            "Epoch 432/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1061 - accuracy: 0.9874 - val_loss: 0.3366 - val_accuracy: 0.9556\n",
            "\n",
            "Epoch 00432: val_accuracy did not improve from 0.98832\n",
            "Epoch 433/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1247 - accuracy: 0.9761 - val_loss: 0.2366 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00433: val_accuracy did not improve from 0.98832\n",
            "Epoch 434/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1052 - accuracy: 0.9840 - val_loss: 0.3343 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00434: val_accuracy did not improve from 0.98832\n",
            "Epoch 435/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0834 - accuracy: 0.9853 - val_loss: 0.1957 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00435: val_accuracy did not improve from 0.98832\n",
            "Epoch 436/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0741 - accuracy: 0.9865 - val_loss: 0.2708 - val_accuracy: 0.9603\n",
            "\n",
            "Epoch 00436: val_accuracy did not improve from 0.98832\n",
            "Epoch 437/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0929 - accuracy: 0.9858 - val_loss: 0.2312 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00437: val_accuracy did not improve from 0.98832\n",
            "Epoch 438/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1115 - accuracy: 0.9846 - val_loss: 0.1821 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00438: val_accuracy did not improve from 0.98832\n",
            "Epoch 439/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0586 - accuracy: 0.9917 - val_loss: 0.2166 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00439: val_accuracy did not improve from 0.98832\n",
            "Epoch 440/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0783 - accuracy: 0.9890 - val_loss: 0.3400 - val_accuracy: 0.9579\n",
            "\n",
            "Epoch 00440: val_accuracy did not improve from 0.98832\n",
            "Epoch 441/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0769 - accuracy: 0.9912 - val_loss: 0.3195 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00441: val_accuracy did not improve from 0.98832\n",
            "Epoch 442/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1161 - accuracy: 0.9786 - val_loss: 0.2659 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00442: val_accuracy did not improve from 0.98832\n",
            "Epoch 443/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0785 - accuracy: 0.9897 - val_loss: 0.2424 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00443: val_accuracy did not improve from 0.98832\n",
            "Epoch 444/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0745 - accuracy: 0.9943 - val_loss: 0.2088 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00444: val_accuracy did not improve from 0.98832\n",
            "Epoch 445/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0715 - accuracy: 0.9871 - val_loss: 0.2261 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00445: val_accuracy did not improve from 0.98832\n",
            "Epoch 446/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1027 - accuracy: 0.9878 - val_loss: 0.3268 - val_accuracy: 0.9556\n",
            "\n",
            "Epoch 00446: val_accuracy did not improve from 0.98832\n",
            "Epoch 447/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1208 - accuracy: 0.9810 - val_loss: 0.3190 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00447: val_accuracy did not improve from 0.98832\n",
            "Epoch 448/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1215 - accuracy: 0.9834 - val_loss: 0.3362 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00448: val_accuracy did not improve from 0.98832\n",
            "Epoch 449/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0902 - accuracy: 0.9902 - val_loss: 0.2907 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00449: val_accuracy did not improve from 0.98832\n",
            "Epoch 450/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0806 - accuracy: 0.9906 - val_loss: 0.2256 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00450: val_accuracy did not improve from 0.98832\n",
            "Epoch 451/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0672 - accuracy: 0.9950 - val_loss: 0.2230 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00451: val_accuracy did not improve from 0.98832\n",
            "Epoch 452/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0587 - accuracy: 0.9930 - val_loss: 0.2423 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00452: val_accuracy did not improve from 0.98832\n",
            "Epoch 453/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0745 - accuracy: 0.9875 - val_loss: 0.4748 - val_accuracy: 0.9603\n",
            "\n",
            "Epoch 00453: val_accuracy did not improve from 0.98832\n",
            "Epoch 454/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1218 - accuracy: 0.9842 - val_loss: 0.4218 - val_accuracy: 0.9463\n",
            "\n",
            "Epoch 00454: val_accuracy did not improve from 0.98832\n",
            "Epoch 455/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1403 - accuracy: 0.9788 - val_loss: 0.3807 - val_accuracy: 0.9486\n",
            "\n",
            "Epoch 00455: val_accuracy did not improve from 0.98832\n",
            "Epoch 456/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1031 - accuracy: 0.9902 - val_loss: 0.2589 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00456: val_accuracy did not improve from 0.98832\n",
            "Epoch 457/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1062 - accuracy: 0.9855 - val_loss: 0.3479 - val_accuracy: 0.9463\n",
            "\n",
            "Epoch 00457: val_accuracy did not improve from 0.98832\n",
            "Epoch 458/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1639 - accuracy: 0.9853 - val_loss: 0.3049 - val_accuracy: 0.9626\n",
            "\n",
            "Epoch 00458: val_accuracy did not improve from 0.98832\n",
            "Epoch 459/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1398 - accuracy: 0.9835 - val_loss: 0.2720 - val_accuracy: 0.9626\n",
            "\n",
            "Epoch 00459: val_accuracy did not improve from 0.98832\n",
            "Epoch 460/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1252 - accuracy: 0.9851 - val_loss: 0.2568 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00460: val_accuracy did not improve from 0.98832\n",
            "Epoch 461/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1295 - accuracy: 0.9861 - val_loss: 0.1957 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00461: val_accuracy did not improve from 0.98832\n",
            "Epoch 462/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0936 - accuracy: 0.9869 - val_loss: 0.2709 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00462: val_accuracy did not improve from 0.98832\n",
            "Epoch 463/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1056 - accuracy: 0.9873 - val_loss: 0.2443 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00463: val_accuracy did not improve from 0.98832\n",
            "Epoch 464/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0742 - accuracy: 0.9934 - val_loss: 0.2334 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00464: val_accuracy did not improve from 0.98832\n",
            "Epoch 465/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1033 - accuracy: 0.9920 - val_loss: 0.2622 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00465: val_accuracy did not improve from 0.98832\n",
            "Epoch 466/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1186 - accuracy: 0.9823 - val_loss: 0.2930 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00466: val_accuracy did not improve from 0.98832\n",
            "Epoch 467/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1030 - accuracy: 0.9819 - val_loss: 0.2301 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00467: val_accuracy did not improve from 0.98832\n",
            "Epoch 468/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1133 - accuracy: 0.9809 - val_loss: 0.4098 - val_accuracy: 0.9579\n",
            "\n",
            "Epoch 00468: val_accuracy did not improve from 0.98832\n",
            "Epoch 469/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1447 - accuracy: 0.9753 - val_loss: 0.2864 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00469: val_accuracy did not improve from 0.98832\n",
            "Epoch 470/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0998 - accuracy: 0.9906 - val_loss: 0.3301 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00470: val_accuracy did not improve from 0.98832\n",
            "Epoch 471/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1191 - accuracy: 0.9783 - val_loss: 0.3730 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00471: val_accuracy did not improve from 0.98832\n",
            "Epoch 472/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1337 - accuracy: 0.9851 - val_loss: 0.1818 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00472: val_accuracy did not improve from 0.98832\n",
            "Epoch 473/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0973 - accuracy: 0.9856 - val_loss: 0.2336 - val_accuracy: 0.9626\n",
            "\n",
            "Epoch 00473: val_accuracy did not improve from 0.98832\n",
            "Epoch 474/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1273 - accuracy: 0.9836 - val_loss: 0.1632 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00474: val_accuracy did not improve from 0.98832\n",
            "Epoch 475/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0748 - accuracy: 0.9892 - val_loss: 0.2789 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00475: val_accuracy did not improve from 0.98832\n",
            "Epoch 476/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.0839 - accuracy: 0.9906 - val_loss: 0.2462 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00476: val_accuracy did not improve from 0.98832\n",
            "Epoch 477/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0639 - accuracy: 0.9928 - val_loss: 0.2613 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00477: val_accuracy did not improve from 0.98832\n",
            "Epoch 478/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0801 - accuracy: 0.9905 - val_loss: 0.2808 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00478: val_accuracy did not improve from 0.98832\n",
            "Epoch 479/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0692 - accuracy: 0.9881 - val_loss: 0.1894 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00479: val_accuracy did not improve from 0.98832\n",
            "Epoch 480/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0989 - accuracy: 0.9826 - val_loss: 0.2473 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00480: val_accuracy did not improve from 0.98832\n",
            "Epoch 481/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0882 - accuracy: 0.9879 - val_loss: 0.1804 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00481: val_accuracy did not improve from 0.98832\n",
            "Epoch 482/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1122 - accuracy: 0.9884 - val_loss: 0.3944 - val_accuracy: 0.9556\n",
            "\n",
            "Epoch 00482: val_accuracy did not improve from 0.98832\n",
            "Epoch 483/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1435 - accuracy: 0.9805 - val_loss: 0.2055 - val_accuracy: 0.9626\n",
            "\n",
            "Epoch 00483: val_accuracy did not improve from 0.98832\n",
            "Epoch 484/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1475 - accuracy: 0.9859 - val_loss: 0.2449 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00484: val_accuracy did not improve from 0.98832\n",
            "Epoch 485/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1266 - accuracy: 0.9829 - val_loss: 0.1488 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00485: val_accuracy did not improve from 0.98832\n",
            "Epoch 486/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0809 - accuracy: 0.9909 - val_loss: 0.2503 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00486: val_accuracy did not improve from 0.98832\n",
            "Epoch 487/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0734 - accuracy: 0.9930 - val_loss: 0.2352 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00487: val_accuracy did not improve from 0.98832\n",
            "Epoch 488/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0842 - accuracy: 0.9889 - val_loss: 0.2038 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00488: val_accuracy did not improve from 0.98832\n",
            "Epoch 489/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0626 - accuracy: 0.9927 - val_loss: 0.1518 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00489: val_accuracy did not improve from 0.98832\n",
            "Epoch 490/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0629 - accuracy: 0.9930 - val_loss: 0.1728 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00490: val_accuracy did not improve from 0.98832\n",
            "Epoch 491/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0817 - accuracy: 0.9847 - val_loss: 0.2469 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00491: val_accuracy did not improve from 0.98832\n",
            "Epoch 492/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0821 - accuracy: 0.9876 - val_loss: 0.1318 - val_accuracy: 0.9860\n",
            "\n",
            "Epoch 00492: val_accuracy did not improve from 0.98832\n",
            "Epoch 493/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0664 - accuracy: 0.9887 - val_loss: 0.2751 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00493: val_accuracy did not improve from 0.98832\n",
            "Epoch 494/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0781 - accuracy: 0.9903 - val_loss: 0.2418 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00494: val_accuracy did not improve from 0.98832\n",
            "Epoch 495/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0948 - accuracy: 0.9847 - val_loss: 0.3532 - val_accuracy: 0.9533\n",
            "\n",
            "Epoch 00495: val_accuracy did not improve from 0.98832\n",
            "Epoch 496/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0820 - accuracy: 0.9909 - val_loss: 0.3196 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00496: val_accuracy did not improve from 0.98832\n",
            "Epoch 497/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0728 - accuracy: 0.9912 - val_loss: 0.2799 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00497: val_accuracy did not improve from 0.98832\n",
            "Epoch 498/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0748 - accuracy: 0.9879 - val_loss: 0.3863 - val_accuracy: 0.9603\n",
            "\n",
            "Epoch 00498: val_accuracy did not improve from 0.98832\n",
            "Epoch 499/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1399 - accuracy: 0.9759 - val_loss: 0.4173 - val_accuracy: 0.9603\n",
            "\n",
            "Epoch 00499: val_accuracy did not improve from 0.98832\n",
            "Epoch 500/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1285 - accuracy: 0.9808 - val_loss: 0.4019 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00500: val_accuracy did not improve from 0.98832\n",
            "Epoch 501/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1083 - accuracy: 0.9862 - val_loss: 0.3569 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00501: val_accuracy did not improve from 0.98832\n",
            "Epoch 502/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0781 - accuracy: 0.9934 - val_loss: 0.3399 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00502: val_accuracy did not improve from 0.98832\n",
            "Epoch 503/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0602 - accuracy: 0.9944 - val_loss: 0.2523 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00503: val_accuracy did not improve from 0.98832\n",
            "Epoch 504/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0648 - accuracy: 0.9911 - val_loss: 0.2838 - val_accuracy: 0.9556\n",
            "\n",
            "Epoch 00504: val_accuracy did not improve from 0.98832\n",
            "Epoch 505/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0662 - accuracy: 0.9881 - val_loss: 0.2957 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00505: val_accuracy did not improve from 0.98832\n",
            "Epoch 506/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0753 - accuracy: 0.9906 - val_loss: 0.3047 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00506: val_accuracy did not improve from 0.98832\n",
            "Epoch 507/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0896 - accuracy: 0.9914 - val_loss: 0.2721 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00507: val_accuracy did not improve from 0.98832\n",
            "Epoch 508/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0621 - accuracy: 0.9931 - val_loss: 0.3067 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00508: val_accuracy did not improve from 0.98832\n",
            "Epoch 509/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0709 - accuracy: 0.9921 - val_loss: 0.2027 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00509: val_accuracy did not improve from 0.98832\n",
            "Epoch 510/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0641 - accuracy: 0.9935 - val_loss: 0.1781 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00510: val_accuracy did not improve from 0.98832\n",
            "Epoch 511/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0838 - accuracy: 0.9887 - val_loss: 0.3853 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00511: val_accuracy did not improve from 0.98832\n",
            "Epoch 512/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1014 - accuracy: 0.9845 - val_loss: 0.2848 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00512: val_accuracy did not improve from 0.98832\n",
            "Epoch 513/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1515 - accuracy: 0.9774 - val_loss: 0.2554 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00513: val_accuracy did not improve from 0.98832\n",
            "Epoch 514/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0724 - accuracy: 0.9926 - val_loss: 0.2328 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00514: val_accuracy did not improve from 0.98832\n",
            "Epoch 515/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0852 - accuracy: 0.9893 - val_loss: 0.2711 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00515: val_accuracy did not improve from 0.98832\n",
            "Epoch 516/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0706 - accuracy: 0.9933 - val_loss: 0.3167 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00516: val_accuracy did not improve from 0.98832\n",
            "Epoch 517/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0855 - accuracy: 0.9822 - val_loss: 0.4528 - val_accuracy: 0.9206\n",
            "\n",
            "Epoch 00517: val_accuracy did not improve from 0.98832\n",
            "Epoch 518/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0828 - accuracy: 0.9888 - val_loss: 0.2605 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00518: val_accuracy did not improve from 0.98832\n",
            "Epoch 519/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0865 - accuracy: 0.9813 - val_loss: 0.1595 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00519: val_accuracy did not improve from 0.98832\n",
            "Epoch 520/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0842 - accuracy: 0.9893 - val_loss: 0.1504 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00520: val_accuracy did not improve from 0.98832\n",
            "Epoch 521/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0636 - accuracy: 0.9878 - val_loss: 0.1130 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00521: val_accuracy did not improve from 0.98832\n",
            "Epoch 522/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0532 - accuracy: 0.9919 - val_loss: 0.1221 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00522: val_accuracy did not improve from 0.98832\n",
            "Epoch 523/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0577 - accuracy: 0.9879 - val_loss: 0.2930 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00523: val_accuracy did not improve from 0.98832\n",
            "Epoch 524/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0653 - accuracy: 0.9901 - val_loss: 0.4964 - val_accuracy: 0.9533\n",
            "\n",
            "Epoch 00524: val_accuracy did not improve from 0.98832\n",
            "Epoch 525/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0976 - accuracy: 0.9859 - val_loss: 0.3606 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00525: val_accuracy did not improve from 0.98832\n",
            "Epoch 526/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0778 - accuracy: 0.9846 - val_loss: 0.3156 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00526: val_accuracy did not improve from 0.98832\n",
            "Epoch 527/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0910 - accuracy: 0.9892 - val_loss: 0.2969 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00527: val_accuracy did not improve from 0.98832\n",
            "Epoch 528/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1029 - accuracy: 0.9876 - val_loss: 0.1841 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00528: val_accuracy did not improve from 0.98832\n",
            "Epoch 529/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1178 - accuracy: 0.9895 - val_loss: 0.2126 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00529: val_accuracy did not improve from 0.98832\n",
            "Epoch 530/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0808 - accuracy: 0.9905 - val_loss: 0.1722 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00530: val_accuracy did not improve from 0.98832\n",
            "Epoch 531/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0887 - accuracy: 0.9866 - val_loss: 0.3516 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00531: val_accuracy did not improve from 0.98832\n",
            "Epoch 532/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0911 - accuracy: 0.9934 - val_loss: 0.2474 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00532: val_accuracy did not improve from 0.98832\n",
            "Epoch 533/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0926 - accuracy: 0.9911 - val_loss: 0.2187 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00533: val_accuracy did not improve from 0.98832\n",
            "Epoch 534/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0802 - accuracy: 0.9911 - val_loss: 0.1897 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00534: val_accuracy did not improve from 0.98832\n",
            "Epoch 535/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0786 - accuracy: 0.9883 - val_loss: 0.2772 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00535: val_accuracy did not improve from 0.98832\n",
            "Epoch 536/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0942 - accuracy: 0.9850 - val_loss: 0.2454 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00536: val_accuracy did not improve from 0.98832\n",
            "Epoch 537/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1054 - accuracy: 0.9853 - val_loss: 0.2784 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00537: val_accuracy did not improve from 0.98832\n",
            "Epoch 538/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0635 - accuracy: 0.9878 - val_loss: 0.2153 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00538: val_accuracy did not improve from 0.98832\n",
            "Epoch 539/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1004 - accuracy: 0.9872 - val_loss: 0.2683 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00539: val_accuracy did not improve from 0.98832\n",
            "Epoch 540/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1148 - accuracy: 0.9896 - val_loss: 0.3165 - val_accuracy: 0.9556\n",
            "\n",
            "Epoch 00540: val_accuracy did not improve from 0.98832\n",
            "Epoch 541/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1259 - accuracy: 0.9846 - val_loss: 0.2529 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00541: val_accuracy did not improve from 0.98832\n",
            "Epoch 542/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1138 - accuracy: 0.9884 - val_loss: 0.2085 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00542: val_accuracy did not improve from 0.98832\n",
            "Epoch 543/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0775 - accuracy: 0.9857 - val_loss: 0.2262 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00543: val_accuracy did not improve from 0.98832\n",
            "Epoch 544/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1068 - accuracy: 0.9824 - val_loss: 0.3161 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00544: val_accuracy did not improve from 0.98832\n",
            "Epoch 545/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0963 - accuracy: 0.9892 - val_loss: 0.1964 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00545: val_accuracy did not improve from 0.98832\n",
            "Epoch 546/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0835 - accuracy: 0.9880 - val_loss: 0.1608 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00546: val_accuracy did not improve from 0.98832\n",
            "Epoch 547/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0664 - accuracy: 0.9870 - val_loss: 0.1593 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00547: val_accuracy did not improve from 0.98832\n",
            "Epoch 548/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0662 - accuracy: 0.9935 - val_loss: 0.2159 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00548: val_accuracy did not improve from 0.98832\n",
            "Epoch 549/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0746 - accuracy: 0.9922 - val_loss: 0.2492 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00549: val_accuracy did not improve from 0.98832\n",
            "Epoch 550/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0750 - accuracy: 0.9902 - val_loss: 0.2253 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00550: val_accuracy did not improve from 0.98832\n",
            "Epoch 551/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0613 - accuracy: 0.9867 - val_loss: 0.2236 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00551: val_accuracy did not improve from 0.98832\n",
            "Epoch 552/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0665 - accuracy: 0.9921 - val_loss: 0.1675 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00552: val_accuracy did not improve from 0.98832\n",
            "Epoch 553/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0781 - accuracy: 0.9890 - val_loss: 0.2373 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00553: val_accuracy did not improve from 0.98832\n",
            "Epoch 554/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0865 - accuracy: 0.9900 - val_loss: 0.3637 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00554: val_accuracy did not improve from 0.98832\n",
            "Epoch 555/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0852 - accuracy: 0.9881 - val_loss: 0.2016 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00555: val_accuracy did not improve from 0.98832\n",
            "Epoch 556/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0959 - accuracy: 0.9870 - val_loss: 0.1644 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00556: val_accuracy did not improve from 0.98832\n",
            "Epoch 557/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0742 - accuracy: 0.9882 - val_loss: 0.1497 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00557: val_accuracy did not improve from 0.98832\n",
            "Epoch 558/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0865 - accuracy: 0.9872 - val_loss: 0.2236 - val_accuracy: 0.9626\n",
            "\n",
            "Epoch 00558: val_accuracy did not improve from 0.98832\n",
            "Epoch 559/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1218 - accuracy: 0.9918 - val_loss: 0.1863 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00559: val_accuracy did not improve from 0.98832\n",
            "Epoch 560/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0674 - accuracy: 0.9943 - val_loss: 0.2379 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00560: val_accuracy did not improve from 0.98832\n",
            "Epoch 561/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0818 - accuracy: 0.9896 - val_loss: 0.3006 - val_accuracy: 0.9603\n",
            "\n",
            "Epoch 00561: val_accuracy did not improve from 0.98832\n",
            "Epoch 562/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0550 - accuracy: 0.9928 - val_loss: 0.1912 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00562: val_accuracy did not improve from 0.98832\n",
            "Epoch 563/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0613 - accuracy: 0.9913 - val_loss: 0.1567 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00563: val_accuracy did not improve from 0.98832\n",
            "Epoch 564/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0887 - accuracy: 0.9894 - val_loss: 0.3985 - val_accuracy: 0.9439\n",
            "\n",
            "Epoch 00564: val_accuracy did not improve from 0.98832\n",
            "Epoch 565/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1215 - accuracy: 0.9845 - val_loss: 0.2159 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00565: val_accuracy did not improve from 0.98832\n",
            "Epoch 566/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0742 - accuracy: 0.9903 - val_loss: 0.1398 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00566: val_accuracy did not improve from 0.98832\n",
            "Epoch 567/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0716 - accuracy: 0.9917 - val_loss: 0.1176 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00567: val_accuracy did not improve from 0.98832\n",
            "Epoch 568/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0715 - accuracy: 0.9876 - val_loss: 0.1353 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00568: val_accuracy did not improve from 0.98832\n",
            "Epoch 569/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0525 - accuracy: 0.9935 - val_loss: 0.1868 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00569: val_accuracy did not improve from 0.98832\n",
            "Epoch 570/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0651 - accuracy: 0.9899 - val_loss: 0.3410 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00570: val_accuracy did not improve from 0.98832\n",
            "Epoch 571/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.1517 - accuracy: 0.9762 - val_loss: 0.3717 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00571: val_accuracy did not improve from 0.98832\n",
            "Epoch 572/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1394 - accuracy: 0.9880 - val_loss: 0.3206 - val_accuracy: 0.9603\n",
            "\n",
            "Epoch 00572: val_accuracy did not improve from 0.98832\n",
            "Epoch 573/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1016 - accuracy: 0.9865 - val_loss: 0.2316 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00573: val_accuracy did not improve from 0.98832\n",
            "Epoch 574/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0927 - accuracy: 0.9865 - val_loss: 0.2230 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00574: val_accuracy did not improve from 0.98832\n",
            "Epoch 575/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1030 - accuracy: 0.9851 - val_loss: 0.2388 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00575: val_accuracy did not improve from 0.98832\n",
            "Epoch 576/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0923 - accuracy: 0.9917 - val_loss: 0.2029 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00576: val_accuracy did not improve from 0.98832\n",
            "Epoch 577/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0915 - accuracy: 0.9851 - val_loss: 0.1890 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00577: val_accuracy did not improve from 0.98832\n",
            "Epoch 578/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1018 - accuracy: 0.9937 - val_loss: 0.2692 - val_accuracy: 0.9626\n",
            "\n",
            "Epoch 00578: val_accuracy did not improve from 0.98832\n",
            "Epoch 579/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1088 - accuracy: 0.9870 - val_loss: 0.4007 - val_accuracy: 0.9416\n",
            "\n",
            "Epoch 00579: val_accuracy did not improve from 0.98832\n",
            "Epoch 580/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1301 - accuracy: 0.9859 - val_loss: 0.2532 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00580: val_accuracy did not improve from 0.98832\n",
            "Epoch 581/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1123 - accuracy: 0.9853 - val_loss: 0.2471 - val_accuracy: 0.9603\n",
            "\n",
            "Epoch 00581: val_accuracy did not improve from 0.98832\n",
            "Epoch 582/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1042 - accuracy: 0.9893 - val_loss: 0.1803 - val_accuracy: 0.9626\n",
            "\n",
            "Epoch 00582: val_accuracy did not improve from 0.98832\n",
            "Epoch 583/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0932 - accuracy: 0.9903 - val_loss: 0.2900 - val_accuracy: 0.9579\n",
            "\n",
            "Epoch 00583: val_accuracy did not improve from 0.98832\n",
            "Epoch 584/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1182 - accuracy: 0.9842 - val_loss: 0.1869 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00584: val_accuracy did not improve from 0.98832\n",
            "Epoch 585/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0616 - accuracy: 0.9964 - val_loss: 0.2472 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00585: val_accuracy did not improve from 0.98832\n",
            "Epoch 586/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0676 - accuracy: 0.9900 - val_loss: 0.1826 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00586: val_accuracy did not improve from 0.98832\n",
            "Epoch 587/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0674 - accuracy: 0.9899 - val_loss: 0.1818 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00587: val_accuracy did not improve from 0.98832\n",
            "Epoch 588/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0624 - accuracy: 0.9911 - val_loss: 0.2610 - val_accuracy: 0.9626\n",
            "\n",
            "Epoch 00588: val_accuracy did not improve from 0.98832\n",
            "Epoch 589/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0700 - accuracy: 0.9907 - val_loss: 0.1710 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00589: val_accuracy did not improve from 0.98832\n",
            "Epoch 590/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0623 - accuracy: 0.9933 - val_loss: 0.2376 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00590: val_accuracy did not improve from 0.98832\n",
            "Epoch 591/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0589 - accuracy: 0.9953 - val_loss: 0.1524 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00591: val_accuracy did not improve from 0.98832\n",
            "Epoch 592/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0686 - accuracy: 0.9925 - val_loss: 0.1874 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00592: val_accuracy did not improve from 0.98832\n",
            "Epoch 593/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0926 - accuracy: 0.9846 - val_loss: 0.2211 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00593: val_accuracy did not improve from 0.98832\n",
            "Epoch 594/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1064 - accuracy: 0.9862 - val_loss: 0.1926 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00594: val_accuracy did not improve from 0.98832\n",
            "Epoch 595/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0843 - accuracy: 0.9884 - val_loss: 0.1929 - val_accuracy: 0.9626\n",
            "\n",
            "Epoch 00595: val_accuracy did not improve from 0.98832\n",
            "Epoch 596/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0674 - accuracy: 0.9927 - val_loss: 0.1734 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00596: val_accuracy did not improve from 0.98832\n",
            "Epoch 597/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0892 - accuracy: 0.9827 - val_loss: 0.2219 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00597: val_accuracy did not improve from 0.98832\n",
            "Epoch 598/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0658 - accuracy: 0.9906 - val_loss: 0.2114 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00598: val_accuracy did not improve from 0.98832\n",
            "Epoch 599/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0517 - accuracy: 0.9914 - val_loss: 0.2013 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00599: val_accuracy did not improve from 0.98832\n",
            "Epoch 600/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0675 - accuracy: 0.9896 - val_loss: 0.1766 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00600: val_accuracy did not improve from 0.98832\n",
            "Epoch 601/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0734 - accuracy: 0.9887 - val_loss: 0.2078 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00601: val_accuracy did not improve from 0.98832\n",
            "Epoch 602/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0839 - accuracy: 0.9834 - val_loss: 0.3219 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00602: val_accuracy did not improve from 0.98832\n",
            "Epoch 603/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.2044 - accuracy: 0.9788 - val_loss: 0.3764 - val_accuracy: 0.9603\n",
            "\n",
            "Epoch 00603: val_accuracy did not improve from 0.98832\n",
            "Epoch 604/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1525 - accuracy: 0.9829 - val_loss: 0.3207 - val_accuracy: 0.9626\n",
            "\n",
            "Epoch 00604: val_accuracy did not improve from 0.98832\n",
            "Epoch 605/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1000 - accuracy: 0.9897 - val_loss: 0.2568 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00605: val_accuracy did not improve from 0.98832\n",
            "Epoch 606/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0968 - accuracy: 0.9926 - val_loss: 0.2637 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00606: val_accuracy did not improve from 0.98832\n",
            "Epoch 607/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0896 - accuracy: 0.9899 - val_loss: 0.1938 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00607: val_accuracy did not improve from 0.98832\n",
            "Epoch 608/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0732 - accuracy: 0.9915 - val_loss: 0.1840 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00608: val_accuracy did not improve from 0.98832\n",
            "Epoch 609/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0713 - accuracy: 0.9900 - val_loss: 0.2055 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00609: val_accuracy did not improve from 0.98832\n",
            "Epoch 610/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0852 - accuracy: 0.9917 - val_loss: 0.2062 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00610: val_accuracy did not improve from 0.98832\n",
            "Epoch 611/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0628 - accuracy: 0.9933 - val_loss: 0.1856 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00611: val_accuracy did not improve from 0.98832\n",
            "Epoch 612/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0681 - accuracy: 0.9922 - val_loss: 0.1909 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00612: val_accuracy did not improve from 0.98832\n",
            "Epoch 613/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0487 - accuracy: 0.9974 - val_loss: 0.3028 - val_accuracy: 0.9603\n",
            "\n",
            "Epoch 00613: val_accuracy did not improve from 0.98832\n",
            "Epoch 614/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0746 - accuracy: 0.9921 - val_loss: 0.2826 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00614: val_accuracy did not improve from 0.98832\n",
            "Epoch 615/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0804 - accuracy: 0.9909 - val_loss: 0.2227 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00615: val_accuracy did not improve from 0.98832\n",
            "Epoch 616/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1245 - accuracy: 0.9836 - val_loss: 0.2268 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00616: val_accuracy did not improve from 0.98832\n",
            "Epoch 617/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0820 - accuracy: 0.9930 - val_loss: 0.1976 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00617: val_accuracy did not improve from 0.98832\n",
            "Epoch 618/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0785 - accuracy: 0.9920 - val_loss: 0.1720 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00618: val_accuracy did not improve from 0.98832\n",
            "Epoch 619/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0634 - accuracy: 0.9877 - val_loss: 0.2172 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00619: val_accuracy did not improve from 0.98832\n",
            "Epoch 620/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0446 - accuracy: 0.9963 - val_loss: 0.1653 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00620: val_accuracy did not improve from 0.98832\n",
            "Epoch 621/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0648 - accuracy: 0.9876 - val_loss: 0.1812 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00621: val_accuracy did not improve from 0.98832\n",
            "Epoch 622/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0523 - accuracy: 0.9937 - val_loss: 0.1530 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00622: val_accuracy did not improve from 0.98832\n",
            "Epoch 623/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0467 - accuracy: 0.9948 - val_loss: 0.1049 - val_accuracy: 0.9860\n",
            "\n",
            "Epoch 00623: val_accuracy did not improve from 0.98832\n",
            "Epoch 624/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0613 - accuracy: 0.9923 - val_loss: 0.2165 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00624: val_accuracy did not improve from 0.98832\n",
            "Epoch 625/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0856 - accuracy: 0.9883 - val_loss: 0.1567 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00625: val_accuracy did not improve from 0.98832\n",
            "Epoch 626/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0614 - accuracy: 0.9897 - val_loss: 0.1484 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00626: val_accuracy did not improve from 0.98832\n",
            "Epoch 627/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0395 - accuracy: 0.9961 - val_loss: 0.1756 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00627: val_accuracy did not improve from 0.98832\n",
            "Epoch 628/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0361 - accuracy: 0.9972 - val_loss: 0.1598 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00628: val_accuracy did not improve from 0.98832\n",
            "Epoch 629/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0568 - accuracy: 0.9936 - val_loss: 0.3558 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00629: val_accuracy did not improve from 0.98832\n",
            "Epoch 630/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0704 - accuracy: 0.9918 - val_loss: 0.2069 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00630: val_accuracy did not improve from 0.98832\n",
            "Epoch 631/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0943 - accuracy: 0.9887 - val_loss: 0.2125 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00631: val_accuracy did not improve from 0.98832\n",
            "Epoch 632/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1286 - accuracy: 0.9895 - val_loss: 0.1757 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00632: val_accuracy did not improve from 0.98832\n",
            "Epoch 633/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0704 - accuracy: 0.9902 - val_loss: 0.3505 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00633: val_accuracy did not improve from 0.98832\n",
            "Epoch 634/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0717 - accuracy: 0.9921 - val_loss: 0.2205 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00634: val_accuracy did not improve from 0.98832\n",
            "Epoch 635/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0759 - accuracy: 0.9912 - val_loss: 0.2082 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00635: val_accuracy did not improve from 0.98832\n",
            "Epoch 636/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0720 - accuracy: 0.9879 - val_loss: 0.1694 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00636: val_accuracy did not improve from 0.98832\n",
            "Epoch 637/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0737 - accuracy: 0.9915 - val_loss: 0.2043 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00637: val_accuracy did not improve from 0.98832\n",
            "Epoch 638/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0902 - accuracy: 0.9943 - val_loss: 0.2830 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00638: val_accuracy did not improve from 0.98832\n",
            "Epoch 639/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0805 - accuracy: 0.9884 - val_loss: 0.2158 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00639: val_accuracy did not improve from 0.98832\n",
            "Epoch 640/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0801 - accuracy: 0.9914 - val_loss: 0.2453 - val_accuracy: 0.9626\n",
            "\n",
            "Epoch 00640: val_accuracy did not improve from 0.98832\n",
            "Epoch 641/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0696 - accuracy: 0.9912 - val_loss: 0.2269 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00641: val_accuracy did not improve from 0.98832\n",
            "Epoch 642/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0818 - accuracy: 0.9924 - val_loss: 0.2475 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00642: val_accuracy did not improve from 0.98832\n",
            "Epoch 643/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1179 - accuracy: 0.9845 - val_loss: 0.3231 - val_accuracy: 0.9626\n",
            "\n",
            "Epoch 00643: val_accuracy did not improve from 0.98832\n",
            "Epoch 644/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0791 - accuracy: 0.9902 - val_loss: 0.2140 - val_accuracy: 0.9626\n",
            "\n",
            "Epoch 00644: val_accuracy did not improve from 0.98832\n",
            "Epoch 645/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0572 - accuracy: 0.9933 - val_loss: 0.2078 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00645: val_accuracy did not improve from 0.98832\n",
            "Epoch 646/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0789 - accuracy: 0.9881 - val_loss: 0.2176 - val_accuracy: 0.9579\n",
            "\n",
            "Epoch 00646: val_accuracy did not improve from 0.98832\n",
            "Epoch 647/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0529 - accuracy: 0.9951 - val_loss: 0.1363 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00647: val_accuracy did not improve from 0.98832\n",
            "Epoch 648/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0591 - accuracy: 0.9934 - val_loss: 0.2286 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00648: val_accuracy did not improve from 0.98832\n",
            "Epoch 649/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0577 - accuracy: 0.9917 - val_loss: 0.2026 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00649: val_accuracy did not improve from 0.98832\n",
            "Epoch 650/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0736 - accuracy: 0.9932 - val_loss: 0.2866 - val_accuracy: 0.9626\n",
            "\n",
            "Epoch 00650: val_accuracy did not improve from 0.98832\n",
            "Epoch 651/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0625 - accuracy: 0.9927 - val_loss: 0.2141 - val_accuracy: 0.9626\n",
            "\n",
            "Epoch 00651: val_accuracy did not improve from 0.98832\n",
            "Epoch 652/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0602 - accuracy: 0.9945 - val_loss: 0.2670 - val_accuracy: 0.9626\n",
            "\n",
            "Epoch 00652: val_accuracy did not improve from 0.98832\n",
            "Epoch 653/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0651 - accuracy: 0.9951 - val_loss: 0.2916 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00653: val_accuracy did not improve from 0.98832\n",
            "Epoch 654/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0578 - accuracy: 0.9941 - val_loss: 0.5546 - val_accuracy: 0.9556\n",
            "\n",
            "Epoch 00654: val_accuracy did not improve from 0.98832\n",
            "Epoch 655/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1259 - accuracy: 0.9848 - val_loss: 0.1916 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00655: val_accuracy did not improve from 0.98832\n",
            "Epoch 656/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0629 - accuracy: 0.9946 - val_loss: 0.1165 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00656: val_accuracy did not improve from 0.98832\n",
            "Epoch 657/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0691 - accuracy: 0.9911 - val_loss: 0.1530 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00657: val_accuracy did not improve from 0.98832\n",
            "Epoch 658/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0800 - accuracy: 0.9917 - val_loss: 0.1871 - val_accuracy: 0.9603\n",
            "\n",
            "Epoch 00658: val_accuracy did not improve from 0.98832\n",
            "Epoch 659/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0894 - accuracy: 0.9889 - val_loss: 0.3047 - val_accuracy: 0.9579\n",
            "\n",
            "Epoch 00659: val_accuracy did not improve from 0.98832\n",
            "Epoch 660/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0753 - accuracy: 0.9861 - val_loss: 0.2164 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00660: val_accuracy did not improve from 0.98832\n",
            "Epoch 661/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0814 - accuracy: 0.9885 - val_loss: 0.2106 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00661: val_accuracy did not improve from 0.98832\n",
            "Epoch 662/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0601 - accuracy: 0.9919 - val_loss: 0.1577 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00662: val_accuracy did not improve from 0.98832\n",
            "Epoch 663/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0496 - accuracy: 0.9947 - val_loss: 0.1686 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00663: val_accuracy did not improve from 0.98832\n",
            "Epoch 664/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0390 - accuracy: 0.9953 - val_loss: 0.1790 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00664: val_accuracy did not improve from 0.98832\n",
            "Epoch 665/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0421 - accuracy: 0.9918 - val_loss: 0.2085 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00665: val_accuracy did not improve from 0.98832\n",
            "Epoch 666/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0679 - accuracy: 0.9923 - val_loss: 0.2179 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00666: val_accuracy did not improve from 0.98832\n",
            "Epoch 667/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0911 - accuracy: 0.9893 - val_loss: 0.1363 - val_accuracy: 0.9860\n",
            "\n",
            "Epoch 00667: val_accuracy did not improve from 0.98832\n",
            "Epoch 668/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0952 - accuracy: 0.9883 - val_loss: 0.1900 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00668: val_accuracy did not improve from 0.98832\n",
            "Epoch 669/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0567 - accuracy: 0.9961 - val_loss: 0.1799 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00669: val_accuracy did not improve from 0.98832\n",
            "Epoch 670/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0597 - accuracy: 0.9954 - val_loss: 0.3140 - val_accuracy: 0.9626\n",
            "\n",
            "Epoch 00670: val_accuracy did not improve from 0.98832\n",
            "Epoch 671/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0499 - accuracy: 0.9975 - val_loss: 0.3511 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00671: val_accuracy did not improve from 0.98832\n",
            "Epoch 672/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0672 - accuracy: 0.9892 - val_loss: 0.2320 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00672: val_accuracy did not improve from 0.98832\n",
            "Epoch 673/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0506 - accuracy: 0.9958 - val_loss: 0.2244 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00673: val_accuracy did not improve from 0.98832\n",
            "Epoch 674/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0417 - accuracy: 0.9964 - val_loss: 0.2461 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00674: val_accuracy did not improve from 0.98832\n",
            "Epoch 675/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0534 - accuracy: 0.9932 - val_loss: 0.2309 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00675: val_accuracy did not improve from 0.98832\n",
            "Epoch 676/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0519 - accuracy: 0.9948 - val_loss: 0.2859 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00676: val_accuracy did not improve from 0.98832\n",
            "Epoch 677/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0501 - accuracy: 0.9932 - val_loss: 0.1976 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00677: val_accuracy did not improve from 0.98832\n",
            "Epoch 678/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0359 - accuracy: 0.9979 - val_loss: 0.1373 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00678: val_accuracy did not improve from 0.98832\n",
            "Epoch 679/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0903 - accuracy: 0.9877 - val_loss: 0.2228 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00679: val_accuracy did not improve from 0.98832\n",
            "Epoch 680/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0501 - accuracy: 0.9946 - val_loss: 0.2630 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00680: val_accuracy did not improve from 0.98832\n",
            "Epoch 681/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0608 - accuracy: 0.9925 - val_loss: 0.4165 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00681: val_accuracy did not improve from 0.98832\n",
            "Epoch 682/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1318 - accuracy: 0.9858 - val_loss: 0.5025 - val_accuracy: 0.9556\n",
            "\n",
            "Epoch 00682: val_accuracy did not improve from 0.98832\n",
            "Epoch 683/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0952 - accuracy: 0.9888 - val_loss: 0.3476 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00683: val_accuracy did not improve from 0.98832\n",
            "Epoch 684/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1150 - accuracy: 0.9854 - val_loss: 0.2253 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00684: val_accuracy did not improve from 0.98832\n",
            "Epoch 685/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1215 - accuracy: 0.9872 - val_loss: 0.2871 - val_accuracy: 0.9533\n",
            "\n",
            "Epoch 00685: val_accuracy did not improve from 0.98832\n",
            "Epoch 686/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0865 - accuracy: 0.9923 - val_loss: 0.2100 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00686: val_accuracy did not improve from 0.98832\n",
            "Epoch 687/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0905 - accuracy: 0.9937 - val_loss: 0.2806 - val_accuracy: 0.9626\n",
            "\n",
            "Epoch 00687: val_accuracy did not improve from 0.98832\n",
            "Epoch 688/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0743 - accuracy: 0.9897 - val_loss: 0.2274 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00688: val_accuracy did not improve from 0.98832\n",
            "Epoch 689/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0765 - accuracy: 0.9893 - val_loss: 0.1869 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00689: val_accuracy did not improve from 0.98832\n",
            "Epoch 690/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0773 - accuracy: 0.9905 - val_loss: 0.2024 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00690: val_accuracy did not improve from 0.98832\n",
            "Epoch 691/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0796 - accuracy: 0.9917 - val_loss: 0.1661 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00691: val_accuracy did not improve from 0.98832\n",
            "Epoch 692/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0735 - accuracy: 0.9876 - val_loss: 0.1904 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00692: val_accuracy did not improve from 0.98832\n",
            "Epoch 693/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0521 - accuracy: 0.9924 - val_loss: 0.3791 - val_accuracy: 0.9463\n",
            "\n",
            "Epoch 00693: val_accuracy did not improve from 0.98832\n",
            "Epoch 694/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0895 - accuracy: 0.9885 - val_loss: 0.3952 - val_accuracy: 0.9626\n",
            "\n",
            "Epoch 00694: val_accuracy did not improve from 0.98832\n",
            "Epoch 695/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0736 - accuracy: 0.9961 - val_loss: 0.2773 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00695: val_accuracy did not improve from 0.98832\n",
            "Epoch 696/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0591 - accuracy: 0.9938 - val_loss: 0.1710 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00696: val_accuracy did not improve from 0.98832\n",
            "Epoch 697/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0453 - accuracy: 0.9969 - val_loss: 0.2226 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00697: val_accuracy did not improve from 0.98832\n",
            "Epoch 698/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0607 - accuracy: 0.9903 - val_loss: 0.1761 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00698: val_accuracy did not improve from 0.98832\n",
            "Epoch 699/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0486 - accuracy: 0.9940 - val_loss: 0.1589 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00699: val_accuracy did not improve from 0.98832\n",
            "Epoch 700/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0446 - accuracy: 0.9938 - val_loss: 0.1815 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00700: val_accuracy did not improve from 0.98832\n",
            "Epoch 701/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0645 - accuracy: 0.9914 - val_loss: 0.2134 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00701: val_accuracy did not improve from 0.98832\n",
            "Epoch 702/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0918 - accuracy: 0.9903 - val_loss: 0.4141 - val_accuracy: 0.9579\n",
            "\n",
            "Epoch 00702: val_accuracy did not improve from 0.98832\n",
            "Epoch 703/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0628 - accuracy: 0.9901 - val_loss: 0.3097 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00703: val_accuracy did not improve from 0.98832\n",
            "Epoch 704/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0773 - accuracy: 0.9882 - val_loss: 0.2116 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00704: val_accuracy did not improve from 0.98832\n",
            "Epoch 705/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0645 - accuracy: 0.9909 - val_loss: 0.2124 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00705: val_accuracy did not improve from 0.98832\n",
            "Epoch 706/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0564 - accuracy: 0.9933 - val_loss: 0.2246 - val_accuracy: 0.9603\n",
            "\n",
            "Epoch 00706: val_accuracy did not improve from 0.98832\n",
            "Epoch 707/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0704 - accuracy: 0.9896 - val_loss: 0.2767 - val_accuracy: 0.9626\n",
            "\n",
            "Epoch 00707: val_accuracy did not improve from 0.98832\n",
            "Epoch 708/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0707 - accuracy: 0.9915 - val_loss: 0.1730 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00708: val_accuracy did not improve from 0.98832\n",
            "Epoch 709/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0748 - accuracy: 0.9920 - val_loss: 0.2292 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00709: val_accuracy did not improve from 0.98832\n",
            "Epoch 710/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1001 - accuracy: 0.9876 - val_loss: 0.3544 - val_accuracy: 0.9509\n",
            "\n",
            "Epoch 00710: val_accuracy did not improve from 0.98832\n",
            "Epoch 711/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0812 - accuracy: 0.9913 - val_loss: 0.1840 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00711: val_accuracy did not improve from 0.98832\n",
            "Epoch 712/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0858 - accuracy: 0.9891 - val_loss: 0.2207 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00712: val_accuracy did not improve from 0.98832\n",
            "Epoch 713/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0480 - accuracy: 0.9962 - val_loss: 0.1820 - val_accuracy: 0.9626\n",
            "\n",
            "Epoch 00713: val_accuracy did not improve from 0.98832\n",
            "Epoch 714/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0679 - accuracy: 0.9926 - val_loss: 0.2287 - val_accuracy: 0.9626\n",
            "\n",
            "Epoch 00714: val_accuracy did not improve from 0.98832\n",
            "Epoch 715/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0589 - accuracy: 0.9938 - val_loss: 0.1857 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00715: val_accuracy did not improve from 0.98832\n",
            "Epoch 716/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0629 - accuracy: 0.9952 - val_loss: 0.2318 - val_accuracy: 0.9626\n",
            "\n",
            "Epoch 00716: val_accuracy did not improve from 0.98832\n",
            "Epoch 717/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0629 - accuracy: 0.9936 - val_loss: 0.2278 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00717: val_accuracy did not improve from 0.98832\n",
            "Epoch 718/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0543 - accuracy: 0.9964 - val_loss: 0.2470 - val_accuracy: 0.9626\n",
            "\n",
            "Epoch 00718: val_accuracy did not improve from 0.98832\n",
            "Epoch 719/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0662 - accuracy: 0.9896 - val_loss: 0.3497 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00719: val_accuracy did not improve from 0.98832\n",
            "Epoch 720/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0588 - accuracy: 0.9969 - val_loss: 0.2688 - val_accuracy: 0.9579\n",
            "\n",
            "Epoch 00720: val_accuracy did not improve from 0.98832\n",
            "Epoch 721/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0656 - accuracy: 0.9883 - val_loss: 0.2352 - val_accuracy: 0.9626\n",
            "\n",
            "Epoch 00721: val_accuracy did not improve from 0.98832\n",
            "Epoch 722/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0397 - accuracy: 0.9952 - val_loss: 0.2762 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00722: val_accuracy did not improve from 0.98832\n",
            "Epoch 723/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0456 - accuracy: 0.9948 - val_loss: 0.1976 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00723: val_accuracy did not improve from 0.98832\n",
            "Epoch 724/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0464 - accuracy: 0.9915 - val_loss: 0.2272 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00724: val_accuracy did not improve from 0.98832\n",
            "Epoch 725/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0688 - accuracy: 0.9873 - val_loss: 0.2687 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00725: val_accuracy did not improve from 0.98832\n",
            "Epoch 726/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1106 - accuracy: 0.9900 - val_loss: 0.4263 - val_accuracy: 0.9579\n",
            "\n",
            "Epoch 00726: val_accuracy did not improve from 0.98832\n",
            "Epoch 727/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1080 - accuracy: 0.9867 - val_loss: 0.2369 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00727: val_accuracy did not improve from 0.98832\n",
            "Epoch 728/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1300 - accuracy: 0.9850 - val_loss: 0.2616 - val_accuracy: 0.9626\n",
            "\n",
            "Epoch 00728: val_accuracy did not improve from 0.98832\n",
            "Epoch 729/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0936 - accuracy: 0.9896 - val_loss: 0.2769 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00729: val_accuracy did not improve from 0.98832\n",
            "Epoch 730/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0918 - accuracy: 0.9937 - val_loss: 0.3216 - val_accuracy: 0.9579\n",
            "\n",
            "Epoch 00730: val_accuracy did not improve from 0.98832\n",
            "Epoch 731/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1102 - accuracy: 0.9885 - val_loss: 0.2958 - val_accuracy: 0.9603\n",
            "\n",
            "Epoch 00731: val_accuracy did not improve from 0.98832\n",
            "Epoch 732/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0881 - accuracy: 0.9890 - val_loss: 0.2874 - val_accuracy: 0.9603\n",
            "\n",
            "Epoch 00732: val_accuracy did not improve from 0.98832\n",
            "Epoch 733/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0922 - accuracy: 0.9866 - val_loss: 0.3877 - val_accuracy: 0.9486\n",
            "\n",
            "Epoch 00733: val_accuracy did not improve from 0.98832\n",
            "Epoch 734/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0911 - accuracy: 0.9907 - val_loss: 0.1977 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00734: val_accuracy did not improve from 0.98832\n",
            "Epoch 735/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0570 - accuracy: 0.9962 - val_loss: 0.2367 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00735: val_accuracy did not improve from 0.98832\n",
            "Epoch 736/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0536 - accuracy: 0.9939 - val_loss: 0.2229 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00736: val_accuracy did not improve from 0.98832\n",
            "Epoch 737/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0938 - accuracy: 0.9857 - val_loss: 0.1514 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00737: val_accuracy did not improve from 0.98832\n",
            "Epoch 738/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0686 - accuracy: 0.9916 - val_loss: 0.2497 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00738: val_accuracy did not improve from 0.98832\n",
            "Epoch 739/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0525 - accuracy: 0.9939 - val_loss: 0.2124 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00739: val_accuracy did not improve from 0.98832\n",
            "Epoch 740/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0631 - accuracy: 0.9916 - val_loss: 0.2300 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00740: val_accuracy did not improve from 0.98832\n",
            "Epoch 741/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0384 - accuracy: 0.9962 - val_loss: 0.2054 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00741: val_accuracy did not improve from 0.98832\n",
            "Epoch 742/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0325 - accuracy: 0.9963 - val_loss: 0.2260 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00742: val_accuracy did not improve from 0.98832\n",
            "Epoch 743/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0516 - accuracy: 0.9936 - val_loss: 0.2031 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00743: val_accuracy did not improve from 0.98832\n",
            "Epoch 744/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0401 - accuracy: 0.9964 - val_loss: 0.2041 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00744: val_accuracy did not improve from 0.98832\n",
            "Epoch 745/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0560 - accuracy: 0.9940 - val_loss: 0.1503 - val_accuracy: 0.9860\n",
            "\n",
            "Epoch 00745: val_accuracy did not improve from 0.98832\n",
            "Epoch 746/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0484 - accuracy: 0.9965 - val_loss: 0.1999 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00746: val_accuracy did not improve from 0.98832\n",
            "Epoch 747/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0434 - accuracy: 0.9944 - val_loss: 0.2154 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00747: val_accuracy did not improve from 0.98832\n",
            "Epoch 748/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0689 - accuracy: 0.9942 - val_loss: 0.2545 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00748: val_accuracy did not improve from 0.98832\n",
            "Epoch 749/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0407 - accuracy: 0.9968 - val_loss: 0.2965 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00749: val_accuracy did not improve from 0.98832\n",
            "Epoch 750/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0844 - accuracy: 0.9891 - val_loss: 0.2046 - val_accuracy: 0.9626\n",
            "\n",
            "Epoch 00750: val_accuracy did not improve from 0.98832\n",
            "Epoch 751/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0706 - accuracy: 0.9931 - val_loss: 0.1982 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00751: val_accuracy did not improve from 0.98832\n",
            "Epoch 752/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0692 - accuracy: 0.9904 - val_loss: 0.3202 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00752: val_accuracy did not improve from 0.98832\n",
            "Epoch 753/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0542 - accuracy: 0.9967 - val_loss: 0.3602 - val_accuracy: 0.9579\n",
            "\n",
            "Epoch 00753: val_accuracy did not improve from 0.98832\n",
            "Epoch 754/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0921 - accuracy: 0.9880 - val_loss: 0.2364 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00754: val_accuracy did not improve from 0.98832\n",
            "Epoch 755/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0530 - accuracy: 0.9896 - val_loss: 0.2295 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00755: val_accuracy did not improve from 0.98832\n",
            "Epoch 756/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0537 - accuracy: 0.9933 - val_loss: 0.3543 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00756: val_accuracy did not improve from 0.98832\n",
            "Epoch 757/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0725 - accuracy: 0.9915 - val_loss: 0.3121 - val_accuracy: 0.9603\n",
            "\n",
            "Epoch 00757: val_accuracy did not improve from 0.98832\n",
            "Epoch 758/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0979 - accuracy: 0.9896 - val_loss: 0.3248 - val_accuracy: 0.9603\n",
            "\n",
            "Epoch 00758: val_accuracy did not improve from 0.98832\n",
            "Epoch 759/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1146 - accuracy: 0.9859 - val_loss: 0.2357 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00759: val_accuracy did not improve from 0.98832\n",
            "Epoch 760/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0701 - accuracy: 0.9936 - val_loss: 0.3485 - val_accuracy: 0.9556\n",
            "\n",
            "Epoch 00760: val_accuracy did not improve from 0.98832\n",
            "Epoch 761/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0610 - accuracy: 0.9968 - val_loss: 0.2135 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00761: val_accuracy did not improve from 0.98832\n",
            "Epoch 762/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0688 - accuracy: 0.9943 - val_loss: 0.1865 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00762: val_accuracy did not improve from 0.98832\n",
            "Epoch 763/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0622 - accuracy: 0.9921 - val_loss: 0.1986 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00763: val_accuracy did not improve from 0.98832\n",
            "Epoch 764/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0679 - accuracy: 0.9929 - val_loss: 0.2226 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00764: val_accuracy did not improve from 0.98832\n",
            "Epoch 765/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0777 - accuracy: 0.9910 - val_loss: 0.2195 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00765: val_accuracy did not improve from 0.98832\n",
            "Epoch 766/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0614 - accuracy: 0.9931 - val_loss: 0.2933 - val_accuracy: 0.9579\n",
            "\n",
            "Epoch 00766: val_accuracy did not improve from 0.98832\n",
            "Epoch 767/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0999 - accuracy: 0.9846 - val_loss: 0.3797 - val_accuracy: 0.9603\n",
            "\n",
            "Epoch 00767: val_accuracy did not improve from 0.98832\n",
            "Epoch 768/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0650 - accuracy: 0.9927 - val_loss: 0.2553 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00768: val_accuracy did not improve from 0.98832\n",
            "Epoch 769/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1061 - accuracy: 0.9888 - val_loss: 0.2068 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00769: val_accuracy did not improve from 0.98832\n",
            "Epoch 770/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0437 - accuracy: 0.9973 - val_loss: 0.1872 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00770: val_accuracy did not improve from 0.98832\n",
            "Epoch 771/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0534 - accuracy: 0.9891 - val_loss: 0.1799 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00771: val_accuracy did not improve from 0.98832\n",
            "Epoch 772/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0723 - accuracy: 0.9918 - val_loss: 0.1927 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00772: val_accuracy did not improve from 0.98832\n",
            "Epoch 773/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0521 - accuracy: 0.9934 - val_loss: 0.2110 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00773: val_accuracy did not improve from 0.98832\n",
            "Epoch 774/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0748 - accuracy: 0.9914 - val_loss: 0.4613 - val_accuracy: 0.9509\n",
            "\n",
            "Epoch 00774: val_accuracy did not improve from 0.98832\n",
            "Epoch 775/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1066 - accuracy: 0.9907 - val_loss: 0.1816 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00775: val_accuracy did not improve from 0.98832\n",
            "Epoch 776/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0737 - accuracy: 0.9892 - val_loss: 0.1422 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00776: val_accuracy did not improve from 0.98832\n",
            "Epoch 777/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0613 - accuracy: 0.9949 - val_loss: 0.1368 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00777: val_accuracy did not improve from 0.98832\n",
            "Epoch 778/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0472 - accuracy: 0.9953 - val_loss: 0.0844 - val_accuracy: 0.9907\n",
            "\n",
            "Epoch 00778: val_accuracy improved from 0.98832 to 0.99065, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 779/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0572 - accuracy: 0.9938 - val_loss: 0.1979 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00779: val_accuracy did not improve from 0.99065\n",
            "Epoch 780/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0817 - accuracy: 0.9903 - val_loss: 0.2839 - val_accuracy: 0.9626\n",
            "\n",
            "Epoch 00780: val_accuracy did not improve from 0.99065\n",
            "Epoch 781/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0660 - accuracy: 0.9937 - val_loss: 0.2217 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00781: val_accuracy did not improve from 0.99065\n",
            "Epoch 782/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0782 - accuracy: 0.9899 - val_loss: 0.2090 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00782: val_accuracy did not improve from 0.99065\n",
            "Epoch 783/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0598 - accuracy: 0.9961 - val_loss: 0.2038 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00783: val_accuracy did not improve from 0.99065\n",
            "Epoch 784/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0455 - accuracy: 0.9969 - val_loss: 0.2131 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00784: val_accuracy did not improve from 0.99065\n",
            "Epoch 785/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0572 - accuracy: 0.9940 - val_loss: 0.2437 - val_accuracy: 0.9579\n",
            "\n",
            "Epoch 00785: val_accuracy did not improve from 0.99065\n",
            "Epoch 786/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0678 - accuracy: 0.9892 - val_loss: 0.1694 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00786: val_accuracy did not improve from 0.99065\n",
            "Epoch 787/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0403 - accuracy: 0.9956 - val_loss: 0.1921 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00787: val_accuracy did not improve from 0.99065\n",
            "Epoch 788/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0596 - accuracy: 0.9956 - val_loss: 0.2724 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00788: val_accuracy did not improve from 0.99065\n",
            "Epoch 789/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0452 - accuracy: 0.9936 - val_loss: 0.2053 - val_accuracy: 0.9626\n",
            "\n",
            "Epoch 00789: val_accuracy did not improve from 0.99065\n",
            "Epoch 790/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0808 - accuracy: 0.9870 - val_loss: 0.3080 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00790: val_accuracy did not improve from 0.99065\n",
            "Epoch 791/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0641 - accuracy: 0.9943 - val_loss: 0.2887 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00791: val_accuracy did not improve from 0.99065\n",
            "Epoch 792/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0915 - accuracy: 0.9873 - val_loss: 0.4573 - val_accuracy: 0.9393\n",
            "\n",
            "Epoch 00792: val_accuracy did not improve from 0.99065\n",
            "Epoch 793/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1227 - accuracy: 0.9780 - val_loss: 0.2106 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00793: val_accuracy did not improve from 0.99065\n",
            "Epoch 794/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0633 - accuracy: 0.9901 - val_loss: 0.1777 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00794: val_accuracy did not improve from 0.99065\n",
            "Epoch 795/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0773 - accuracy: 0.9931 - val_loss: 0.1480 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00795: val_accuracy did not improve from 0.99065\n",
            "Epoch 796/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0572 - accuracy: 0.9933 - val_loss: 0.1120 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00796: val_accuracy did not improve from 0.99065\n",
            "Epoch 797/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0610 - accuracy: 0.9885 - val_loss: 0.1662 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00797: val_accuracy did not improve from 0.99065\n",
            "Epoch 798/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0429 - accuracy: 0.9959 - val_loss: 0.1783 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00798: val_accuracy did not improve from 0.99065\n",
            "Epoch 799/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0472 - accuracy: 0.9960 - val_loss: 0.1519 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00799: val_accuracy did not improve from 0.99065\n",
            "Epoch 800/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0345 - accuracy: 0.9971 - val_loss: 0.1158 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00800: val_accuracy did not improve from 0.99065\n",
            "Epoch 801/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0380 - accuracy: 0.9971 - val_loss: 0.2258 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00801: val_accuracy did not improve from 0.99065\n",
            "Epoch 802/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0522 - accuracy: 0.9929 - val_loss: 0.2736 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00802: val_accuracy did not improve from 0.99065\n",
            "Epoch 803/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0631 - accuracy: 0.9910 - val_loss: 0.2048 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00803: val_accuracy did not improve from 0.99065\n",
            "Epoch 804/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0474 - accuracy: 0.9947 - val_loss: 0.1896 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00804: val_accuracy did not improve from 0.99065\n",
            "Epoch 805/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0572 - accuracy: 0.9904 - val_loss: 0.1517 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00805: val_accuracy did not improve from 0.99065\n",
            "Epoch 806/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0454 - accuracy: 0.9945 - val_loss: 0.1582 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00806: val_accuracy did not improve from 0.99065\n",
            "Epoch 807/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0495 - accuracy: 0.9946 - val_loss: 0.3207 - val_accuracy: 0.9626\n",
            "\n",
            "Epoch 00807: val_accuracy did not improve from 0.99065\n",
            "Epoch 808/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0369 - accuracy: 0.9966 - val_loss: 0.2598 - val_accuracy: 0.9603\n",
            "\n",
            "Epoch 00808: val_accuracy did not improve from 0.99065\n",
            "Epoch 809/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0683 - accuracy: 0.9893 - val_loss: 0.3049 - val_accuracy: 0.9626\n",
            "\n",
            "Epoch 00809: val_accuracy did not improve from 0.99065\n",
            "Epoch 810/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0557 - accuracy: 0.9907 - val_loss: 0.3017 - val_accuracy: 0.9603\n",
            "\n",
            "Epoch 00810: val_accuracy did not improve from 0.99065\n",
            "Epoch 811/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0656 - accuracy: 0.9910 - val_loss: 0.2176 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00811: val_accuracy did not improve from 0.99065\n",
            "Epoch 812/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0936 - accuracy: 0.9925 - val_loss: 0.2900 - val_accuracy: 0.9556\n",
            "\n",
            "Epoch 00812: val_accuracy did not improve from 0.99065\n",
            "Epoch 813/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0794 - accuracy: 0.9926 - val_loss: 0.2365 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00813: val_accuracy did not improve from 0.99065\n",
            "Epoch 814/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0716 - accuracy: 0.9885 - val_loss: 0.2512 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00814: val_accuracy did not improve from 0.99065\n",
            "Epoch 815/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0533 - accuracy: 0.9932 - val_loss: 0.2402 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00815: val_accuracy did not improve from 0.99065\n",
            "Epoch 816/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0571 - accuracy: 0.9931 - val_loss: 0.2088 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00816: val_accuracy did not improve from 0.99065\n",
            "Epoch 817/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0698 - accuracy: 0.9944 - val_loss: 0.4499 - val_accuracy: 0.9626\n",
            "\n",
            "Epoch 00817: val_accuracy did not improve from 0.99065\n",
            "Epoch 818/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0745 - accuracy: 0.9898 - val_loss: 0.4013 - val_accuracy: 0.9556\n",
            "\n",
            "Epoch 00818: val_accuracy did not improve from 0.99065\n",
            "Epoch 819/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0467 - accuracy: 0.9953 - val_loss: 0.3616 - val_accuracy: 0.9626\n",
            "\n",
            "Epoch 00819: val_accuracy did not improve from 0.99065\n",
            "Epoch 820/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0564 - accuracy: 0.9935 - val_loss: 0.3665 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00820: val_accuracy did not improve from 0.99065\n",
            "Epoch 821/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0946 - accuracy: 0.9862 - val_loss: 0.4586 - val_accuracy: 0.9533\n",
            "\n",
            "Epoch 00821: val_accuracy did not improve from 0.99065\n",
            "Epoch 822/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0638 - accuracy: 0.9936 - val_loss: 0.2840 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00822: val_accuracy did not improve from 0.99065\n",
            "Epoch 823/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0847 - accuracy: 0.9892 - val_loss: 0.3206 - val_accuracy: 0.9626\n",
            "\n",
            "Epoch 00823: val_accuracy did not improve from 0.99065\n",
            "Epoch 824/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0661 - accuracy: 0.9923 - val_loss: 0.2376 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00824: val_accuracy did not improve from 0.99065\n",
            "Epoch 825/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0579 - accuracy: 0.9952 - val_loss: 0.1921 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00825: val_accuracy did not improve from 0.99065\n",
            "Epoch 826/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0571 - accuracy: 0.9900 - val_loss: 0.2740 - val_accuracy: 0.9603\n",
            "\n",
            "Epoch 00826: val_accuracy did not improve from 0.99065\n",
            "Epoch 827/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0548 - accuracy: 0.9937 - val_loss: 0.2228 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00827: val_accuracy did not improve from 0.99065\n",
            "Epoch 828/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0906 - accuracy: 0.9909 - val_loss: 0.2120 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00828: val_accuracy did not improve from 0.99065\n",
            "Epoch 829/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1114 - accuracy: 0.9869 - val_loss: 0.2185 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00829: val_accuracy did not improve from 0.99065\n",
            "Epoch 830/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0590 - accuracy: 0.9946 - val_loss: 0.2430 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00830: val_accuracy did not improve from 0.99065\n",
            "Epoch 831/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0481 - accuracy: 0.9980 - val_loss: 0.3123 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00831: val_accuracy did not improve from 0.99065\n",
            "Epoch 832/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0602 - accuracy: 0.9918 - val_loss: 0.2925 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00832: val_accuracy did not improve from 0.99065\n",
            "Epoch 833/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0680 - accuracy: 0.9902 - val_loss: 0.2681 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00833: val_accuracy did not improve from 0.99065\n",
            "Epoch 834/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0696 - accuracy: 0.9845 - val_loss: 0.2392 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00834: val_accuracy did not improve from 0.99065\n",
            "Epoch 835/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0575 - accuracy: 0.9937 - val_loss: 0.2215 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00835: val_accuracy did not improve from 0.99065\n",
            "Epoch 836/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0427 - accuracy: 0.9931 - val_loss: 0.2833 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00836: val_accuracy did not improve from 0.99065\n",
            "Epoch 837/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0759 - accuracy: 0.9874 - val_loss: 0.3669 - val_accuracy: 0.9626\n",
            "\n",
            "Epoch 00837: val_accuracy did not improve from 0.99065\n",
            "Epoch 838/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0737 - accuracy: 0.9868 - val_loss: 0.2738 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00838: val_accuracy did not improve from 0.99065\n",
            "Epoch 839/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0778 - accuracy: 0.9829 - val_loss: 0.3365 - val_accuracy: 0.9626\n",
            "\n",
            "Epoch 00839: val_accuracy did not improve from 0.99065\n",
            "Epoch 840/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0545 - accuracy: 0.9963 - val_loss: 0.2231 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00840: val_accuracy did not improve from 0.99065\n",
            "Epoch 841/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0620 - accuracy: 0.9957 - val_loss: 0.1592 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00841: val_accuracy did not improve from 0.99065\n",
            "Epoch 842/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0584 - accuracy: 0.9912 - val_loss: 0.1620 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00842: val_accuracy did not improve from 0.99065\n",
            "Epoch 843/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0682 - accuracy: 0.9914 - val_loss: 0.3424 - val_accuracy: 0.9579\n",
            "\n",
            "Epoch 00843: val_accuracy did not improve from 0.99065\n",
            "Epoch 844/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0633 - accuracy: 0.9942 - val_loss: 0.2282 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00844: val_accuracy did not improve from 0.99065\n",
            "Epoch 845/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0564 - accuracy: 0.9926 - val_loss: 0.1553 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00845: val_accuracy did not improve from 0.99065\n",
            "Epoch 846/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0458 - accuracy: 0.9957 - val_loss: 0.1649 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00846: val_accuracy did not improve from 0.99065\n",
            "Epoch 847/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0925 - accuracy: 0.9900 - val_loss: 0.1958 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00847: val_accuracy did not improve from 0.99065\n",
            "Epoch 848/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0560 - accuracy: 0.9938 - val_loss: 0.1823 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00848: val_accuracy did not improve from 0.99065\n",
            "Epoch 849/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0472 - accuracy: 0.9926 - val_loss: 0.2311 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00849: val_accuracy did not improve from 0.99065\n",
            "Epoch 850/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0423 - accuracy: 0.9954 - val_loss: 0.1933 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00850: val_accuracy did not improve from 0.99065\n",
            "Epoch 851/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0414 - accuracy: 0.9968 - val_loss: 0.2237 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00851: val_accuracy did not improve from 0.99065\n",
            "Epoch 852/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0612 - accuracy: 0.9892 - val_loss: 0.2569 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00852: val_accuracy did not improve from 0.99065\n",
            "Epoch 853/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0454 - accuracy: 0.9964 - val_loss: 0.2818 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00853: val_accuracy did not improve from 0.99065\n",
            "Epoch 854/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0480 - accuracy: 0.9933 - val_loss: 0.3432 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00854: val_accuracy did not improve from 0.99065\n",
            "Epoch 855/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0482 - accuracy: 0.9952 - val_loss: 0.3590 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00855: val_accuracy did not improve from 0.99065\n",
            "Epoch 856/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0367 - accuracy: 0.9977 - val_loss: 0.3275 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00856: val_accuracy did not improve from 0.99065\n",
            "Epoch 857/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0508 - accuracy: 0.9919 - val_loss: 0.3426 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00857: val_accuracy did not improve from 0.99065\n",
            "Epoch 858/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0552 - accuracy: 0.9919 - val_loss: 0.2712 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00858: val_accuracy did not improve from 0.99065\n",
            "Epoch 859/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0634 - accuracy: 0.9948 - val_loss: 0.2927 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00859: val_accuracy did not improve from 0.99065\n",
            "Epoch 860/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0613 - accuracy: 0.9920 - val_loss: 0.2101 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00860: val_accuracy did not improve from 0.99065\n",
            "Epoch 861/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0990 - accuracy: 0.9853 - val_loss: 0.4281 - val_accuracy: 0.9626\n",
            "\n",
            "Epoch 00861: val_accuracy did not improve from 0.99065\n",
            "Epoch 862/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0599 - accuracy: 0.9932 - val_loss: 0.3200 - val_accuracy: 0.9626\n",
            "\n",
            "Epoch 00862: val_accuracy did not improve from 0.99065\n",
            "Epoch 863/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1065 - accuracy: 0.9837 - val_loss: 0.3263 - val_accuracy: 0.9556\n",
            "\n",
            "Epoch 00863: val_accuracy did not improve from 0.99065\n",
            "Epoch 864/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0860 - accuracy: 0.9891 - val_loss: 0.2625 - val_accuracy: 0.9603\n",
            "\n",
            "Epoch 00864: val_accuracy did not improve from 0.99065\n",
            "Epoch 865/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.1200 - accuracy: 0.9840 - val_loss: 0.3858 - val_accuracy: 0.9626\n",
            "\n",
            "Epoch 00865: val_accuracy did not improve from 0.99065\n",
            "Epoch 866/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0664 - accuracy: 0.9948 - val_loss: 0.2588 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00866: val_accuracy did not improve from 0.99065\n",
            "Epoch 867/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0550 - accuracy: 0.9971 - val_loss: 0.1740 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00867: val_accuracy did not improve from 0.99065\n",
            "Epoch 868/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0524 - accuracy: 0.9946 - val_loss: 0.1769 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00868: val_accuracy did not improve from 0.99065\n",
            "Epoch 869/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0633 - accuracy: 0.9953 - val_loss: 0.2297 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00869: val_accuracy did not improve from 0.99065\n",
            "Epoch 870/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0530 - accuracy: 0.9924 - val_loss: 0.2108 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00870: val_accuracy did not improve from 0.99065\n",
            "Epoch 871/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0386 - accuracy: 0.9953 - val_loss: 0.2529 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00871: val_accuracy did not improve from 0.99065\n",
            "Epoch 872/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0499 - accuracy: 0.9935 - val_loss: 0.2650 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00872: val_accuracy did not improve from 0.99065\n",
            "Epoch 873/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0579 - accuracy: 0.9936 - val_loss: 0.1584 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00873: val_accuracy did not improve from 0.99065\n",
            "Epoch 874/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0850 - accuracy: 0.9861 - val_loss: 0.1667 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00874: val_accuracy did not improve from 0.99065\n",
            "Epoch 875/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0876 - accuracy: 0.9874 - val_loss: 0.1384 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00875: val_accuracy did not improve from 0.99065\n",
            "Epoch 876/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1160 - accuracy: 0.9928 - val_loss: 0.1190 - val_accuracy: 0.9860\n",
            "\n",
            "Epoch 00876: val_accuracy did not improve from 0.99065\n",
            "Epoch 877/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0607 - accuracy: 0.9942 - val_loss: 0.1661 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00877: val_accuracy did not improve from 0.99065\n",
            "Epoch 878/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0458 - accuracy: 0.9960 - val_loss: 0.1668 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00878: val_accuracy did not improve from 0.99065\n",
            "Epoch 879/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0752 - accuracy: 0.9866 - val_loss: 0.1356 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00879: val_accuracy did not improve from 0.99065\n",
            "Epoch 880/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0481 - accuracy: 0.9942 - val_loss: 0.1841 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00880: val_accuracy did not improve from 0.99065\n",
            "Epoch 881/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0530 - accuracy: 0.9944 - val_loss: 0.1677 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00881: val_accuracy did not improve from 0.99065\n",
            "Epoch 882/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0483 - accuracy: 0.9943 - val_loss: 0.1346 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00882: val_accuracy did not improve from 0.99065\n",
            "Epoch 883/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0441 - accuracy: 0.9931 - val_loss: 0.1306 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00883: val_accuracy did not improve from 0.99065\n",
            "Epoch 884/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0459 - accuracy: 0.9944 - val_loss: 0.1555 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00884: val_accuracy did not improve from 0.99065\n",
            "Epoch 885/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0523 - accuracy: 0.9879 - val_loss: 0.1665 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00885: val_accuracy did not improve from 0.99065\n",
            "Epoch 886/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0529 - accuracy: 0.9942 - val_loss: 0.2592 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00886: val_accuracy did not improve from 0.99065\n",
            "Epoch 887/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0666 - accuracy: 0.9895 - val_loss: 0.4354 - val_accuracy: 0.9579\n",
            "\n",
            "Epoch 00887: val_accuracy did not improve from 0.99065\n",
            "Epoch 888/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0734 - accuracy: 0.9888 - val_loss: 0.3387 - val_accuracy: 0.9626\n",
            "\n",
            "Epoch 00888: val_accuracy did not improve from 0.99065\n",
            "Epoch 889/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0662 - accuracy: 0.9939 - val_loss: 0.2846 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00889: val_accuracy did not improve from 0.99065\n",
            "Epoch 890/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.1017 - accuracy: 0.9832 - val_loss: 0.2461 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00890: val_accuracy did not improve from 0.99065\n",
            "Epoch 891/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0522 - accuracy: 0.9942 - val_loss: 0.2498 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00891: val_accuracy did not improve from 0.99065\n",
            "Epoch 892/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0499 - accuracy: 0.9964 - val_loss: 0.1881 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00892: val_accuracy did not improve from 0.99065\n",
            "Epoch 893/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0535 - accuracy: 0.9919 - val_loss: 0.4194 - val_accuracy: 0.9556\n",
            "\n",
            "Epoch 00893: val_accuracy did not improve from 0.99065\n",
            "Epoch 894/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.1113 - accuracy: 0.9853 - val_loss: 0.2385 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00894: val_accuracy did not improve from 0.99065\n",
            "Epoch 895/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0777 - accuracy: 0.9911 - val_loss: 0.2309 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00895: val_accuracy did not improve from 0.99065\n",
            "Epoch 896/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0638 - accuracy: 0.9949 - val_loss: 0.2874 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00896: val_accuracy did not improve from 0.99065\n",
            "Epoch 897/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0877 - accuracy: 0.9904 - val_loss: 0.2293 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00897: val_accuracy did not improve from 0.99065\n",
            "Epoch 898/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0696 - accuracy: 0.9930 - val_loss: 0.2555 - val_accuracy: 0.9626\n",
            "\n",
            "Epoch 00898: val_accuracy did not improve from 0.99065\n",
            "Epoch 899/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0682 - accuracy: 0.9938 - val_loss: 0.2022 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00899: val_accuracy did not improve from 0.99065\n",
            "Epoch 900/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0523 - accuracy: 0.9987 - val_loss: 0.1831 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00900: val_accuracy did not improve from 0.99065\n",
            "Epoch 901/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0528 - accuracy: 0.9955 - val_loss: 0.2004 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00901: val_accuracy did not improve from 0.99065\n",
            "Epoch 902/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0588 - accuracy: 0.9932 - val_loss: 0.1710 - val_accuracy: 0.9860\n",
            "\n",
            "Epoch 00902: val_accuracy did not improve from 0.99065\n",
            "Epoch 903/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0719 - accuracy: 0.9940 - val_loss: 0.1457 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00903: val_accuracy did not improve from 0.99065\n",
            "Epoch 904/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0638 - accuracy: 0.9950 - val_loss: 0.1899 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00904: val_accuracy did not improve from 0.99065\n",
            "Epoch 905/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0437 - accuracy: 0.9956 - val_loss: 0.2537 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00905: val_accuracy did not improve from 0.99065\n",
            "Epoch 906/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0615 - accuracy: 0.9912 - val_loss: 0.2325 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00906: val_accuracy did not improve from 0.99065\n",
            "Epoch 907/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0452 - accuracy: 0.9935 - val_loss: 0.2604 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00907: val_accuracy did not improve from 0.99065\n",
            "Epoch 908/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0469 - accuracy: 0.9940 - val_loss: 0.2460 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00908: val_accuracy did not improve from 0.99065\n",
            "Epoch 909/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0798 - accuracy: 0.9898 - val_loss: 0.1640 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00909: val_accuracy did not improve from 0.99065\n",
            "Epoch 910/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0504 - accuracy: 0.9950 - val_loss: 0.1584 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00910: val_accuracy did not improve from 0.99065\n",
            "Epoch 911/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0455 - accuracy: 0.9956 - val_loss: 0.1587 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00911: val_accuracy did not improve from 0.99065\n",
            "Epoch 912/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0587 - accuracy: 0.9947 - val_loss: 0.2107 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00912: val_accuracy did not improve from 0.99065\n",
            "Epoch 913/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0713 - accuracy: 0.9914 - val_loss: 0.1922 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00913: val_accuracy did not improve from 0.99065\n",
            "Epoch 914/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0424 - accuracy: 0.9985 - val_loss: 0.2470 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00914: val_accuracy did not improve from 0.99065\n",
            "Epoch 915/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0707 - accuracy: 0.9910 - val_loss: 0.3155 - val_accuracy: 0.9603\n",
            "\n",
            "Epoch 00915: val_accuracy did not improve from 0.99065\n",
            "Epoch 916/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0790 - accuracy: 0.9877 - val_loss: 0.1603 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00916: val_accuracy did not improve from 0.99065\n",
            "Epoch 917/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0483 - accuracy: 0.9936 - val_loss: 0.1274 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00917: val_accuracy did not improve from 0.99065\n",
            "Epoch 918/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0538 - accuracy: 0.9935 - val_loss: 0.0865 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00918: val_accuracy did not improve from 0.99065\n",
            "Epoch 919/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0575 - accuracy: 0.9922 - val_loss: 0.1566 - val_accuracy: 0.9860\n",
            "\n",
            "Epoch 00919: val_accuracy did not improve from 0.99065\n",
            "Epoch 920/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0493 - accuracy: 0.9966 - val_loss: 0.1722 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00920: val_accuracy did not improve from 0.99065\n",
            "Epoch 921/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0569 - accuracy: 0.9902 - val_loss: 0.2137 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00921: val_accuracy did not improve from 0.99065\n",
            "Epoch 922/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0697 - accuracy: 0.9896 - val_loss: 0.1733 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00922: val_accuracy did not improve from 0.99065\n",
            "Epoch 923/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0446 - accuracy: 0.9965 - val_loss: 0.1988 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00923: val_accuracy did not improve from 0.99065\n",
            "Epoch 924/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0843 - accuracy: 0.9910 - val_loss: 0.2874 - val_accuracy: 0.9603\n",
            "\n",
            "Epoch 00924: val_accuracy did not improve from 0.99065\n",
            "Epoch 925/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0542 - accuracy: 0.9952 - val_loss: 0.2170 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00925: val_accuracy did not improve from 0.99065\n",
            "Epoch 926/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0605 - accuracy: 0.9943 - val_loss: 0.1415 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00926: val_accuracy did not improve from 0.99065\n",
            "Epoch 927/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0564 - accuracy: 0.9931 - val_loss: 0.1254 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00927: val_accuracy did not improve from 0.99065\n",
            "Epoch 928/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0529 - accuracy: 0.9970 - val_loss: 0.2298 - val_accuracy: 0.9626\n",
            "\n",
            "Epoch 00928: val_accuracy did not improve from 0.99065\n",
            "Epoch 929/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0571 - accuracy: 0.9949 - val_loss: 0.1523 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00929: val_accuracy did not improve from 0.99065\n",
            "Epoch 930/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0719 - accuracy: 0.9926 - val_loss: 0.2751 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00930: val_accuracy did not improve from 0.99065\n",
            "Epoch 931/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0696 - accuracy: 0.9946 - val_loss: 0.1870 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00931: val_accuracy did not improve from 0.99065\n",
            "Epoch 932/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0746 - accuracy: 0.9934 - val_loss: 0.1203 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00932: val_accuracy did not improve from 0.99065\n",
            "Epoch 933/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0570 - accuracy: 0.9937 - val_loss: 0.1313 - val_accuracy: 0.9883\n",
            "\n",
            "Epoch 00933: val_accuracy did not improve from 0.99065\n",
            "Epoch 934/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.1046 - accuracy: 0.9867 - val_loss: 0.2565 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00934: val_accuracy did not improve from 0.99065\n",
            "Epoch 935/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0465 - accuracy: 0.9984 - val_loss: 0.1535 - val_accuracy: 0.9883\n",
            "\n",
            "Epoch 00935: val_accuracy did not improve from 0.99065\n",
            "Epoch 936/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0461 - accuracy: 0.9961 - val_loss: 0.1701 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00936: val_accuracy did not improve from 0.99065\n",
            "Epoch 937/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0358 - accuracy: 0.9982 - val_loss: 0.1303 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00937: val_accuracy did not improve from 0.99065\n",
            "Epoch 938/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0432 - accuracy: 0.9946 - val_loss: 0.1175 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00938: val_accuracy did not improve from 0.99065\n",
            "Epoch 939/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0476 - accuracy: 0.9937 - val_loss: 0.1589 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00939: val_accuracy did not improve from 0.99065\n",
            "Epoch 940/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0477 - accuracy: 0.9957 - val_loss: 0.1979 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00940: val_accuracy did not improve from 0.99065\n",
            "Epoch 941/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0783 - accuracy: 0.9925 - val_loss: 0.2088 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00941: val_accuracy did not improve from 0.99065\n",
            "Epoch 942/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0592 - accuracy: 0.9948 - val_loss: 0.2397 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00942: val_accuracy did not improve from 0.99065\n",
            "Epoch 943/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0740 - accuracy: 0.9911 - val_loss: 0.2284 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00943: val_accuracy did not improve from 0.99065\n",
            "Epoch 944/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0460 - accuracy: 0.9966 - val_loss: 0.1850 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00944: val_accuracy did not improve from 0.99065\n",
            "Epoch 945/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0522 - accuracy: 0.9966 - val_loss: 0.1919 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00945: val_accuracy did not improve from 0.99065\n",
            "Epoch 946/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0543 - accuracy: 0.9942 - val_loss: 0.2135 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00946: val_accuracy did not improve from 0.99065\n",
            "Epoch 947/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.1296 - accuracy: 0.9929 - val_loss: 0.1779 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00947: val_accuracy did not improve from 0.99065\n",
            "Epoch 948/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0697 - accuracy: 0.9941 - val_loss: 0.1310 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00948: val_accuracy did not improve from 0.99065\n",
            "Epoch 949/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0662 - accuracy: 0.9934 - val_loss: 0.1522 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00949: val_accuracy did not improve from 0.99065\n",
            "Epoch 950/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0472 - accuracy: 0.9957 - val_loss: 0.1397 - val_accuracy: 0.9907\n",
            "\n",
            "Epoch 00950: val_accuracy did not improve from 0.99065\n",
            "Epoch 951/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.1064 - accuracy: 0.9900 - val_loss: 0.2043 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00951: val_accuracy did not improve from 0.99065\n",
            "Epoch 952/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0615 - accuracy: 0.9914 - val_loss: 0.1562 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00952: val_accuracy did not improve from 0.99065\n",
            "Epoch 953/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0420 - accuracy: 0.9946 - val_loss: 0.1649 - val_accuracy: 0.9907\n",
            "\n",
            "Epoch 00953: val_accuracy did not improve from 0.99065\n",
            "Epoch 954/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0441 - accuracy: 0.9942 - val_loss: 0.1422 - val_accuracy: 0.9883\n",
            "\n",
            "Epoch 00954: val_accuracy did not improve from 0.99065\n",
            "Epoch 955/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0385 - accuracy: 0.9966 - val_loss: 0.1433 - val_accuracy: 0.9860\n",
            "\n",
            "Epoch 00955: val_accuracy did not improve from 0.99065\n",
            "Epoch 956/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0511 - accuracy: 0.9922 - val_loss: 0.1759 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00956: val_accuracy did not improve from 0.99065\n",
            "Epoch 957/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0411 - accuracy: 0.9941 - val_loss: 0.1813 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00957: val_accuracy did not improve from 0.99065\n",
            "Epoch 958/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0710 - accuracy: 0.9871 - val_loss: 0.1411 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00958: val_accuracy did not improve from 0.99065\n",
            "Epoch 959/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0457 - accuracy: 0.9981 - val_loss: 0.1599 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00959: val_accuracy did not improve from 0.99065\n",
            "Epoch 960/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0568 - accuracy: 0.9899 - val_loss: 0.2033 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00960: val_accuracy did not improve from 0.99065\n",
            "Epoch 961/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0455 - accuracy: 0.9951 - val_loss: 0.2051 - val_accuracy: 0.9626\n",
            "\n",
            "Epoch 00961: val_accuracy did not improve from 0.99065\n",
            "Epoch 962/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0410 - accuracy: 0.9959 - val_loss: 0.2206 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00962: val_accuracy did not improve from 0.99065\n",
            "Epoch 963/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0595 - accuracy: 0.9936 - val_loss: 0.2127 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00963: val_accuracy did not improve from 0.99065\n",
            "Epoch 964/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0407 - accuracy: 0.9960 - val_loss: 0.1982 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00964: val_accuracy did not improve from 0.99065\n",
            "Epoch 965/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0588 - accuracy: 0.9894 - val_loss: 0.1647 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00965: val_accuracy did not improve from 0.99065\n",
            "Epoch 966/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0739 - accuracy: 0.9932 - val_loss: 0.1793 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00966: val_accuracy did not improve from 0.99065\n",
            "Epoch 967/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0359 - accuracy: 0.9990 - val_loss: 0.1332 - val_accuracy: 0.9883\n",
            "\n",
            "Epoch 00967: val_accuracy did not improve from 0.99065\n",
            "Epoch 968/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0463 - accuracy: 0.9938 - val_loss: 0.1569 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00968: val_accuracy did not improve from 0.99065\n",
            "Epoch 969/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0417 - accuracy: 0.9929 - val_loss: 0.1578 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00969: val_accuracy did not improve from 0.99065\n",
            "Epoch 970/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0590 - accuracy: 0.9950 - val_loss: 0.1338 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00970: val_accuracy did not improve from 0.99065\n",
            "Epoch 971/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0289 - accuracy: 0.9969 - val_loss: 0.1871 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00971: val_accuracy did not improve from 0.99065\n",
            "Epoch 972/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0235 - accuracy: 0.9958 - val_loss: 0.1517 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00972: val_accuracy did not improve from 0.99065\n",
            "Epoch 973/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0276 - accuracy: 0.9977 - val_loss: 0.2010 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00973: val_accuracy did not improve from 0.99065\n",
            "Epoch 974/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0471 - accuracy: 0.9893 - val_loss: 0.4047 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00974: val_accuracy did not improve from 0.99065\n",
            "Epoch 975/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0769 - accuracy: 0.9923 - val_loss: 0.4402 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00975: val_accuracy did not improve from 0.99065\n",
            "Epoch 976/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0683 - accuracy: 0.9945 - val_loss: 0.3155 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00976: val_accuracy did not improve from 0.99065\n",
            "Epoch 977/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.1161 - accuracy: 0.9888 - val_loss: 0.2134 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00977: val_accuracy did not improve from 0.99065\n",
            "Epoch 978/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0885 - accuracy: 0.9929 - val_loss: 0.2176 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00978: val_accuracy did not improve from 0.99065\n",
            "Epoch 979/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0677 - accuracy: 0.9925 - val_loss: 0.1042 - val_accuracy: 0.9883\n",
            "\n",
            "Epoch 00979: val_accuracy did not improve from 0.99065\n",
            "Epoch 980/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0523 - accuracy: 0.9940 - val_loss: 0.1112 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00980: val_accuracy did not improve from 0.99065\n",
            "Epoch 981/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0578 - accuracy: 0.9918 - val_loss: 0.1598 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00981: val_accuracy did not improve from 0.99065\n",
            "Epoch 982/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0554 - accuracy: 0.9940 - val_loss: 0.1763 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00982: val_accuracy did not improve from 0.99065\n",
            "Epoch 983/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0402 - accuracy: 0.9981 - val_loss: 0.1250 - val_accuracy: 0.9860\n",
            "\n",
            "Epoch 00983: val_accuracy did not improve from 0.99065\n",
            "Epoch 984/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0414 - accuracy: 0.9970 - val_loss: 0.1208 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00984: val_accuracy did not improve from 0.99065\n",
            "Epoch 985/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0551 - accuracy: 0.9925 - val_loss: 0.1277 - val_accuracy: 0.9883\n",
            "\n",
            "Epoch 00985: val_accuracy did not improve from 0.99065\n",
            "Epoch 986/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0426 - accuracy: 0.9984 - val_loss: 0.1072 - val_accuracy: 0.9907\n",
            "\n",
            "Epoch 00986: val_accuracy did not improve from 0.99065\n",
            "Epoch 987/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0370 - accuracy: 0.9955 - val_loss: 0.2464 - val_accuracy: 0.9603\n",
            "\n",
            "Epoch 00987: val_accuracy did not improve from 0.99065\n",
            "Epoch 988/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0623 - accuracy: 0.9901 - val_loss: 0.3009 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00988: val_accuracy did not improve from 0.99065\n",
            "Epoch 989/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.1130 - accuracy: 0.9886 - val_loss: 0.3334 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00989: val_accuracy did not improve from 0.99065\n",
            "Epoch 990/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0828 - accuracy: 0.9920 - val_loss: 0.2952 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00990: val_accuracy did not improve from 0.99065\n",
            "Epoch 991/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0497 - accuracy: 0.9938 - val_loss: 0.2704 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00991: val_accuracy did not improve from 0.99065\n",
            "Epoch 992/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0464 - accuracy: 0.9966 - val_loss: 0.2273 - val_accuracy: 0.9556\n",
            "\n",
            "Epoch 00992: val_accuracy did not improve from 0.99065\n",
            "Epoch 993/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0768 - accuracy: 0.9930 - val_loss: 0.3268 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00993: val_accuracy did not improve from 0.99065\n",
            "Epoch 994/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0714 - accuracy: 0.9949 - val_loss: 0.2818 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00994: val_accuracy did not improve from 0.99065\n",
            "Epoch 995/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0768 - accuracy: 0.9925 - val_loss: 0.2420 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00995: val_accuracy did not improve from 0.99065\n",
            "Epoch 996/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0641 - accuracy: 0.9894 - val_loss: 0.2581 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00996: val_accuracy did not improve from 0.99065\n",
            "Epoch 997/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0712 - accuracy: 0.9944 - val_loss: 0.1878 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00997: val_accuracy did not improve from 0.99065\n",
            "Epoch 998/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.1356 - accuracy: 0.9890 - val_loss: 0.1198 - val_accuracy: 0.9883\n",
            "\n",
            "Epoch 00998: val_accuracy did not improve from 0.99065\n",
            "Epoch 999/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0589 - accuracy: 0.9937 - val_loss: 0.2380 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00999: val_accuracy did not improve from 0.99065\n",
            "Epoch 1000/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0827 - accuracy: 0.9936 - val_loss: 0.1976 - val_accuracy: 0.9860\n",
            "\n",
            "Epoch 01000: val_accuracy did not improve from 0.99065\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JEoi1Ld3JLjc",
        "outputId": "2710b171-1051-43d4-c677-8b4ac7d5b339"
      },
      "source": [
        "# PLOT MODEL HISTORY OF ACCURACY AND LOSS OVER EPOCHS\n",
        "# Plot the results\n",
        "train_loss=model_history.history['loss']\n",
        "val_loss=model_history.history['val_loss']\n",
        "train_acc=model_history.history['accuracy']\n",
        "val_acc=model_history.history['val_accuracy']\n",
        "plt.rcParams['figure.dpi'] = 150 \n",
        "plt.figure(1,figsize=(7,5))\n",
        "plt.plot(train_loss)\n",
        "plt.plot(val_loss)\n",
        "plt.xlabel('Number of epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training loss vs Validation loss')\n",
        "plt.grid(True)\n",
        "plt.legend(['Training','Validation'], loc=1)\n",
        "plt.style.use(['seaborn-darkgrid'])\n",
        "\n",
        "plt.rcParams['figure.dpi'] = 150 \n",
        "plt.figure(2,figsize=(7,5))\n",
        "plt.plot(train_acc)\n",
        "plt.plot(val_acc)\n",
        "plt.xlabel('Number of epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training accuracy vs Validation accuracy')\n",
        "plt.grid(True)\n",
        "plt.legend(['Training','Validation'],loc=4)\n",
        "plt.style.use(['seaborn-darkgrid'])      \n",
        "\n",
        "# PRINT LOSS AND ACCURACY PERCENTAGE ON TEST SET\n",
        "print(\"Loss of the model is - \" , model.evaluate(x_test,y_test)[0])\n",
        "print(\"Accuracy of the model is - \" , model.evaluate(x_test,y_test)[1]*100 , \"%\") \n",
        "\n",
        "# PREDICTION LABELS\n",
        "predictions = model.predict(x_test, batch_size=32)\n",
        "predictions=predictions.argmax(axis=1)\n",
        "predictions\n",
        "predictions = predictions.astype(int).flatten()\n",
        "predictions = (lb.inverse_transform((predictions)))\n",
        "predictions = pd.DataFrame({'Predicted Values': predictions}) \n",
        "\n",
        "# ACTUAL LABELS\n",
        "TRUE = y_test.argmax(axis=1)\n",
        "TRUE = TRUE.astype(int).flatten()\n",
        "TRUE = (lb.inverse_transform((TRUE)))\n",
        "TRUE = pd.DataFrame({'TRUE Values': TRUE})\n",
        "\n",
        "# COMBINE PREDICTION AND ACTUAL LABELS\n",
        "finaldf = TRUE.join(predictions)\n",
        "finaldf[10:25] \n",
        "# CREATE CONFUSION MATRIX OF ACTUAL VS. PREDICTION -SGD-MFCC\n",
        "cm = confusion_matrix(TRUE, predictions)\n",
        "plt.figure(figsize = (9,7))\n",
        "plt.rcParams['figure.dpi'] = 125 \n",
        "cm = pd.DataFrame(cm , index = [i for i in lb.classes_] , columns = [i for i in lb.classes_])\n",
        "ax = sns.heatmap(cm, linecolor='white', cmap='Accent', linewidth=1, annot=True, fmt='')\n",
        "bottom, top = ax.get_ylim()\n",
        "ax.set_ylim(bottom + 0.6, top - 0.6)\n",
        "plt.title('Confusion Matrix', size=20)\n",
        "plt.xlabel('Predicted Classes', size=15)\n",
        "plt.ylabel('True Classes', size=15)\n",
        "plt.savefig('emo-db.png')\n",
        "plt.show() \n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(TRUE, predictions, target_names = ['Angry', 'Boredom', 'Disgust', 'Fear', 'Happy', 'Neutral','Sadness']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1976 - accuracy: 0.9860\n",
            "Loss of the model is -  0.1976107954978943\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1976 - accuracy: 0.9860\n",
            "Accuracy of the model is -  98.5981285572052 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1050x750 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1050x750 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1350x1050 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Angry       1.00      1.00      1.00       104\n",
            "     Boredom       0.96      0.97      0.96        69\n",
            "     Disgust       0.96      1.00      0.98        26\n",
            "        Fear       0.98      1.00      0.99        63\n",
            "       Happy       1.00      0.98      0.99        55\n",
            "     Neutral       0.98      0.98      0.98        62\n",
            "     Sadness       1.00      0.96      0.98        49\n",
            "\n",
            "    accuracy                           0.99       428\n",
            "   macro avg       0.98      0.99      0.98       428\n",
            "weighted avg       0.99      0.99      0.99       428\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YgZCU4r1eS2"
      },
      "source": [
        "#CONV-LSTM"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9fmgi8e1ilj",
        "outputId": "44e073eb-9931-47c4-b2e1-367c91847486"
      },
      "source": [
        "model = tf.keras.Sequential()\n",
        "model.add(layers.Conv1D(256, kernel_size=(8),strides=1,dilation_rate=1,padding=\"same\", activation='relu', input_shape=(x_train.shape[1],1)))\n",
        "model.add(layers.Conv1D(256, kernel_size=(8),strides=1,activation='relu',dilation_rate=1,kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
        "model.add(layers.MaxPooling1D(pool_size=(2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.Dropout(0.25))\n",
        "model.add(layers.Conv1D(256, kernel_size=(8),strides=1,dilation_rate=1,padding=\"same\",activation='relu'))\n",
        "model.add(layers.MaxPooling1D(pool_size=(2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.Dropout(0.25))\n",
        "model.add(layers.Conv1D(128, kernel_size=(8),strides=1,dilation_rate=1,padding=\"same\",activation='relu'))\n",
        "model.add(layers.MaxPooling1D(pool_size=(2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.Dropout(0.25))\n",
        "model.add(layers.Conv1D(128, kernel_size=(8),strides=1,dilation_rate=1,padding=\"same\",activation='relu'))\n",
        "model.add(layers.MaxPooling1D(pool_size=(2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.Dropout(0.25))\n",
        "model.add(layers.Conv1D(128, kernel_size=(8),strides=1,dilation_rate=1,padding=\"same\",activation='relu'))\n",
        "model.add(layers.MaxPooling1D(pool_size=(2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Conv1D(256, kernel_size=(8),strides=1,dilation_rate=1,padding=\"same\",activation='relu'))\n",
        "model.add(layers.MaxPooling1D(pool_size=(2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Conv1D(64, kernel_size=(8),strides=1,dilation_rate=1,padding=\"same\",activation='relu'))\n",
        "model.add(layers.MaxPooling1D(pool_size=(2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.LSTM(512))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(7, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='Adam',metrics=['accuracy'])\n",
        "model.summary()\n",
        "checkpoint = ModelCheckpoint(\"SER_best_initial_model.hdf5\", monitor='val_accuracy', verbose=1, save_best_only=True, mode='max', period=1, save_weights_only=True)\n",
        "model_history=model.fit(x_train, y_train,batch_size=32, epochs=1000, validation_data=(x_test, y_test),callbacks=[checkpoint])"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_32 (Conv1D)           (None, 155, 256)          2304      \n",
            "_________________________________________________________________\n",
            "conv1d_33 (Conv1D)           (None, 148, 256)          524544    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_28 (MaxPooling (None, 74, 256)           0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_28 (Batc (None, 74, 256)           1024      \n",
            "_________________________________________________________________\n",
            "dropout_34 (Dropout)         (None, 74, 256)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_34 (Conv1D)           (None, 74, 256)           524544    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_29 (MaxPooling (None, 37, 256)           0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_29 (Batc (None, 37, 256)           1024      \n",
            "_________________________________________________________________\n",
            "dropout_35 (Dropout)         (None, 37, 256)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_35 (Conv1D)           (None, 37, 128)           262272    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_30 (MaxPooling (None, 18, 128)           0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_30 (Batc (None, 18, 128)           512       \n",
            "_________________________________________________________________\n",
            "dropout_36 (Dropout)         (None, 18, 128)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_36 (Conv1D)           (None, 18, 128)           131200    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_31 (MaxPooling (None, 9, 128)            0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_31 (Batc (None, 9, 128)            512       \n",
            "_________________________________________________________________\n",
            "dropout_37 (Dropout)         (None, 9, 128)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_37 (Conv1D)           (None, 9, 128)            131200    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_32 (MaxPooling (None, 4, 128)            0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_32 (Batc (None, 4, 128)            512       \n",
            "_________________________________________________________________\n",
            "dropout_38 (Dropout)         (None, 4, 128)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_38 (Conv1D)           (None, 4, 256)            262400    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_33 (MaxPooling (None, 2, 256)            0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_33 (Batc (None, 2, 256)            1024      \n",
            "_________________________________________________________________\n",
            "dropout_39 (Dropout)         (None, 2, 256)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_39 (Conv1D)           (None, 2, 64)             131136    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_34 (MaxPooling (None, 1, 64)             0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_34 (Batc (None, 1, 64)             256       \n",
            "_________________________________________________________________\n",
            "dropout_40 (Dropout)         (None, 1, 64)             0         \n",
            "_________________________________________________________________\n",
            "lstm_6 (LSTM)                (None, 512)               1181696   \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_41 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dropout_42 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_43 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 7)                 455       \n",
            "=================================================================\n",
            "Total params: 3,230,535\n",
            "Trainable params: 3,228,103\n",
            "Non-trainable params: 2,432\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/1000\n",
            "54/54 [==============================] - 5s 30ms/step - loss: 4.1990 - accuracy: 0.1784 - val_loss: 2.9067 - val_accuracy: 0.2734\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.27336, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 2/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 2.6037 - accuracy: 0.3032 - val_loss: 1.9991 - val_accuracy: 0.4042\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.27336 to 0.40421, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 3/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 1.7587 - accuracy: 0.3740 - val_loss: 1.9235 - val_accuracy: 0.2360\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.40421\n",
            "Epoch 4/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 1.5704 - accuracy: 0.3964 - val_loss: 1.7643 - val_accuracy: 0.3551\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.40421\n",
            "Epoch 5/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 1.5110 - accuracy: 0.4229 - val_loss: 1.4287 - val_accuracy: 0.4393\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.40421 to 0.43925, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 6/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 1.3925 - accuracy: 0.4660 - val_loss: 1.2291 - val_accuracy: 0.5327\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.43925 to 0.53271, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 7/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 1.3633 - accuracy: 0.4937 - val_loss: 1.2521 - val_accuracy: 0.5397\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.53271 to 0.53972, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 8/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 1.3168 - accuracy: 0.4849 - val_loss: 1.1223 - val_accuracy: 0.5514\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.53972 to 0.55140, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 9/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 1.2730 - accuracy: 0.5048 - val_loss: 1.1194 - val_accuracy: 0.5397\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.55140\n",
            "Epoch 10/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 1.2520 - accuracy: 0.5054 - val_loss: 1.4196 - val_accuracy: 0.4720\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.55140\n",
            "Epoch 11/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 1.2443 - accuracy: 0.5327 - val_loss: 1.1001 - val_accuracy: 0.5864\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.55140 to 0.58645, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 12/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 1.1517 - accuracy: 0.5691 - val_loss: 1.1426 - val_accuracy: 0.5631\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.58645\n",
            "Epoch 13/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 1.1536 - accuracy: 0.5576 - val_loss: 1.0733 - val_accuracy: 0.5794\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.58645\n",
            "Epoch 14/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 1.1079 - accuracy: 0.5647 - val_loss: 0.9636 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00014: val_accuracy improved from 0.58645 to 0.60748, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 15/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 1.0974 - accuracy: 0.5790 - val_loss: 0.9348 - val_accuracy: 0.6332\n",
            "\n",
            "Epoch 00015: val_accuracy improved from 0.60748 to 0.63318, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 16/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 1.0449 - accuracy: 0.5997 - val_loss: 1.0436 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.63318\n",
            "Epoch 17/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 1.0959 - accuracy: 0.5676 - val_loss: 0.9420 - val_accuracy: 0.6355\n",
            "\n",
            "Epoch 00017: val_accuracy improved from 0.63318 to 0.63551, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 18/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.9695 - accuracy: 0.5969 - val_loss: 1.2275 - val_accuracy: 0.5678\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.63551\n",
            "Epoch 19/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 1.0234 - accuracy: 0.5977 - val_loss: 1.0830 - val_accuracy: 0.5841\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.63551\n",
            "Epoch 20/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.9560 - accuracy: 0.6342 - val_loss: 0.9566 - val_accuracy: 0.6308\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.63551\n",
            "Epoch 21/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.8965 - accuracy: 0.6476 - val_loss: 1.1372 - val_accuracy: 0.6098\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.63551\n",
            "Epoch 22/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.9328 - accuracy: 0.6294 - val_loss: 1.1021 - val_accuracy: 0.6238\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.63551\n",
            "Epoch 23/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.9240 - accuracy: 0.6142 - val_loss: 1.0300 - val_accuracy: 0.6402\n",
            "\n",
            "Epoch 00023: val_accuracy improved from 0.63551 to 0.64019, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 24/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.8418 - accuracy: 0.6804 - val_loss: 0.9104 - val_accuracy: 0.6846\n",
            "\n",
            "Epoch 00024: val_accuracy improved from 0.64019 to 0.68458, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 25/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.8094 - accuracy: 0.6639 - val_loss: 0.7496 - val_accuracy: 0.7173\n",
            "\n",
            "Epoch 00025: val_accuracy improved from 0.68458 to 0.71729, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 26/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.8056 - accuracy: 0.6974 - val_loss: 0.8131 - val_accuracy: 0.6706\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.71729\n",
            "Epoch 27/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.7677 - accuracy: 0.7073 - val_loss: 0.9564 - val_accuracy: 0.6612\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.71729\n",
            "Epoch 28/1000\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.7453 - accuracy: 0.7064 - val_loss: 0.7364 - val_accuracy: 0.7079\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.71729\n",
            "Epoch 29/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.7709 - accuracy: 0.7089 - val_loss: 0.7867 - val_accuracy: 0.6799\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.71729\n",
            "Epoch 30/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.7398 - accuracy: 0.6999 - val_loss: 0.8019 - val_accuracy: 0.6752\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.71729\n",
            "Epoch 31/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.7041 - accuracy: 0.7382 - val_loss: 0.7954 - val_accuracy: 0.7220\n",
            "\n",
            "Epoch 00031: val_accuracy improved from 0.71729 to 0.72196, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 32/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.7723 - accuracy: 0.6901 - val_loss: 0.6921 - val_accuracy: 0.7196\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.72196\n",
            "Epoch 33/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.6598 - accuracy: 0.7439 - val_loss: 0.7111 - val_accuracy: 0.6869\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.72196\n",
            "Epoch 34/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.6198 - accuracy: 0.7316 - val_loss: 0.7383 - val_accuracy: 0.7523\n",
            "\n",
            "Epoch 00034: val_accuracy improved from 0.72196 to 0.75234, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 35/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.6352 - accuracy: 0.7232 - val_loss: 0.6729 - val_accuracy: 0.7126\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.75234\n",
            "Epoch 36/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.6612 - accuracy: 0.7233 - val_loss: 0.6548 - val_accuracy: 0.7500\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.75234\n",
            "Epoch 37/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.6239 - accuracy: 0.7559 - val_loss: 0.7136 - val_accuracy: 0.7290\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.75234\n",
            "Epoch 38/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.5922 - accuracy: 0.7614 - val_loss: 0.6789 - val_accuracy: 0.7617\n",
            "\n",
            "Epoch 00038: val_accuracy improved from 0.75234 to 0.76168, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 39/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.5890 - accuracy: 0.7650 - val_loss: 0.5906 - val_accuracy: 0.7734\n",
            "\n",
            "Epoch 00039: val_accuracy improved from 0.76168 to 0.77336, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 40/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.5998 - accuracy: 0.7467 - val_loss: 0.9420 - val_accuracy: 0.6449\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.77336\n",
            "Epoch 41/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.6592 - accuracy: 0.7542 - val_loss: 0.5643 - val_accuracy: 0.8107\n",
            "\n",
            "Epoch 00041: val_accuracy improved from 0.77336 to 0.81075, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 42/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.5804 - accuracy: 0.7768 - val_loss: 0.6729 - val_accuracy: 0.7500\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.81075\n",
            "Epoch 43/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.5227 - accuracy: 0.7945 - val_loss: 0.4814 - val_accuracy: 0.7921\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.81075\n",
            "Epoch 44/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.5185 - accuracy: 0.8013 - val_loss: 0.4412 - val_accuracy: 0.8154\n",
            "\n",
            "Epoch 00044: val_accuracy improved from 0.81075 to 0.81542, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 45/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.5266 - accuracy: 0.7934 - val_loss: 0.4629 - val_accuracy: 0.8271\n",
            "\n",
            "Epoch 00045: val_accuracy improved from 0.81542 to 0.82710, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 46/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.4293 - accuracy: 0.8248 - val_loss: 0.5733 - val_accuracy: 0.8411\n",
            "\n",
            "Epoch 00046: val_accuracy improved from 0.82710 to 0.84112, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 47/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.5340 - accuracy: 0.7961 - val_loss: 0.8397 - val_accuracy: 0.7640\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.84112\n",
            "Epoch 48/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.4951 - accuracy: 0.8203 - val_loss: 0.4623 - val_accuracy: 0.8364\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.84112\n",
            "Epoch 49/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.4740 - accuracy: 0.8328 - val_loss: 0.3586 - val_accuracy: 0.8785\n",
            "\n",
            "Epoch 00049: val_accuracy improved from 0.84112 to 0.87850, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 50/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.4081 - accuracy: 0.8643 - val_loss: 0.4843 - val_accuracy: 0.8224\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.87850\n",
            "Epoch 51/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.4559 - accuracy: 0.8339 - val_loss: 0.6213 - val_accuracy: 0.7687\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.87850\n",
            "Epoch 52/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.4075 - accuracy: 0.8533 - val_loss: 0.8329 - val_accuracy: 0.7313\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.87850\n",
            "Epoch 53/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.3989 - accuracy: 0.8441 - val_loss: 0.4277 - val_accuracy: 0.8598\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.87850\n",
            "Epoch 54/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.4017 - accuracy: 0.8646 - val_loss: 0.4474 - val_accuracy: 0.8411\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.87850\n",
            "Epoch 55/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.4196 - accuracy: 0.8731 - val_loss: 0.7870 - val_accuracy: 0.7734\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.87850\n",
            "Epoch 56/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.3770 - accuracy: 0.8732 - val_loss: 0.4370 - val_accuracy: 0.8481\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.87850\n",
            "Epoch 57/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.3909 - accuracy: 0.8742 - val_loss: 0.4457 - val_accuracy: 0.8668\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.87850\n",
            "Epoch 58/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.4052 - accuracy: 0.8784 - val_loss: 0.5127 - val_accuracy: 0.8551\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.87850\n",
            "Epoch 59/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.3667 - accuracy: 0.8847 - val_loss: 0.6716 - val_accuracy: 0.7757\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.87850\n",
            "Epoch 60/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.3949 - accuracy: 0.8845 - val_loss: 0.6128 - val_accuracy: 0.8061\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.87850\n",
            "Epoch 61/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.3164 - accuracy: 0.9098 - val_loss: 0.4164 - val_accuracy: 0.8832\n",
            "\n",
            "Epoch 00061: val_accuracy improved from 0.87850 to 0.88318, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 62/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.3175 - accuracy: 0.9007 - val_loss: 0.3968 - val_accuracy: 0.9065\n",
            "\n",
            "Epoch 00062: val_accuracy improved from 0.88318 to 0.90654, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 63/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.3541 - accuracy: 0.9034 - val_loss: 0.3417 - val_accuracy: 0.9042\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.90654\n",
            "Epoch 64/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.3217 - accuracy: 0.9045 - val_loss: 0.2657 - val_accuracy: 0.9322\n",
            "\n",
            "Epoch 00064: val_accuracy improved from 0.90654 to 0.93224, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 65/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.2786 - accuracy: 0.9236 - val_loss: 0.2693 - val_accuracy: 0.9322\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.93224\n",
            "Epoch 66/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.3220 - accuracy: 0.9110 - val_loss: 0.3709 - val_accuracy: 0.9019\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.93224\n",
            "Epoch 67/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.3903 - accuracy: 0.9053 - val_loss: 0.3051 - val_accuracy: 0.9019\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.93224\n",
            "Epoch 68/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.2752 - accuracy: 0.9217 - val_loss: 0.3030 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.93224\n",
            "Epoch 69/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.3095 - accuracy: 0.9193 - val_loss: 0.4118 - val_accuracy: 0.9112\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.93224\n",
            "Epoch 70/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.2766 - accuracy: 0.9308 - val_loss: 0.4902 - val_accuracy: 0.8972\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.93224\n",
            "Epoch 71/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.2877 - accuracy: 0.9356 - val_loss: 0.2740 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00071: val_accuracy improved from 0.93224 to 0.93458, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 72/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.2599 - accuracy: 0.9351 - val_loss: 0.2812 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.93458\n",
            "Epoch 73/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.2335 - accuracy: 0.9432 - val_loss: 0.3329 - val_accuracy: 0.8995\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.93458\n",
            "Epoch 74/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.2614 - accuracy: 0.9310 - val_loss: 0.3256 - val_accuracy: 0.9299\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.93458\n",
            "Epoch 75/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.2890 - accuracy: 0.9353 - val_loss: 0.2241 - val_accuracy: 0.9463\n",
            "\n",
            "Epoch 00075: val_accuracy improved from 0.93458 to 0.94626, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 76/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.2118 - accuracy: 0.9546 - val_loss: 0.3417 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.94626\n",
            "Epoch 77/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.2798 - accuracy: 0.9300 - val_loss: 0.3983 - val_accuracy: 0.9206\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.94626\n",
            "Epoch 78/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.2463 - accuracy: 0.9447 - val_loss: 0.3213 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.94626\n",
            "Epoch 79/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.2251 - accuracy: 0.9457 - val_loss: 0.3043 - val_accuracy: 0.9229\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.94626\n",
            "Epoch 80/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.2276 - accuracy: 0.9463 - val_loss: 0.7185 - val_accuracy: 0.7921\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.94626\n",
            "Epoch 81/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.2923 - accuracy: 0.9400 - val_loss: 0.2445 - val_accuracy: 0.9369\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.94626\n",
            "Epoch 82/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.2186 - accuracy: 0.9500 - val_loss: 0.2832 - val_accuracy: 0.9206\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.94626\n",
            "Epoch 83/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.2386 - accuracy: 0.9323 - val_loss: 0.1788 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00083: val_accuracy improved from 0.94626 to 0.96495, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 84/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.2218 - accuracy: 0.9630 - val_loss: 0.2221 - val_accuracy: 0.9463\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.96495\n",
            "Epoch 85/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.2034 - accuracy: 0.9630 - val_loss: 1.2047 - val_accuracy: 0.7617\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.96495\n",
            "Epoch 86/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.2283 - accuracy: 0.9602 - val_loss: 0.1880 - val_accuracy: 0.9486\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.96495\n",
            "Epoch 87/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1899 - accuracy: 0.9609 - val_loss: 0.8674 - val_accuracy: 0.8154\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.96495\n",
            "Epoch 88/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.2144 - accuracy: 0.9549 - val_loss: 0.1968 - val_accuracy: 0.9603\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.96495\n",
            "Epoch 89/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1646 - accuracy: 0.9696 - val_loss: 0.2369 - val_accuracy: 0.9486\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.96495\n",
            "Epoch 90/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.2676 - accuracy: 0.9528 - val_loss: 0.2040 - val_accuracy: 0.9556\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.96495\n",
            "Epoch 91/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.2174 - accuracy: 0.9522 - val_loss: 0.3552 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.96495\n",
            "Epoch 92/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1819 - accuracy: 0.9732 - val_loss: 0.3512 - val_accuracy: 0.9369\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.96495\n",
            "Epoch 93/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1768 - accuracy: 0.9662 - val_loss: 0.2407 - val_accuracy: 0.9556\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.96495\n",
            "Epoch 94/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.2096 - accuracy: 0.9679 - val_loss: 0.2995 - val_accuracy: 0.9276\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.96495\n",
            "Epoch 95/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.2253 - accuracy: 0.9544 - val_loss: 0.3475 - val_accuracy: 0.9276\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.96495\n",
            "Epoch 96/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.2115 - accuracy: 0.9587 - val_loss: 0.2401 - val_accuracy: 0.9416\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.96495\n",
            "Epoch 97/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1865 - accuracy: 0.9694 - val_loss: 0.2409 - val_accuracy: 0.9626\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.96495\n",
            "Epoch 98/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.2066 - accuracy: 0.9611 - val_loss: 0.3089 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.96495\n",
            "Epoch 99/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.2145 - accuracy: 0.9676 - val_loss: 0.2411 - val_accuracy: 0.9603\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.96495\n",
            "Epoch 100/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1889 - accuracy: 0.9577 - val_loss: 0.2427 - val_accuracy: 0.9416\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.96495\n",
            "Epoch 101/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1828 - accuracy: 0.9696 - val_loss: 0.2540 - val_accuracy: 0.9509\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.96495\n",
            "Epoch 102/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1711 - accuracy: 0.9740 - val_loss: 0.2566 - val_accuracy: 0.9579\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.96495\n",
            "Epoch 103/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1785 - accuracy: 0.9720 - val_loss: 0.1974 - val_accuracy: 0.9626\n",
            "\n",
            "Epoch 00103: val_accuracy did not improve from 0.96495\n",
            "Epoch 104/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1460 - accuracy: 0.9787 - val_loss: 0.1735 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 0.96495\n",
            "Epoch 105/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1439 - accuracy: 0.9740 - val_loss: 0.3231 - val_accuracy: 0.9322\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.96495\n",
            "Epoch 106/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.2088 - accuracy: 0.9691 - val_loss: 0.2469 - val_accuracy: 0.9533\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.96495\n",
            "Epoch 107/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1650 - accuracy: 0.9770 - val_loss: 0.5284 - val_accuracy: 0.8949\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.96495\n",
            "Epoch 108/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1616 - accuracy: 0.9666 - val_loss: 0.3007 - val_accuracy: 0.9393\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 0.96495\n",
            "Epoch 109/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1770 - accuracy: 0.9788 - val_loss: 0.3029 - val_accuracy: 0.9486\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.96495\n",
            "Epoch 110/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.2770 - accuracy: 0.9516 - val_loss: 0.2030 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.96495\n",
            "Epoch 111/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1527 - accuracy: 0.9771 - val_loss: 0.3179 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 0.96495\n",
            "Epoch 112/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1645 - accuracy: 0.9735 - val_loss: 0.2379 - val_accuracy: 0.9603\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.96495\n",
            "Epoch 113/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1460 - accuracy: 0.9833 - val_loss: 0.5338 - val_accuracy: 0.9042\n",
            "\n",
            "Epoch 00113: val_accuracy did not improve from 0.96495\n",
            "Epoch 114/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.2344 - accuracy: 0.9596 - val_loss: 0.4275 - val_accuracy: 0.9369\n",
            "\n",
            "Epoch 00114: val_accuracy did not improve from 0.96495\n",
            "Epoch 115/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1852 - accuracy: 0.9716 - val_loss: 0.2732 - val_accuracy: 0.9579\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.96495\n",
            "Epoch 116/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1477 - accuracy: 0.9832 - val_loss: 0.3646 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.96495\n",
            "Epoch 117/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1411 - accuracy: 0.9769 - val_loss: 0.1575 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00117: val_accuracy improved from 0.96495 to 0.96729, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 118/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1329 - accuracy: 0.9767 - val_loss: 0.2891 - val_accuracy: 0.9603\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.96729\n",
            "Epoch 119/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1471 - accuracy: 0.9778 - val_loss: 0.2169 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.96729\n",
            "Epoch 120/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1306 - accuracy: 0.9759 - val_loss: 0.1711 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00120: val_accuracy improved from 0.96729 to 0.97196, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 121/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1933 - accuracy: 0.9711 - val_loss: 0.2778 - val_accuracy: 0.9416\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.97196\n",
            "Epoch 122/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.2129 - accuracy: 0.9753 - val_loss: 0.2810 - val_accuracy: 0.9463\n",
            "\n",
            "Epoch 00122: val_accuracy did not improve from 0.97196\n",
            "Epoch 123/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1443 - accuracy: 0.9770 - val_loss: 0.2210 - val_accuracy: 0.9579\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.97196\n",
            "Epoch 124/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.2124 - accuracy: 0.9641 - val_loss: 0.2124 - val_accuracy: 0.9556\n",
            "\n",
            "Epoch 00124: val_accuracy did not improve from 0.97196\n",
            "Epoch 125/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1492 - accuracy: 0.9829 - val_loss: 0.2380 - val_accuracy: 0.9556\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.97196\n",
            "Epoch 126/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1724 - accuracy: 0.9795 - val_loss: 0.1546 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.97196\n",
            "Epoch 127/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0956 - accuracy: 0.9902 - val_loss: 0.1342 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00127: val_accuracy did not improve from 0.97196\n",
            "Epoch 128/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1266 - accuracy: 0.9765 - val_loss: 0.2037 - val_accuracy: 0.9626\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.97196\n",
            "Epoch 129/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1376 - accuracy: 0.9806 - val_loss: 0.1837 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.97196\n",
            "Epoch 130/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1690 - accuracy: 0.9703 - val_loss: 0.2009 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.97196\n",
            "Epoch 131/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1316 - accuracy: 0.9844 - val_loss: 0.2574 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.97196\n",
            "Epoch 132/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1670 - accuracy: 0.9735 - val_loss: 0.3842 - val_accuracy: 0.9369\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.97196\n",
            "Epoch 133/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1928 - accuracy: 0.9642 - val_loss: 0.2663 - val_accuracy: 0.9579\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.97196\n",
            "Epoch 134/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.2032 - accuracy: 0.9722 - val_loss: 0.2256 - val_accuracy: 0.9603\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.97196\n",
            "Epoch 135/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1606 - accuracy: 0.9801 - val_loss: 0.1583 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00135: val_accuracy did not improve from 0.97196\n",
            "Epoch 136/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1379 - accuracy: 0.9782 - val_loss: 0.2973 - val_accuracy: 0.9486\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.97196\n",
            "Epoch 137/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.2222 - accuracy: 0.9682 - val_loss: 0.2699 - val_accuracy: 0.9533\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 0.97196\n",
            "Epoch 138/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1884 - accuracy: 0.9732 - val_loss: 0.2442 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.97196\n",
            "Epoch 139/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1660 - accuracy: 0.9817 - val_loss: 0.1850 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.97196\n",
            "Epoch 140/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1534 - accuracy: 0.9791 - val_loss: 0.1365 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.97196\n",
            "Epoch 141/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1550 - accuracy: 0.9747 - val_loss: 0.1724 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00141: val_accuracy did not improve from 0.97196\n",
            "Epoch 142/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1212 - accuracy: 0.9817 - val_loss: 0.2040 - val_accuracy: 0.9603\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.97196\n",
            "Epoch 143/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1366 - accuracy: 0.9805 - val_loss: 0.1205 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00143: val_accuracy improved from 0.97196 to 0.97664, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 144/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0973 - accuracy: 0.9810 - val_loss: 0.1481 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00144: val_accuracy did not improve from 0.97664\n",
            "Epoch 145/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1106 - accuracy: 0.9822 - val_loss: 0.3182 - val_accuracy: 0.9393\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.97664\n",
            "Epoch 146/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1333 - accuracy: 0.9771 - val_loss: 0.2111 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00146: val_accuracy did not improve from 0.97664\n",
            "Epoch 147/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1251 - accuracy: 0.9798 - val_loss: 0.3859 - val_accuracy: 0.9439\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.97664\n",
            "Epoch 148/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1720 - accuracy: 0.9786 - val_loss: 0.5144 - val_accuracy: 0.9229\n",
            "\n",
            "Epoch 00148: val_accuracy did not improve from 0.97664\n",
            "Epoch 149/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.2249 - accuracy: 0.9735 - val_loss: 0.2069 - val_accuracy: 0.9626\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.97664\n",
            "Epoch 150/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1475 - accuracy: 0.9844 - val_loss: 0.1688 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 0.97664\n",
            "Epoch 151/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1347 - accuracy: 0.9835 - val_loss: 0.2254 - val_accuracy: 0.9626\n",
            "\n",
            "Epoch 00151: val_accuracy did not improve from 0.97664\n",
            "Epoch 152/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1422 - accuracy: 0.9840 - val_loss: 0.1967 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00152: val_accuracy did not improve from 0.97664\n",
            "Epoch 153/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1196 - accuracy: 0.9852 - val_loss: 0.1610 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00153: val_accuracy did not improve from 0.97664\n",
            "Epoch 154/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1008 - accuracy: 0.9888 - val_loss: 0.1629 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00154: val_accuracy did not improve from 0.97664\n",
            "Epoch 155/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0743 - accuracy: 0.9953 - val_loss: 0.1850 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00155: val_accuracy did not improve from 0.97664\n",
            "Epoch 156/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0958 - accuracy: 0.9906 - val_loss: 0.2506 - val_accuracy: 0.9533\n",
            "\n",
            "Epoch 00156: val_accuracy did not improve from 0.97664\n",
            "Epoch 157/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1451 - accuracy: 0.9810 - val_loss: 0.1498 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00157: val_accuracy did not improve from 0.97664\n",
            "Epoch 158/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1104 - accuracy: 0.9824 - val_loss: 0.1707 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00158: val_accuracy did not improve from 0.97664\n",
            "Epoch 159/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1127 - accuracy: 0.9856 - val_loss: 0.1269 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00159: val_accuracy did not improve from 0.97664\n",
            "Epoch 160/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1792 - accuracy: 0.9786 - val_loss: 0.1463 - val_accuracy: 0.9626\n",
            "\n",
            "Epoch 00160: val_accuracy did not improve from 0.97664\n",
            "Epoch 161/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1804 - accuracy: 0.9707 - val_loss: 0.1907 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00161: val_accuracy did not improve from 0.97664\n",
            "Epoch 162/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1495 - accuracy: 0.9864 - val_loss: 0.1242 - val_accuracy: 0.9860\n",
            "\n",
            "Epoch 00162: val_accuracy improved from 0.97664 to 0.98598, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 163/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0916 - accuracy: 0.9914 - val_loss: 0.1288 - val_accuracy: 0.9883\n",
            "\n",
            "Epoch 00163: val_accuracy improved from 0.98598 to 0.98832, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 164/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0698 - accuracy: 0.9942 - val_loss: 0.1339 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00164: val_accuracy did not improve from 0.98832\n",
            "Epoch 165/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1455 - accuracy: 0.9829 - val_loss: 0.1706 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00165: val_accuracy did not improve from 0.98832\n",
            "Epoch 166/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1481 - accuracy: 0.9761 - val_loss: 0.1949 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00166: val_accuracy did not improve from 0.98832\n",
            "Epoch 167/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1764 - accuracy: 0.9754 - val_loss: 0.1950 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00167: val_accuracy did not improve from 0.98832\n",
            "Epoch 168/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1435 - accuracy: 0.9859 - val_loss: 0.1449 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00168: val_accuracy did not improve from 0.98832\n",
            "Epoch 169/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0984 - accuracy: 0.9833 - val_loss: 0.1452 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00169: val_accuracy did not improve from 0.98832\n",
            "Epoch 170/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0766 - accuracy: 0.9933 - val_loss: 0.2125 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00170: val_accuracy did not improve from 0.98832\n",
            "Epoch 171/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0807 - accuracy: 0.9939 - val_loss: 0.1095 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00171: val_accuracy did not improve from 0.98832\n",
            "Epoch 172/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1138 - accuracy: 0.9892 - val_loss: 0.1564 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00172: val_accuracy did not improve from 0.98832\n",
            "Epoch 173/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1096 - accuracy: 0.9829 - val_loss: 0.1063 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00173: val_accuracy did not improve from 0.98832\n",
            "Epoch 174/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1006 - accuracy: 0.9886 - val_loss: 0.1628 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00174: val_accuracy did not improve from 0.98832\n",
            "Epoch 175/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0858 - accuracy: 0.9908 - val_loss: 0.2159 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00175: val_accuracy did not improve from 0.98832\n",
            "Epoch 176/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0790 - accuracy: 0.9909 - val_loss: 0.1847 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00176: val_accuracy did not improve from 0.98832\n",
            "Epoch 177/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0851 - accuracy: 0.9892 - val_loss: 0.2183 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00177: val_accuracy did not improve from 0.98832\n",
            "Epoch 178/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1289 - accuracy: 0.9846 - val_loss: 0.2706 - val_accuracy: 0.9533\n",
            "\n",
            "Epoch 00178: val_accuracy did not improve from 0.98832\n",
            "Epoch 179/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1233 - accuracy: 0.9808 - val_loss: 0.2039 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00179: val_accuracy did not improve from 0.98832\n",
            "Epoch 180/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0913 - accuracy: 0.9908 - val_loss: 0.1818 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00180: val_accuracy did not improve from 0.98832\n",
            "Epoch 181/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0614 - accuracy: 0.9949 - val_loss: 0.2960 - val_accuracy: 0.9579\n",
            "\n",
            "Epoch 00181: val_accuracy did not improve from 0.98832\n",
            "Epoch 182/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1208 - accuracy: 0.9878 - val_loss: 0.3269 - val_accuracy: 0.9603\n",
            "\n",
            "Epoch 00182: val_accuracy did not improve from 0.98832\n",
            "Epoch 183/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1450 - accuracy: 0.9768 - val_loss: 0.2420 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00183: val_accuracy did not improve from 0.98832\n",
            "Epoch 184/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1062 - accuracy: 0.9839 - val_loss: 0.3107 - val_accuracy: 0.9626\n",
            "\n",
            "Epoch 00184: val_accuracy did not improve from 0.98832\n",
            "Epoch 185/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1220 - accuracy: 0.9803 - val_loss: 0.2462 - val_accuracy: 0.9509\n",
            "\n",
            "Epoch 00185: val_accuracy did not improve from 0.98832\n",
            "Epoch 186/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1449 - accuracy: 0.9761 - val_loss: 0.2091 - val_accuracy: 0.9603\n",
            "\n",
            "Epoch 00186: val_accuracy did not improve from 0.98832\n",
            "Epoch 187/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1345 - accuracy: 0.9791 - val_loss: 0.2537 - val_accuracy: 0.9626\n",
            "\n",
            "Epoch 00187: val_accuracy did not improve from 0.98832\n",
            "Epoch 188/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1099 - accuracy: 0.9892 - val_loss: 0.2162 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00188: val_accuracy did not improve from 0.98832\n",
            "Epoch 189/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1167 - accuracy: 0.9822 - val_loss: 0.1520 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00189: val_accuracy did not improve from 0.98832\n",
            "Epoch 190/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0902 - accuracy: 0.9927 - val_loss: 0.1996 - val_accuracy: 0.9486\n",
            "\n",
            "Epoch 00190: val_accuracy did not improve from 0.98832\n",
            "Epoch 191/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1046 - accuracy: 0.9855 - val_loss: 0.2454 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00191: val_accuracy did not improve from 0.98832\n",
            "Epoch 192/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1029 - accuracy: 0.9840 - val_loss: 0.1532 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00192: val_accuracy did not improve from 0.98832\n",
            "Epoch 193/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0976 - accuracy: 0.9872 - val_loss: 0.1886 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00193: val_accuracy did not improve from 0.98832\n",
            "Epoch 194/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1217 - accuracy: 0.9816 - val_loss: 0.3754 - val_accuracy: 0.9556\n",
            "\n",
            "Epoch 00194: val_accuracy did not improve from 0.98832\n",
            "Epoch 195/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1267 - accuracy: 0.9864 - val_loss: 0.1684 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00195: val_accuracy did not improve from 0.98832\n",
            "Epoch 196/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1427 - accuracy: 0.9767 - val_loss: 0.2483 - val_accuracy: 0.9556\n",
            "\n",
            "Epoch 00196: val_accuracy did not improve from 0.98832\n",
            "Epoch 197/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1264 - accuracy: 0.9837 - val_loss: 0.1678 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00197: val_accuracy did not improve from 0.98832\n",
            "Epoch 198/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1128 - accuracy: 0.9869 - val_loss: 0.1771 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00198: val_accuracy did not improve from 0.98832\n",
            "Epoch 199/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0995 - accuracy: 0.9874 - val_loss: 0.2122 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00199: val_accuracy did not improve from 0.98832\n",
            "Epoch 200/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1303 - accuracy: 0.9844 - val_loss: 0.2475 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00200: val_accuracy did not improve from 0.98832\n",
            "Epoch 201/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0961 - accuracy: 0.9871 - val_loss: 0.1798 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00201: val_accuracy did not improve from 0.98832\n",
            "Epoch 202/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1129 - accuracy: 0.9867 - val_loss: 0.1949 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00202: val_accuracy did not improve from 0.98832\n",
            "Epoch 203/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1553 - accuracy: 0.9784 - val_loss: 0.1760 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00203: val_accuracy did not improve from 0.98832\n",
            "Epoch 204/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0762 - accuracy: 0.9889 - val_loss: 0.1129 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00204: val_accuracy did not improve from 0.98832\n",
            "Epoch 205/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0738 - accuracy: 0.9904 - val_loss: 0.1346 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00205: val_accuracy did not improve from 0.98832\n",
            "Epoch 206/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0890 - accuracy: 0.9864 - val_loss: 0.1630 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00206: val_accuracy did not improve from 0.98832\n",
            "Epoch 207/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1006 - accuracy: 0.9858 - val_loss: 0.1493 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00207: val_accuracy did not improve from 0.98832\n",
            "Epoch 208/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1151 - accuracy: 0.9876 - val_loss: 0.2077 - val_accuracy: 0.9579\n",
            "\n",
            "Epoch 00208: val_accuracy did not improve from 0.98832\n",
            "Epoch 209/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1075 - accuracy: 0.9834 - val_loss: 0.2813 - val_accuracy: 0.9486\n",
            "\n",
            "Epoch 00209: val_accuracy did not improve from 0.98832\n",
            "Epoch 210/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1081 - accuracy: 0.9885 - val_loss: 0.4501 - val_accuracy: 0.9439\n",
            "\n",
            "Epoch 00210: val_accuracy did not improve from 0.98832\n",
            "Epoch 211/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1780 - accuracy: 0.9692 - val_loss: 0.2226 - val_accuracy: 0.9626\n",
            "\n",
            "Epoch 00211: val_accuracy did not improve from 0.98832\n",
            "Epoch 212/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1176 - accuracy: 0.9866 - val_loss: 0.3854 - val_accuracy: 0.9416\n",
            "\n",
            "Epoch 00212: val_accuracy did not improve from 0.98832\n",
            "Epoch 213/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1705 - accuracy: 0.9801 - val_loss: 0.1208 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00213: val_accuracy did not improve from 0.98832\n",
            "Epoch 214/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0937 - accuracy: 0.9918 - val_loss: 0.1228 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00214: val_accuracy did not improve from 0.98832\n",
            "Epoch 215/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1080 - accuracy: 0.9901 - val_loss: 0.1193 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00215: val_accuracy did not improve from 0.98832\n",
            "Epoch 216/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0950 - accuracy: 0.9919 - val_loss: 0.1612 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00216: val_accuracy did not improve from 0.98832\n",
            "Epoch 217/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0770 - accuracy: 0.9868 - val_loss: 0.1870 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00217: val_accuracy did not improve from 0.98832\n",
            "Epoch 218/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0876 - accuracy: 0.9948 - val_loss: 0.1866 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00218: val_accuracy did not improve from 0.98832\n",
            "Epoch 219/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1365 - accuracy: 0.9842 - val_loss: 0.2008 - val_accuracy: 0.9533\n",
            "\n",
            "Epoch 00219: val_accuracy did not improve from 0.98832\n",
            "Epoch 220/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1557 - accuracy: 0.9827 - val_loss: 0.1921 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00220: val_accuracy did not improve from 0.98832\n",
            "Epoch 221/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1182 - accuracy: 0.9883 - val_loss: 0.1099 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00221: val_accuracy did not improve from 0.98832\n",
            "Epoch 222/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0988 - accuracy: 0.9869 - val_loss: 0.1145 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00222: val_accuracy did not improve from 0.98832\n",
            "Epoch 223/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1355 - accuracy: 0.9891 - val_loss: 0.1395 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00223: val_accuracy did not improve from 0.98832\n",
            "Epoch 224/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0806 - accuracy: 0.9926 - val_loss: 0.1431 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00224: val_accuracy did not improve from 0.98832\n",
            "Epoch 225/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1130 - accuracy: 0.9930 - val_loss: 0.1179 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00225: val_accuracy did not improve from 0.98832\n",
            "Epoch 226/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1023 - accuracy: 0.9896 - val_loss: 0.0917 - val_accuracy: 0.9883\n",
            "\n",
            "Epoch 00226: val_accuracy did not improve from 0.98832\n",
            "Epoch 227/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0692 - accuracy: 0.9958 - val_loss: 0.1459 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00227: val_accuracy did not improve from 0.98832\n",
            "Epoch 228/1000\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.0766 - accuracy: 0.9918 - val_loss: 0.2398 - val_accuracy: 0.9603\n",
            "\n",
            "Epoch 00228: val_accuracy did not improve from 0.98832\n",
            "Epoch 229/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0783 - accuracy: 0.9912 - val_loss: 0.2442 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00229: val_accuracy did not improve from 0.98832\n",
            "Epoch 230/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0676 - accuracy: 0.9891 - val_loss: 0.1795 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00230: val_accuracy did not improve from 0.98832\n",
            "Epoch 231/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0646 - accuracy: 0.9927 - val_loss: 0.1192 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00231: val_accuracy did not improve from 0.98832\n",
            "Epoch 232/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0649 - accuracy: 0.9906 - val_loss: 0.1621 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00232: val_accuracy did not improve from 0.98832\n",
            "Epoch 233/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0972 - accuracy: 0.9869 - val_loss: 0.1997 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00233: val_accuracy did not improve from 0.98832\n",
            "Epoch 234/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1116 - accuracy: 0.9852 - val_loss: 0.1177 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00234: val_accuracy did not improve from 0.98832\n",
            "Epoch 235/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1155 - accuracy: 0.9876 - val_loss: 0.1715 - val_accuracy: 0.9626\n",
            "\n",
            "Epoch 00235: val_accuracy did not improve from 0.98832\n",
            "Epoch 236/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0836 - accuracy: 0.9904 - val_loss: 0.1400 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00236: val_accuracy did not improve from 0.98832\n",
            "Epoch 237/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1392 - accuracy: 0.9837 - val_loss: 0.1402 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00237: val_accuracy did not improve from 0.98832\n",
            "Epoch 238/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0855 - accuracy: 0.9929 - val_loss: 0.1645 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00238: val_accuracy did not improve from 0.98832\n",
            "Epoch 239/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0799 - accuracy: 0.9927 - val_loss: 0.1556 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00239: val_accuracy did not improve from 0.98832\n",
            "Epoch 240/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0812 - accuracy: 0.9872 - val_loss: 0.0923 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00240: val_accuracy did not improve from 0.98832\n",
            "Epoch 241/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0768 - accuracy: 0.9913 - val_loss: 0.2032 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00241: val_accuracy did not improve from 0.98832\n",
            "Epoch 242/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1210 - accuracy: 0.9863 - val_loss: 0.2388 - val_accuracy: 0.9626\n",
            "\n",
            "Epoch 00242: val_accuracy did not improve from 0.98832\n",
            "Epoch 243/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0721 - accuracy: 0.9905 - val_loss: 0.1538 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00243: val_accuracy did not improve from 0.98832\n",
            "Epoch 244/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0582 - accuracy: 0.9955 - val_loss: 0.1441 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00244: val_accuracy did not improve from 0.98832\n",
            "Epoch 245/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0727 - accuracy: 0.9939 - val_loss: 0.1186 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00245: val_accuracy did not improve from 0.98832\n",
            "Epoch 246/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0648 - accuracy: 0.9954 - val_loss: 0.1355 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00246: val_accuracy did not improve from 0.98832\n",
            "Epoch 247/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0760 - accuracy: 0.9937 - val_loss: 0.0896 - val_accuracy: 0.9907\n",
            "\n",
            "Epoch 00247: val_accuracy improved from 0.98832 to 0.99065, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 248/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0592 - accuracy: 0.9938 - val_loss: 0.2434 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00248: val_accuracy did not improve from 0.99065\n",
            "Epoch 249/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0764 - accuracy: 0.9915 - val_loss: 0.1296 - val_accuracy: 0.9883\n",
            "\n",
            "Epoch 00249: val_accuracy did not improve from 0.99065\n",
            "Epoch 250/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1129 - accuracy: 0.9904 - val_loss: 0.1614 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00250: val_accuracy did not improve from 0.99065\n",
            "Epoch 251/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1248 - accuracy: 0.9834 - val_loss: 0.2232 - val_accuracy: 0.9556\n",
            "\n",
            "Epoch 00251: val_accuracy did not improve from 0.99065\n",
            "Epoch 252/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1038 - accuracy: 0.9893 - val_loss: 0.2554 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00252: val_accuracy did not improve from 0.99065\n",
            "Epoch 253/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.1108 - accuracy: 0.9855 - val_loss: 0.1860 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00253: val_accuracy did not improve from 0.99065\n",
            "Epoch 254/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0700 - accuracy: 0.9941 - val_loss: 0.1568 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00254: val_accuracy did not improve from 0.99065\n",
            "Epoch 255/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.1003 - accuracy: 0.9866 - val_loss: 0.2987 - val_accuracy: 0.9486\n",
            "\n",
            "Epoch 00255: val_accuracy did not improve from 0.99065\n",
            "Epoch 256/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1985 - accuracy: 0.9690 - val_loss: 0.1832 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00256: val_accuracy did not improve from 0.99065\n",
            "Epoch 257/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1084 - accuracy: 0.9950 - val_loss: 0.0783 - val_accuracy: 0.9930\n",
            "\n",
            "Epoch 00257: val_accuracy improved from 0.99065 to 0.99299, saving model to SER_best_initial_model.hdf5\n",
            "Epoch 258/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0789 - accuracy: 0.9908 - val_loss: 0.1011 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00258: val_accuracy did not improve from 0.99299\n",
            "Epoch 259/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0958 - accuracy: 0.9877 - val_loss: 0.2070 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00259: val_accuracy did not improve from 0.99299\n",
            "Epoch 260/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.1241 - accuracy: 0.9852 - val_loss: 0.1695 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00260: val_accuracy did not improve from 0.99299\n",
            "Epoch 261/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0843 - accuracy: 0.9884 - val_loss: 0.1975 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00261: val_accuracy did not improve from 0.99299\n",
            "Epoch 262/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1005 - accuracy: 0.9916 - val_loss: 0.3489 - val_accuracy: 0.9579\n",
            "\n",
            "Epoch 00262: val_accuracy did not improve from 0.99299\n",
            "Epoch 263/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1600 - accuracy: 0.9881 - val_loss: 0.2482 - val_accuracy: 0.9556\n",
            "\n",
            "Epoch 00263: val_accuracy did not improve from 0.99299\n",
            "Epoch 264/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0973 - accuracy: 0.9921 - val_loss: 0.2268 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00264: val_accuracy did not improve from 0.99299\n",
            "Epoch 265/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0949 - accuracy: 0.9942 - val_loss: 0.1198 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00265: val_accuracy did not improve from 0.99299\n",
            "Epoch 266/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0868 - accuracy: 0.9913 - val_loss: 0.2255 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00266: val_accuracy did not improve from 0.99299\n",
            "Epoch 267/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1187 - accuracy: 0.9810 - val_loss: 0.2037 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00267: val_accuracy did not improve from 0.99299\n",
            "Epoch 268/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0983 - accuracy: 0.9893 - val_loss: 0.1808 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00268: val_accuracy did not improve from 0.99299\n",
            "Epoch 269/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0700 - accuracy: 0.9938 - val_loss: 0.1734 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00269: val_accuracy did not improve from 0.99299\n",
            "Epoch 270/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0860 - accuracy: 0.9907 - val_loss: 0.2208 - val_accuracy: 0.9579\n",
            "\n",
            "Epoch 00270: val_accuracy did not improve from 0.99299\n",
            "Epoch 271/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0897 - accuracy: 0.9922 - val_loss: 0.1964 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00271: val_accuracy did not improve from 0.99299\n",
            "Epoch 272/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1295 - accuracy: 0.9810 - val_loss: 0.1958 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00272: val_accuracy did not improve from 0.99299\n",
            "Epoch 273/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1245 - accuracy: 0.9864 - val_loss: 0.1250 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00273: val_accuracy did not improve from 0.99299\n",
            "Epoch 274/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0692 - accuracy: 0.9935 - val_loss: 0.3086 - val_accuracy: 0.9579\n",
            "\n",
            "Epoch 00274: val_accuracy did not improve from 0.99299\n",
            "Epoch 275/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0824 - accuracy: 0.9908 - val_loss: 0.1594 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00275: val_accuracy did not improve from 0.99299\n",
            "Epoch 276/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1128 - accuracy: 0.9881 - val_loss: 0.3372 - val_accuracy: 0.9416\n",
            "\n",
            "Epoch 00276: val_accuracy did not improve from 0.99299\n",
            "Epoch 277/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1592 - accuracy: 0.9862 - val_loss: 0.2110 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00277: val_accuracy did not improve from 0.99299\n",
            "Epoch 278/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.1132 - accuracy: 0.9903 - val_loss: 0.1687 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00278: val_accuracy did not improve from 0.99299\n",
            "Epoch 279/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0824 - accuracy: 0.9907 - val_loss: 0.2338 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00279: val_accuracy did not improve from 0.99299\n",
            "Epoch 280/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0974 - accuracy: 0.9870 - val_loss: 0.2469 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00280: val_accuracy did not improve from 0.99299\n",
            "Epoch 281/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0842 - accuracy: 0.9906 - val_loss: 0.1941 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00281: val_accuracy did not improve from 0.99299\n",
            "Epoch 282/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0652 - accuracy: 0.9914 - val_loss: 0.2051 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00282: val_accuracy did not improve from 0.99299\n",
            "Epoch 283/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1016 - accuracy: 0.9908 - val_loss: 0.4261 - val_accuracy: 0.9603\n",
            "\n",
            "Epoch 00283: val_accuracy did not improve from 0.99299\n",
            "Epoch 284/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1055 - accuracy: 0.9905 - val_loss: 0.1818 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00284: val_accuracy did not improve from 0.99299\n",
            "Epoch 285/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0785 - accuracy: 0.9892 - val_loss: 0.2119 - val_accuracy: 0.9556\n",
            "\n",
            "Epoch 00285: val_accuracy did not improve from 0.99299\n",
            "Epoch 286/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0819 - accuracy: 0.9898 - val_loss: 0.1905 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00286: val_accuracy did not improve from 0.99299\n",
            "Epoch 287/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1565 - accuracy: 0.9899 - val_loss: 0.3360 - val_accuracy: 0.9322\n",
            "\n",
            "Epoch 00287: val_accuracy did not improve from 0.99299\n",
            "Epoch 288/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1080 - accuracy: 0.9902 - val_loss: 0.1713 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00288: val_accuracy did not improve from 0.99299\n",
            "Epoch 289/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0676 - accuracy: 0.9928 - val_loss: 0.1536 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00289: val_accuracy did not improve from 0.99299\n",
            "Epoch 290/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0816 - accuracy: 0.9914 - val_loss: 0.1487 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00290: val_accuracy did not improve from 0.99299\n",
            "Epoch 291/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0867 - accuracy: 0.9938 - val_loss: 0.2664 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00291: val_accuracy did not improve from 0.99299\n",
            "Epoch 292/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0977 - accuracy: 0.9898 - val_loss: 0.1775 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00292: val_accuracy did not improve from 0.99299\n",
            "Epoch 293/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.1360 - accuracy: 0.9887 - val_loss: 0.2806 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00293: val_accuracy did not improve from 0.99299\n",
            "Epoch 294/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1089 - accuracy: 0.9877 - val_loss: 0.2731 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00294: val_accuracy did not improve from 0.99299\n",
            "Epoch 295/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0896 - accuracy: 0.9921 - val_loss: 0.2347 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00295: val_accuracy did not improve from 0.99299\n",
            "Epoch 296/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0748 - accuracy: 0.9959 - val_loss: 0.2124 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00296: val_accuracy did not improve from 0.99299\n",
            "Epoch 297/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0674 - accuracy: 0.9976 - val_loss: 0.2735 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00297: val_accuracy did not improve from 0.99299\n",
            "Epoch 298/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1026 - accuracy: 0.9875 - val_loss: 0.2100 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00298: val_accuracy did not improve from 0.99299\n",
            "Epoch 299/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1236 - accuracy: 0.9845 - val_loss: 0.3361 - val_accuracy: 0.9626\n",
            "\n",
            "Epoch 00299: val_accuracy did not improve from 0.99299\n",
            "Epoch 300/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.1166 - accuracy: 0.9851 - val_loss: 0.1584 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00300: val_accuracy did not improve from 0.99299\n",
            "Epoch 301/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0688 - accuracy: 0.9931 - val_loss: 0.2886 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00301: val_accuracy did not improve from 0.99299\n",
            "Epoch 302/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0857 - accuracy: 0.9914 - val_loss: 0.2457 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00302: val_accuracy did not improve from 0.99299\n",
            "Epoch 303/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1290 - accuracy: 0.9829 - val_loss: 0.3260 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00303: val_accuracy did not improve from 0.99299\n",
            "Epoch 304/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.2207 - accuracy: 0.9770 - val_loss: 0.3107 - val_accuracy: 0.9579\n",
            "\n",
            "Epoch 00304: val_accuracy did not improve from 0.99299\n",
            "Epoch 305/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1315 - accuracy: 0.9863 - val_loss: 0.1688 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00305: val_accuracy did not improve from 0.99299\n",
            "Epoch 306/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0841 - accuracy: 0.9917 - val_loss: 0.1863 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00306: val_accuracy did not improve from 0.99299\n",
            "Epoch 307/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.1123 - accuracy: 0.9891 - val_loss: 0.1725 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00307: val_accuracy did not improve from 0.99299\n",
            "Epoch 308/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0938 - accuracy: 0.9928 - val_loss: 0.1471 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00308: val_accuracy did not improve from 0.99299\n",
            "Epoch 309/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0840 - accuracy: 0.9926 - val_loss: 0.1866 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00309: val_accuracy did not improve from 0.99299\n",
            "Epoch 310/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0549 - accuracy: 0.9986 - val_loss: 0.1809 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00310: val_accuracy did not improve from 0.99299\n",
            "Epoch 311/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0755 - accuracy: 0.9934 - val_loss: 0.1780 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00311: val_accuracy did not improve from 0.99299\n",
            "Epoch 312/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0520 - accuracy: 0.9959 - val_loss: 0.1742 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00312: val_accuracy did not improve from 0.99299\n",
            "Epoch 313/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0649 - accuracy: 0.9961 - val_loss: 0.2362 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00313: val_accuracy did not improve from 0.99299\n",
            "Epoch 314/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0610 - accuracy: 0.9928 - val_loss: 0.1726 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00314: val_accuracy did not improve from 0.99299\n",
            "Epoch 315/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0968 - accuracy: 0.9932 - val_loss: 0.2384 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00315: val_accuracy did not improve from 0.99299\n",
            "Epoch 316/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1251 - accuracy: 0.9911 - val_loss: 0.3109 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00316: val_accuracy did not improve from 0.99299\n",
            "Epoch 317/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.1028 - accuracy: 0.9884 - val_loss: 0.2739 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00317: val_accuracy did not improve from 0.99299\n",
            "Epoch 318/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0776 - accuracy: 0.9910 - val_loss: 0.4220 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00318: val_accuracy did not improve from 0.99299\n",
            "Epoch 319/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0883 - accuracy: 0.9942 - val_loss: 0.3071 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00319: val_accuracy did not improve from 0.99299\n",
            "Epoch 320/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0776 - accuracy: 0.9926 - val_loss: 0.2763 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00320: val_accuracy did not improve from 0.99299\n",
            "Epoch 321/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.1017 - accuracy: 0.9912 - val_loss: 0.2504 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00321: val_accuracy did not improve from 0.99299\n",
            "Epoch 322/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0706 - accuracy: 0.9954 - val_loss: 0.1903 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00322: val_accuracy did not improve from 0.99299\n",
            "Epoch 323/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0784 - accuracy: 0.9910 - val_loss: 0.1966 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00323: val_accuracy did not improve from 0.99299\n",
            "Epoch 324/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0714 - accuracy: 0.9938 - val_loss: 0.2241 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00324: val_accuracy did not improve from 0.99299\n",
            "Epoch 325/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0607 - accuracy: 0.9944 - val_loss: 0.2014 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00325: val_accuracy did not improve from 0.99299\n",
            "Epoch 326/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0795 - accuracy: 0.9963 - val_loss: 0.3537 - val_accuracy: 0.9556\n",
            "\n",
            "Epoch 00326: val_accuracy did not improve from 0.99299\n",
            "Epoch 327/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0753 - accuracy: 0.9944 - val_loss: 0.2233 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00327: val_accuracy did not improve from 0.99299\n",
            "Epoch 328/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0875 - accuracy: 0.9911 - val_loss: 0.4162 - val_accuracy: 0.9603\n",
            "\n",
            "Epoch 00328: val_accuracy did not improve from 0.99299\n",
            "Epoch 329/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1193 - accuracy: 0.9936 - val_loss: 0.1536 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00329: val_accuracy did not improve from 0.99299\n",
            "Epoch 330/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0546 - accuracy: 0.9980 - val_loss: 0.2607 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00330: val_accuracy did not improve from 0.99299\n",
            "Epoch 331/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0399 - accuracy: 0.9982 - val_loss: 0.1887 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00331: val_accuracy did not improve from 0.99299\n",
            "Epoch 332/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0415 - accuracy: 0.9969 - val_loss: 0.2116 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00332: val_accuracy did not improve from 0.99299\n",
            "Epoch 333/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0795 - accuracy: 0.9918 - val_loss: 0.5354 - val_accuracy: 0.9229\n",
            "\n",
            "Epoch 00333: val_accuracy did not improve from 0.99299\n",
            "Epoch 334/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.3454 - accuracy: 0.9623 - val_loss: 0.8601 - val_accuracy: 0.8855\n",
            "\n",
            "Epoch 00334: val_accuracy did not improve from 0.99299\n",
            "Epoch 335/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.2081 - accuracy: 0.9800 - val_loss: 0.4560 - val_accuracy: 0.9556\n",
            "\n",
            "Epoch 00335: val_accuracy did not improve from 0.99299\n",
            "Epoch 336/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1778 - accuracy: 0.9901 - val_loss: 0.2657 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00336: val_accuracy did not improve from 0.99299\n",
            "Epoch 337/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1239 - accuracy: 0.9908 - val_loss: 0.2423 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00337: val_accuracy did not improve from 0.99299\n",
            "Epoch 338/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0823 - accuracy: 0.9962 - val_loss: 0.2250 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00338: val_accuracy did not improve from 0.99299\n",
            "Epoch 339/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0957 - accuracy: 0.9907 - val_loss: 0.1834 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00339: val_accuracy did not improve from 0.99299\n",
            "Epoch 340/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0628 - accuracy: 0.9972 - val_loss: 0.2069 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00340: val_accuracy did not improve from 0.99299\n",
            "Epoch 341/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0952 - accuracy: 0.9909 - val_loss: 0.2028 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00341: val_accuracy did not improve from 0.99299\n",
            "Epoch 342/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0889 - accuracy: 0.9946 - val_loss: 0.1534 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00342: val_accuracy did not improve from 0.99299\n",
            "Epoch 343/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0675 - accuracy: 0.9936 - val_loss: 0.1770 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00343: val_accuracy did not improve from 0.99299\n",
            "Epoch 344/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0756 - accuracy: 0.9947 - val_loss: 0.1404 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00344: val_accuracy did not improve from 0.99299\n",
            "Epoch 345/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0828 - accuracy: 0.9932 - val_loss: 0.2437 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00345: val_accuracy did not improve from 0.99299\n",
            "Epoch 346/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0729 - accuracy: 0.9942 - val_loss: 0.2466 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00346: val_accuracy did not improve from 0.99299\n",
            "Epoch 347/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.1143 - accuracy: 0.9841 - val_loss: 0.2731 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00347: val_accuracy did not improve from 0.99299\n",
            "Epoch 348/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0755 - accuracy: 0.9934 - val_loss: 0.1527 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00348: val_accuracy did not improve from 0.99299\n",
            "Epoch 349/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0560 - accuracy: 0.9992 - val_loss: 0.1515 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00349: val_accuracy did not improve from 0.99299\n",
            "Epoch 350/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0576 - accuracy: 0.9923 - val_loss: 0.1358 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00350: val_accuracy did not improve from 0.99299\n",
            "Epoch 351/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.1250 - accuracy: 0.9861 - val_loss: 0.1100 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00351: val_accuracy did not improve from 0.99299\n",
            "Epoch 352/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0717 - accuracy: 0.9929 - val_loss: 0.1452 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00352: val_accuracy did not improve from 0.99299\n",
            "Epoch 353/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0625 - accuracy: 0.9948 - val_loss: 0.1276 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00353: val_accuracy did not improve from 0.99299\n",
            "Epoch 354/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0672 - accuracy: 0.9940 - val_loss: 0.1624 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00354: val_accuracy did not improve from 0.99299\n",
            "Epoch 355/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.1105 - accuracy: 0.9845 - val_loss: 0.2702 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00355: val_accuracy did not improve from 0.99299\n",
            "Epoch 356/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.1158 - accuracy: 0.9875 - val_loss: 0.2299 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00356: val_accuracy did not improve from 0.99299\n",
            "Epoch 357/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0936 - accuracy: 0.9881 - val_loss: 0.1922 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00357: val_accuracy did not improve from 0.99299\n",
            "Epoch 358/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0588 - accuracy: 0.9972 - val_loss: 0.2165 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00358: val_accuracy did not improve from 0.99299\n",
            "Epoch 359/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0691 - accuracy: 0.9951 - val_loss: 0.2249 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00359: val_accuracy did not improve from 0.99299\n",
            "Epoch 360/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1377 - accuracy: 0.9786 - val_loss: 0.2912 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00360: val_accuracy did not improve from 0.99299\n",
            "Epoch 361/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.1196 - accuracy: 0.9927 - val_loss: 0.3506 - val_accuracy: 0.9579\n",
            "\n",
            "Epoch 00361: val_accuracy did not improve from 0.99299\n",
            "Epoch 362/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1235 - accuracy: 0.9896 - val_loss: 0.2725 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00362: val_accuracy did not improve from 0.99299\n",
            "Epoch 363/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0925 - accuracy: 0.9886 - val_loss: 0.2055 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00363: val_accuracy did not improve from 0.99299\n",
            "Epoch 364/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0964 - accuracy: 0.9896 - val_loss: 0.1431 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00364: val_accuracy did not improve from 0.99299\n",
            "Epoch 365/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0845 - accuracy: 0.9857 - val_loss: 0.1763 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00365: val_accuracy did not improve from 0.99299\n",
            "Epoch 366/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0566 - accuracy: 0.9961 - val_loss: 0.1730 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00366: val_accuracy did not improve from 0.99299\n",
            "Epoch 367/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1600 - accuracy: 0.9863 - val_loss: 0.1303 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00367: val_accuracy did not improve from 0.99299\n",
            "Epoch 368/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0806 - accuracy: 0.9918 - val_loss: 0.1314 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00368: val_accuracy did not improve from 0.99299\n",
            "Epoch 369/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0738 - accuracy: 0.9953 - val_loss: 0.1148 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00369: val_accuracy did not improve from 0.99299\n",
            "Epoch 370/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0983 - accuracy: 0.9905 - val_loss: 0.2146 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00370: val_accuracy did not improve from 0.99299\n",
            "Epoch 371/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0636 - accuracy: 0.9929 - val_loss: 0.1528 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00371: val_accuracy did not improve from 0.99299\n",
            "Epoch 372/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0709 - accuracy: 0.9898 - val_loss: 0.1552 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00372: val_accuracy did not improve from 0.99299\n",
            "Epoch 373/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0901 - accuracy: 0.9897 - val_loss: 0.1263 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00373: val_accuracy did not improve from 0.99299\n",
            "Epoch 374/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0860 - accuracy: 0.9910 - val_loss: 0.1387 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00374: val_accuracy did not improve from 0.99299\n",
            "Epoch 375/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0856 - accuracy: 0.9939 - val_loss: 0.0983 - val_accuracy: 0.9907\n",
            "\n",
            "Epoch 00375: val_accuracy did not improve from 0.99299\n",
            "Epoch 376/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0634 - accuracy: 0.9961 - val_loss: 0.1301 - val_accuracy: 0.9860\n",
            "\n",
            "Epoch 00376: val_accuracy did not improve from 0.99299\n",
            "Epoch 377/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0691 - accuracy: 0.9928 - val_loss: 0.1244 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00377: val_accuracy did not improve from 0.99299\n",
            "Epoch 378/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0674 - accuracy: 0.9923 - val_loss: 0.1228 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00378: val_accuracy did not improve from 0.99299\n",
            "Epoch 379/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0758 - accuracy: 0.9915 - val_loss: 0.2202 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00379: val_accuracy did not improve from 0.99299\n",
            "Epoch 380/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0693 - accuracy: 0.9950 - val_loss: 0.2005 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00380: val_accuracy did not improve from 0.99299\n",
            "Epoch 381/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1611 - accuracy: 0.9871 - val_loss: 0.1471 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00381: val_accuracy did not improve from 0.99299\n",
            "Epoch 382/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0623 - accuracy: 0.9975 - val_loss: 0.1637 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00382: val_accuracy did not improve from 0.99299\n",
            "Epoch 383/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0586 - accuracy: 0.9906 - val_loss: 0.1123 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00383: val_accuracy did not improve from 0.99299\n",
            "Epoch 384/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0755 - accuracy: 0.9936 - val_loss: 0.2743 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00384: val_accuracy did not improve from 0.99299\n",
            "Epoch 385/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.1057 - accuracy: 0.9872 - val_loss: 0.1888 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00385: val_accuracy did not improve from 0.99299\n",
            "Epoch 386/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0799 - accuracy: 0.9912 - val_loss: 0.2101 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00386: val_accuracy did not improve from 0.99299\n",
            "Epoch 387/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0813 - accuracy: 0.9922 - val_loss: 0.1930 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00387: val_accuracy did not improve from 0.99299\n",
            "Epoch 388/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0830 - accuracy: 0.9951 - val_loss: 0.1606 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00388: val_accuracy did not improve from 0.99299\n",
            "Epoch 389/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0700 - accuracy: 0.9939 - val_loss: 0.0980 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00389: val_accuracy did not improve from 0.99299\n",
            "Epoch 390/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0678 - accuracy: 0.9961 - val_loss: 0.1365 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00390: val_accuracy did not improve from 0.99299\n",
            "Epoch 391/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0959 - accuracy: 0.9866 - val_loss: 0.1506 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00391: val_accuracy did not improve from 0.99299\n",
            "Epoch 392/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0745 - accuracy: 0.9912 - val_loss: 0.1232 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00392: val_accuracy did not improve from 0.99299\n",
            "Epoch 393/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0680 - accuracy: 0.9884 - val_loss: 0.1426 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00393: val_accuracy did not improve from 0.99299\n",
            "Epoch 394/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0586 - accuracy: 0.9932 - val_loss: 0.1503 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00394: val_accuracy did not improve from 0.99299\n",
            "Epoch 395/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0591 - accuracy: 0.9953 - val_loss: 0.2005 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00395: val_accuracy did not improve from 0.99299\n",
            "Epoch 396/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0559 - accuracy: 0.9940 - val_loss: 0.2103 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00396: val_accuracy did not improve from 0.99299\n",
            "Epoch 397/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0666 - accuracy: 0.9932 - val_loss: 0.2158 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00397: val_accuracy did not improve from 0.99299\n",
            "Epoch 398/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0993 - accuracy: 0.9869 - val_loss: 0.3317 - val_accuracy: 0.9603\n",
            "\n",
            "Epoch 00398: val_accuracy did not improve from 0.99299\n",
            "Epoch 399/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.1183 - accuracy: 0.9879 - val_loss: 0.2264 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00399: val_accuracy did not improve from 0.99299\n",
            "Epoch 400/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0793 - accuracy: 0.9922 - val_loss: 0.2274 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00400: val_accuracy did not improve from 0.99299\n",
            "Epoch 401/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0880 - accuracy: 0.9919 - val_loss: 0.1771 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00401: val_accuracy did not improve from 0.99299\n",
            "Epoch 402/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0497 - accuracy: 0.9943 - val_loss: 0.1491 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00402: val_accuracy did not improve from 0.99299\n",
            "Epoch 403/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0601 - accuracy: 0.9960 - val_loss: 0.1385 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00403: val_accuracy did not improve from 0.99299\n",
            "Epoch 404/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0744 - accuracy: 0.9926 - val_loss: 0.1614 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00404: val_accuracy did not improve from 0.99299\n",
            "Epoch 405/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0417 - accuracy: 0.9985 - val_loss: 0.1480 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00405: val_accuracy did not improve from 0.99299\n",
            "Epoch 406/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0639 - accuracy: 0.9930 - val_loss: 0.1526 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00406: val_accuracy did not improve from 0.99299\n",
            "Epoch 407/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0459 - accuracy: 0.9975 - val_loss: 0.1885 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00407: val_accuracy did not improve from 0.99299\n",
            "Epoch 408/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0354 - accuracy: 0.9987 - val_loss: 0.1386 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00408: val_accuracy did not improve from 0.99299\n",
            "Epoch 409/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0372 - accuracy: 0.9963 - val_loss: 0.2119 - val_accuracy: 0.9626\n",
            "\n",
            "Epoch 00409: val_accuracy did not improve from 0.99299\n",
            "Epoch 410/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0820 - accuracy: 0.9920 - val_loss: 0.2948 - val_accuracy: 0.9579\n",
            "\n",
            "Epoch 00410: val_accuracy did not improve from 0.99299\n",
            "Epoch 411/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0675 - accuracy: 0.9910 - val_loss: 0.1393 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00411: val_accuracy did not improve from 0.99299\n",
            "Epoch 412/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0631 - accuracy: 0.9937 - val_loss: 0.1185 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00412: val_accuracy did not improve from 0.99299\n",
            "Epoch 413/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.1142 - accuracy: 0.9857 - val_loss: 0.1667 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00413: val_accuracy did not improve from 0.99299\n",
            "Epoch 414/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0825 - accuracy: 0.9928 - val_loss: 0.1836 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00414: val_accuracy did not improve from 0.99299\n",
            "Epoch 415/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0909 - accuracy: 0.9920 - val_loss: 0.1002 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00415: val_accuracy did not improve from 0.99299\n",
            "Epoch 416/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0529 - accuracy: 0.9978 - val_loss: 0.1251 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00416: val_accuracy did not improve from 0.99299\n",
            "Epoch 417/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0617 - accuracy: 0.9965 - val_loss: 0.1551 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00417: val_accuracy did not improve from 0.99299\n",
            "Epoch 418/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0458 - accuracy: 0.9969 - val_loss: 0.0978 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00418: val_accuracy did not improve from 0.99299\n",
            "Epoch 419/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0448 - accuracy: 0.9954 - val_loss: 0.1280 - val_accuracy: 0.9860\n",
            "\n",
            "Epoch 00419: val_accuracy did not improve from 0.99299\n",
            "Epoch 420/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1019 - accuracy: 0.9854 - val_loss: 0.2723 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00420: val_accuracy did not improve from 0.99299\n",
            "Epoch 421/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0708 - accuracy: 0.9949 - val_loss: 0.1195 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00421: val_accuracy did not improve from 0.99299\n",
            "Epoch 422/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0656 - accuracy: 0.9938 - val_loss: 0.1742 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00422: val_accuracy did not improve from 0.99299\n",
            "Epoch 423/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0833 - accuracy: 0.9924 - val_loss: 0.1416 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00423: val_accuracy did not improve from 0.99299\n",
            "Epoch 424/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0761 - accuracy: 0.9949 - val_loss: 0.1766 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00424: val_accuracy did not improve from 0.99299\n",
            "Epoch 425/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0547 - accuracy: 0.9979 - val_loss: 0.2075 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00425: val_accuracy did not improve from 0.99299\n",
            "Epoch 426/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0731 - accuracy: 0.9916 - val_loss: 0.1225 - val_accuracy: 0.9883\n",
            "\n",
            "Epoch 00426: val_accuracy did not improve from 0.99299\n",
            "Epoch 427/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0616 - accuracy: 0.9948 - val_loss: 0.1016 - val_accuracy: 0.9860\n",
            "\n",
            "Epoch 00427: val_accuracy did not improve from 0.99299\n",
            "Epoch 428/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.1054 - accuracy: 0.9915 - val_loss: 0.1125 - val_accuracy: 0.9860\n",
            "\n",
            "Epoch 00428: val_accuracy did not improve from 0.99299\n",
            "Epoch 429/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0973 - accuracy: 0.9912 - val_loss: 0.2007 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00429: val_accuracy did not improve from 0.99299\n",
            "Epoch 430/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0640 - accuracy: 0.9927 - val_loss: 0.1469 - val_accuracy: 0.9860\n",
            "\n",
            "Epoch 00430: val_accuracy did not improve from 0.99299\n",
            "Epoch 431/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0443 - accuracy: 0.9991 - val_loss: 0.1245 - val_accuracy: 0.9860\n",
            "\n",
            "Epoch 00431: val_accuracy did not improve from 0.99299\n",
            "Epoch 432/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0338 - accuracy: 0.9984 - val_loss: 0.0870 - val_accuracy: 0.9860\n",
            "\n",
            "Epoch 00432: val_accuracy did not improve from 0.99299\n",
            "Epoch 433/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0581 - accuracy: 0.9907 - val_loss: 0.2241 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00433: val_accuracy did not improve from 0.99299\n",
            "Epoch 434/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0439 - accuracy: 0.9994 - val_loss: 0.2279 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00434: val_accuracy did not improve from 0.99299\n",
            "Epoch 435/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0880 - accuracy: 0.9918 - val_loss: 0.2834 - val_accuracy: 0.9486\n",
            "\n",
            "Epoch 00435: val_accuracy did not improve from 0.99299\n",
            "Epoch 436/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0795 - accuracy: 0.9907 - val_loss: 0.1641 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00436: val_accuracy did not improve from 0.99299\n",
            "Epoch 437/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0808 - accuracy: 0.9933 - val_loss: 0.2669 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00437: val_accuracy did not improve from 0.99299\n",
            "Epoch 438/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0844 - accuracy: 0.9933 - val_loss: 0.2364 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00438: val_accuracy did not improve from 0.99299\n",
            "Epoch 439/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0621 - accuracy: 0.9963 - val_loss: 0.2269 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00439: val_accuracy did not improve from 0.99299\n",
            "Epoch 440/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0588 - accuracy: 0.9951 - val_loss: 0.1899 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00440: val_accuracy did not improve from 0.99299\n",
            "Epoch 441/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0759 - accuracy: 0.9948 - val_loss: 0.1780 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00441: val_accuracy did not improve from 0.99299\n",
            "Epoch 442/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0562 - accuracy: 0.9939 - val_loss: 0.1840 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00442: val_accuracy did not improve from 0.99299\n",
            "Epoch 443/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0490 - accuracy: 0.9960 - val_loss: 0.1955 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00443: val_accuracy did not improve from 0.99299\n",
            "Epoch 444/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0415 - accuracy: 0.9964 - val_loss: 0.1859 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00444: val_accuracy did not improve from 0.99299\n",
            "Epoch 445/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0646 - accuracy: 0.9949 - val_loss: 0.3334 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00445: val_accuracy did not improve from 0.99299\n",
            "Epoch 446/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0789 - accuracy: 0.9904 - val_loss: 0.2362 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00446: val_accuracy did not improve from 0.99299\n",
            "Epoch 447/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.1311 - accuracy: 0.9881 - val_loss: 0.1584 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00447: val_accuracy did not improve from 0.99299\n",
            "Epoch 448/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0651 - accuracy: 0.9961 - val_loss: 0.1866 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00448: val_accuracy did not improve from 0.99299\n",
            "Epoch 449/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0990 - accuracy: 0.9914 - val_loss: 0.1588 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00449: val_accuracy did not improve from 0.99299\n",
            "Epoch 450/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0785 - accuracy: 0.9909 - val_loss: 0.2025 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00450: val_accuracy did not improve from 0.99299\n",
            "Epoch 451/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1388 - accuracy: 0.9885 - val_loss: 0.1241 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00451: val_accuracy did not improve from 0.99299\n",
            "Epoch 452/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0717 - accuracy: 0.9897 - val_loss: 0.1279 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00452: val_accuracy did not improve from 0.99299\n",
            "Epoch 453/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0511 - accuracy: 0.9972 - val_loss: 0.1368 - val_accuracy: 0.9860\n",
            "\n",
            "Epoch 00453: val_accuracy did not improve from 0.99299\n",
            "Epoch 454/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0396 - accuracy: 0.9985 - val_loss: 0.1266 - val_accuracy: 0.9883\n",
            "\n",
            "Epoch 00454: val_accuracy did not improve from 0.99299\n",
            "Epoch 455/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0399 - accuracy: 0.9972 - val_loss: 0.1385 - val_accuracy: 0.9860\n",
            "\n",
            "Epoch 00455: val_accuracy did not improve from 0.99299\n",
            "Epoch 456/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0279 - accuracy: 0.9991 - val_loss: 0.0905 - val_accuracy: 0.9907\n",
            "\n",
            "Epoch 00456: val_accuracy did not improve from 0.99299\n",
            "Epoch 457/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0741 - accuracy: 0.9951 - val_loss: 0.3341 - val_accuracy: 0.9579\n",
            "\n",
            "Epoch 00457: val_accuracy did not improve from 0.99299\n",
            "Epoch 458/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0460 - accuracy: 0.9964 - val_loss: 0.1159 - val_accuracy: 0.9883\n",
            "\n",
            "Epoch 00458: val_accuracy did not improve from 0.99299\n",
            "Epoch 459/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0707 - accuracy: 0.9924 - val_loss: 0.1197 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00459: val_accuracy did not improve from 0.99299\n",
            "Epoch 460/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.1153 - accuracy: 0.9893 - val_loss: 0.2215 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00460: val_accuracy did not improve from 0.99299\n",
            "Epoch 461/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0913 - accuracy: 0.9885 - val_loss: 0.1819 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00461: val_accuracy did not improve from 0.99299\n",
            "Epoch 462/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0754 - accuracy: 0.9932 - val_loss: 0.1154 - val_accuracy: 0.9860\n",
            "\n",
            "Epoch 00462: val_accuracy did not improve from 0.99299\n",
            "Epoch 463/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0842 - accuracy: 0.9922 - val_loss: 0.1022 - val_accuracy: 0.9860\n",
            "\n",
            "Epoch 00463: val_accuracy did not improve from 0.99299\n",
            "Epoch 464/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0530 - accuracy: 0.9978 - val_loss: 0.1775 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00464: val_accuracy did not improve from 0.99299\n",
            "Epoch 465/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.1014 - accuracy: 0.9874 - val_loss: 0.1267 - val_accuracy: 0.9907\n",
            "\n",
            "Epoch 00465: val_accuracy did not improve from 0.99299\n",
            "Epoch 466/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0716 - accuracy: 0.9944 - val_loss: 0.1220 - val_accuracy: 0.9860\n",
            "\n",
            "Epoch 00466: val_accuracy did not improve from 0.99299\n",
            "Epoch 467/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0902 - accuracy: 0.9935 - val_loss: 0.1524 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00467: val_accuracy did not improve from 0.99299\n",
            "Epoch 468/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.1177 - accuracy: 0.9886 - val_loss: 0.2016 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00468: val_accuracy did not improve from 0.99299\n",
            "Epoch 469/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0681 - accuracy: 0.9960 - val_loss: 0.1523 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00469: val_accuracy did not improve from 0.99299\n",
            "Epoch 470/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0586 - accuracy: 0.9958 - val_loss: 0.1681 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00470: val_accuracy did not improve from 0.99299\n",
            "Epoch 471/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0629 - accuracy: 0.9935 - val_loss: 0.1230 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00471: val_accuracy did not improve from 0.99299\n",
            "Epoch 472/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0572 - accuracy: 0.9941 - val_loss: 0.0723 - val_accuracy: 0.9860\n",
            "\n",
            "Epoch 00472: val_accuracy did not improve from 0.99299\n",
            "Epoch 473/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0400 - accuracy: 0.9973 - val_loss: 0.0544 - val_accuracy: 0.9883\n",
            "\n",
            "Epoch 00473: val_accuracy did not improve from 0.99299\n",
            "Epoch 474/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0996 - accuracy: 0.9894 - val_loss: 0.1118 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00474: val_accuracy did not improve from 0.99299\n",
            "Epoch 475/1000\n",
            "54/54 [==============================] - 1s 22ms/step - loss: 0.0405 - accuracy: 0.9960 - val_loss: 0.0931 - val_accuracy: 0.9860\n",
            "\n",
            "Epoch 00475: val_accuracy did not improve from 0.99299\n",
            "Epoch 476/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0379 - accuracy: 0.9964 - val_loss: 0.0765 - val_accuracy: 0.9883\n",
            "\n",
            "Epoch 00476: val_accuracy did not improve from 0.99299\n",
            "Epoch 477/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0316 - accuracy: 0.9991 - val_loss: 0.1052 - val_accuracy: 0.9883\n",
            "\n",
            "Epoch 00477: val_accuracy did not improve from 0.99299\n",
            "Epoch 478/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0280 - accuracy: 0.9986 - val_loss: 0.0795 - val_accuracy: 0.9907\n",
            "\n",
            "Epoch 00478: val_accuracy did not improve from 0.99299\n",
            "Epoch 479/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0412 - accuracy: 0.9971 - val_loss: 0.1369 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00479: val_accuracy did not improve from 0.99299\n",
            "Epoch 480/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0398 - accuracy: 0.9968 - val_loss: 0.2180 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00480: val_accuracy did not improve from 0.99299\n",
            "Epoch 481/1000\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.0648 - accuracy: 0.9925 - val_loss: 0.3215 - val_accuracy: 0.9556\n",
            "\n",
            "Epoch 00481: val_accuracy did not improve from 0.99299\n",
            "Epoch 482/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0774 - accuracy: 0.9918 - val_loss: 0.3116 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00482: val_accuracy did not improve from 0.99299\n",
            "Epoch 483/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0711 - accuracy: 0.9918 - val_loss: 0.1966 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00483: val_accuracy did not improve from 0.99299\n",
            "Epoch 484/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0921 - accuracy: 0.9861 - val_loss: 0.2142 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00484: val_accuracy did not improve from 0.99299\n",
            "Epoch 485/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0598 - accuracy: 0.9937 - val_loss: 0.2087 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00485: val_accuracy did not improve from 0.99299\n",
            "Epoch 486/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0646 - accuracy: 0.9941 - val_loss: 0.1471 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00486: val_accuracy did not improve from 0.99299\n",
            "Epoch 487/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0505 - accuracy: 0.9962 - val_loss: 0.1492 - val_accuracy: 0.9860\n",
            "\n",
            "Epoch 00487: val_accuracy did not improve from 0.99299\n",
            "Epoch 488/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0421 - accuracy: 0.9977 - val_loss: 0.1423 - val_accuracy: 0.9860\n",
            "\n",
            "Epoch 00488: val_accuracy did not improve from 0.99299\n",
            "Epoch 489/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0463 - accuracy: 0.9968 - val_loss: 0.6575 - val_accuracy: 0.9439\n",
            "\n",
            "Epoch 00489: val_accuracy did not improve from 0.99299\n",
            "Epoch 490/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0654 - accuracy: 0.9939 - val_loss: 0.1852 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00490: val_accuracy did not improve from 0.99299\n",
            "Epoch 491/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0542 - accuracy: 0.9970 - val_loss: 0.2273 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00491: val_accuracy did not improve from 0.99299\n",
            "Epoch 492/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0821 - accuracy: 0.9940 - val_loss: 0.1670 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00492: val_accuracy did not improve from 0.99299\n",
            "Epoch 493/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0467 - accuracy: 0.9980 - val_loss: 0.1595 - val_accuracy: 0.9883\n",
            "\n",
            "Epoch 00493: val_accuracy did not improve from 0.99299\n",
            "Epoch 494/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0846 - accuracy: 0.9929 - val_loss: 0.1544 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00494: val_accuracy did not improve from 0.99299\n",
            "Epoch 495/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0751 - accuracy: 0.9935 - val_loss: 0.2143 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00495: val_accuracy did not improve from 0.99299\n",
            "Epoch 496/1000\n",
            "54/54 [==============================] - 1s 22ms/step - loss: 0.0703 - accuracy: 0.9952 - val_loss: 0.1563 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00496: val_accuracy did not improve from 0.99299\n",
            "Epoch 497/1000\n",
            "54/54 [==============================] - 1s 22ms/step - loss: 0.0988 - accuracy: 0.9939 - val_loss: 0.1076 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00497: val_accuracy did not improve from 0.99299\n",
            "Epoch 498/1000\n",
            "54/54 [==============================] - 1s 22ms/step - loss: 0.0463 - accuracy: 0.9974 - val_loss: 0.1583 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00498: val_accuracy did not improve from 0.99299\n",
            "Epoch 499/1000\n",
            "54/54 [==============================] - 1s 22ms/step - loss: 0.1117 - accuracy: 0.9906 - val_loss: 0.1267 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00499: val_accuracy did not improve from 0.99299\n",
            "Epoch 500/1000\n",
            "54/54 [==============================] - 1s 22ms/step - loss: 0.0607 - accuracy: 0.9894 - val_loss: 0.1249 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00500: val_accuracy did not improve from 0.99299\n",
            "Epoch 501/1000\n",
            "54/54 [==============================] - 1s 23ms/step - loss: 0.0375 - accuracy: 0.9988 - val_loss: 0.1381 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00501: val_accuracy did not improve from 0.99299\n",
            "Epoch 502/1000\n",
            "54/54 [==============================] - 1s 22ms/step - loss: 0.0721 - accuracy: 0.9951 - val_loss: 0.1387 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00502: val_accuracy did not improve from 0.99299\n",
            "Epoch 503/1000\n",
            "54/54 [==============================] - 1s 23ms/step - loss: 0.0523 - accuracy: 0.9975 - val_loss: 0.1691 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00503: val_accuracy did not improve from 0.99299\n",
            "Epoch 504/1000\n",
            "54/54 [==============================] - 1s 22ms/step - loss: 0.0831 - accuracy: 0.9944 - val_loss: 0.3433 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00504: val_accuracy did not improve from 0.99299\n",
            "Epoch 505/1000\n",
            "54/54 [==============================] - 1s 22ms/step - loss: 0.0869 - accuracy: 0.9912 - val_loss: 0.1531 - val_accuracy: 0.9860\n",
            "\n",
            "Epoch 00505: val_accuracy did not improve from 0.99299\n",
            "Epoch 506/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0719 - accuracy: 0.9945 - val_loss: 0.1711 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00506: val_accuracy did not improve from 0.99299\n",
            "Epoch 507/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0629 - accuracy: 0.9938 - val_loss: 0.1207 - val_accuracy: 0.9883\n",
            "\n",
            "Epoch 00507: val_accuracy did not improve from 0.99299\n",
            "Epoch 508/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0598 - accuracy: 0.9953 - val_loss: 0.1535 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00508: val_accuracy did not improve from 0.99299\n",
            "Epoch 509/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0677 - accuracy: 0.9957 - val_loss: 0.1726 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00509: val_accuracy did not improve from 0.99299\n",
            "Epoch 510/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0722 - accuracy: 0.9947 - val_loss: 0.1263 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00510: val_accuracy did not improve from 0.99299\n",
            "Epoch 511/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0527 - accuracy: 0.9980 - val_loss: 0.1356 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00511: val_accuracy did not improve from 0.99299\n",
            "Epoch 512/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0364 - accuracy: 0.9987 - val_loss: 0.1026 - val_accuracy: 0.9860\n",
            "\n",
            "Epoch 00512: val_accuracy did not improve from 0.99299\n",
            "Epoch 513/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0531 - accuracy: 0.9981 - val_loss: 0.1242 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00513: val_accuracy did not improve from 0.99299\n",
            "Epoch 514/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.1100 - accuracy: 0.9956 - val_loss: 0.2257 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00514: val_accuracy did not improve from 0.99299\n",
            "Epoch 515/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0615 - accuracy: 0.9960 - val_loss: 0.1840 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00515: val_accuracy did not improve from 0.99299\n",
            "Epoch 516/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0584 - accuracy: 0.9938 - val_loss: 0.2799 - val_accuracy: 0.9860\n",
            "\n",
            "Epoch 00516: val_accuracy did not improve from 0.99299\n",
            "Epoch 517/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.1176 - accuracy: 0.9926 - val_loss: 0.1375 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00517: val_accuracy did not improve from 0.99299\n",
            "Epoch 518/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0953 - accuracy: 0.9936 - val_loss: 0.1310 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00518: val_accuracy did not improve from 0.99299\n",
            "Epoch 519/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0477 - accuracy: 0.9990 - val_loss: 0.1386 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00519: val_accuracy did not improve from 0.99299\n",
            "Epoch 520/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0964 - accuracy: 0.9912 - val_loss: 0.1821 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00520: val_accuracy did not improve from 0.99299\n",
            "Epoch 521/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0726 - accuracy: 0.9920 - val_loss: 0.1340 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00521: val_accuracy did not improve from 0.99299\n",
            "Epoch 522/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0728 - accuracy: 0.9945 - val_loss: 0.1911 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00522: val_accuracy did not improve from 0.99299\n",
            "Epoch 523/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0884 - accuracy: 0.9926 - val_loss: 0.1174 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00523: val_accuracy did not improve from 0.99299\n",
            "Epoch 524/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0598 - accuracy: 0.9965 - val_loss: 0.1043 - val_accuracy: 0.9883\n",
            "\n",
            "Epoch 00524: val_accuracy did not improve from 0.99299\n",
            "Epoch 525/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0506 - accuracy: 0.9988 - val_loss: 0.1449 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00525: val_accuracy did not improve from 0.99299\n",
            "Epoch 526/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0513 - accuracy: 0.9932 - val_loss: 0.1857 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00526: val_accuracy did not improve from 0.99299\n",
            "Epoch 527/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0521 - accuracy: 0.9981 - val_loss: 0.1797 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00527: val_accuracy did not improve from 0.99299\n",
            "Epoch 528/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0698 - accuracy: 0.9913 - val_loss: 0.2321 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00528: val_accuracy did not improve from 0.99299\n",
            "Epoch 529/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0540 - accuracy: 0.9933 - val_loss: 0.1728 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00529: val_accuracy did not improve from 0.99299\n",
            "Epoch 530/1000\n",
            "54/54 [==============================] - 1s 22ms/step - loss: 0.0760 - accuracy: 0.9945 - val_loss: 0.4267 - val_accuracy: 0.9509\n",
            "\n",
            "Epoch 00530: val_accuracy did not improve from 0.99299\n",
            "Epoch 531/1000\n",
            "54/54 [==============================] - 1s 22ms/step - loss: 0.1095 - accuracy: 0.9883 - val_loss: 0.1721 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00531: val_accuracy did not improve from 0.99299\n",
            "Epoch 532/1000\n",
            "54/54 [==============================] - 1s 22ms/step - loss: 0.0770 - accuracy: 0.9947 - val_loss: 0.1302 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00532: val_accuracy did not improve from 0.99299\n",
            "Epoch 533/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0631 - accuracy: 0.9926 - val_loss: 0.1169 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00533: val_accuracy did not improve from 0.99299\n",
            "Epoch 534/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0409 - accuracy: 0.9996 - val_loss: 0.1087 - val_accuracy: 0.9907\n",
            "\n",
            "Epoch 00534: val_accuracy did not improve from 0.99299\n",
            "Epoch 535/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0378 - accuracy: 0.9990 - val_loss: 0.2359 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00535: val_accuracy did not improve from 0.99299\n",
            "Epoch 536/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0807 - accuracy: 0.9922 - val_loss: 0.1816 - val_accuracy: 0.9860\n",
            "\n",
            "Epoch 00536: val_accuracy did not improve from 0.99299\n",
            "Epoch 537/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0487 - accuracy: 0.9953 - val_loss: 0.1974 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00537: val_accuracy did not improve from 0.99299\n",
            "Epoch 538/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0756 - accuracy: 0.9973 - val_loss: 0.2071 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00538: val_accuracy did not improve from 0.99299\n",
            "Epoch 539/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0806 - accuracy: 0.9944 - val_loss: 0.2285 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00539: val_accuracy did not improve from 0.99299\n",
            "Epoch 540/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0972 - accuracy: 0.9925 - val_loss: 0.1808 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00540: val_accuracy did not improve from 0.99299\n",
            "Epoch 541/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0543 - accuracy: 0.9978 - val_loss: 0.1549 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00541: val_accuracy did not improve from 0.99299\n",
            "Epoch 542/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0421 - accuracy: 0.9966 - val_loss: 0.1509 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00542: val_accuracy did not improve from 0.99299\n",
            "Epoch 543/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0461 - accuracy: 0.9958 - val_loss: 0.2307 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00543: val_accuracy did not improve from 0.99299\n",
            "Epoch 544/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0635 - accuracy: 0.9948 - val_loss: 0.1631 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00544: val_accuracy did not improve from 0.99299\n",
            "Epoch 545/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0903 - accuracy: 0.9920 - val_loss: 0.2476 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00545: val_accuracy did not improve from 0.99299\n",
            "Epoch 546/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0740 - accuracy: 0.9945 - val_loss: 0.1631 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00546: val_accuracy did not improve from 0.99299\n",
            "Epoch 547/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0572 - accuracy: 0.9968 - val_loss: 0.3898 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00547: val_accuracy did not improve from 0.99299\n",
            "Epoch 548/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0595 - accuracy: 0.9972 - val_loss: 0.1538 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00548: val_accuracy did not improve from 0.99299\n",
            "Epoch 549/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0619 - accuracy: 0.9966 - val_loss: 0.2065 - val_accuracy: 0.9860\n",
            "\n",
            "Epoch 00549: val_accuracy did not improve from 0.99299\n",
            "Epoch 550/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0589 - accuracy: 0.9944 - val_loss: 0.2041 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00550: val_accuracy did not improve from 0.99299\n",
            "Epoch 551/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0440 - accuracy: 0.9966 - val_loss: 0.1823 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00551: val_accuracy did not improve from 0.99299\n",
            "Epoch 552/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0490 - accuracy: 0.9917 - val_loss: 0.1934 - val_accuracy: 0.9860\n",
            "\n",
            "Epoch 00552: val_accuracy did not improve from 0.99299\n",
            "Epoch 553/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.1374 - accuracy: 0.9959 - val_loss: 0.1324 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00553: val_accuracy did not improve from 0.99299\n",
            "Epoch 554/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0542 - accuracy: 0.9949 - val_loss: 0.2009 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00554: val_accuracy did not improve from 0.99299\n",
            "Epoch 555/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.1164 - accuracy: 0.9920 - val_loss: 0.3065 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00555: val_accuracy did not improve from 0.99299\n",
            "Epoch 556/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0774 - accuracy: 0.9917 - val_loss: 0.2270 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00556: val_accuracy did not improve from 0.99299\n",
            "Epoch 557/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0716 - accuracy: 0.9915 - val_loss: 0.1999 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00557: val_accuracy did not improve from 0.99299\n",
            "Epoch 558/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0746 - accuracy: 0.9906 - val_loss: 0.3052 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00558: val_accuracy did not improve from 0.99299\n",
            "Epoch 559/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0825 - accuracy: 0.9919 - val_loss: 0.1581 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00559: val_accuracy did not improve from 0.99299\n",
            "Epoch 560/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0565 - accuracy: 0.9970 - val_loss: 0.1467 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00560: val_accuracy did not improve from 0.99299\n",
            "Epoch 561/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0863 - accuracy: 0.9897 - val_loss: 0.1320 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00561: val_accuracy did not improve from 0.99299\n",
            "Epoch 562/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0639 - accuracy: 0.9943 - val_loss: 0.1629 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00562: val_accuracy did not improve from 0.99299\n",
            "Epoch 563/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0405 - accuracy: 0.9980 - val_loss: 0.1557 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00563: val_accuracy did not improve from 0.99299\n",
            "Epoch 564/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0672 - accuracy: 0.9941 - val_loss: 0.2603 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00564: val_accuracy did not improve from 0.99299\n",
            "Epoch 565/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0445 - accuracy: 0.9960 - val_loss: 0.1544 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00565: val_accuracy did not improve from 0.99299\n",
            "Epoch 566/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0516 - accuracy: 0.9907 - val_loss: 0.2055 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00566: val_accuracy did not improve from 0.99299\n",
            "Epoch 567/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0493 - accuracy: 0.9970 - val_loss: 0.1347 - val_accuracy: 0.9860\n",
            "\n",
            "Epoch 00567: val_accuracy did not improve from 0.99299\n",
            "Epoch 568/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0425 - accuracy: 0.9985 - val_loss: 0.1202 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00568: val_accuracy did not improve from 0.99299\n",
            "Epoch 569/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0366 - accuracy: 0.9994 - val_loss: 0.1393 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00569: val_accuracy did not improve from 0.99299\n",
            "Epoch 570/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0392 - accuracy: 0.9980 - val_loss: 0.2087 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00570: val_accuracy did not improve from 0.99299\n",
            "Epoch 571/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0310 - accuracy: 0.9980 - val_loss: 0.2009 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00571: val_accuracy did not improve from 0.99299\n",
            "Epoch 572/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0530 - accuracy: 0.9980 - val_loss: 0.1713 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00572: val_accuracy did not improve from 0.99299\n",
            "Epoch 573/1000\n",
            "54/54 [==============================] - 1s 22ms/step - loss: 0.0340 - accuracy: 0.9972 - val_loss: 0.1272 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00573: val_accuracy did not improve from 0.99299\n",
            "Epoch 574/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0343 - accuracy: 0.9965 - val_loss: 0.4921 - val_accuracy: 0.9369\n",
            "\n",
            "Epoch 00574: val_accuracy did not improve from 0.99299\n",
            "Epoch 575/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0833 - accuracy: 0.9915 - val_loss: 0.1069 - val_accuracy: 0.9860\n",
            "\n",
            "Epoch 00575: val_accuracy did not improve from 0.99299\n",
            "Epoch 576/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0471 - accuracy: 0.9980 - val_loss: 0.1048 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00576: val_accuracy did not improve from 0.99299\n",
            "Epoch 577/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.1433 - accuracy: 0.9940 - val_loss: 0.2080 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00577: val_accuracy did not improve from 0.99299\n",
            "Epoch 578/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.1002 - accuracy: 0.9907 - val_loss: 0.1817 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00578: val_accuracy did not improve from 0.99299\n",
            "Epoch 579/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0559 - accuracy: 0.9943 - val_loss: 0.1481 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00579: val_accuracy did not improve from 0.99299\n",
            "Epoch 580/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0560 - accuracy: 0.9953 - val_loss: 0.1439 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00580: val_accuracy did not improve from 0.99299\n",
            "Epoch 581/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0577 - accuracy: 0.9966 - val_loss: 0.1372 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00581: val_accuracy did not improve from 0.99299\n",
            "Epoch 582/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0420 - accuracy: 0.9971 - val_loss: 0.1705 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00582: val_accuracy did not improve from 0.99299\n",
            "Epoch 583/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0608 - accuracy: 0.9932 - val_loss: 0.1973 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00583: val_accuracy did not improve from 0.99299\n",
            "Epoch 584/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0653 - accuracy: 0.9900 - val_loss: 0.1725 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00584: val_accuracy did not improve from 0.99299\n",
            "Epoch 585/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0392 - accuracy: 0.9977 - val_loss: 0.1482 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00585: val_accuracy did not improve from 0.99299\n",
            "Epoch 586/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0468 - accuracy: 0.9968 - val_loss: 0.1193 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00586: val_accuracy did not improve from 0.99299\n",
            "Epoch 587/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0478 - accuracy: 0.9952 - val_loss: 0.2338 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00587: val_accuracy did not improve from 0.99299\n",
            "Epoch 588/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0766 - accuracy: 0.9910 - val_loss: 0.1661 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00588: val_accuracy did not improve from 0.99299\n",
            "Epoch 589/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0401 - accuracy: 0.9986 - val_loss: 0.1586 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00589: val_accuracy did not improve from 0.99299\n",
            "Epoch 590/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0950 - accuracy: 0.9908 - val_loss: 0.1251 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00590: val_accuracy did not improve from 0.99299\n",
            "Epoch 591/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0548 - accuracy: 0.9952 - val_loss: 0.1275 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00591: val_accuracy did not improve from 0.99299\n",
            "Epoch 592/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0909 - accuracy: 0.9902 - val_loss: 0.3584 - val_accuracy: 0.9603\n",
            "\n",
            "Epoch 00592: val_accuracy did not improve from 0.99299\n",
            "Epoch 593/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0689 - accuracy: 0.9924 - val_loss: 0.1700 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00593: val_accuracy did not improve from 0.99299\n",
            "Epoch 594/1000\n",
            "54/54 [==============================] - 1s 22ms/step - loss: 0.0592 - accuracy: 0.9937 - val_loss: 0.2495 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00594: val_accuracy did not improve from 0.99299\n",
            "Epoch 595/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0465 - accuracy: 0.9958 - val_loss: 0.2351 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00595: val_accuracy did not improve from 0.99299\n",
            "Epoch 596/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0490 - accuracy: 0.9971 - val_loss: 0.1823 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00596: val_accuracy did not improve from 0.99299\n",
            "Epoch 597/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0396 - accuracy: 0.9989 - val_loss: 0.1760 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00597: val_accuracy did not improve from 0.99299\n",
            "Epoch 598/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0508 - accuracy: 0.9977 - val_loss: 0.2775 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00598: val_accuracy did not improve from 0.99299\n",
            "Epoch 599/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.1014 - accuracy: 0.9909 - val_loss: 0.2415 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00599: val_accuracy did not improve from 0.99299\n",
            "Epoch 600/1000\n",
            "54/54 [==============================] - 1s 22ms/step - loss: 0.0736 - accuracy: 0.9952 - val_loss: 0.2053 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00600: val_accuracy did not improve from 0.99299\n",
            "Epoch 601/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0411 - accuracy: 0.9990 - val_loss: 0.1886 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00601: val_accuracy did not improve from 0.99299\n",
            "Epoch 602/1000\n",
            "54/54 [==============================] - 1s 22ms/step - loss: 0.0387 - accuracy: 0.9977 - val_loss: 0.2180 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00602: val_accuracy did not improve from 0.99299\n",
            "Epoch 603/1000\n",
            "54/54 [==============================] - 1s 22ms/step - loss: 0.0359 - accuracy: 0.9960 - val_loss: 0.1853 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00603: val_accuracy did not improve from 0.99299\n",
            "Epoch 604/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0565 - accuracy: 0.9937 - val_loss: 0.2208 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00604: val_accuracy did not improve from 0.99299\n",
            "Epoch 605/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0466 - accuracy: 0.9939 - val_loss: 0.2049 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00605: val_accuracy did not improve from 0.99299\n",
            "Epoch 606/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0509 - accuracy: 0.9942 - val_loss: 0.1756 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00606: val_accuracy did not improve from 0.99299\n",
            "Epoch 607/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.1024 - accuracy: 0.9902 - val_loss: 0.2046 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00607: val_accuracy did not improve from 0.99299\n",
            "Epoch 608/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0575 - accuracy: 0.9934 - val_loss: 0.1311 - val_accuracy: 0.9860\n",
            "\n",
            "Epoch 00608: val_accuracy did not improve from 0.99299\n",
            "Epoch 609/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0484 - accuracy: 0.9981 - val_loss: 0.2753 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00609: val_accuracy did not improve from 0.99299\n",
            "Epoch 610/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0568 - accuracy: 0.9961 - val_loss: 0.2016 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00610: val_accuracy did not improve from 0.99299\n",
            "Epoch 611/1000\n",
            "54/54 [==============================] - 1s 22ms/step - loss: 0.0642 - accuracy: 0.9926 - val_loss: 0.1526 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00611: val_accuracy did not improve from 0.99299\n",
            "Epoch 612/1000\n",
            "54/54 [==============================] - 1s 22ms/step - loss: 0.0808 - accuracy: 0.9913 - val_loss: 0.1225 - val_accuracy: 0.9907\n",
            "\n",
            "Epoch 00612: val_accuracy did not improve from 0.99299\n",
            "Epoch 613/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0490 - accuracy: 0.9955 - val_loss: 0.2078 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00613: val_accuracy did not improve from 0.99299\n",
            "Epoch 614/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0462 - accuracy: 0.9968 - val_loss: 0.2580 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00614: val_accuracy did not improve from 0.99299\n",
            "Epoch 615/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0623 - accuracy: 0.9921 - val_loss: 0.2471 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00615: val_accuracy did not improve from 0.99299\n",
            "Epoch 616/1000\n",
            "54/54 [==============================] - 1s 22ms/step - loss: 0.0579 - accuracy: 0.9931 - val_loss: 0.2304 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00616: val_accuracy did not improve from 0.99299\n",
            "Epoch 617/1000\n",
            "54/54 [==============================] - 1s 22ms/step - loss: 0.0442 - accuracy: 0.9941 - val_loss: 0.2326 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00617: val_accuracy did not improve from 0.99299\n",
            "Epoch 618/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0436 - accuracy: 0.9934 - val_loss: 0.1957 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00618: val_accuracy did not improve from 0.99299\n",
            "Epoch 619/1000\n",
            "54/54 [==============================] - 1s 22ms/step - loss: 0.0456 - accuracy: 0.9940 - val_loss: 0.2436 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00619: val_accuracy did not improve from 0.99299\n",
            "Epoch 620/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0392 - accuracy: 0.9987 - val_loss: 0.1843 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00620: val_accuracy did not improve from 0.99299\n",
            "Epoch 621/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0440 - accuracy: 0.9959 - val_loss: 0.1742 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00621: val_accuracy did not improve from 0.99299\n",
            "Epoch 622/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0315 - accuracy: 0.9975 - val_loss: 0.2229 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00622: val_accuracy did not improve from 0.99299\n",
            "Epoch 623/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0361 - accuracy: 0.9958 - val_loss: 0.2221 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00623: val_accuracy did not improve from 0.99299\n",
            "Epoch 624/1000\n",
            "54/54 [==============================] - 1s 22ms/step - loss: 0.0792 - accuracy: 0.9914 - val_loss: 0.3158 - val_accuracy: 0.9603\n",
            "\n",
            "Epoch 00624: val_accuracy did not improve from 0.99299\n",
            "Epoch 625/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.1099 - accuracy: 0.9894 - val_loss: 0.2125 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00625: val_accuracy did not improve from 0.99299\n",
            "Epoch 626/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.1000 - accuracy: 0.9870 - val_loss: 0.2110 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00626: val_accuracy did not improve from 0.99299\n",
            "Epoch 627/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.1640 - accuracy: 0.9881 - val_loss: 0.1446 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00627: val_accuracy did not improve from 0.99299\n",
            "Epoch 628/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0709 - accuracy: 0.9946 - val_loss: 0.1507 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00628: val_accuracy did not improve from 0.99299\n",
            "Epoch 629/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0711 - accuracy: 0.9952 - val_loss: 0.1853 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00629: val_accuracy did not improve from 0.99299\n",
            "Epoch 630/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0926 - accuracy: 0.9941 - val_loss: 0.2057 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00630: val_accuracy did not improve from 0.99299\n",
            "Epoch 631/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0632 - accuracy: 0.9953 - val_loss: 0.1794 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00631: val_accuracy did not improve from 0.99299\n",
            "Epoch 632/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0574 - accuracy: 0.9980 - val_loss: 0.1518 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00632: val_accuracy did not improve from 0.99299\n",
            "Epoch 633/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0937 - accuracy: 0.9939 - val_loss: 0.1491 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00633: val_accuracy did not improve from 0.99299\n",
            "Epoch 634/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0422 - accuracy: 0.9993 - val_loss: 0.1833 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00634: val_accuracy did not improve from 0.99299\n",
            "Epoch 635/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0396 - accuracy: 0.9973 - val_loss: 0.2004 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00635: val_accuracy did not improve from 0.99299\n",
            "Epoch 636/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0571 - accuracy: 0.9961 - val_loss: 0.1419 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00636: val_accuracy did not improve from 0.99299\n",
            "Epoch 637/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0523 - accuracy: 0.9947 - val_loss: 0.1919 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00637: val_accuracy did not improve from 0.99299\n",
            "Epoch 638/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0521 - accuracy: 0.9959 - val_loss: 0.2536 - val_accuracy: 0.9556\n",
            "\n",
            "Epoch 00638: val_accuracy did not improve from 0.99299\n",
            "Epoch 639/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0549 - accuracy: 0.9942 - val_loss: 0.1086 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00639: val_accuracy did not improve from 0.99299\n",
            "Epoch 640/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0664 - accuracy: 0.9947 - val_loss: 0.1603 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00640: val_accuracy did not improve from 0.99299\n",
            "Epoch 641/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0539 - accuracy: 0.9980 - val_loss: 0.0757 - val_accuracy: 0.9860\n",
            "\n",
            "Epoch 00641: val_accuracy did not improve from 0.99299\n",
            "Epoch 642/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0417 - accuracy: 0.9955 - val_loss: 0.1057 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00642: val_accuracy did not improve from 0.99299\n",
            "Epoch 643/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0405 - accuracy: 0.9950 - val_loss: 0.2056 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00643: val_accuracy did not improve from 0.99299\n",
            "Epoch 644/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0568 - accuracy: 0.9944 - val_loss: 0.2028 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00644: val_accuracy did not improve from 0.99299\n",
            "Epoch 645/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0356 - accuracy: 0.9983 - val_loss: 0.1834 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00645: val_accuracy did not improve from 0.99299\n",
            "Epoch 646/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0421 - accuracy: 0.9978 - val_loss: 0.1532 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00646: val_accuracy did not improve from 0.99299\n",
            "Epoch 647/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0362 - accuracy: 0.9982 - val_loss: 0.1369 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00647: val_accuracy did not improve from 0.99299\n",
            "Epoch 648/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0255 - accuracy: 0.9997 - val_loss: 0.1679 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00648: val_accuracy did not improve from 0.99299\n",
            "Epoch 649/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0235 - accuracy: 0.9991 - val_loss: 0.1411 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00649: val_accuracy did not improve from 0.99299\n",
            "Epoch 650/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0228 - accuracy: 0.9998 - val_loss: 0.1511 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00650: val_accuracy did not improve from 0.99299\n",
            "Epoch 651/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0661 - accuracy: 0.9978 - val_loss: 0.4487 - val_accuracy: 0.9486\n",
            "\n",
            "Epoch 00651: val_accuracy did not improve from 0.99299\n",
            "Epoch 652/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.1373 - accuracy: 0.9888 - val_loss: 0.1967 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00652: val_accuracy did not improve from 0.99299\n",
            "Epoch 653/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0602 - accuracy: 0.9977 - val_loss: 0.1685 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00653: val_accuracy did not improve from 0.99299\n",
            "Epoch 654/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0499 - accuracy: 0.9972 - val_loss: 0.2050 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00654: val_accuracy did not improve from 0.99299\n",
            "Epoch 655/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0681 - accuracy: 0.9923 - val_loss: 0.1807 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00655: val_accuracy did not improve from 0.99299\n",
            "Epoch 656/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0891 - accuracy: 0.9922 - val_loss: 0.2263 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00656: val_accuracy did not improve from 0.99299\n",
            "Epoch 657/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0709 - accuracy: 0.9961 - val_loss: 0.1588 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00657: val_accuracy did not improve from 0.99299\n",
            "Epoch 658/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0449 - accuracy: 0.9969 - val_loss: 0.1996 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00658: val_accuracy did not improve from 0.99299\n",
            "Epoch 659/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0413 - accuracy: 0.9970 - val_loss: 0.1345 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00659: val_accuracy did not improve from 0.99299\n",
            "Epoch 660/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0478 - accuracy: 0.9931 - val_loss: 0.2843 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00660: val_accuracy did not improve from 0.99299\n",
            "Epoch 661/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0568 - accuracy: 0.9976 - val_loss: 0.2624 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00661: val_accuracy did not improve from 0.99299\n",
            "Epoch 662/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0597 - accuracy: 0.9939 - val_loss: 0.1425 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00662: val_accuracy did not improve from 0.99299\n",
            "Epoch 663/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0450 - accuracy: 0.9945 - val_loss: 0.1220 - val_accuracy: 0.9860\n",
            "\n",
            "Epoch 00663: val_accuracy did not improve from 0.99299\n",
            "Epoch 664/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0569 - accuracy: 0.9951 - val_loss: 0.1417 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00664: val_accuracy did not improve from 0.99299\n",
            "Epoch 665/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0449 - accuracy: 0.9974 - val_loss: 0.1348 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00665: val_accuracy did not improve from 0.99299\n",
            "Epoch 666/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0379 - accuracy: 0.9955 - val_loss: 0.1256 - val_accuracy: 0.9860\n",
            "\n",
            "Epoch 00666: val_accuracy did not improve from 0.99299\n",
            "Epoch 667/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0507 - accuracy: 0.9950 - val_loss: 0.1770 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00667: val_accuracy did not improve from 0.99299\n",
            "Epoch 668/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0379 - accuracy: 0.9983 - val_loss: 0.1782 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00668: val_accuracy did not improve from 0.99299\n",
            "Epoch 669/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0488 - accuracy: 0.9935 - val_loss: 0.2016 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00669: val_accuracy did not improve from 0.99299\n",
            "Epoch 670/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0829 - accuracy: 0.9895 - val_loss: 0.2240 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00670: val_accuracy did not improve from 0.99299\n",
            "Epoch 671/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0554 - accuracy: 0.9946 - val_loss: 0.2221 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00671: val_accuracy did not improve from 0.99299\n",
            "Epoch 672/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0336 - accuracy: 0.9968 - val_loss: 0.1546 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00672: val_accuracy did not improve from 0.99299\n",
            "Epoch 673/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0403 - accuracy: 0.9978 - val_loss: 0.1729 - val_accuracy: 0.9860\n",
            "\n",
            "Epoch 00673: val_accuracy did not improve from 0.99299\n",
            "Epoch 674/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0633 - accuracy: 0.9962 - val_loss: 0.1852 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00674: val_accuracy did not improve from 0.99299\n",
            "Epoch 675/1000\n",
            "54/54 [==============================] - 1s 22ms/step - loss: 0.0280 - accuracy: 0.9997 - val_loss: 0.2009 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00675: val_accuracy did not improve from 0.99299\n",
            "Epoch 676/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0402 - accuracy: 0.9968 - val_loss: 0.1038 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00676: val_accuracy did not improve from 0.99299\n",
            "Epoch 677/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0423 - accuracy: 0.9975 - val_loss: 0.0754 - val_accuracy: 0.9883\n",
            "\n",
            "Epoch 00677: val_accuracy did not improve from 0.99299\n",
            "Epoch 678/1000\n",
            "54/54 [==============================] - 1s 22ms/step - loss: 0.0394 - accuracy: 0.9964 - val_loss: 0.1851 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00678: val_accuracy did not improve from 0.99299\n",
            "Epoch 679/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0428 - accuracy: 0.9984 - val_loss: 0.2113 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00679: val_accuracy did not improve from 0.99299\n",
            "Epoch 680/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0402 - accuracy: 0.9966 - val_loss: 0.2571 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00680: val_accuracy did not improve from 0.99299\n",
            "Epoch 681/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0643 - accuracy: 0.9935 - val_loss: 0.2856 - val_accuracy: 0.9533\n",
            "\n",
            "Epoch 00681: val_accuracy did not improve from 0.99299\n",
            "Epoch 682/1000\n",
            "54/54 [==============================] - 1s 22ms/step - loss: 0.0391 - accuracy: 0.9987 - val_loss: 0.1107 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00682: val_accuracy did not improve from 0.99299\n",
            "Epoch 683/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0408 - accuracy: 0.9969 - val_loss: 0.0545 - val_accuracy: 0.9883\n",
            "\n",
            "Epoch 00683: val_accuracy did not improve from 0.99299\n",
            "Epoch 684/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0516 - accuracy: 0.9944 - val_loss: 0.2305 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00684: val_accuracy did not improve from 0.99299\n",
            "Epoch 685/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0464 - accuracy: 0.9960 - val_loss: 0.3194 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00685: val_accuracy did not improve from 0.99299\n",
            "Epoch 686/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0593 - accuracy: 0.9942 - val_loss: 0.2457 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00686: val_accuracy did not improve from 0.99299\n",
            "Epoch 687/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0682 - accuracy: 0.9956 - val_loss: 0.0928 - val_accuracy: 0.9930\n",
            "\n",
            "Epoch 00687: val_accuracy did not improve from 0.99299\n",
            "Epoch 688/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0515 - accuracy: 0.9959 - val_loss: 0.1731 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00688: val_accuracy did not improve from 0.99299\n",
            "Epoch 689/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0486 - accuracy: 0.9949 - val_loss: 0.1344 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00689: val_accuracy did not improve from 0.99299\n",
            "Epoch 690/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0856 - accuracy: 0.9937 - val_loss: 0.1219 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00690: val_accuracy did not improve from 0.99299\n",
            "Epoch 691/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0298 - accuracy: 0.9996 - val_loss: 0.1184 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00691: val_accuracy did not improve from 0.99299\n",
            "Epoch 692/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0302 - accuracy: 0.9968 - val_loss: 0.0865 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00692: val_accuracy did not improve from 0.99299\n",
            "Epoch 693/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0348 - accuracy: 0.9965 - val_loss: 0.2631 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00693: val_accuracy did not improve from 0.99299\n",
            "Epoch 694/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0510 - accuracy: 0.9959 - val_loss: 0.3133 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00694: val_accuracy did not improve from 0.99299\n",
            "Epoch 695/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0388 - accuracy: 0.9943 - val_loss: 0.1617 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00695: val_accuracy did not improve from 0.99299\n",
            "Epoch 696/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0715 - accuracy: 0.9946 - val_loss: 0.3672 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00696: val_accuracy did not improve from 0.99299\n",
            "Epoch 697/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0605 - accuracy: 0.9929 - val_loss: 0.3386 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00697: val_accuracy did not improve from 0.99299\n",
            "Epoch 698/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0748 - accuracy: 0.9946 - val_loss: 0.1649 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00698: val_accuracy did not improve from 0.99299\n",
            "Epoch 699/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0547 - accuracy: 0.9980 - val_loss: 0.1322 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00699: val_accuracy did not improve from 0.99299\n",
            "Epoch 700/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0499 - accuracy: 0.9962 - val_loss: 0.1689 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00700: val_accuracy did not improve from 0.99299\n",
            "Epoch 701/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0607 - accuracy: 0.9929 - val_loss: 0.1547 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00701: val_accuracy did not improve from 0.99299\n",
            "Epoch 702/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0572 - accuracy: 0.9972 - val_loss: 0.2868 - val_accuracy: 0.9579\n",
            "\n",
            "Epoch 00702: val_accuracy did not improve from 0.99299\n",
            "Epoch 703/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0911 - accuracy: 0.9913 - val_loss: 0.1371 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00703: val_accuracy did not improve from 0.99299\n",
            "Epoch 704/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0451 - accuracy: 0.9980 - val_loss: 0.1647 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00704: val_accuracy did not improve from 0.99299\n",
            "Epoch 705/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0567 - accuracy: 0.9972 - val_loss: 0.1370 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00705: val_accuracy did not improve from 0.99299\n",
            "Epoch 706/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0402 - accuracy: 0.9991 - val_loss: 0.1341 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00706: val_accuracy did not improve from 0.99299\n",
            "Epoch 707/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0338 - accuracy: 0.9993 - val_loss: 0.0916 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00707: val_accuracy did not improve from 0.99299\n",
            "Epoch 708/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0335 - accuracy: 0.9995 - val_loss: 0.0614 - val_accuracy: 0.9860\n",
            "\n",
            "Epoch 00708: val_accuracy did not improve from 0.99299\n",
            "Epoch 709/1000\n",
            "54/54 [==============================] - 1s 22ms/step - loss: 0.0367 - accuracy: 0.9964 - val_loss: 0.0806 - val_accuracy: 0.9860\n",
            "\n",
            "Epoch 00709: val_accuracy did not improve from 0.99299\n",
            "Epoch 710/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0248 - accuracy: 0.9985 - val_loss: 0.0871 - val_accuracy: 0.9860\n",
            "\n",
            "Epoch 00710: val_accuracy did not improve from 0.99299\n",
            "Epoch 711/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0314 - accuracy: 0.9965 - val_loss: 0.1460 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00711: val_accuracy did not improve from 0.99299\n",
            "Epoch 712/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.1065 - accuracy: 0.9886 - val_loss: 0.0949 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00712: val_accuracy did not improve from 0.99299\n",
            "Epoch 713/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0681 - accuracy: 0.9937 - val_loss: 0.1042 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00713: val_accuracy did not improve from 0.99299\n",
            "Epoch 714/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0761 - accuracy: 0.9909 - val_loss: 0.2371 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00714: val_accuracy did not improve from 0.99299\n",
            "Epoch 715/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0789 - accuracy: 0.9953 - val_loss: 0.2087 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00715: val_accuracy did not improve from 0.99299\n",
            "Epoch 716/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0723 - accuracy: 0.9941 - val_loss: 0.3163 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00716: val_accuracy did not improve from 0.99299\n",
            "Epoch 717/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0864 - accuracy: 0.9903 - val_loss: 0.2939 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00717: val_accuracy did not improve from 0.99299\n",
            "Epoch 718/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0832 - accuracy: 0.9897 - val_loss: 0.1340 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00718: val_accuracy did not improve from 0.99299\n",
            "Epoch 719/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0491 - accuracy: 0.9981 - val_loss: 0.1387 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00719: val_accuracy did not improve from 0.99299\n",
            "Epoch 720/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0774 - accuracy: 0.9924 - val_loss: 0.0890 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00720: val_accuracy did not improve from 0.99299\n",
            "Epoch 721/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0396 - accuracy: 0.9986 - val_loss: 0.1014 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00721: val_accuracy did not improve from 0.99299\n",
            "Epoch 722/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0312 - accuracy: 0.9993 - val_loss: 0.1164 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00722: val_accuracy did not improve from 0.99299\n",
            "Epoch 723/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0268 - accuracy: 0.9999 - val_loss: 0.0953 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00723: val_accuracy did not improve from 0.99299\n",
            "Epoch 724/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0530 - accuracy: 0.9949 - val_loss: 0.1227 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00724: val_accuracy did not improve from 0.99299\n",
            "Epoch 725/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0276 - accuracy: 0.9986 - val_loss: 0.1168 - val_accuracy: 0.9860\n",
            "\n",
            "Epoch 00725: val_accuracy did not improve from 0.99299\n",
            "Epoch 726/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0332 - accuracy: 0.9971 - val_loss: 0.0772 - val_accuracy: 0.9860\n",
            "\n",
            "Epoch 00726: val_accuracy did not improve from 0.99299\n",
            "Epoch 727/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0358 - accuracy: 0.9968 - val_loss: 0.1943 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00727: val_accuracy did not improve from 0.99299\n",
            "Epoch 728/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0524 - accuracy: 0.9952 - val_loss: 0.1586 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00728: val_accuracy did not improve from 0.99299\n",
            "Epoch 729/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0591 - accuracy: 0.9951 - val_loss: 0.1293 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00729: val_accuracy did not improve from 0.99299\n",
            "Epoch 730/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0439 - accuracy: 0.9987 - val_loss: 0.1503 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00730: val_accuracy did not improve from 0.99299\n",
            "Epoch 731/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0369 - accuracy: 0.9996 - val_loss: 0.1479 - val_accuracy: 0.9883\n",
            "\n",
            "Epoch 00731: val_accuracy did not improve from 0.99299\n",
            "Epoch 732/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0349 - accuracy: 0.9974 - val_loss: 0.1498 - val_accuracy: 0.9860\n",
            "\n",
            "Epoch 00732: val_accuracy did not improve from 0.99299\n",
            "Epoch 733/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0409 - accuracy: 0.9969 - val_loss: 0.1350 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00733: val_accuracy did not improve from 0.99299\n",
            "Epoch 734/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0371 - accuracy: 0.9987 - val_loss: 0.0795 - val_accuracy: 0.9883\n",
            "\n",
            "Epoch 00734: val_accuracy did not improve from 0.99299\n",
            "Epoch 735/1000\n",
            "54/54 [==============================] - 1s 22ms/step - loss: 0.0489 - accuracy: 0.9951 - val_loss: 0.1820 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00735: val_accuracy did not improve from 0.99299\n",
            "Epoch 736/1000\n",
            "54/54 [==============================] - 1s 22ms/step - loss: 0.1811 - accuracy: 0.9886 - val_loss: 0.1968 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00736: val_accuracy did not improve from 0.99299\n",
            "Epoch 737/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0749 - accuracy: 0.9912 - val_loss: 0.2048 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00737: val_accuracy did not improve from 0.99299\n",
            "Epoch 738/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0581 - accuracy: 0.9959 - val_loss: 0.1858 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00738: val_accuracy did not improve from 0.99299\n",
            "Epoch 739/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0780 - accuracy: 0.9903 - val_loss: 0.1503 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00739: val_accuracy did not improve from 0.99299\n",
            "Epoch 740/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0665 - accuracy: 0.9948 - val_loss: 0.1120 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00740: val_accuracy did not improve from 0.99299\n",
            "Epoch 741/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0403 - accuracy: 0.9978 - val_loss: 0.0891 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00741: val_accuracy did not improve from 0.99299\n",
            "Epoch 742/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0416 - accuracy: 0.9967 - val_loss: 0.1371 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00742: val_accuracy did not improve from 0.99299\n",
            "Epoch 743/1000\n",
            "54/54 [==============================] - 1s 22ms/step - loss: 0.1235 - accuracy: 0.9897 - val_loss: 0.2366 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00743: val_accuracy did not improve from 0.99299\n",
            "Epoch 744/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0604 - accuracy: 0.9954 - val_loss: 0.1440 - val_accuracy: 0.9907\n",
            "\n",
            "Epoch 00744: val_accuracy did not improve from 0.99299\n",
            "Epoch 745/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0455 - accuracy: 0.9986 - val_loss: 0.1411 - val_accuracy: 0.9860\n",
            "\n",
            "Epoch 00745: val_accuracy did not improve from 0.99299\n",
            "Epoch 746/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0425 - accuracy: 0.9981 - val_loss: 0.1281 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00746: val_accuracy did not improve from 0.99299\n",
            "Epoch 747/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0404 - accuracy: 0.9975 - val_loss: 0.1279 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00747: val_accuracy did not improve from 0.99299\n",
            "Epoch 748/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0402 - accuracy: 0.9981 - val_loss: 0.1428 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00748: val_accuracy did not improve from 0.99299\n",
            "Epoch 749/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0856 - accuracy: 0.9962 - val_loss: 0.1621 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00749: val_accuracy did not improve from 0.99299\n",
            "Epoch 750/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0672 - accuracy: 0.9952 - val_loss: 0.3250 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00750: val_accuracy did not improve from 0.99299\n",
            "Epoch 751/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0428 - accuracy: 0.9968 - val_loss: 0.2627 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00751: val_accuracy did not improve from 0.99299\n",
            "Epoch 752/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0532 - accuracy: 0.9923 - val_loss: 0.1913 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00752: val_accuracy did not improve from 0.99299\n",
            "Epoch 753/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0403 - accuracy: 0.9956 - val_loss: 0.1592 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00753: val_accuracy did not improve from 0.99299\n",
            "Epoch 754/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0317 - accuracy: 0.9983 - val_loss: 0.1762 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00754: val_accuracy did not improve from 0.99299\n",
            "Epoch 755/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0501 - accuracy: 0.9955 - val_loss: 0.2032 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00755: val_accuracy did not improve from 0.99299\n",
            "Epoch 756/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0793 - accuracy: 0.9969 - val_loss: 0.2300 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00756: val_accuracy did not improve from 0.99299\n",
            "Epoch 757/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0460 - accuracy: 0.9951 - val_loss: 0.2266 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00757: val_accuracy did not improve from 0.99299\n",
            "Epoch 758/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0611 - accuracy: 0.9956 - val_loss: 0.3817 - val_accuracy: 0.9626\n",
            "\n",
            "Epoch 00758: val_accuracy did not improve from 0.99299\n",
            "Epoch 759/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.1016 - accuracy: 0.9888 - val_loss: 0.1567 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00759: val_accuracy did not improve from 0.99299\n",
            "Epoch 760/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0524 - accuracy: 0.9970 - val_loss: 0.1364 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00760: val_accuracy did not improve from 0.99299\n",
            "Epoch 761/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0553 - accuracy: 0.9936 - val_loss: 0.1191 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00761: val_accuracy did not improve from 0.99299\n",
            "Epoch 762/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0414 - accuracy: 0.9949 - val_loss: 0.1476 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00762: val_accuracy did not improve from 0.99299\n",
            "Epoch 763/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0926 - accuracy: 0.9936 - val_loss: 0.1634 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00763: val_accuracy did not improve from 0.99299\n",
            "Epoch 764/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0443 - accuracy: 0.9969 - val_loss: 0.1290 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00764: val_accuracy did not improve from 0.99299\n",
            "Epoch 765/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0358 - accuracy: 0.9988 - val_loss: 0.1757 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00765: val_accuracy did not improve from 0.99299\n",
            "Epoch 766/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0351 - accuracy: 0.9983 - val_loss: 0.2799 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00766: val_accuracy did not improve from 0.99299\n",
            "Epoch 767/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0475 - accuracy: 0.9966 - val_loss: 0.2243 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00767: val_accuracy did not improve from 0.99299\n",
            "Epoch 768/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0452 - accuracy: 0.9969 - val_loss: 0.1399 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00768: val_accuracy did not improve from 0.99299\n",
            "Epoch 769/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0379 - accuracy: 0.9980 - val_loss: 0.1389 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00769: val_accuracy did not improve from 0.99299\n",
            "Epoch 770/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0421 - accuracy: 0.9978 - val_loss: 0.1401 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00770: val_accuracy did not improve from 0.99299\n",
            "Epoch 771/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0674 - accuracy: 0.9950 - val_loss: 0.1488 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00771: val_accuracy did not improve from 0.99299\n",
            "Epoch 772/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0500 - accuracy: 0.9980 - val_loss: 0.1428 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00772: val_accuracy did not improve from 0.99299\n",
            "Epoch 773/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0828 - accuracy: 0.9913 - val_loss: 0.1433 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00773: val_accuracy did not improve from 0.99299\n",
            "Epoch 774/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0485 - accuracy: 0.9941 - val_loss: 0.1197 - val_accuracy: 0.9860\n",
            "\n",
            "Epoch 00774: val_accuracy did not improve from 0.99299\n",
            "Epoch 775/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0813 - accuracy: 0.9947 - val_loss: 0.1802 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00775: val_accuracy did not improve from 0.99299\n",
            "Epoch 776/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0666 - accuracy: 0.9987 - val_loss: 0.1939 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00776: val_accuracy did not improve from 0.99299\n",
            "Epoch 777/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0859 - accuracy: 0.9898 - val_loss: 0.1332 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00777: val_accuracy did not improve from 0.99299\n",
            "Epoch 778/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0620 - accuracy: 0.9949 - val_loss: 0.0976 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00778: val_accuracy did not improve from 0.99299\n",
            "Epoch 779/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0411 - accuracy: 0.9996 - val_loss: 0.1284 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00779: val_accuracy did not improve from 0.99299\n",
            "Epoch 780/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0313 - accuracy: 1.0000 - val_loss: 0.1275 - val_accuracy: 0.9860\n",
            "\n",
            "Epoch 00780: val_accuracy did not improve from 0.99299\n",
            "Epoch 781/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0304 - accuracy: 0.9998 - val_loss: 0.1357 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00781: val_accuracy did not improve from 0.99299\n",
            "Epoch 782/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0318 - accuracy: 0.9982 - val_loss: 0.1929 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00782: val_accuracy did not improve from 0.99299\n",
            "Epoch 783/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.1460 - accuracy: 0.9871 - val_loss: 0.3423 - val_accuracy: 0.9556\n",
            "\n",
            "Epoch 00783: val_accuracy did not improve from 0.99299\n",
            "Epoch 784/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0747 - accuracy: 0.9968 - val_loss: 0.1910 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00784: val_accuracy did not improve from 0.99299\n",
            "Epoch 785/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0783 - accuracy: 0.9923 - val_loss: 0.1083 - val_accuracy: 0.9883\n",
            "\n",
            "Epoch 00785: val_accuracy did not improve from 0.99299\n",
            "Epoch 786/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0754 - accuracy: 0.9957 - val_loss: 0.2020 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00786: val_accuracy did not improve from 0.99299\n",
            "Epoch 787/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0686 - accuracy: 0.9971 - val_loss: 0.2018 - val_accuracy: 0.9860\n",
            "\n",
            "Epoch 00787: val_accuracy did not improve from 0.99299\n",
            "Epoch 788/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0489 - accuracy: 0.9978 - val_loss: 0.1595 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00788: val_accuracy did not improve from 0.99299\n",
            "Epoch 789/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0540 - accuracy: 0.9977 - val_loss: 0.1849 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00789: val_accuracy did not improve from 0.99299\n",
            "Epoch 790/1000\n",
            "54/54 [==============================] - 1s 22ms/step - loss: 0.0653 - accuracy: 0.9966 - val_loss: 0.1350 - val_accuracy: 0.9860\n",
            "\n",
            "Epoch 00790: val_accuracy did not improve from 0.99299\n",
            "Epoch 791/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0507 - accuracy: 0.9957 - val_loss: 0.1200 - val_accuracy: 0.9883\n",
            "\n",
            "Epoch 00791: val_accuracy did not improve from 0.99299\n",
            "Epoch 792/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0371 - accuracy: 0.9991 - val_loss: 0.1202 - val_accuracy: 0.9883\n",
            "\n",
            "Epoch 00792: val_accuracy did not improve from 0.99299\n",
            "Epoch 793/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0457 - accuracy: 0.9978 - val_loss: 0.1096 - val_accuracy: 0.9860\n",
            "\n",
            "Epoch 00793: val_accuracy did not improve from 0.99299\n",
            "Epoch 794/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0349 - accuracy: 0.9997 - val_loss: 0.1199 - val_accuracy: 0.9860\n",
            "\n",
            "Epoch 00794: val_accuracy did not improve from 0.99299\n",
            "Epoch 795/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0336 - accuracy: 0.9983 - val_loss: 0.1304 - val_accuracy: 0.9860\n",
            "\n",
            "Epoch 00795: val_accuracy did not improve from 0.99299\n",
            "Epoch 796/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0417 - accuracy: 0.9959 - val_loss: 0.1358 - val_accuracy: 0.9860\n",
            "\n",
            "Epoch 00796: val_accuracy did not improve from 0.99299\n",
            "Epoch 797/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0392 - accuracy: 0.9963 - val_loss: 0.1123 - val_accuracy: 0.9883\n",
            "\n",
            "Epoch 00797: val_accuracy did not improve from 0.99299\n",
            "Epoch 798/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0441 - accuracy: 0.9986 - val_loss: 0.1518 - val_accuracy: 0.9860\n",
            "\n",
            "Epoch 00798: val_accuracy did not improve from 0.99299\n",
            "Epoch 799/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0347 - accuracy: 0.9980 - val_loss: 0.1391 - val_accuracy: 0.9860\n",
            "\n",
            "Epoch 00799: val_accuracy did not improve from 0.99299\n",
            "Epoch 800/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0461 - accuracy: 0.9957 - val_loss: 0.1615 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00800: val_accuracy did not improve from 0.99299\n",
            "Epoch 801/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0381 - accuracy: 0.9968 - val_loss: 0.1835 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00801: val_accuracy did not improve from 0.99299\n",
            "Epoch 802/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0301 - accuracy: 0.9992 - val_loss: 0.2226 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00802: val_accuracy did not improve from 0.99299\n",
            "Epoch 803/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0587 - accuracy: 0.9976 - val_loss: 0.2320 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00803: val_accuracy did not improve from 0.99299\n",
            "Epoch 804/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0489 - accuracy: 0.9945 - val_loss: 0.2372 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00804: val_accuracy did not improve from 0.99299\n",
            "Epoch 805/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0376 - accuracy: 0.9976 - val_loss: 0.2962 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00805: val_accuracy did not improve from 0.99299\n",
            "Epoch 806/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0610 - accuracy: 0.9953 - val_loss: 0.1904 - val_accuracy: 0.9860\n",
            "\n",
            "Epoch 00806: val_accuracy did not improve from 0.99299\n",
            "Epoch 807/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0410 - accuracy: 0.9979 - val_loss: 0.1665 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00807: val_accuracy did not improve from 0.99299\n",
            "Epoch 808/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0462 - accuracy: 0.9940 - val_loss: 0.1516 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00808: val_accuracy did not improve from 0.99299\n",
            "Epoch 809/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0350 - accuracy: 0.9972 - val_loss: 0.1434 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00809: val_accuracy did not improve from 0.99299\n",
            "Epoch 810/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0453 - accuracy: 0.9949 - val_loss: 0.1849 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00810: val_accuracy did not improve from 0.99299\n",
            "Epoch 811/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0541 - accuracy: 0.9942 - val_loss: 0.2181 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00811: val_accuracy did not improve from 0.99299\n",
            "Epoch 812/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0778 - accuracy: 0.9931 - val_loss: 0.1224 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00812: val_accuracy did not improve from 0.99299\n",
            "Epoch 813/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0416 - accuracy: 0.9985 - val_loss: 0.1772 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00813: val_accuracy did not improve from 0.99299\n",
            "Epoch 814/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0386 - accuracy: 0.9990 - val_loss: 0.1548 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00814: val_accuracy did not improve from 0.99299\n",
            "Epoch 815/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0679 - accuracy: 0.9938 - val_loss: 0.1792 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00815: val_accuracy did not improve from 0.99299\n",
            "Epoch 816/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0723 - accuracy: 0.9925 - val_loss: 0.2934 - val_accuracy: 0.9603\n",
            "\n",
            "Epoch 00816: val_accuracy did not improve from 0.99299\n",
            "Epoch 817/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0448 - accuracy: 0.9989 - val_loss: 0.2012 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00817: val_accuracy did not improve from 0.99299\n",
            "Epoch 818/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0410 - accuracy: 0.9975 - val_loss: 0.1938 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00818: val_accuracy did not improve from 0.99299\n",
            "Epoch 819/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0364 - accuracy: 0.9990 - val_loss: 0.1216 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00819: val_accuracy did not improve from 0.99299\n",
            "Epoch 820/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0379 - accuracy: 0.9959 - val_loss: 0.1321 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00820: val_accuracy did not improve from 0.99299\n",
            "Epoch 821/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0342 - accuracy: 0.9975 - val_loss: 0.1473 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00821: val_accuracy did not improve from 0.99299\n",
            "Epoch 822/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0417 - accuracy: 0.9977 - val_loss: 0.1770 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00822: val_accuracy did not improve from 0.99299\n",
            "Epoch 823/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0703 - accuracy: 0.9960 - val_loss: 0.2548 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00823: val_accuracy did not improve from 0.99299\n",
            "Epoch 824/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0687 - accuracy: 0.9956 - val_loss: 0.1874 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00824: val_accuracy did not improve from 0.99299\n",
            "Epoch 825/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0440 - accuracy: 0.9962 - val_loss: 0.1740 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00825: val_accuracy did not improve from 0.99299\n",
            "Epoch 826/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0672 - accuracy: 0.9950 - val_loss: 0.1799 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00826: val_accuracy did not improve from 0.99299\n",
            "Epoch 827/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0679 - accuracy: 0.9879 - val_loss: 0.2397 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00827: val_accuracy did not improve from 0.99299\n",
            "Epoch 828/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0418 - accuracy: 0.9964 - val_loss: 0.1828 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00828: val_accuracy did not improve from 0.99299\n",
            "Epoch 829/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0504 - accuracy: 0.9980 - val_loss: 0.2257 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00829: val_accuracy did not improve from 0.99299\n",
            "Epoch 830/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0656 - accuracy: 0.9950 - val_loss: 0.1688 - val_accuracy: 0.9860\n",
            "\n",
            "Epoch 00830: val_accuracy did not improve from 0.99299\n",
            "Epoch 831/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0390 - accuracy: 0.9956 - val_loss: 0.1586 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00831: val_accuracy did not improve from 0.99299\n",
            "Epoch 832/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0379 - accuracy: 0.9967 - val_loss: 0.1494 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00832: val_accuracy did not improve from 0.99299\n",
            "Epoch 833/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0351 - accuracy: 0.9984 - val_loss: 0.2074 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00833: val_accuracy did not improve from 0.99299\n",
            "Epoch 834/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0517 - accuracy: 0.9951 - val_loss: 0.1247 - val_accuracy: 0.9883\n",
            "\n",
            "Epoch 00834: val_accuracy did not improve from 0.99299\n",
            "Epoch 835/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0404 - accuracy: 0.9975 - val_loss: 0.2305 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00835: val_accuracy did not improve from 0.99299\n",
            "Epoch 836/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0436 - accuracy: 0.9968 - val_loss: 0.1520 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00836: val_accuracy did not improve from 0.99299\n",
            "Epoch 837/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0294 - accuracy: 0.9991 - val_loss: 0.1446 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00837: val_accuracy did not improve from 0.99299\n",
            "Epoch 838/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0314 - accuracy: 0.9987 - val_loss: 0.1498 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00838: val_accuracy did not improve from 0.99299\n",
            "Epoch 839/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0324 - accuracy: 0.9970 - val_loss: 0.1102 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00839: val_accuracy did not improve from 0.99299\n",
            "Epoch 840/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0237 - accuracy: 0.9998 - val_loss: 0.1013 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00840: val_accuracy did not improve from 0.99299\n",
            "Epoch 841/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0354 - accuracy: 0.9952 - val_loss: 0.0749 - val_accuracy: 0.9907\n",
            "\n",
            "Epoch 00841: val_accuracy did not improve from 0.99299\n",
            "Epoch 842/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0328 - accuracy: 0.9973 - val_loss: 0.0804 - val_accuracy: 0.9883\n",
            "\n",
            "Epoch 00842: val_accuracy did not improve from 0.99299\n",
            "Epoch 843/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0241 - accuracy: 0.9990 - val_loss: 0.0880 - val_accuracy: 0.9883\n",
            "\n",
            "Epoch 00843: val_accuracy did not improve from 0.99299\n",
            "Epoch 844/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0640 - accuracy: 0.9933 - val_loss: 0.2321 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00844: val_accuracy did not improve from 0.99299\n",
            "Epoch 845/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0484 - accuracy: 0.9969 - val_loss: 0.1928 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00845: val_accuracy did not improve from 0.99299\n",
            "Epoch 846/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0638 - accuracy: 0.9932 - val_loss: 0.1401 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00846: val_accuracy did not improve from 0.99299\n",
            "Epoch 847/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0528 - accuracy: 0.9936 - val_loss: 0.1817 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00847: val_accuracy did not improve from 0.99299\n",
            "Epoch 848/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0347 - accuracy: 0.9967 - val_loss: 0.1435 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00848: val_accuracy did not improve from 0.99299\n",
            "Epoch 849/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0347 - accuracy: 0.9993 - val_loss: 0.2070 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00849: val_accuracy did not improve from 0.99299\n",
            "Epoch 850/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0323 - accuracy: 0.9994 - val_loss: 0.2489 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00850: val_accuracy did not improve from 0.99299\n",
            "Epoch 851/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0316 - accuracy: 0.9964 - val_loss: 0.1384 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00851: val_accuracy did not improve from 0.99299\n",
            "Epoch 852/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0428 - accuracy: 0.9988 - val_loss: 0.1723 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00852: val_accuracy did not improve from 0.99299\n",
            "Epoch 853/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0521 - accuracy: 0.9956 - val_loss: 0.2310 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00853: val_accuracy did not improve from 0.99299\n",
            "Epoch 854/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0531 - accuracy: 0.9972 - val_loss: 0.1916 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00854: val_accuracy did not improve from 0.99299\n",
            "Epoch 855/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0319 - accuracy: 0.9978 - val_loss: 0.1413 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00855: val_accuracy did not improve from 0.99299\n",
            "Epoch 856/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0241 - accuracy: 0.9998 - val_loss: 0.1117 - val_accuracy: 0.9907\n",
            "\n",
            "Epoch 00856: val_accuracy did not improve from 0.99299\n",
            "Epoch 857/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0251 - accuracy: 0.9985 - val_loss: 0.1369 - val_accuracy: 0.9860\n",
            "\n",
            "Epoch 00857: val_accuracy did not improve from 0.99299\n",
            "Epoch 858/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0433 - accuracy: 0.9950 - val_loss: 0.1983 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00858: val_accuracy did not improve from 0.99299\n",
            "Epoch 859/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0304 - accuracy: 0.9973 - val_loss: 0.1888 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00859: val_accuracy did not improve from 0.99299\n",
            "Epoch 860/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0377 - accuracy: 0.9972 - val_loss: 0.2596 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00860: val_accuracy did not improve from 0.99299\n",
            "Epoch 861/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0446 - accuracy: 0.9966 - val_loss: 0.3489 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00861: val_accuracy did not improve from 0.99299\n",
            "Epoch 862/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0496 - accuracy: 0.9945 - val_loss: 0.2575 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00862: val_accuracy did not improve from 0.99299\n",
            "Epoch 863/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0381 - accuracy: 0.9967 - val_loss: 0.2011 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00863: val_accuracy did not improve from 0.99299\n",
            "Epoch 864/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0611 - accuracy: 0.9934 - val_loss: 0.3278 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00864: val_accuracy did not improve from 0.99299\n",
            "Epoch 865/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.1234 - accuracy: 0.9910 - val_loss: 0.2258 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00865: val_accuracy did not improve from 0.99299\n",
            "Epoch 866/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.1201 - accuracy: 0.9824 - val_loss: 0.2512 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00866: val_accuracy did not improve from 0.99299\n",
            "Epoch 867/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0561 - accuracy: 0.9978 - val_loss: 0.1631 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00867: val_accuracy did not improve from 0.99299\n",
            "Epoch 868/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0562 - accuracy: 0.9955 - val_loss: 0.1365 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00868: val_accuracy did not improve from 0.99299\n",
            "Epoch 869/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0379 - accuracy: 0.9973 - val_loss: 0.0918 - val_accuracy: 0.9860\n",
            "\n",
            "Epoch 00869: val_accuracy did not improve from 0.99299\n",
            "Epoch 870/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0427 - accuracy: 0.9983 - val_loss: 0.1327 - val_accuracy: 0.9860\n",
            "\n",
            "Epoch 00870: val_accuracy did not improve from 0.99299\n",
            "Epoch 871/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0336 - accuracy: 0.9986 - val_loss: 0.1809 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00871: val_accuracy did not improve from 0.99299\n",
            "Epoch 872/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0601 - accuracy: 0.9949 - val_loss: 0.0971 - val_accuracy: 0.9907\n",
            "\n",
            "Epoch 00872: val_accuracy did not improve from 0.99299\n",
            "Epoch 873/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0532 - accuracy: 0.9963 - val_loss: 0.1332 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00873: val_accuracy did not improve from 0.99299\n",
            "Epoch 874/1000\n",
            "54/54 [==============================] - 1s 22ms/step - loss: 0.0376 - accuracy: 0.9972 - val_loss: 0.1342 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00874: val_accuracy did not improve from 0.99299\n",
            "Epoch 875/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0957 - accuracy: 0.9933 - val_loss: 0.0584 - val_accuracy: 0.9883\n",
            "\n",
            "Epoch 00875: val_accuracy did not improve from 0.99299\n",
            "Epoch 876/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0471 - accuracy: 0.9959 - val_loss: 0.0962 - val_accuracy: 0.9883\n",
            "\n",
            "Epoch 00876: val_accuracy did not improve from 0.99299\n",
            "Epoch 877/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0380 - accuracy: 0.9965 - val_loss: 0.1150 - val_accuracy: 0.9883\n",
            "\n",
            "Epoch 00877: val_accuracy did not improve from 0.99299\n",
            "Epoch 878/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0305 - accuracy: 0.9984 - val_loss: 0.0856 - val_accuracy: 0.9930\n",
            "\n",
            "Epoch 00878: val_accuracy did not improve from 0.99299\n",
            "Epoch 879/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0362 - accuracy: 0.9975 - val_loss: 0.1801 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00879: val_accuracy did not improve from 0.99299\n",
            "Epoch 880/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0567 - accuracy: 0.9959 - val_loss: 0.1816 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00880: val_accuracy did not improve from 0.99299\n",
            "Epoch 881/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0610 - accuracy: 0.9954 - val_loss: 0.1301 - val_accuracy: 0.9860\n",
            "\n",
            "Epoch 00881: val_accuracy did not improve from 0.99299\n",
            "Epoch 882/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0325 - accuracy: 0.9986 - val_loss: 0.1510 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00882: val_accuracy did not improve from 0.99299\n",
            "Epoch 883/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0443 - accuracy: 0.9979 - val_loss: 0.1624 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00883: val_accuracy did not improve from 0.99299\n",
            "Epoch 884/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0304 - accuracy: 0.9990 - val_loss: 0.1588 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00884: val_accuracy did not improve from 0.99299\n",
            "Epoch 885/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0322 - accuracy: 0.9990 - val_loss: 0.1950 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00885: val_accuracy did not improve from 0.99299\n",
            "Epoch 886/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0342 - accuracy: 0.9986 - val_loss: 0.0798 - val_accuracy: 0.9860\n",
            "\n",
            "Epoch 00886: val_accuracy did not improve from 0.99299\n",
            "Epoch 887/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0388 - accuracy: 0.9975 - val_loss: 0.1029 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00887: val_accuracy did not improve from 0.99299\n",
            "Epoch 888/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0369 - accuracy: 0.9948 - val_loss: 0.0873 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00888: val_accuracy did not improve from 0.99299\n",
            "Epoch 889/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0248 - accuracy: 0.9989 - val_loss: 0.0933 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00889: val_accuracy did not improve from 0.99299\n",
            "Epoch 890/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0262 - accuracy: 0.9984 - val_loss: 0.1078 - val_accuracy: 0.9860\n",
            "\n",
            "Epoch 00890: val_accuracy did not improve from 0.99299\n",
            "Epoch 891/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0505 - accuracy: 0.9961 - val_loss: 0.1437 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00891: val_accuracy did not improve from 0.99299\n",
            "Epoch 892/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0376 - accuracy: 0.9971 - val_loss: 0.1718 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00892: val_accuracy did not improve from 0.99299\n",
            "Epoch 893/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0379 - accuracy: 0.9975 - val_loss: 0.1356 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00893: val_accuracy did not improve from 0.99299\n",
            "Epoch 894/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0348 - accuracy: 0.9977 - val_loss: 0.1330 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00894: val_accuracy did not improve from 0.99299\n",
            "Epoch 895/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0553 - accuracy: 0.9934 - val_loss: 0.2189 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00895: val_accuracy did not improve from 0.99299\n",
            "Epoch 896/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0396 - accuracy: 0.9976 - val_loss: 0.1623 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00896: val_accuracy did not improve from 0.99299\n",
            "Epoch 897/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0280 - accuracy: 0.9986 - val_loss: 0.1027 - val_accuracy: 0.9883\n",
            "\n",
            "Epoch 00897: val_accuracy did not improve from 0.99299\n",
            "Epoch 898/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0465 - accuracy: 0.9989 - val_loss: 0.1469 - val_accuracy: 0.9860\n",
            "\n",
            "Epoch 00898: val_accuracy did not improve from 0.99299\n",
            "Epoch 899/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0491 - accuracy: 0.9957 - val_loss: 0.1247 - val_accuracy: 0.9860\n",
            "\n",
            "Epoch 00899: val_accuracy did not improve from 0.99299\n",
            "Epoch 900/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0508 - accuracy: 0.9953 - val_loss: 0.1486 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00900: val_accuracy did not improve from 0.99299\n",
            "Epoch 901/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0433 - accuracy: 0.9946 - val_loss: 0.0885 - val_accuracy: 0.9860\n",
            "\n",
            "Epoch 00901: val_accuracy did not improve from 0.99299\n",
            "Epoch 902/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0576 - accuracy: 0.9958 - val_loss: 0.1316 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00902: val_accuracy did not improve from 0.99299\n",
            "Epoch 903/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0279 - accuracy: 0.9998 - val_loss: 0.1418 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00903: val_accuracy did not improve from 0.99299\n",
            "Epoch 904/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0313 - accuracy: 0.9955 - val_loss: 0.1521 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00904: val_accuracy did not improve from 0.99299\n",
            "Epoch 905/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0263 - accuracy: 0.9998 - val_loss: 0.2024 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00905: val_accuracy did not improve from 0.99299\n",
            "Epoch 906/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0323 - accuracy: 0.9992 - val_loss: 0.1838 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00906: val_accuracy did not improve from 0.99299\n",
            "Epoch 907/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0397 - accuracy: 0.9962 - val_loss: 0.1855 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00907: val_accuracy did not improve from 0.99299\n",
            "Epoch 908/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0504 - accuracy: 0.9945 - val_loss: 0.1327 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00908: val_accuracy did not improve from 0.99299\n",
            "Epoch 909/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0363 - accuracy: 0.9976 - val_loss: 0.1261 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00909: val_accuracy did not improve from 0.99299\n",
            "Epoch 910/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0329 - accuracy: 0.9974 - val_loss: 0.1132 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00910: val_accuracy did not improve from 0.99299\n",
            "Epoch 911/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0311 - accuracy: 0.9987 - val_loss: 0.1134 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00911: val_accuracy did not improve from 0.99299\n",
            "Epoch 912/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0327 - accuracy: 0.9991 - val_loss: 0.1350 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00912: val_accuracy did not improve from 0.99299\n",
            "Epoch 913/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0241 - accuracy: 0.9997 - val_loss: 0.1367 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00913: val_accuracy did not improve from 0.99299\n",
            "Epoch 914/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0282 - accuracy: 0.9976 - val_loss: 0.2115 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00914: val_accuracy did not improve from 0.99299\n",
            "Epoch 915/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0310 - accuracy: 0.9971 - val_loss: 0.2753 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00915: val_accuracy did not improve from 0.99299\n",
            "Epoch 916/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0645 - accuracy: 0.9971 - val_loss: 0.2069 - val_accuracy: 0.9673\n",
            "\n",
            "Epoch 00916: val_accuracy did not improve from 0.99299\n",
            "Epoch 917/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0757 - accuracy: 0.9954 - val_loss: 0.4004 - val_accuracy: 0.9556\n",
            "\n",
            "Epoch 00917: val_accuracy did not improve from 0.99299\n",
            "Epoch 918/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0717 - accuracy: 0.9941 - val_loss: 0.1300 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00918: val_accuracy did not improve from 0.99299\n",
            "Epoch 919/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0420 - accuracy: 0.9984 - val_loss: 0.1191 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00919: val_accuracy did not improve from 0.99299\n",
            "Epoch 920/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0451 - accuracy: 0.9947 - val_loss: 0.0794 - val_accuracy: 0.9860\n",
            "\n",
            "Epoch 00920: val_accuracy did not improve from 0.99299\n",
            "Epoch 921/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0356 - accuracy: 0.9974 - val_loss: 0.0807 - val_accuracy: 0.9907\n",
            "\n",
            "Epoch 00921: val_accuracy did not improve from 0.99299\n",
            "Epoch 922/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0342 - accuracy: 0.9982 - val_loss: 0.0848 - val_accuracy: 0.9860\n",
            "\n",
            "Epoch 00922: val_accuracy did not improve from 0.99299\n",
            "Epoch 923/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0328 - accuracy: 0.9978 - val_loss: 0.1192 - val_accuracy: 0.9860\n",
            "\n",
            "Epoch 00923: val_accuracy did not improve from 0.99299\n",
            "Epoch 924/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0286 - accuracy: 0.9997 - val_loss: 0.1108 - val_accuracy: 0.9883\n",
            "\n",
            "Epoch 00924: val_accuracy did not improve from 0.99299\n",
            "Epoch 925/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0780 - accuracy: 0.9956 - val_loss: 0.1226 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00925: val_accuracy did not improve from 0.99299\n",
            "Epoch 926/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0707 - accuracy: 0.9963 - val_loss: 0.1110 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00926: val_accuracy did not improve from 0.99299\n",
            "Epoch 927/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0478 - accuracy: 0.9990 - val_loss: 0.0730 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00927: val_accuracy did not improve from 0.99299\n",
            "Epoch 928/1000\n",
            "54/54 [==============================] - 1s 22ms/step - loss: 0.0557 - accuracy: 0.9979 - val_loss: 0.1406 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00928: val_accuracy did not improve from 0.99299\n",
            "Epoch 929/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0453 - accuracy: 0.9967 - val_loss: 0.1566 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00929: val_accuracy did not improve from 0.99299\n",
            "Epoch 930/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0395 - accuracy: 0.9984 - val_loss: 0.1896 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00930: val_accuracy did not improve from 0.99299\n",
            "Epoch 931/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0535 - accuracy: 0.9962 - val_loss: 0.2312 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00931: val_accuracy did not improve from 0.99299\n",
            "Epoch 932/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0406 - accuracy: 0.9971 - val_loss: 0.2016 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00932: val_accuracy did not improve from 0.99299\n",
            "Epoch 933/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0609 - accuracy: 0.9942 - val_loss: 0.1833 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00933: val_accuracy did not improve from 0.99299\n",
            "Epoch 934/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0539 - accuracy: 0.9933 - val_loss: 0.1364 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00934: val_accuracy did not improve from 0.99299\n",
            "Epoch 935/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0778 - accuracy: 0.9942 - val_loss: 0.1534 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00935: val_accuracy did not improve from 0.99299\n",
            "Epoch 936/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0782 - accuracy: 0.9881 - val_loss: 0.1529 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00936: val_accuracy did not improve from 0.99299\n",
            "Epoch 937/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0413 - accuracy: 0.9963 - val_loss: 0.1339 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00937: val_accuracy did not improve from 0.99299\n",
            "Epoch 938/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0328 - accuracy: 0.9967 - val_loss: 0.1348 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00938: val_accuracy did not improve from 0.99299\n",
            "Epoch 939/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0270 - accuracy: 0.9991 - val_loss: 0.1431 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00939: val_accuracy did not improve from 0.99299\n",
            "Epoch 940/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0375 - accuracy: 0.9983 - val_loss: 0.1258 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00940: val_accuracy did not improve from 0.99299\n",
            "Epoch 941/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0471 - accuracy: 0.9964 - val_loss: 0.2477 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00941: val_accuracy did not improve from 0.99299\n",
            "Epoch 942/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0358 - accuracy: 0.9960 - val_loss: 0.2454 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00942: val_accuracy did not improve from 0.99299\n",
            "Epoch 943/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0470 - accuracy: 0.9959 - val_loss: 0.2974 - val_accuracy: 0.9556\n",
            "\n",
            "Epoch 00943: val_accuracy did not improve from 0.99299\n",
            "Epoch 944/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0436 - accuracy: 0.9957 - val_loss: 0.2283 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00944: val_accuracy did not improve from 0.99299\n",
            "Epoch 945/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0388 - accuracy: 0.9983 - val_loss: 0.2060 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00945: val_accuracy did not improve from 0.99299\n",
            "Epoch 946/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0705 - accuracy: 0.9931 - val_loss: 0.1708 - val_accuracy: 0.9907\n",
            "\n",
            "Epoch 00946: val_accuracy did not improve from 0.99299\n",
            "Epoch 947/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0359 - accuracy: 0.9981 - val_loss: 0.2189 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00947: val_accuracy did not improve from 0.99299\n",
            "Epoch 948/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0747 - accuracy: 0.9951 - val_loss: 0.2137 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00948: val_accuracy did not improve from 0.99299\n",
            "Epoch 949/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0599 - accuracy: 0.9926 - val_loss: 0.2096 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00949: val_accuracy did not improve from 0.99299\n",
            "Epoch 950/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0655 - accuracy: 0.9937 - val_loss: 0.1258 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00950: val_accuracy did not improve from 0.99299\n",
            "Epoch 951/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0523 - accuracy: 0.9966 - val_loss: 0.1307 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00951: val_accuracy did not improve from 0.99299\n",
            "Epoch 952/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0363 - accuracy: 0.9982 - val_loss: 0.1303 - val_accuracy: 0.9860\n",
            "\n",
            "Epoch 00952: val_accuracy did not improve from 0.99299\n",
            "Epoch 953/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0659 - accuracy: 0.9933 - val_loss: 0.1647 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00953: val_accuracy did not improve from 0.99299\n",
            "Epoch 954/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0410 - accuracy: 0.9980 - val_loss: 0.1617 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00954: val_accuracy did not improve from 0.99299\n",
            "Epoch 955/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0355 - accuracy: 0.9989 - val_loss: 0.1268 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00955: val_accuracy did not improve from 0.99299\n",
            "Epoch 956/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0389 - accuracy: 0.9979 - val_loss: 0.1240 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00956: val_accuracy did not improve from 0.99299\n",
            "Epoch 957/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0530 - accuracy: 0.9962 - val_loss: 0.1594 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00957: val_accuracy did not improve from 0.99299\n",
            "Epoch 958/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0451 - accuracy: 0.9958 - val_loss: 0.1411 - val_accuracy: 0.9860\n",
            "\n",
            "Epoch 00958: val_accuracy did not improve from 0.99299\n",
            "Epoch 959/1000\n",
            "54/54 [==============================] - 1s 22ms/step - loss: 0.0369 - accuracy: 0.9957 - val_loss: 0.1073 - val_accuracy: 0.9883\n",
            "\n",
            "Epoch 00959: val_accuracy did not improve from 0.99299\n",
            "Epoch 960/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0361 - accuracy: 0.9952 - val_loss: 0.1174 - val_accuracy: 0.9907\n",
            "\n",
            "Epoch 00960: val_accuracy did not improve from 0.99299\n",
            "Epoch 961/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0292 - accuracy: 0.9969 - val_loss: 0.1155 - val_accuracy: 0.9860\n",
            "\n",
            "Epoch 00961: val_accuracy did not improve from 0.99299\n",
            "Epoch 962/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0544 - accuracy: 0.9949 - val_loss: 0.1075 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00962: val_accuracy did not improve from 0.99299\n",
            "Epoch 963/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0405 - accuracy: 0.9971 - val_loss: 0.1044 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00963: val_accuracy did not improve from 0.99299\n",
            "Epoch 964/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0492 - accuracy: 0.9958 - val_loss: 0.1296 - val_accuracy: 0.9907\n",
            "\n",
            "Epoch 00964: val_accuracy did not improve from 0.99299\n",
            "Epoch 965/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0426 - accuracy: 0.9945 - val_loss: 0.2367 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00965: val_accuracy did not improve from 0.99299\n",
            "Epoch 966/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0460 - accuracy: 0.9941 - val_loss: 0.1636 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00966: val_accuracy did not improve from 0.99299\n",
            "Epoch 967/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0458 - accuracy: 0.9975 - val_loss: 0.1300 - val_accuracy: 0.9860\n",
            "\n",
            "Epoch 00967: val_accuracy did not improve from 0.99299\n",
            "Epoch 968/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0335 - accuracy: 0.9980 - val_loss: 0.1598 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00968: val_accuracy did not improve from 0.99299\n",
            "Epoch 969/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0374 - accuracy: 0.9954 - val_loss: 0.1668 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00969: val_accuracy did not improve from 0.99299\n",
            "Epoch 970/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0262 - accuracy: 0.9975 - val_loss: 0.1602 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00970: val_accuracy did not improve from 0.99299\n",
            "Epoch 971/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0286 - accuracy: 0.9978 - val_loss: 0.1201 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00971: val_accuracy did not improve from 0.99299\n",
            "Epoch 972/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0237 - accuracy: 0.9997 - val_loss: 0.0972 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00972: val_accuracy did not improve from 0.99299\n",
            "Epoch 973/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0241 - accuracy: 0.9974 - val_loss: 0.0965 - val_accuracy: 0.9860\n",
            "\n",
            "Epoch 00973: val_accuracy did not improve from 0.99299\n",
            "Epoch 974/1000\n",
            "54/54 [==============================] - 1s 22ms/step - loss: 0.0354 - accuracy: 0.9959 - val_loss: 0.1523 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00974: val_accuracy did not improve from 0.99299\n",
            "Epoch 975/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0455 - accuracy: 0.9980 - val_loss: 0.2017 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00975: val_accuracy did not improve from 0.99299\n",
            "Epoch 976/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0551 - accuracy: 0.9959 - val_loss: 0.2168 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00976: val_accuracy did not improve from 0.99299\n",
            "Epoch 977/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0391 - accuracy: 0.9966 - val_loss: 0.1952 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00977: val_accuracy did not improve from 0.99299\n",
            "Epoch 978/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0362 - accuracy: 0.9988 - val_loss: 0.2521 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00978: val_accuracy did not improve from 0.99299\n",
            "Epoch 979/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0565 - accuracy: 0.9946 - val_loss: 0.1806 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00979: val_accuracy did not improve from 0.99299\n",
            "Epoch 980/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0310 - accuracy: 0.9978 - val_loss: 0.1329 - val_accuracy: 0.9860\n",
            "\n",
            "Epoch 00980: val_accuracy did not improve from 0.99299\n",
            "Epoch 981/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0541 - accuracy: 0.9959 - val_loss: 0.3110 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00981: val_accuracy did not improve from 0.99299\n",
            "Epoch 982/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0357 - accuracy: 0.9982 - val_loss: 0.2352 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00982: val_accuracy did not improve from 0.99299\n",
            "Epoch 983/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0441 - accuracy: 0.9949 - val_loss: 0.2098 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00983: val_accuracy did not improve from 0.99299\n",
            "Epoch 984/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0304 - accuracy: 0.9996 - val_loss: 0.1830 - val_accuracy: 0.9813\n",
            "\n",
            "Epoch 00984: val_accuracy did not improve from 0.99299\n",
            "Epoch 985/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0423 - accuracy: 0.9962 - val_loss: 0.1796 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00985: val_accuracy did not improve from 0.99299\n",
            "Epoch 986/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0368 - accuracy: 0.9976 - val_loss: 0.1220 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00986: val_accuracy did not improve from 0.99299\n",
            "Epoch 987/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0704 - accuracy: 0.9964 - val_loss: 0.2267 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00987: val_accuracy did not improve from 0.99299\n",
            "Epoch 988/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0472 - accuracy: 0.9956 - val_loss: 0.1968 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00988: val_accuracy did not improve from 0.99299\n",
            "Epoch 989/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0451 - accuracy: 0.9978 - val_loss: 0.2300 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00989: val_accuracy did not improve from 0.99299\n",
            "Epoch 990/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0845 - accuracy: 0.9899 - val_loss: 0.2610 - val_accuracy: 0.9650\n",
            "\n",
            "Epoch 00990: val_accuracy did not improve from 0.99299\n",
            "Epoch 991/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0776 - accuracy: 0.9937 - val_loss: 0.1586 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00991: val_accuracy did not improve from 0.99299\n",
            "Epoch 992/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0526 - accuracy: 0.9983 - val_loss: 0.2030 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00992: val_accuracy did not improve from 0.99299\n",
            "Epoch 993/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0643 - accuracy: 0.9977 - val_loss: 0.1530 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00993: val_accuracy did not improve from 0.99299\n",
            "Epoch 994/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0505 - accuracy: 0.9975 - val_loss: 0.1793 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00994: val_accuracy did not improve from 0.99299\n",
            "Epoch 995/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0378 - accuracy: 0.9992 - val_loss: 0.1491 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00995: val_accuracy did not improve from 0.99299\n",
            "Epoch 996/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0361 - accuracy: 0.9990 - val_loss: 0.1479 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00996: val_accuracy did not improve from 0.99299\n",
            "Epoch 997/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0367 - accuracy: 0.9968 - val_loss: 0.2022 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00997: val_accuracy did not improve from 0.99299\n",
            "Epoch 998/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0486 - accuracy: 0.9985 - val_loss: 0.1507 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00998: val_accuracy did not improve from 0.99299\n",
            "Epoch 999/1000\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.0722 - accuracy: 0.9910 - val_loss: 0.2078 - val_accuracy: 0.9790\n",
            "\n",
            "Epoch 00999: val_accuracy did not improve from 0.99299\n",
            "Epoch 1000/1000\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.0513 - accuracy: 0.9936 - val_loss: 0.2159 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 01000: val_accuracy did not improve from 0.99299\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZckxX9HZ6wND",
        "outputId": "70ba2be6-188c-425d-b599-971ae66c8028"
      },
      "source": [
        "# PLOT MODEL HISTORY OF ACCURACY AND LOSS OVER EPOCHS\n",
        "# Plot the results\n",
        "train_loss=model_history.history['loss']\n",
        "val_loss=model_history.history['val_loss']\n",
        "train_acc=model_history.history['accuracy']\n",
        "val_acc=model_history.history['val_accuracy']\n",
        "plt.rcParams['figure.dpi'] = 150 \n",
        "plt.figure(1,figsize=(7,5))\n",
        "plt.plot(train_loss)\n",
        "plt.plot(val_loss)\n",
        "plt.xlabel('Number of epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training loss vs Validation loss')\n",
        "plt.grid(True)\n",
        "plt.legend(['Training','Validation'], loc=1)\n",
        "plt.style.use(['seaborn-darkgrid'])\n",
        "\n",
        "plt.rcParams['figure.dpi'] = 150 \n",
        "plt.figure(2,figsize=(7,5))\n",
        "plt.plot(train_acc)\n",
        "plt.plot(val_acc)\n",
        "plt.xlabel('Number of epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training accuracy vs Validation accuracy')\n",
        "plt.grid(True)\n",
        "plt.legend(['Training','Validation'],loc=4)\n",
        "plt.style.use(['seaborn-darkgrid'])      \n",
        "\n",
        "# PRINT LOSS AND ACCURACY PERCENTAGE ON TEST SET\n",
        "print(\"Loss of the model is - \" , model.evaluate(x_test,y_test)[0])\n",
        "print(\"Accuracy of the model is - \" , model.evaluate(x_test,y_test)[1]*100 , \"%\") \n",
        "\n",
        "# PREDICTION LABELS\n",
        "predictions = model.predict(x_test, batch_size=32)\n",
        "predictions=predictions.argmax(axis=1)\n",
        "predictions\n",
        "predictions = predictions.astype(int).flatten()\n",
        "predictions = (lb.inverse_transform((predictions)))\n",
        "predictions = pd.DataFrame({'Predicted Values': predictions}) \n",
        "\n",
        "# ACTUAL LABELS\n",
        "TRUE = y_test.argmax(axis=1)\n",
        "TRUE = TRUE.astype(int).flatten()\n",
        "TRUE = (lb.inverse_transform((TRUE)))\n",
        "TRUE = pd.DataFrame({'TRUE Values': TRUE})\n",
        "\n",
        "# COMBINE PREDICTION AND ACTUAL LABELS\n",
        "finaldf = TRUE.join(predictions)\n",
        "finaldf[10:25] \n",
        "# CREATE CONFUSION MATRIX OF ACTUAL VS. PREDICTION -SGD-MFCC\n",
        "cm = confusion_matrix(TRUE, predictions)\n",
        "plt.figure(figsize = (9,7))\n",
        "plt.rcParams['figure.dpi'] = 125 \n",
        "cm = pd.DataFrame(cm , index = [i for i in lb.classes_] , columns = [i for i in lb.classes_])\n",
        "ax = sns.heatmap(cm, linecolor='white', cmap='Accent', linewidth=1, annot=True, fmt='')\n",
        "bottom, top = ax.get_ylim()\n",
        "ax.set_ylim(bottom + 0.6, top - 0.6)\n",
        "plt.title('Confusion Matrix', size=20)\n",
        "plt.xlabel('Predicted Classes', size=15)\n",
        "plt.ylabel('True Classes', size=15)\n",
        "plt.savefig('emo-db.png')\n",
        "plt.show() \n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(TRUE, predictions, target_names = ['Angry', 'Boredom', 'Disgust', 'Fear', 'Happy', 'Neutral','Sadness']))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14/14 [==============================] - 0s 7ms/step - loss: 0.2159 - accuracy: 0.9836\n",
            "Loss of the model is -  0.2158588320016861\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.2159 - accuracy: 0.9836\n",
            "Accuracy of the model is -  98.36448431015015 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4sAAAKpCAYAAAAVALnqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAXEQAAFxEByibzPwAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeWDM1/7/8dckIfYKiV0TQaiKoihXtPai9kptLe5V1dqqet3W1b3VqirfWy1pSYtSO5eilqotuCpibW21tLLYt5CNZH5/5DfTTBaSzCeS+fT5+Cs+65mZM21eeZ9zPhar1WoVAAAAAABpuOV3AwAAAAAABQ9hEQAAAACQAWERAAAAAJABYREAAAAAkAFhEQAAAACQAWERAAAAAJABYREAAAAAkAFhEQAAAACQAWERAAAAAJABYREAAAAAkAFhEQAAAACQAWERAAAAAJABYREAAAAAkAFhEQAAAACQAWERAPLZc889p1q1amnatGlOX2v37t2qVauWatWqZUDL8kbr1q1Vq1YtLV++PL+bglzI7PNbvny5atWqpdatW+foWtOmTVOtWrX03HPPGd1MB3wvACB3PPK7AQBwv0ybNk2ff/55js/r0aOHJk6cmActStWwYUOVLFlS/v7+Tl/Ly8tLbdq0MaBVKOi6dOmi48eP56h/Hjp0SL169ZIkzZs3T40bNzakLRUrVlSbNm1UtmxZQ65nNL4XAJA7hEUAfxn+/v6Z/sJ4/PhxnT17VqVLl9ajjz6aYX+dOnXytF2vvPKKYdcKCAjQ9OnTDbseCq5evXrpww8/1Pr16/Xmm2+qePHi9zxnxYoVkiQ/Pz/DgqIkNWvWTM2aNTPserkVHh6u/v3766OPPlLPnj3t2/leAEDuEBYB/GU89dRTeuqppzJsnzBhgubOncsvlHAp3bp10+TJkxUXF6f169c7hKPMJCUlac2aNZJkry6azYEDB/K7CQBgKsxZBADABZUuXVrt2rWT9GfF8G42b96sa9euqVChQurRo0deNy9fEBYBwFhUFgEgm1q3bq2oqCjNnDlTiYmJmjp1qs6ePavZs2fbh6/euXNHS5cu1Zo1a3T8+HHdvHlTRYsWVc2aNdWzZ0/16tVLFovF4brPPfecfv75Z40YMUIjR46UJEVGRtqHzB48eFAnT57UjBkztG/fPl27dk3lypVTmzZt9Morr6hYsWL2a+3evVsDBgyQJB07dsy+/fXXX9eKFSs0ZMgQjR49Wt98841WrVqls2fPys3NTXXq1NGwYcP0t7/9LcPrvnbtmqZNm6affvpJly5dUtmyZdWmTRuNGDFCBw4c0NChQ1W5cmX99NNPTr/Hf/zxh0JDQ7Vz506dP39e7u7uqlixooKCgjR48GCVL18+wzlRUVGaNWuWdu3apZiYGEmSj4+P6tWrp/79+2cYWmy1WrVq1SqtWLFCR48eVWxsrEqVKqVKlSqpU6dO6t27t0qUKHHPtrZr105//PGHXn31Vb3wwguZHnPw4EEFBwfLYrFo06ZNqly5smH3l6Tg4GCtWbNGe/bs0dmzZ1W1atUsj7UFypYtW8rb21uSFB8fr3nz5mnjxo06deqU4uLiVLJkSdWpU0f9+vWzh9F7Wb58ucaNG5dpP4iOjtb//d//aceOHbpx44Z8fHzUpk0be1/Pyrlz5+yfa1RUlO7cuaMyZcqoUaNGGjJkiB566KEM97cZN26cxo0bpyZNmujbb7/N8nths3HjRi1evFi//PKLbty4oeLFiysgIEBdunRRz5495eHh+OuS7Tv7zjvvqGvXrvrqq6+0bt06xcTEyNPTU/Xr19fLL7+sunXrZuv9uxdX+l4AMBfCIgDk0KlTpzR58mRVr15dTZs2VZEiRSRJKSkpevHFF7V9+3ZZLBbVqVNHZcuW1blz5xQREaGIiAjt3bs3x4vlRERE6KWXXlKZMmVUu3ZtnT9/XsePH9fcuXN16tQphYaGZvtaVqtVo0aN0rZt2/TII48oMDBQx48f1549e/T888/r22+/dfgl8vr16+rdu7fOnDkjd3d31atXT56enlqyZInCwsI0dOjQHL2Wu9m+fbtGjBihhIQElS5dWo0aNVJKSooOHTqkOXPmaOXKlfr666/18MMP2885efKk+vbtq+vXr6t06dKqV6+eChcurNOnT2vNmjX64YcfNHHiRHXr1s1+zttvv61FixbJYrGoVq1aCgwMVGxsrA4fPqzDhw/rhx9+0OzZs+/5i3GnTp0UEhKijRs3ZhkWf/jhB0lSgwYNVLlyZUPvL0lNmzZVlSpVFBkZqf/+979ZBrDLly9r+/btkv4cghofH69+/frp119/lYeHh+rWrasSJUro7Nmz2rlzp3bu3OnwB4zciIyM1DPPPKPLly+raNGiatiwoSRp2bJlCgsLU8uWLTM978SJE+rfv7+uX7+u4sWLq169enJzc9Px48e1Zs0abdiwQSEhIQoKCpL05wI7O3bsUEJCgurUqaOKFSuqZs2a92zj+PHjtXTpUklS9erVVbduXV26dEnh4eH6+eeftX79es2YMUOFCxfOcG5SUpIGDRqkEydOqH79+ipTpoyOHTumbdu2KTw8XCtXrtSDDz6Yy3cvlat9LwCYjBUA/uI++OADa0BAgPXZZ5+963GtWrWyBgQEWFu3bm2dMWNGhv0bN260BgQEWAMDA6379u1z2Ld+/XprQECANSAgwLpnzx6Hfc8++6w1ICDA+tlnn9m3nT171n58y5YtrV999ZU1JSXFvn/FihX2/UeOHLFv/9///mffntZrr71mv1aHDh2sZ8+ete+7efOmtUuXLtaAgADr8OHDHc6bMGGCNSAgwNq4cWPr0aNH7dvPnTtn7d69u/09adWq1V3fu7Rs5yxbtsy+7fLly9YmTZpYAwICrP/+97+tCQkJ9n2xsbHWoUOHWgMCAqzt27e3JiUl2feNHj3aGhAQYB09erQ1MTHR4T6LFi2yBgQEWJs0aWLf99tvv1kDAgKsdevWtR44cMDh+PPnz1t79OhhDQgIsIaGht7zdRw9etQaEBBgrVWrlvXcuXOZHtO6dWtrQECAdd68eYbf3+aLL76w98u0fSStb775xhoQEGB9/PHHrXfu3HHY1rRpU+vp06czPf6hhx6y/vHHHw77Mvv8li1blmk/GDlypP1zO3/+vH37jRs3rH//+9+t9evXz/S799JLL1kDAgKsffv2td66dcu+PSEhwTpq1ChrQECAtW3bthleZ2Zts1qz/l4sWbLE/p396aefHPYdOnTI3ienTZvmsM/2nW3ZsqW1X79+1suXL9v3Xbhwwdq8eXNrQECA9cMPP8zQxqyY5XsBwFyYswgAOZSSkpJlJal79+76+9//rvr16ztsb9++vR555BFJsld4sqtmzZoaMmSIw/DVbt26qUyZMpJyNk8rOjpaH3/8sapUqWLfVrx4cfXu3VuStH//fvv2lJQUrVy5UpL0wgsvODyjrnz58po6darOnTuXo9eSlaVLl+ratWuqWLGi3n77bXl6etr3lShRQh9++KEKFy6sM2fOaNu2bfZ9R44ckZT6fqSv/DzzzDMaN26cXn75ZcXHx0uSjh49Kil1dcx69eo5HF+uXDlNmDBBY8aMydYKuLVq1VKNGjVktVr1448/Zth/+PBhRUZGysPDQx07djT8/jZPP/203N3dFRkZqd27d2d6jG0Iao8ePeTu7i4p9XPv0qWLXnzxRfn5+TkcP3DgQPn4+Cg5OVm7du3KdlvSun79ujZt2iRJGjt2rMqVK2ffV7JkSU2cOFG3b9/O9Nxq1aqpQ4cOGjlypMMwa09PT40aNUpS6tDMM2fO5KptNraq/IABA9SqVSuHfXXr1tXw4cMlSfPnz9edO3cynH/x4kVNmTLF/l2UUod6dunSRZLzcyhd8XsBwFwIiwCQQ02bNpWbW8b/fLZt21Yff/xxlo/CsM0nu3jxYo7uZ/vFMy2LxWK/3tWrV7N9LT8/vwy/DKZt27Vr1+zbTp06Zf93ZsMF/fz8DHtcgi1At23bNtPhfmXKlLEPj00bXkqVKiVJWr9+vZKTkzOcN2jQIPXr108PPPCApNSQIqW+NtsvyGk99NBDGjp0qJo2bZqtdttC4IYNGzLsW79+vSSpefPm9jBh9P2l1ODeokULSZkvdHPkyBEdPXpUFotFTz/9tH17cHCwJk+erIEDB2Y4x2Kx2P+gkNP+anPgwAHduXNH7u7uat68eYb95cqVsw9LTW/s2LH6z3/+k2n/Sjsv89KlS7lqm5Q6p+/UqVOSUocUZ6Z9+/aSpCtXruj48eMZ9jdp0iTT+YK2oac5+W5mxlW/FwDMgzmLAJBDmf1ymNbevXu1e/dunTt3TlevXrX/svbrr79KSq3Y5URWc55sVYasqjOZyWoBlMyuFRkZKSk1OPj6+mZ6Xv369RUWFpbt+2fl5MmTklIrG1nx9/fXrl27dPr0afu2gQMHasyYMVq+fLn279+v7t27q1mzZqpbt26mgb5p06aqVauWjh07puDgYLVv315t2rRR06ZNHapD2fXUU09p2rRpCg8P17Vr11S6dGn7PluA7Ny5c57d3yY4OFhbtmzRhg0b9NZbbzk8c3H58uX2e6f//FNSUrRjxw7t27dPFy5c0LVr1+z90/Y+57S/2pw9e1ZSaigsWrRopsfUqFEjy2rorVu39NNPP+nYsWO6ePGibt68KavV6nBMZkEou3777TdJqf27Ro0amR5ToUIFFStWTHFxcTp16lSGylpOvk+54arfCwDmQVgEgByy/TU+vevXr2v06NHauXOnoffLrKJwP64VGxsrSSpatKgKFSqU6TG2VTWddePGDUl/VjgyY9tnO1ZKDWsJCQmaMmWKTp06pSlTpkhKfaxE69atNXDgQNWuXdt+fOHChfX111/rjTfe0ObNm7V69WqtXr1aFotFgYGB6t69u4KDg7P9PlWrVk116tTRr7/+qs2bN9sfSXH06FGdOXNGRYsWVdu2bfPs/ja2FU4vXbqkdevW2SuIt2/f1urVqyWlBsq0oqOjNXz4cPsfMYxm6z93WxAlq897165dGjNmjK5cuZInbZP+bF+RIkXu+n6XKFFCcXFxDv3OxsjvZmZc9XsBwDwYhgoAOZT+0Rc2b775pnbu3KlixYrpX//6lzZs2KADBw7o2LFjOnbsmMs92y59FSczWb0XOZWd69jak74y8vTTT2vTpk2aOnWqunfvLm9vb127dk3Lly9X9+7dNXv2bIfjvb29FRISotWrV+vll19WgwYN5ObmpoMHD+q9995Tz549deHChWy33TaEcePGjfZt69atkyS1adPGYc5dXtxfkjw8PNS9e3dJjkNRt27dqitXrjg8k9Fm1KhR+vXXX+Xt7a13331Xmzdv1qFDh+z9tUmTJjlqQ3q2z+tun21mVcsLFy5oxIgRunLligIDA/X5559r165d+vXXX+1tM0J2+25W/e5+cOXvBQBzICwCgAGuXLliDwvjx4/X4MGD5evra3+shiQlJCTkV/NyxRZyEhISshzud/nyZUPuZavWZla9sbl+/bqkP+djpVWkSBF16tRJH3/8scLCwvTdd9+pZcuWslqtmjRpkn04X1o1a9bUsGHDtHDhQu3cuVNvvvmmSpQooRMnTujjjz/Odttt8xZ37NihuLg4SZkPQc2r+9vYKofh4eH2IaC2BYq6du3qUBX65ZdfdOjQIUnS5MmT1adPH1WqVMnhGGf7q63/3Lx5M8tjbJ9pWmvWrNHNmzdVokQJhYaGql27dipTpox9YR6jvke2fhQfH6+kpKRMj7FarfYKZGb9Lq+58vcCgDkQFgHAAGfPnrVXSWyLjaSVkpLi9MqI91ulSpUkpbY9Ojo602PSrp7qDNvz8DJbRMTmxIkTDsdmxWKx6NFHH1VISIjq1aun5ORk/e9//7vrOaVLl9azzz6rTz/9VJJyNJS4SpUqql+/vhISErRz506dPHlSJ0+eVOnSpe3PAbwXZ+5v4+fnp8aNG8tqtWr9+vW6efOmtm7dKinjENTff/9dklSoUKFMFy25devWXT+L7LAtkHPhwgUlJiZmekxm97CtcFqvXr1Mh3zv27fPqXbZpJ0HmNVrPXv2rD2c3m3eYF5x5e8FAHMgLAKAAdLOy8rsF+MVK1bYA1dmS/AXRDVq1LAvTJLZIjZ//PGHYb88PvHEE5JSh3JmVuWJiYmxB1NbGD916pTeeecdffLJJ5le02KxqGLFipL+/EzmzZunYcOG2X/BTs8WkHNavbINRd22bZv9cREdOnTIMNczr+5v06tXL0mp7+O2bduUmJioevXqZQg6tv6akpKS6SIsoaGh9jbktr/Wq1dPFotFd+7cyTSUREZG6uDBgxm22+bgZfY9SklJ0fTp0+3/zqrinZ2Fb8qXL29/HMyaNWsyPeaHH36QJFWuXFn+/v73vKbRXP17AcD1ERYBwABVq1a1r0A5b948+3ar1aply5bpo48+sg9JTLtqYUFWuHBhtWnTRpIUEhJiXx1VSq0WjR492uF5jc7o2bOnvL29df78eb3//vsOAeb69et67bXXlJycrHr16tkrYcWLF9eyZcv0zTffaOnSpRnmv+3du9f+6IHHHntMUmrVatOmTXrjjTcyzL9KSkrSjBkzHI7Prg4dOsjNzU1hYWHasmWLpMwfeZJX90/bjpIlS+rAgQP2fpi+qiilVsnc3d2VnJys7777zr79zp07+vLLL7Vo0SL7cwdz2199fHzsj76YPHmyw2I1169f17hx4xxWbbWxLbxy4MAB+1BZKfWxLmPGjJG7u7sqV64sSfZHX9jYVqPN7qI9Q4cOlZT6nU3//NPw8HB9+eWXkqTBgwfny5xFV/9eAHB9rIYKAAYoXLiwXnzxRX366aeaM2eOwsLCVLFiRf3222+6cOGCPvjgA3l7e2v16tU6fPiwgoOD1b17d/Xv3z+/m35Xo0ePVlhYmM6dO6dOnTrpkUcekbu7u/bt26eHHnpIwcHBeuedd5y+T6lSpTR16lQNHTpUixcv1saNG1WzZk3Fx8frt99+U3x8vKpUqaIpU6bYF/0oX768/vWvf+mDDz7Q+PHj9X//93/y9/eXp6enzp07Zx+6949//EMPP/ywJGn48OHavn279u/fr5YtW+qhhx5S2bJlFR8fryNHjig2NlY+Pj4aN25cjtpfvnx5NWrUSD///LNiYmJUqVIl+/Pv0sqr+9sUKVJEnTt31oIFC7R3714VK1Ys02cIVqhQQb169dKiRYv00UcfadWqVSpdurSOHDmiW7du6fPPP1dkZKQ2b96s9evX67nnnlO/fv3s8zOza9y4cerTp4+OHz+utm3b6pFHHlFKSooOHjyosmXLauDAgZo2bZrDOR07dlRISIhOnDihvn37qkGDBpJSw6O3t7e+/fZbffLJJ4qKitLkyZO1efNmjR8/Xv7+/mrYsKF++eUXfffdd9qxY4cSEhIcHlaf3lNPPaWIiAjNmzdPzz//vKpVq6ZKlSopKirKPhy2Z8+e6tevX45et1Fc/XsBwPURFgHAIEOGDJGbm5uWLFmiP/74Qzdu3FCdOnU0adIkPfbYY7Jarerbt69Wr16t06dPO/0MtvuhatWqWrx4saZMmaLdu3frwIEDqlKlil544QX94x//sA/f8/Bw/n8nTZo00apVqzRz5kzt3LlT+/fvl4eHh/z8/NS2bVsNHDgwwyMEnnvuOdWuXVtLly5VRESEDh8+rKSkJHl5ealt27Z65pln7EP5JMnLy0tLly7VokWLtHHjRkVGRurYsWMqVKiQfH199cQTT2jQoEHy8vLKcfs7deqkn3/+WSkpKerUqVOmK1nm5f1tgoODtWDBAkmpwSurR1e88cYbeuCBB7R69WodP35cZcuW1WOPPaahQ4fqoYceUkJCgnbv3q1t27bpxIkT2VodN72AgAAtWbJEn332mXbv3q09e/bIx8dHXbt21csvv2xfCCgtd3d3hYaGatKkSQoLC9P+/ftVqVIl9enTR0OGDJGPj4/GjBmjqKgo+yNKbIvfDB8+XDExMdq5c6cuXryY5fNB03rzzTfVrFkzLVy4UIcPH9bZs2dVsmRJtWjRQs8884zat2+f49dtJFf/XgBwbRZrbv7rDwCApJkzZ2ry5MmqX7++Fi1alN/NAQAABqKyCADI0sGDB3XkyBFVqVJFzZs3z7DftnCJbTgbAAAwD8IiACBLW7Zs0RdffCEfHx/NmTNH1atXt+9bunSpwsLCZLFY1KNHj3xsJQAAyAsMQwUAZOnmzZsaNGiQDh06JDc3N9WtW1elSpXS6dOnFRUVJUkaOXKkRowYkc8tBQAARiMsAgDu6ubNm5o9e7Y2btyoP/74Q0lJSSpdurQCAwPVt29fh4UyAACAeRAWAQAAAAAZ3P8nzOaBHTt2qFatWqpVq1a2z9mzZ4+ef/55NWnSRHXr1tWTTz6pqVOnKi4uLg9bCgAAAACuweUrizdv3lSXLl0UHR0tSTp27Ng9z/nxxx81atQoVa5cWf3791eZMmUUHh6uJUuWqEGDBpo7d64hzwwDAAAAAFfl8olo0qRJunbtmvz9/XXq1Kl7Hp+UlKS3335bJUqU0IIFC+Tt7S1J6tq1q7y8vBQSEqJFixapf//+ed10AAAAACiwXHoY6q5du7R48WK9+OKL9tB3L1u2bNGlS5fUpUuXDOcMHDhQFotFS5cuzYvmAgAAAIDLcNmweOvWLY0fP1516tTR4MGDs33evn37JEkNGjTIsK9MmTLy9fXV0aNHmbsIAAAA4C/NZcPi5MmTdeHCBX344Yc5ml8YGRkpSapYsWKm+ytVqqSUlBT788MAAAAA4K/IJecs7t69WwsWLNBLL72k2rVr5+jcW7duSZKKFSuW6f6iRYtKSl04517u3EnO0b3zmrt7avZPTk7J55bADOhPMBL9CUaiP8FI9CcYqaD2Jw8P99ydZ3A78lx8fLzGjx+vmjVr6qWXXsrx+RaL5a77c7I47NWrBWuoqpdXagAuaO2Ca6I/wUj0JxiJ/gQj0Z9gpILan3x8SubqPJcLi59++qmio6O1cOFCFS5cOMfnFy9eXNKfFcb0bNtLlszdGwoAAAAAZuBSYTE8PFzz5s1T7969Va5cOZ07d86+LykpSZLs2ypUqJDpNXx9fSXJ/lzG9CIjI+Xh4aGqVasa2XQAAAAAcCkuFRZ37dolq9WqhQsXauHChZke88QTT0iSjh07lun+Rx99VJK0Z88ede3a1WFfdHS0oqKi1KBBA3l6ehrYcgAAAABwLS4VFjt37qy6detmum/KlCk6fvy4QkJC7NuuXLmiq1evysfHR6VKlZIkBQUFqXLlylq9erWGDx/uUIGcNWuWJKlv3755+CoAAAAAoOBzqbBYrVo1VatWLdN9X3/9tSSpVatW9m3z58/X559/rjfffFPPPvusJMnDw0MTJkzQCy+8oH79+mnAgAHy8vJSWFiYVq1apTZt2mSoOAIAAADAX41LhUWjNGvWTPPnz9f06dM1ffp0xcfHy9fXV//85z81aNCge66YCgAAAABmZ7Hm5FkRcHDxYmx+N8FBQV2qF66J/gQj0Z9gJPoTjER/gpEKan/K7aMz3AxuBwAAAADABAiLAAAAAIAMCIsAAAAAgAwIiwAAAACADAiLAAAAAIAMCIsAAAAAgAwIiwAAAACADAiLAAAAAIAMCIsAAAAAgAwIiwAAAACADAiLAAAAAAq8mJhoBQU10ogRL+T6Gr16dVFQUCMDW2VuHvndAAAAAACuIzT0S33zzcxsH//ZZyFq2ND5gOblVUbvvz9RpUt75foar776uhIS4p1uy18FYREAAABAtrVu3U7+/tUdtq1bt0Y7dmxXz57BatDgUYd91ao5HptbRYoUUatWbZ26RrNmzQ1py18FYREAAABAtlWr5q9q1fwdtv3yy2FJ21W7dh2nAx0KDuYsAgAAAMgzEya8o6CgRjp8+JDeemuc2rV7XHPmhNr3R0SEa+zYl9W5czs98cRjevLJJzRy5FDt3BnmcJ3M5iyGhn6poKBG2rZti7Zu3awhQwaoXbsWatfucb388jCdPPmbwzXSz1mMiAhXUFAj/ec/n+rkyd80duzL6tixtVq1aqZBg/ppy5ZNGV7PwYP7NWLEC2rXroU6dGip118fo8jIs5o8+SM9/HAd/fzzz0a9dfmOyqJJXI1L0mc7zqhcSU/1qltBHm6W/G4SAAAAYDd//mwlJydr7Nh/y9fXT5IUHv6zxowZIW9vH/XrN0A+Pj66cOG8li1brNdee0UTJ05R8+Yt7nntLVs2af/+CPXoEayePb21b99erV37vf75z1FavHilChUqdNfzo6MjNXr0MHXo8JRat26nqKhILVw4T2+//W+Fhs5TjRo1JUnHjh3V6NHD5Obmpt69+8vX10/79kVo+PDnVb16TSffoYKHsGgSX+38XUsPxEiSKhYrrCdqlM3nFgEAAPx1JNxO1u1ka343454KuVtUpJB7vtw7OjpKoaHz5OHxZwQ5ffqU6tWrryFDXtIjjzSwb69bt56GDx+ixYsXZCsshoVt03ffLZO3t7ckqWPHzoqOjtL+/RE6dOjAPRfY2bFjuz7+eKrDvSwWi775Zqa2bv3JHhbnzg1VUlKSxo9/Rx07dpYktW/fUXPnVtRXX03P/pvhIgiLJnEuNtH+c8yNhHxsCQAAwF/Lp5tPavG+KKUU/KwoN4v0TIPKerWVMYvO5ETr1u0cgqIkBQf3UXBwH/u/4+JuKTk5ReXLV5QknTsXna1rt2nT3h4UberUqav9+yN06dLFe55fpcqDGUJpnTp1Jcnh/L1796hw4cJq06a9w7G9e/fTvHlzFBd3K1vtdRWERZNIO+jUBf47BQAAYBpLXCQoSlKKNbW9+REWK1WqnGFbcnKyFi6cp3Xr1igqKlJJSUkZ9mdH1aoPZtjm6ekpSbpz5849z3/wwXuff+PGdd28eVNVqz6owoULpzu2iAICamn//ohstddVEBYBAAAAJwQ3qOwylUV3S2p780OxYsUzbPvkkw+1evVK+fn5a9iwUapcuao8PT2VmJiosWNfzva1PUA9ZggAACAASURBVD0L3/ugu0gf/jITH5/6fMaiRYtmur9kyZJOtaEgIiyahMXyZ23RanWB/1IBAACYxKutqmt4kB9zFnPo8uVLWrv2e5UpU1bTp89UqVIP2PddvHghH1uWucKFUyuN6aufNrdumWsIqkRYNA3WPgUAAMg/RQq5q8jdF9xEOjExMUpJSVHt2nUcgqKUukpqQVO6dGl5enrq/PlzSk5Olrv7n6H79u3bOn78WD62Lm/wnEWTSFNYFIVFAAAAFHS2BWnSL2Jz7lyMvvturtzd3ZWYmJjZqfnCYrGobt1HFB8fr127HJ8BuWTJQt26dTOfWpZ3qCyaEFkRAAAABV2FChUVGFhPhw4d1Pvvv6UmTZoqJiZaS5cu0qhRYzR37tc6c+a0vv12tv72tyAVK1Ysv5us/v0HKCJijyZMeFfBwX1UoUJFHTp0UPv371Xjxk3188+78ruJhqKyaBLMWQQAAICree+9iWrVqq12796lKVM+1u7dOzVu3Ftq376jhgwZpjJlymrOnFk6dOhAfjdVktSkSVO9995HKl++gubNm62QkM+VlJSoadO+UtGiRSRJ7u7miVgWK8ki1y5ejM3vJti9tupX/XTikiRp1OPV9FzjqvncIrg6L6/Uv95dvRqXzy2BGdCfYCT6E4xEf4JRhg17XgcP7tf336+Wl1eF/G6OAx+f3K3Uap7Y+xfHnEUAAAAgb23ZskmvvjpKW7f+5LD9zJnT+uWXQ/L29pafn1/+NC4PMGfRJNKuhkpWBAAAAIzn5+evw4cP6ODB/Tp27Kj8/KrpwoXzWrJkgZKTkzV69CtyczNPPY6waBrMWQQAAADykp9fNc2YEar58+do/fq1unLlsjw9i6hWrdr617/eUOfOT+Z3Ew1FWDQJh2Go+dcMAAAAwNT8/WvozTffz+9m3BfmqZH+xVnufQgAAAAAZBth0SRY4AYAAACAkQiLJmRlICoAAAAAJxEWTcJiSbvATT42BAAAAIApEBZNgkdnAAAAADASYdEkLKxwAwAAAMBAhEUzorQIAAAAwEmERZNwHIZKWgQAAADgHMKiWbDADQAAAAADERZNggVuAAAAABiJsGgShEUAAACYwYQJ7ygoqJEiIsLt24KCGqlXry7ZOn/t2u8VFNRIoaFfGtquiIhwBQU10oQJ7xh63YKMsGgSDquhMg4VAAAAeeS1115RUFAjbdq04Z7HLlu2WEFBjfThh+86dc/335+oV1993alr5MQff5zJEDarVauu99+fqKeffua+tSO/ERZNwpKmtkhUBAAAQF7p2TM1LK1cufyex65alXrM00/3duqerVq1VbNmzZ26Rk5s3bpF33wz02Gbl5eXWrVqq9q169y3duQ3wqJZpKksUlgEAABAXmnSpKmqVKmqiIhw/fHH71ked/jwQZ08+ZsefjhQtWrVvo8tdN6vvx7K7yYUCB753QAYgzmLAAAAuB8sFot69OiladOmatWqFRoxYnSmx61atUKS1LNnsOLibmnevDnavn2LoqOjlJycLB+fcmre/HENHjxUJUuWvOs9g4IaqUKFilq69Hv7tgsXzuuLL/6jPXt2KyEhQb6+vurbd0CW14iICNeCBd/qyJFfFRt7Q0WKFFFAQG317fuc/va3IElSTEy0goO7OtxXksLCwhUREa5Ro15Ux46dNX78O/Zjrl69qm+//Vo7dmzXhQvnVahQIT34oJ86dnxKPXoEy83NzeF6NWoE6LPPQjRjxjTt3Lld169fU9my3urcuZsGDhzscHx+IyyahIXKIgAAQP65HS9LSlJ+t+KerG6FpUJFnb5Op05dNXPmDP3ww/d64YVhKly4sMP+2NhYbdq0QaVLpw7dHDNmhPbvj1C7dh3Ur98AWa1WhYf/rKVLF+rXXw8rJOTrHIWkhIQEjRw5VFFRkerUqYvq1auvq1ev6Ouvv1LFihUzHB8e/rPGjBkhb28f9es3QD4+Prpw4byWLVus1157RRMnTlHz5i3k5VVG778/UZ9++rGuXbuq99+feNd2XL9+TS+8MEgXLpzTU091VaNGDZWQEK8fflivqVM/0dGjRxyCpSTduXNbo0cPU9WqD2rIkJcUF3dLixcvUGjolypV6oECNSeSsGgSFmqLAAAA+aL49rdV9NA3slhT8rsp92S1uCk+8O+61cK5BWdKliypdu066Pvv/6stW35S+/YdHPavX79GiYmJeuaZfrp166aKFi2aoSLXqVMXXb58SXv37tGhQwf1yCP1s33/tWu/V1RUpLp166mxY/9t3961aw/16/d0huNPnz6levXqa8iQl/TIIw3s2+vWrafhw4do8eIFat68hYoUKaJWrdrqiy/+Iyl1ruTdfPPNTMXERGnkyFfUu3d/eXkVkyQ9+WQ3DRv2vH74YbW6dXtadesG2s85c+a0+vR51qEiW6NGgEaNelGbN/9YoMJiwalxwilUFgEAAPJH0UOzXSIoSpLFmqKih2Ybcq2ePYMl/bmITVqrVq2Qu7u7unV7Wl5eZfTJJ/+xB8U7d+4oNjZWsbGxqlrVV5J07lx0ju69Z89uSVL79p0ctj/wQGk98UTrDMcHB/fR559/ZQ+KcXG3FBsbq/LlK+bq/jabN2+Sh4eHunVzDKju7u7q0qWbJGn79i0ZzuvTp7/Dvx9+uK4k6dKli7lqR16hsmhCZEUAAID7Jz5wkAtVFt0VHzjIkGvVrFlLgYGPaP/+CP3++xn5+vpJkg4dOqBTp06qRYsnVKFCBUnSb7+d0DfffKX9+yN048YNWdNVN5KTk3N07+joSElS1apVM+zz96+eYVtycrIWLpyndevWKCoqUklJSRn251RsbKwuX76kqlUfVJEiRTLs9/Pzl5T6GI60ihYtKm9vH4dtnp6p59+5cyfH7chLhEWT4DGLAAAA+eNWi3d1q+nrf6k5izY9ewbr0KEDWrlymUaNelXSn4/UsD1i4/ffz+ill/6hxMREdenSXY0bP6aSJUvJYrHov/9dpp9+2pjj+8bHx0uSPD09M+zLLLh98smHWr16pfz8/DVs2ChVrlxVnp6eSkxM1NixL+f4/qltiJOUGv4yYwuAtrbapJ/fWZARFk3CYkn7nEXSIgAAwH1VqKisMi6EuYqWLdto2rSp+uGHNRo6dISSkpK0efOPevBBXzVq1ESStGTJQsXHx2vIkJc0cOBgh/M3blyXq/vaQmJSUpKKF3fcd+vWLYd/X758SWvXfq8yZcpq+vSZKlXqAfu+ixcv5Or+klSsWOqN4+LiM91vC5O241wRcxZNwnLvQwAAAABDFSpUSF26dFds7A2FhW3Tpk0blJiYqB49gu3FjOjoKEnSY4/9zeHc5ORk7du3N1f3rVixsiQpKioyw76TJ39z+HdMTIxSUlJUu3Ydh6Aopa6SmlslSpRQuXLlFRMTpbi4uAz7T51KbYefX7Vc3yO/ERYBAAAA5Fq3bj3l7u6uH39cpx9/XG9f+dTG29tbkhQTE+Vw3uzZs3Tjxg1JUmJiYo7u+eijqc8/TF+ZvHz5krZt2+ywzXb/9IvYnDsXo+++myt3d/cM93d3d///7Uq4azvatm2v5ORk/fe/Sx2237lzxz4ct3Xrdtl5SQWSSw5DjYyM1OzZsxUWFqaYmBi5u7urZs2a6tq1q/r06WP/cLM6t02bNne9/syZM/X4448b3ew8xWqoAAAAyA/lypVXUNDj2rkzTMnJyerSpbtKlChh39+27ZNau/Z7ffbZFF25cllFihTV1q2bdeHCeY0c+YomTHhHa9euUvHixdW+fcds3bNz525atOg7LV++RElJt1W3bqCuXLms77//r+rVq6+dO8Psx1aoUFGBgfV06NBBvf/+W2rSpKliYqK1dOkijRo1RnPnfq0zZ07r229n629/C1L16jVUqVJlRUVFatKkCapePSDDo0FsBg4crB07tisk5HNFR0epUaOGio2N1erVa3TixHH16/ecatSo6dwbnI9cLiweO3ZMAwYM0O3bt9WnTx8FBATo2rVrWrJkid577z0dOHBAkyZNuud1mjRpov79+2e6r06dOkY3+74iKwIAAOB+6tnzGW3dutn+c1pNmjTVv//9tr777ltNn/6ZSpf2UlDQ43rzzffk6empH3/coH379mrmzJBsh8XixUto2rQv9cUX/9HmzRu1fv1aVa36oP7+9yEqXbq0Q1iUpPfem6jPPpui3bt3KSxsq/z9q2vcuLfUvHkLeXoW0aefTtScObNUsmRJVa9eQ0OHDtfFixe0adNG7d0brhYtnsiyHTNmhGrOnFBt375Vq1evlKenp/z9a+itt97P9uspqCzW9OvWFnB9+/ZVRESE5s+fr0aNGtm337x5Ux06dNDFixe1YcMG+fr6Znq+rbLYo0cPTZw40am2XLwY69T5Rvp080ktjEgt7fduUEn/bF0jn1sEV2d7qOzVqxnH4AM5RX+CkehPMBL9CUYqqP3Jx6dkrs5zuTmLHTt21NixYx2CopQ6wbRhw4aSpOjo3D1U05WxwA0AAAAAI7ncMNQBAwZkuj0lJUW///67ChUqJH9//2xfz2q1Kj4+XkWLFnV4/ISrYc4iAAAAACO5XFhM6+bNm0pMTNSpU6c0a9YsnThxQq+//rrKly9/z3MjIyM1atQobdu2TfHx8fL09FSzZs00evRoPfTQQ9m6v63MXBAUKVLI/nNhT48C1Ta4Jnf31IEH9CUYgf4EI9GfYCT6E4xktv7k0mGxf//+Onr0qCSpZs2aCg0NVbNmzbJ1bkREhLp3765JkybJarVqx44dWrJkif73v//p22+/Vb169fKy6YZLWxOlsAgAAADAWS63wE1ahw4d0vXr13X27FmtWrVKBw4c0JAhQ/TKK69keU5CQoJ27dqlihUrqnbt2g77Fi5cqLfffluNGjXS/Pnz73n/grTAzX+2ntK88NSHkj79SEW93tZ1l+hFwVBQJ2jDNdGfYCT6E4xEf4KRCmp/+ssscJNWYGCggoKC1LdvX82bN0+tWrVSSEiIfvzxxyzPKVKkiFq1apUhKEpS7969VbJkSe3du1e3bt3Ky6YbznVnWwIAAAAoiFw6LKbl7u6u4OBgSdLWrVtzdQ2LxSJvb29ZrVbXC4sscAMAAADAQC4VFqOjo9WqVassV0S9fv26pNSVUbNy4MABLVq0SFeuXMmwLykpSZGRkSpWrJjKlCljTKPvmz/TopVZiwAAAACc5FJhsVKlSrJYLNqzZ4/Cw8Md9lmtVq1YsUKS1LhxY0nSlStXdPLkSd24ccN+3Pbt2/XWW29p5syZGa4/Y8YM3b59W+3atZOHh2ut/UNlEQAAAICRXCsRSXr33Xc1bNgwDR48WH369FHt2rUVGxurNWvWaP/+/WrYsKE6d+4sSZo/f74+//xzvfnmm3r22WclSYMGDdKGDRv09ddf6/fff1dQUJDc3d21fft2bdy4UVWrVtXYsWPz8yXmCquhAgAAADCSy4XFFi1aaNmyZZo1a5bWrVun+fPny8PDQ35+fhozZowGDRp016pgiRIlNH/+fM2dO1erV6/W9u3bZbFYVKVKFQ0dOlSDBw/WAw88cB9fkTEspEUAAAAABnLpR2fkt4L06IwZYaf19e6zkqSudcvrzSdr5XOL4OoK6tLPcE30JxiJ/gQj0Z9gpILan/6Sj84AAAAAAOQNwqJZpBmHSq0YAAAAgLMIiybBlEUAAAAARiIsmgRhEQAAAICRCIsm4bgaKnERAAAAgHMIiyZhSVNbJCoCAAAAcBZh0SzSVBYpLAIAAABwFmHRJJizCAAAAMBIhEWTsDhUFomLAAAAAJxDWDQJi0NtEQAAAACcQ1g0CQtzFgEAAAAYiLBoQmRFAAAAAM4iLJoEj1kEAAAAYCTCoklYLKyHCgAAAMA4hEWTICoCAAAAMBJh0SRY4AYAAACAkQiLAAAAAIAMCIsmRGERAAAAgLMIiyaRdoEbK+NQAQAAADiJsGgSlnsfAgAAAADZRlg0CRa4AQAAAGAkwqIJkRUBAAAAOIuwaBLMWQQAAABgJMKiSaSds0hUBAAAAOAswqJJsMANAAAAACMRFk2CBW4AAAAAGImwaBpp5iwyEBUAAACAkwiLJkFlEQAAAICRCIsmwQI3AAAAAIxEWDQJC2kRAAAAgIEIiybhmBVJiwAAAACcQ1g0izSlReYsAgAAAHAWYdEkeM4iAAAAACMRFk2IwiIAAAAAZxEWTYL1bQAAAAAYibBoEo6roRIXAQAAADiHsGgSljS1RaIiAAAAAGcRFs0iTWWRwiIAAAAAZxEWTYI5iwAAAACMRFg0CeYsAgAAADASYdEkmLMIAAAAwEiERZOwMGcRAAAAgIEIiyZEVgQAAADgLMKiSVBZBAAAAGAkwqJJWFgPFQAAAICBCIsmQVQEAAAAYCTCokkwDBUAAACAkQiLJkRWBAAAAOAswqJJWNKWFgEAAADASYRFE7IyDhUAAACAkwiLJkFdEQAAAICRCIsmwQI3AAAAAIxEWDQJHp0BAAAAwEge+d2A3IiMjNTs2bMVFhammJgYubu7q2bNmuratav69Okjd3f3e15jz549+vLLL3Xw4EHFxcWpcuXK6tChg4YOHapixYrdh1dhsDSlReYsAgAAAHCWy4XFY8eOacCAAbp9+7b69OmjgIAAXbt2TUuWLNF7772nAwcOaNKkSXe9xo8//qhRo0apcuXKGjZsmMqUKaPw8HB99dVX2rNnj+bOnSsPD9d6a6gsAgAAADCSayUiSe+8846uXbum+fPnq1GjRvbtvXr1UocOHbRy5UoNHz5cvr6+mZ6flJSkt99+WyVKlNCCBQvk7e0tSeratau8vLwUEhKiRYsWqX///vfl9RiFBW4AAAAAGMnl5ix27NhRY8eOdQiKklSiRAk1bNhQkhQdHZ3l+Vu2bNGlS5fUpUsXe1C0GThwoCwWi5YuXWp8w/MYC9wAAAAAMJLLVRYHDBiQ6faUlBT9/vvvKlSokPz9/bM8f9++fZKkBg0aZNhXpkwZ+fr66ujRo4qLi3OxuYtp5iwyEBUAAACAk1wuLKZ18+ZNJSYm6tSpU5o1a5ZOnDih119/XeXLl8/ynMjISElSxYoVM91fqVIlnTlzRlFRUapZs+Zd7+/lVXDCZMmSN+0/u7m5Fai2wTW5u6cOPKAvwQj0JxiJ/gQj0Z9gJLP1J5cOi/3799fRo0clSTVr1lRoaKiaNWt213Nu3bolSVlWDYsWLSopNYi6Eha4AQAAAGAklw6LH3zwga5fv66zZ89q1apVGjx4sIYMGaJXXnkly3MslrsvBZOTx05cvRqX7WPz2q1bifafk++kFKi2wTXZ/iJGX4IR6E8wEv0JRqI/wUgFtT/5+JTM1XkuHRYDAwPtPz/zzDMaNWqUQkJCFBgYqLZt22Z6TvHixSX9WWFMz7a9ZMncvaH5xcKcRQAAAAAGcrnVULPi7u6u4OBgSdLWrVuzPM72SI2sVkyNjIyUh4eHqlatanwj8xKroQIAAAAwkEuFxejoaLVq1SrLFVGvX78uKXVl1Kw8+uijkqQ9e/Zkev2oqCgFBgbK09PTgBbfP8xZBAAAAGAklwqLlSpVksVi0Z49exQeHu6wz2q1asWKFZKkxo0bS5KuXLmikydP6saNG/bjgoKCVLlyZa1evVrnzp1zuMasWbMkSX379s3Ll5En7jEVEwAAAAByxKXCoiS9++678vDw0ODBg/XRRx9pxYoVmjt3rvr06aNdu3apYcOG6ty5syRp/vz56tSpk1atWmU/38PDQxMmTNCdO3fUr18/zZ49WytXrtTYsWM1f/58tWnTRl27ds2vlwcAAAAABYLLLXDTokULLVu2TLNmzdK6des0f/58eXh4yM/PT2PGjNGgQYPk4XH3l9WsWTPNnz9f06dP1/Tp0xUfHy9fX1/985//1KBBg+65YmpB5DAMlUmLAAAAAJxksZIscu3ixdj8boLd7jNXNWLZIUlSldJFtGJwk3xuEVxdQV36Ga6J/gQj0Z9gJPoTjFRQ+1NuH53hcsNQkQVWQwUAAABgIMKiSbAaKgAAAAAjudycRWSuWNxZfVlois5bvfR1yt/zuzkAAAAAXBxh0SRq/DZLVd1THydyPCVQ0uP52yAAAAAALo1hqCbhmXjZ/nMZ67V8bAkAAAAAMyAsmoTVkvajZNYiAAAAAOcQFk3DkuanlHxsBwAAAAAzICyaRZrKooXKIgAAAAAnERZNI21lkbAIAAAAwDmERbOwpAmLVsIiAAAAAOcQFk2CBW4AAAAAGImwaBIWhqECAAAAMBBh0SSsLHADAAAAwECERbOwpP2RsAgAAADAOYRF00hTWWSBGwAAAABOIiyahYU5iwAAAACMQ1g0C4fVUFPyrRkAAAAAzIGwaBp/VhbdqCwCAAAAcBJh0SzSDEPlOYsAAAAAnEVYNAmHR2ewwA0AAAAAJxEWTcLiMAyVOYsAAAAAnENYNAmrhY8SAAAAgHFIGKZBZREAAACAcQiLZpG2ssiURQAAAABOIiyahCXNaqgWKosAAAAAnERYNAmH1VApLQIAAABwEmHRhAiLAAAAAJxFWDQLKosAAAAADERYNAmHOYtW5iwCAAAAcA5h0TTSVhYBAAAAwDmERZOwshoqAAAAAAMRFs2COYsAAAAADERYNA1LJj8BAAAAQO4QFs0iTWXRjWGoAAAAAJxEWDQLS9p6IsNQAQAAADiHsGgSjo/OICwCAAAAcA5h0SSsLHADAAAAwECERZOwpFnWxs1CWAQAAADgHMKiWVjSfpRWWRmKCgAAAMAJhEWzSDNn0U1WBqICAAAAcAph0SzSzVmksAgAAADAGYRFE6KyCAAAAMBZhEWzsLj/+aOsorQIAAAAwBmERZNweM4ilUUAAAAATiIsmkX6BW5IiwAAAACcQFg0i/QL3ORjUwAAAAC4PsKiaThWFgEAAADAGYRFk7BmeHQGgREAAABA7hEWTSL9AjcAAAAA4AzColkwZxEAAACAgQiLJmERq6ECAAAAMA5h0SwyVBZJiwAAAAByj7BoFjxnEQAAAICBPPK7AbkRGxurWbNmae3atYqJiVGhQoUUEBCgXr16qVevXg6LvWRm9+7dGjBgwF2PWbt2rapXr25ks/NWusoiAAAAADjD5cLi+fPn1adPH124cEHdunVTo0aNdOPGDS1atEhvvPGGTp06pddeey1b1+rQoYM6duyY6b7y5csb2ey8Z0n7I5VFAAAAAM5xubD4xRdfKDo6WuPHj3eoDvbs2VMdOnTQnDlz9Pzzz6ts2bL3vFaNGjXUoUOHvGzufWOxuNt/dmPOIgAAAAAnudycxXLlyunJJ59Ur169HLaXKlVKDRs2VHJyso4fP55PrctH6Re4ISsCAAAAcILLVRZHjBiR5b7Y2FhJUokSJXJ0zZSUFCUkJKhYsWJOtS1fpRmG6mahrggAAADAOS4XFrNy7Ngx7dmzRzVr1tTDDz+crXOOHDmiwYMHa/fu3bp9+7aKFy+uli1b6pVXXlHVqlXveb6XV8EJl4nFi9h/tsiqBx4oKq/ihfOxRXB17u6p1eqC1M/huuhPMBL9CUaiP8FIZutPpgiLMTExGj58uNzc3PTOO+/IzS17o2t37Nih3r17q3///oqLi9OmTZu0Zs0a7dy5U0uXLlWVKlXyuOXGsaQpLVqYsQgAAADASS4fFg8cOKDhw4fr2rVr+vTTT9WoUaN7nhMQEKCQkBD5+/vL19fXvr1z586qUqWKvvrqK3322WeaNGnSXa9z9Wqc0+03iiXhjmx/v7DIqmvX4uSWdCdf2wTXZvuLWEHq53Bd9CcYif4EI9GfYKSC2p98fErm6jyXW+AmrVWrVum5557T7du3FRoaqieffDJb53l5ealVq1YOQdHm+eeflyRt377d0LbmtbSVRTcWuAEAAADgJJcNi6GhoRo7dqx8fX21dOlSPfbYY4Zct1SpUvL09LQvluMy0q2GCgAAAADOcMmwOH/+fE2aNElNmzbVggULsrUYTVq7du3Sd999p6SkpAz7IiMjlZiYqMqVKxvV3PvCmr6ymI9tAQAAAOD6XG7OYkREhCZMmKAGDRroyy+/VJEiRe56/IULFxQbG6uKFSvaH42xatUqLV++XCkpKXr22Wcdjv/8888lSZ06dcqbF5BHLA6L+ljFOFQAAAAAznC5sDhhwgQlJyerZcuW2rJlS6bH1KhRQzVq1JAkTZkyRStWrFBISIhatWolSRo9erR27typDz/8UAcPHlTjxo2VmJioDRs2aPfu3QoMDNSQIUPu10syCJVFAAAAAMZxubB4+PBhSdLUqVOzPGbEiBEaOXJklvvLly+vZcuWKTQ0VBs2bNDatWvl4eEhPz8/vfrqqxo4cKA8PT0Nb3teSltZZIEbAAAAAM6yWK3Eity6eLHgLILjcWKNvDYMlST9kuIr66CfVL6kawVeFCwFdelnuCb6E4xEf4KR6E8wUkHtT3/JR2fgT9YMlUX+BgAAAAAg9wiLJmFRugVuAAAAAMAJhEWzcGOBGwAAAADGISyaRNrKooUFbgAAAAA4ibBoEhZL+soiaREAAABA7hEWTcJqobIIAAAAwDiERbNIU1m0UFUEAAAA4CTCollQWQQAAABgIMKiabAaKgAAAADjEBbNIkNlkbgIAAAAIPcIiybkZiEoAgAAAHAOYdEs0lcW87EpAAAAAFwfYdEs0oVF0iIAAAAAZxAWTcLKAjcAAAAADERYNIsMw1CJiwAAAAByj7BoFhbHymIKWREAAACAEwiLpmFJ8zNzFgEAAAA4h7BoFhkqi6RFAAAAALlHWDSLdHMWCYsAAAAAnEFYNA3mLAIAAAAwDmHRLNKvhkplEQAAAIATCIsmkfY5ixYqiwAAAACcRFg0Cxa4AQAAAGAgwqJZWKgsAgAAADAOYdE03NL8RGURAAAAgHMIi2aRlAvbNwAAIABJREFUYYGbfGwLAAAAAJdHWDSLDMNQSYsAAAAAco+waBZUFgEAAAAYiLBoQm6yKpm0CAAAAMAJhEWTsFJZBAAAAGAgwqJp/Dln0d3CnEUAAAAAziEsmoXF8aNM4UGLAAAAAJxAWDQNi8O/rNaUfGoHAAAAADMgLJpFusoiYREAAACAMwiLZuFYWFRKCmERAAAAQO4RFs2CyiIAAAAAAxEWTSPdnEUWuAEAAADgBMKiSVjTVxaVnE8tAQAAAGAGhEWzSB8WGYUKAAAAwAmERdNwHIaakkJlEQAAAEDuERbNwpJuOVQrcxYBAAAA5B5h0TTSLXDDOFQAAAAATiAsmkW6OYspVBYBAAAAOIGwaBaW9I/OYM4iAAAAgNz7f+zdd4AU5f0/8PfMbL3bq1QFv1iwBCu2xBqNPTEG+WJEEcUaFVuiyddeQIwSDb/ERJEmYtCAKIoIIkVpKqAgRaTXo8PdcWXvts7vj73b252yO7s7W+/9+ofdmdmZh73Z3fnM5/M8D4PFAiEr/pRMLBIRERERUSoYLBYK1QA3zCwSEREREVHyGCwWCmUZKlOLRERERESUAgaLBYOjoRIRERERkXkYLBYKxWioHOCGiIiIiIhSwWCxUCiDRVahEhERERFRChgsFgxOnUFEREREROZhsFgoBOWfkqlFIiIiIiJKXsaCxWAwiPXr12Pr1q2ZOmT7ohoNlQPcEBERERFR8izp2Okrr7yCw4cP46WXXgIA7Nu3D3fccQe2bNkCALjwwgvx73//GzabLan919fXY8yYMZgxYwb27NkDq9WKE044Af369UO/fv0gKOcc1DFnzhyMHz8ea9euhc/nw9FHH40+ffpg0KBBkCQpqbZlUxACxJaMohxkZpGIiIiIiJJnembxP//5D95++22IYtuuhw4dis2bN+Pyyy/Htddei4ULF2LChAlJ7X/fvn247rrrMGbMGJxzzjkYMmQIHn74YdTV1eHpp5/G8OHDDbdz8ODBcLvdePTRRzF06FAce+yxGD58OB577LGk2pZ9bUEyM4tERERERJQK0zOLH3/8MS666CK8+OKLAIDq6mp8+eWXuOSSS/D666+HDmqxYNasWbjrrrsS3v+///1v7N69G0899RRuvfXW8PK+ffvi6quvxjvvvIO77roLHTp00N3HgQMHMHz4cPTo0QMTJ06E0+kEAPTp0wePPvoopk+fjt/97ne45JJLEm5fNsmRwSL7LBIRERERUQpMzyzu3LkTV155Zfj5N998g2AwiN/97nfhZeeeey527dqV1P47d+6Mq666Cv369YtaXlpaijPPPBOBQAAbNmyIuY/p06fD4/Ggf//+4UCx1aBBgwAAU6ZMSap92SRHlt8GmVkkIiIiIqLkmZ5Z9Hg8UQHYkiVLIIoizj///LaDWixoaGhIav8PPPCA7rr6+noAgMvlirmPFStWAAB69+6tWnfyySfDbreHt8knckTsL3OiRSIiIiIiSoHpwWKXLl3CI576fD7MmzcPvXr1QllZWXibHTt2oLKy0tTjrl+/HsuWLcPxxx+Pk08+Oea2VVVVAIAjjzxStU4URXTt2hXbt2+H2+1GUVGR7n4qKvTXZUNkeGizCjnXPsovkhS6+cDziMzA84nMxPOJzMTzicxUaOeT6cHieeedhwkTJqCoqAjLly/HoUOHcN9994XXV1dX48MPP8SZZ55p2jH37NmDwYMHQxRFPP/881GD62hpbGwEAFUJaqvW5Q0NDTGDxVzjE+2wBrwAACnQlOXWEBERERFRPjM9WLznnnswZ84c/O1vfwMQ6p94ww03hNffcMMNOHToEO644w5Tjrdy5UoMHjwYtbW1eO2113D22WenvE+jJZw1Ne6Uj2UmUSpDUSBUiis11eRc+yi/tN4R43lEZuD5RGbi+URm4vlEZsrV86lTp5KkXmd6sHjkkUfi888/x7fffguLxYILLrgAVqs1vL5Pnz44//zzccopp6R8rGnTpuHpp5+G0+nE2LFj8fOf/9zQ61r7NLrdbpSWlqrWt2YeS0qSe1OzpclSCoQSi3D4D2e3MURERERElNdMDxaBUDB2+eWXa6578MEHTTnG2LFjMXz4cJxwwgl44403cNRRRxl+bY8ePbBmzRrs2rULXbt2jVrn9/uxb98+dO3aVbdMNVc1WdoCX6e/LostISIiIiKifGf61BkA8OOPP2LatGlRy9566y307dsX/fv3x4wZM1La/8SJEzF8+HD84he/wPvvv59QoAgAZ511FgBg2bJlqnUrVqyAz+czpZw105ojgsWiAINFIiIiIiJKnunB4sqVK3HzzTdj6tSp4WWjRo3CiBEjsGHDBvz000947LHH8M033yS1/+XLl2PYsGHo3bs33nrrrbjTZOzfvx+bN2+G291WN/yb3/wGLpcLkyZNUk3hMXbsWADATTfdlFT7sqnZ0jbirIOZRSIiIiIiSoHpZahjxoxBhw4dMGTIEABAIBDAuHHjcNRRR+GDDz6AzWbDLbfcgnfeeQfnnXdewvsfNmwYAoEALrnkEnz11Vea2/Ts2RM9e/YEAPz973/H1KlTMXLkSFx66aUAgPLycjzzzDN4/PHHcfPNN6N///5wOp2YOXMm5s+fj4EDB+ZnZtHaFiwys0hERERERKkwPVhcuXIlbrnllnBp6Pfff4/a2lrcc889KC8vBwBcf/31GD9+fFL7X7NmDQBgxIgRuts88MADcftG9unTB506dcKoUaPw6quvIhAI4LjjjsPQoUOjRm/NJyxDJSIiIiIis5geLNbU1KB79+7h599++y0EQcDFF18cXtahQwccOHAgqf2vX78+oe1ffvllvPzyy5rrLrjgAlxwwQVJtSMXeazl4cetU2gQERERERElw/Q+i+Xl5aipqQk/X7RoETp37hwuCwWA2travJrsPl9EZRaDzCwSEREREVHyTA8WTzjhBHz88ceoqanBjBkzsGrVKtU0GnPnzsXRRx9t9qHbPa81YuqMQEOMLYmIiIiIiGIzvQx14MCBuPfee3H++ecDCM25OGjQoPD6v/zlL/j666/x/PPPm33odk+WHOHHVtmL5iy2hYiIiIiI8pvpweIll1yCESNGYNq0abBarbj77ruj5kHctm0bbr75Ztx4441mH7rd80v28GOr7MliS4iIiIiIKN+ZHiwCwDXXXINrrrlGc92ECRPgcDg011FqghGZRQlBIOADJGsWW0RERERERPkqLcFiq61bt2LLli1oampCcXExevbsGZVlJHPJFnvUcyHQDJnBIhERERERJSEtweLXX3+NF198EVu3blWt69WrF1544QWccsop6Th0uxaZWQQA+D2ArSQ7jSEiIiIiorxmerC4atUq3HPPPZBlGWeeeSaOO+44OJ1OuN1ubNiwAatWrcJtt92GDz74AMcee6zZh2/XlMGi4G+GnKW2EBERERFRfjM9WBw1ahTKy8sxbtw4nHDCCar1q1atwt13342RI0di+PDhZh++XRNFER7ZArvgBxAqQyUiIiIiIkqG6fMsrlixAjfddJNmoAgAp512Gvr3749vv/3W7EO3e6IgwIO2PoqCn8EiERERERElx/Rg8fDhw+jevXvMbY455hhUV1ebfeh2TxAAD2xtCwKcPoOIiIiIiJJjerBYUlKCPXv2xNxm//79cLlcZh+63RMFAc1yW7DIzCIRERERESXL9GDx9NNPx+TJk7Fv3z7N9Xv27MF7772H3r17m33odk8SBTSDwSIREREREaXO9AFu7rrrLtx222245pprcMUVV+C4445DUVER3G431q9fj3nz5sHn8+Hee+81+9DtXqgMNWJeRX9T9hpDRERERER5zfRg8eyzz8arr76KF154AZ988gkAQBAEyHJoEofOnTtj6NChOP30080+dLsnCorMIkdDJSIiIiKiJJkeLALANddcg8suuwzLli3Dpk2b4Ha7UVxcjOOPPx7nnHMOLJa0HLbdEwWgWY4cDZUD3BARERERUXLSFrXZbDZccMEFuOCCC1Tr5s2bh8cffxxLly5N1+HbJVVmkX0WiYiIiIgoSaYPcGOEz+dDfX19Ng5d0ATFPItgGSoRERERESUpK8EipYckgJlFIiIiIiIyBYPFAiKKAjyR8ywG2GeRiIiIiIiSw2CxgAiKPotgZpGIiIiIiJLEYLGAiCxDJSIiIiIikzBYLCCiIMATNXUGg0UiIiIiIkqOKVNnPPzwwwltv2/fPjMOSwqiIMAbORpq0J+9xhARERERUV4zJVicNWtWwq8RBMGMQ1MEUQD8EcliQWawSEREREREyTElWJwwYYIZu6EUiYKAAKS2BQEGi0RERERElBxTgsVzzz3XjN1QigRFZhHMLBIRERERUZI4wE0BUWYWhWAgi60hIiIiIqJ8xmCxgEiiAH9kGSoHuCEiIiIioiQxWCwgggD45YhgkWWoRERERESUJAaLBUQUhOjRUFmGSkRERERESWKwWEBEAdGjobIMlYiIiIiIksRgsYCEMosMFomIiIiIKHUMFguIJAoIRJahss8iERERERElicFiAbFbREVmkX0WiYiIiIgoOQwWC4jDKrEMlYiIiIiITMFgsYAws0hERERERGZhsFhA7FYJATniT8rMIhERERERJYnBYgFxqDKLDBaJiIiIiCg5DBYLiMMqRY2GiqAve40hIiIiIqK8xmCxgEiiAIiWtgXss0hERERERElisFhgREtbsMh5FomIiIiIKFkMFguMKNnanjCzSERERERESWKwWGAsUZlFBotERERERJQcBosFxmJtyyyKsh+Q5Sy2hoiIiIiI8hWDxQIjWazRC+RgdhpCRERERER5jcFigbFIimCR02cQEREREVESGCwWGIvVEr2Ag9wQEREREVESGCwWGGtEn0WA02cQEREREVFyGCwWGIsiWGRmkYiIiIiIksFgscBYrco+i8wsEhERERFR4hgsFhhlsMgyVCIiIiIiSgaDxQJjYxkqERERERGZwBJ/k9z10UcfYdiwYWhoaMDcuXPRvXv3uK+pqqrCZZddFnOb0aNH4+KLLzarmRllt0rwyyIsQmh+RYFTZxARERERURLyMlg8dOgQnn32WcydOxdOpzOpfZx77rkYMGCA5rpevXql0rysclglBCDBglCwyMwiERERERElIy+DxX79+sHn82H06NEYNWoUli5dmvA+unXrhquvvjoNrcuuUocFfoiwty5gn0UiIiIiIkpCXvZZPOOMMzBt2jRcdNFF2W5KzulS6oAfUvi5wMwiERERERElIS8ziyNGjDBtX7Iso6mpCU6nE4IgmLbfbOlSao8KFjl1BhERERERJSMvg0UzVFVV4aGHHsKCBQvQ1NQEu92O8847D4888gh+9rOfGdpHRUVRmluZGEkScWRFEQIRwaLDIcKaY+2k/CBJocKDXDvPKT/xfCIz8XwiM/F8IjMV2vmUl2WoZli+fDlcLheGDx+Of/7zn+jTpw8WLFiA/v37Y9WqVdluXtI6l9jhj/iz1jQ0ZbE1RERERESUr9pdZrFjx44YOXIkjjjiCJx00knh5VdddRV69eqF5557Dq+88gomTpwYd181Ne50NjVhFRVFEAHIQtufddf+WlhzrJ2UH1rviOXaeU75iecTmYnnE5mJ5xOZKVfPp06dSpJ6XbvLLDocDlx66aVRgWKrG2+8ESUlJfj+++/R2NiYhdaZRGwrQ61rbM5iQ4iIiIiIKF+1u2AxFkEQ0LFjR8iynOfBojX80O3xZLEhRERERESUr9pdsLhy5UpMmjQJ1dXVqnVerxdVVVUoKipCZWVlFlpnDlloyyw2e71ZbAkREREREeWrgg4Wq6ursXnzZtTV1YWXLVy4EM8++yxGjx6t2v7NN9+Ez+fDFVdcAYslf7tzCmJb2z1eXxZbQkRERERE+SrvIqJdu3Zh9erV4eetGcIFCxaEs4HdunXDqaeeiokTJ+Jf//oXnnnmGdxyyy0AgEGDBuGLL77AuHHjsH37dlx44YWQJAkLFy7E7NmzcdRRR+HPf/5z5v9jZpIigkUfM4tERERERJS4vAsWlyxZgieeeEK1/IUXXgg/vv766/Hyyy9rvt7lcmHixImYMGECpk+fjoULF0IQBHTv3h1/+MMfcOedd6KsrCxt7c+EyMyil2WoRERERESUBEGWZTnbjchXBw7UZ7sJUVqH6j34+mXoengFAOCfxX/ETYMezWazKE/l6tDPlJ94PpGZeD6RmXg+kZly9Xzi1BkUJkaUofr8XtjXfYDyD34Dx5oJWWwVERERERHlk7wrQ6X4BIu97bGvEaVz/wgAsO5fCU/P6yA7yrPVNCIiIiIiyhPMLBYgMSJYLPIfjl7XuCfTzSEiIiIiojzEYLEASda2YFEMcoAbIiIiIiJKHIPFAmSxOsKPHWCwSEREREREiWOwWIAiM4vFQrNirZDZxhARERERUV5isFiILLbwwyIog0XOlEJERERERPExWCxAshgxwA080SuDwQy3hoiIiIiI8hGDxUIkRWQWFWWoQtCX6dYQEREREVEeYrBYgOSIYLFYmVmUAxluDRERERER5SMGiwUoMlhU9lkUgv5MN4eIiIiIiPIQg8VCJMUYDZXBIhERERERGcBgsQBFZhadqgFuGCwSEREREVF8DBYLUUSw6FINcMNgkYiIiIiI4mOwWIAiM4sqDBaJiIiIiMgABosFSI7os6heyWCRiIiIiIjiY7BYiGJkFlmGSkRERERERjBYLEAsQyUiIiIiolQxWCxEMYPFQObaQUREREREeYvBYgGK1WdRCPoy2BIiIiIiIspXDBYLUazMoszMIhERERERxcdgsQDJon6wuKemPoMtISIiIiKifMVgsQDFGuBm8ab9GWwJERERERHlKwaLhShGn8W9h90ZbAgREREREeUrBosFKFZm0QL2WSQiIiIiovgYLBaiOMFis48BIxERERERxcZgsQDFyixKQgCHm/0AANvmGSideTesOxdmqmlERERERJQnLNluAKVBjD6LVgRwuMmHrjYPyj6/BwBg3zITB+7fAQi8d0BERERERCGMDgqRIKD5xP/VXCUhiLpmP6SaTdErfE0ZaBgREREREeULBosFqv7ilzSXW+HH4Wafql+jEGjORLPMF/Ci6Lt/oPiblyB4OYckEREREZFZWIZaqCwOzcUSgjjc7IcsRv/pBV8TZGcmGmYu55p3UbzkbwAAwedGw8UvZrlFRERERESFgZnFQiVKkDX6Llpa+ixCDkYtF/z5Of+ia9Fz4cfO1eOz1xAiIiIiogLDYLGAydYi1TILAqht8kEI+qKWC372WSQiIiIiojYMFguYbFHXlUpCAKt31wNBf9RyBotERERERBSJfRYLmHZmMYi1e+vQ3CxFLRd8+VmGSkRERERE6cHMYgGTLVrBoh8BGdh84HD0CmYWiYiIiIgoAoPFAiZb1WWoFoQGtqmpj84ksgyViIiIiIgiMVgsZBp9FrsINQCA2sbo4FDwMVgkIiIiIqI2DBYLmFafxTPEzThT2IDDimDRuXIMpINrM9U0IiIiIiLKcQwWC5hWn0UAGG4dhTp3c9QyS+1mlH/UF4L7YCaaRkREREREOY7BYgHTyiwCQE9xN+qb1GWnoq8BzlVj090sIiIiIiLKAwwWC5jWPIutfD6v5nJL7ZZ0NYeIiIiIiPIIg8UCFig/RnedBQHN5WJ9VbqaQ0REREREeYTBYgFr/ll/uHvfq1reKNt1g0Wpbke6m0VERERERHmAwWIhEy1oPP9pNJ79cNRiG/ywwa/9kuaaTLSMiIiIiIhyHIPFdqD5xH5Rz61CAOVCvf4L/JxzkYiIiIiovWOw2A4Ey4/B4atGRi3rjFrd7ZldJCIiIiIiBovthLfntQg6O4SfdxH0A0KhWT+QJCIiIiKi9oHBYjsSdFSGH3cWmFkkIiIiIiJ9DBbbEdlWEn5cJjTqbic2VWeiOURERERElMMYLLYjsrU4/LgM+sGi4GFmkYiIiIiovWOw2I7ItrZgsUTQH/GUZahERERERMRgsR2RrS5D2wksQyUiIiIiavfyOlj86KOPcNZZZ+HEE09EVVVVQq9dtmwZ7rrrLpx77rk45ZRTcNVVV2HEiBFwu91pam32RZahxsLMIhERERERWbLdgGQcOnQIzz77LObOnQun05nw6+fMmYOHHnoI3bp1w/3334/Kykp89913GDVqFJYtW4YJEybAYsnLtyamyDLUWAQGi0RERERE7V5eRkT9+vWDz+fD6NGjMWrUKCxdutTwa71eL5577jm4XC68//776NixIwDguuuuQ0VFBUaOHIlJkyZhwIAB6Wp+1hguQ/UVbnaViIiIiIiMycsy1DPOOAPTpk3DRRddlPBrv/rqKxw8eBC//e1vw4Fiq9tuuw2CIGDKlClmNTWnGC1DFXz6I6USEREREVH7kJeZxREjRiT92hUrVgAAevfurVpXWVmJHj16YN26dXC73SgqKkr6OLnIcLDoZ2aRiIiIiKi9y8tgMRWtA+EcccQRmuuPPPJIbNu2Dbt27cLxxx8fc18VFbkVTEpSKFGs1y6hotLYfgJNOfd/Mypf252L4p1PRIng+URm4vlEZuL5RGYqtPMpL8tQU9HYGCqx1Msatg6Y09DQkLE2ZYzdWJ9FeAvw/05ERERERAlpd5lFQRBirpdl2fC+ampyq1yz9Q6GXrsszRZUGNmRtxE11Y1AnPcqF3RSPM+1v0k+i3c+ESWC5xOZiecTmYnnE5kpV8+nTp1Kknpdu8ssFheH+u21ZhiVWpeXlCT3huYy2WZwNFQ5CAQ8aW4NERERERHlsnYXLPbo0QMAsHv3bs31VVVVsFgsOOqoozLZrIwwOsANwOkziIiIiIjau3YXLJ511lkAgGXLlqnW7d69G7t27cKpp54Ku92e6aalnWwzni0tn9oP5ZOvgXTopzS2iIiIiIiIclVBB4vV1dXYvHkz6urqwssuvPBCdOvWDdOnT8fevXujth8zZgwA4KabbspoOzNFdhjqsQgAsNRsgPXAapTOui+NLSIiIiIiolyVdwPc7Nq1C6tXrw4/r66uBgAsWLAAlZWhqSG6deuGU089FRMnTsS//vUvPPPMM7jlllsAABaLBcOGDcM999yDm2++GbfeeisqKiqwaNEiTJs2DZdddhmuu+66zP/HMkEQIIsWCEG/atU+uRxdhFrVckvNJt3d2bbMgmv+E/B3PBl1vx4LSDZTm0tERERERNmTd8HikiVL8MQTT6iWv/DCC+HH119/PV5++WXdfZx33nmYOHEi3njjDbzxxhtoampCjx498Nhjj2HQoEFxR0zNZ4HSHrDUbo5a9qTvTkwO/BLzbI/if8QDhvdVNvNOAIC0Yz8c6z9Cc6/+praViIiIiIiyJ++Cxb59+6Jv376Gtn3wwQfx4IMPaq477bTTMHLkSDOblhc8Pa+F5bt/hJ+vxPGYFLgEAUhww5H0fi37vgcYLBIRERERFYyC7rNIau6zHoCv8+mQLUWo+9VruF0YhgCk0DoU3qA+RERERESUnLzLLFKKLE7U3vBZaB5FyY5bGnbinwu2AgAa5eQzi0REREREVFiYWWyvpFAW8cbe3XDL2d0BAE0pZRYLt58nEREREVF7xGCxnbNZRDz8y2Nx6hGlKQaLRERERERUSBgsEgDgiSt6olnm1BdERERERBTCYJEAAN3LnWiGNYU9sAyViIiIiKiQMFgkAIDTKkG0coAbIiIiIiIKYbBIYXZHUbabkDLnyjHZbgIRERERUUFgsEhhNnv+B4uuRc9DcB/MdjOITOP8YRTKJ10F+7oPst0UIiIiamcYLFKYZHNqr5Dl+C8WcqfPolS3I9tNIDKF4D4A1+IhsB78EaVz/wgEA9luEhEREbUjDBYpTNQLFoM+9TI5qL+jgBcI+s1pFFE7Jh3eHr1A5ueKiIiIMofBIoVZ9YLFgEawqBMMWnYvRYexp6Fyws8hHt4GABAb9oQCSCJKkCKrH4xxk4aIiIjIZJZsN4Byh9WuHSwKQS9kFEcvVJXDhcpQy6bfCtHXAPga4Fr4LAKVJ6BoxUj4Op+O2n6fAkIm7k8YKJslygeKEnBB9vPsJiIiooxhZpHCrDoD3AgaWUFBpxxO9DWEH9uqFqNoxcjQvvevhHXHfBNaSdR+CKrMIvssEhERUeYwWKQwh97UGQmUoUZRDHojNh1KolVEFCYzWCQiIqLMYbBIYXrzLApBjf6GhjIcihFSM1KCSlRImFkkIiKi7OHVO4U5ncWayysnXgzH2v9GLdMrQ42iHDFVlJJtGlH7pOqzyGCRiIiIMofBIoU5i3TKUAG4vvwzrLu+bltgJMOhmHJDFhgsEiWGmUUiIiLKHgaLFKbbZxGhgTYc66a0LVD1WVSP0SgoMotls+5F2bQBEDx1qTTTACH+JkT5QDlVBjOLRERElEEMFqmNRWeexRZCc3XbY+VFq8GLWNvO+XD+8FbCTSNqlxTl3ixDJSIiokxisEhhssURc73gbZsWQ5lZFBIoj7Nv+TyhdhG1V6rPFctQiYiIKIMYLFKYLCUQLCozHEam0iCixCj6/SozjURERETpxGCR2ljssddHBIuqjEdOlcep+08S5SXlTRhlH0YiIiKiNGKwSG3izIMoeOvbnqguYnMoWJQZLFJhUPZRNDRlDREREZFJGCySYZbmQ/Bt/zY0f2IOX8RyEBAqGLl8U4aIiIgKHoNFiuI+7Y6Y64+c3g/Fi56HkMpFrJDmqS1klupRgVB+zngjhIiIiDKIwSJFabzwBVTfPB+B4i662xStGpfbF7EMFqlAKG/KMGtOREREmcRgkaIJAgIVx6HuyjcRKO6KjVJP7e1SmDojVbats+Fa8DSkms3aG7DPIhUK1ajDDBaJiIgocyzZbgDlJv+R56L6tmW48+3vMMt9I5yCN2p9+acDol+xfeIjAAAgAElEQVSQoakzxMZ9KJtxOwDAtv1Lna2YWaTCIASUU2cwWCQiIqLMYWaR9AkCDjf50ARb/G0zdBFr2zo7/Fiq267TFgaLVCCYWSQiIqIsYrBIMf28RwUqhYa42wlyIEMXsvFLTAUGi1Qo2GeRiIiIsojBIsV0/0VHG9sw6AeCvvjbZQL7LFKBSGnUYSIiIqIUMVikmLqVOXG4/OS42zU2e9UXttnCzCIVCtWowznyGSMiIqJ2gcEixVV95p9QKxfH3Kb88I8IeOKXq4YIkGq3QPDWJ9EaA1lDBotUKBRlp0KQ5zYRERFlDoNFisvS83Kc6XkLE/xXxNzOvvglY/s79BMqJ16MyvHnQHAfSKwxhkpMeUFNhUGVrWdmkYiIiDKIwSLF5bBKKLbbsFPuFHO78s0fJbRf0dcA16IXUmmaNvbrokKhChZ5bucz8fA2WHcuYPUDERHlDQaLZMiRZQ7MD55u+n4tB9cm+Aojo6FygBsqEBzgpmCIDbtR+d/LUT7tZhR/89dsN4eIiMgQBotkyJFlDmyQu5u+X8GXTL/FeHjXngqDIHPqjEJR9P2/IPibQ49XvJnl1hARERnDYJEM6VJiByDgIe9gU/creNIQLLLEiwpFgJnFQiE012S7CURERAljsEiGiELo32nBC3BS89vm7ddndATVFkZKTBksUqFQDmjDzGIeE7LdACIiooQxWCRDTu5aEn7cDHsWW2IA+yxSgRCCyqkzOBoqERERZQ6DRTLkVyd0Qu/uZenZeULBHTOL1I4EfdHPeW4TERFRBlmy3QDKDxZRwKgbT4fHH8RrX24CNpi3b8HXCNnmMm9/vKCmQqHso8jMIhEREWUQM4uUELtFxJNXnGDqPoXmWlP3x9FQqVAoR0NlZjGPCeyzSERE+YfBImWdEPQa35YD3FB7ouyzyAFuiIiIKIMYLFL2BTzm7o8D3FCBEJR9FlmGSkRERBnEYJGS0vSz/qbtS/AnEiwys0jtiLLPIs9tIiIiyiAGi5SUxvOfgvfIn5uzs4DxMlRDF8ss1aNCoeizyKkziIiIKJMYLFJSZEcF6i//pyn7EhIJFg1cLHM0VCoUquCQN0KIiIgogxgsUvJMunAVEumzaCizyD6LVCCUwaKyLJWIiIgojRgsUtKCJUfB1+FnJuwokdFQDVwsM7NIhULVZ5HBIhEREWUOg0VKniDg8PVTUt+NyWWoDBapUChHQxWYWSQiIqIMsmS7Acnw+/0YP348PvnkE2zfvh2SJOHkk0/G7bffjssuuyzu60888cSY659//nncdNNNZjW3oMn2Muy1dEdXf1XyOzF7gBukFiwKnjo41k2Gv/w4+HpcmtK+iFLCzCIRERFlUV4Gi3/6058wa9YsXHnllbjjjjvg8XjwwQcf4P777zcc6PXs2RMPPvig5rqTTz7Z7CYXNMFiB1IYpDGRPouGRoNMsM+ic+UY2LbPg/usB+Drdj6Klr6KolXjAADV/ecg0OGkhPZHZBpZ2WeRo6HmLyHbDSAiIkpY3gWLc+bMwaxZs3DttdfitddeCy/v06cPrrvuOrzyyiu46qqrUFlZGXM/lZWVuPrqq9Pd3HZBsjqA5uRfn9A8iwYyK4mMhipVb4Rr0fMAANvOBTgwuCocKAKAa+FzONxnkvH2EZlIWXbKkX6JiIgok/Kuz+KUKaE+crfffnvUcofDgRtvvBFNTU2YPn16NprWblltjtR2kFCfRSOjoRq/oLbu/ibmesHfZHhfibLuXISK/14J14KnOIIraVP0WWRmsYAw8CciojyQd8HiDz/8ALvdjl69eqnWnXnmmQCAFStWJLRPt9uNoJEghDTZ7KkFi0ICo6GqyvI0t0nkbxmnNCyRaT0SVD6tPyyH1sK5+h3Yts9L23Eoj7HPYuHiYEVERJQH8ipYbGhoQE1NDbp27QpRVDf9yCOPBADs2LEj7r5qamrw5JNP4uyzz0bv3r1x2mmnYeDAgViyZInp7S50ojVzmUXzp86IHSwK/hTqaxMQL8NJ7ZOgvDnCbFT+EhTfNQz8iYgoD+RVn8XGxkYAgNPp1FzfuryhoSHuvjZu3Ihjjz0WQ4YMgc1mw/Lly/Huu+9i0KBBeP3113H55ZfH3UdFRVECrU8/SQoF0Jlul6jz9zDKaQ3CHtlmnxvCsjGAxQb5rDsAydZ2LGv8+xtOhxS9vxiEYlvU84oye9RzSfZm5P10FBXDxvOJFJTBos0i5+3fo72fT6It+ue2oswO2NrJe+FzQ/z0QQi12xG45lXgiDNS3mV7P5/IXDyfyEyFdj7lVbAoKO/MKsgG+32NHDkSlZWVOP3008PLLr/8cpx33nm46667MGzYMFx22WVxj0ctJHv8bWJRDHAjLB0F6cshAICAswPkU29oW2mkz1ZCJcWKv7Eyy5nI4DspkCVrRo5DeUZZqshy+cLRjjKLwvLxENdOBQBI/+2PwB/XZblFRERkVF4Fiy6XC0Coj6GW1sxjSUlJzP1ceqn23HkXXXQRTjzxRKxfvx6bN29Gz549Y+6npka7HdnSegcj0+0qCUhIpRDV43ajIaLNnVoCRQCQPvkDDnT/Tfi5q9mLeHnM5mYPGg2+B44mPyLPltpDh9Ex4rnsa0rP+xn0o1PE0yYv0MTziRQ6BqIHuPF5PKjL079Hez+fSryBqO/J2uoGyI68+glOWvnqqZBaHguN+005B9r7+UTm4vlEZsrV86lTp9jxkZ686rNYVFSETp06Ye/evQgE1Hdlq6pCE8Mfc8wxSR+jU6fQJXx9fX3S+2hvgvbSlF4vxOizKIvRZaJp77OoGH0yoWk9EjmqcpTVVLOzVJgUmXRD5z/lB/Y/JSKiPJBXwSIQGvHU6/Vi5cqVqnVLly4FAJxzzjm6r1+/fj2mTJmCnTt3aq7funUrAKBbt24mtLZ9CJT+T4o70A/IZKsij2ikDDWBaShkRamxMnBNaKTWBAi+6LtNLEMlFVlWB4ccQbNwMPAnIqI8kHfBYv/+/QEAY8eOjVpeX1+PyZMno7y8HL/+9a/DyzZv3ozq6urwdmvXrsVTTz2Fv/3tb6p9T5kyBbt27cLZZ5+Nzp07p/F/UViCpT1Ser0QM1gsViwwd55FFeW8dumiCBYhSNrb5SixcS/nhkw3rWCCAUbBYJaYiIjyQd51mDj//PPRr18/TJkyBffddx+uvPJKuN1uvP/++zh48CD+/ve/h/s2zp49G0888QTuuOMO/N///R8A4Nprr8Wnn36KWbNmYeDAgbjiiitQVFSE77//HlOnTkVFRQWGDBkSqwmkEChLLViMNXWGbI0eScrsMlRBWXaawDQeqVCVoebRZOtF376C4u9fh6/Lmaj930/UUwKQOTTOCSGPzhNSUE2dwTLUQiJ4G1D62W2Qarei/vL/B99RF2e7SUREpsi7YBEAhg4dil69emHy5Ml47rnnYLPZcPrpp+PZZ5/FueeeG/O1VqsVb775JiZPnowpU6bgtddeQyAQQNeuXTFgwADcc8896NKlS4b+J4UhUNI9pddHBWiKCyjZohh22FAZagIXYcr9ZSpYVGQW8ynLUPz96wAA677lsO34Et4ev8pyiwqTZmCYofOT0kCZiW9PI9u2gyoEx+rxsO0OzdNcPu1mHBhcleUWERGZIy+DRVEUMWDAAAwYMCDmdn379kXfvn1Vy+12OwYOHIiBAwemq4ntiyWVsVCjg0XBUxe1TtVn0UAgKCCRzKJiABGti/FgABDNLRNVZRYDGSp/NZngPpjtJhQurcwig8U8pgiY8ugGEcVnq1qc7SYQEaVF3vVZpNxUf/GLkEULfJ1Ph9dA+U3TqYPankT0WRQ8tdEbKgNRkwe4UQZpQqBZtYngazS+P4OUmcW8uXBUButi4XyF2LbPQ8V/L0fxoufTe6CAB7ZtcyE018TeTuuciNG/l3Kc4rOTyWoC5w+j0WH0z+Ca92jGjtnusByfiApUXmYWKfc0nzoInhP7QbYWo2T2A7rbfRw4H6tLLoF/o4wXWpZFZkvEZkWwGFBOHWDuADeqUj9fk3obXyPkFKcHUe3TryhDzdTAOqlSBSuFEyyWTb8VAGA5tA7eo6+Ar/sFaTlO6ReDYd/yOQKubqi+ZREQORJuwAfH+g8BOQDvUb9UvZaZxTymHMk2g30WXYtD37bOnyah6bQ7EejYK2PHbj8YLBJRYWKwSKaRba6Wf6Mn/aySQ9Pcv+r7PT4OXghUA78UVwKtUyhGlGQKnsNRr1UFUWbPs6iaV1FjAlW/OtuYKlVmMU8GLlHNOykUTrAYybp7SdqCRfuWzwEAUsMu2HZ8Be8xV7St2/QJSr58DADQeM4f1S9msJi3sjYNiqLSQqrbwWCRiIgMY7BIplNOd/GE7y4sDJ4WtWy33CH8WDq8HUJTNWRnJURFsBh1cRzwxS/dAxIr6VT2WdTKLGqUpqZK2WcxX0a5VL0XBRospo0iQBB8DVHPS+c8En5cvGyE6uXpOBcpQ5Q3sTJVhpoTJe6FP8ANE4tEatLBtZDqdsJ79GWAyJAjX/FKj0zXmmFs5Zbtqm02yt2wV64AAAiQYdu5IPTYWx+1XWvZneA+iMoJv4D14I9xjy8k0GdRkBXBonLgGQACM4ttlJnFQpWu/kfKcynBC3mWoeYxVZ/FDJWhplLi3g5GMTUPo0WiSFLtFlROuhJlM+9E0fJ/Z7s5lAIGi2Q6ZRnqRSd2R59Tuyq2ErAwcGr4mXXP0tBS5WAyLRc6rm+GQXLvM9iABC7ClH0ilUEcEgsWxYbdELwN8TfM03kWBUWfRduOr3hBmQD1/JoJBgwMFvOX8sZAhjJ+QjIjLfubUfbJTah89zxYd31jfqMKkMxgkSiKa8HT4cfFS/6WxZZQqhgskumUZai3XnAirunVWbXdevmo8GOxYQ8AqAKt1kyKNZFhybPUZ9G2aToqJ/wClePPgli/O+a26nkWsxwsGnzPlIGzY91kOH58Nx0tyixVwJueCz/l+5foiJiCHMibGwsUTZVJzFSfxSTOl6If3oKtaiGk+iqUf3xD6m1oDzeUOBpqSpw/jEL5pKtg3/BxtptCJlGOQUH5i8EimU6WostOZYsTJXZ1rfp+uTz8WGzcB2nnYgQ2zoreKNhShprI3fEURkPVziyqS1O1lM26F4IchOhrhGvBU7GPqwxAA9kLAGzb5qLD271RNrVf/MyVxtQNJfOfTFPLMkhZqpemCz9Vn8NkSpyZXcxPqj6LmSlDFYKJny+2HV+Z35CCx2AxWWL9brgWD4H14I8onf1A+7i50B5kcMRnSi8Gi2Q+xQT2usEiKsKPrQdWoXLajSitje6TGO6jldAFTwI/NAYyi85VYxOe385y6KeY65XlnMhiZrHss9sgNh2Cbfe3cK4aF3Nb1WiohSKZUr0kqAY2SmIOT9W5Q/lBObhRpgaeyeKNKMo8x+rxqPjPRXD+MCrbTTFMqtkYvSAnBmWilDFYLBgMFsl0sqAIFq1FcMXJLOpquYhPZGAPIeCBZe9yQ1kbdWZRnUW07V4Cx7oPDB8fQPw7o4oL/lwZDdW6Z1nM9YU6Gqc6+5KZAW60MtnxMFjMU9nqs6g8t3Pku8YI6475KPliMKzbv8x2U+JTjgydjexYwIOSBU/DcngrXIuHQGyI3R0iV6hunGTo5h2lV8YG8aK0Y7BIplNNYC9aUWSTVNsZCRbDF8YJBIv2LZ+j4sPrUDnxIlgOrIZ06Cf9O1zK8kOdi/eSrx43fPyQ2BcKqgxdvlzApWFkWDNZ9q+CbevshN/PTI0yGiuzWPzNS8Z2kmJbrTsXwfXV47DsW5HSfihByuAh0cGNkqW8IZYv3zUBD8o/HQDHxk9QPn2gelCwnKO4wZSF7Jjy5pN1z/cZb0NSlCMFJ1E63e74mmDfOA1S7ZZst0Qfg8WCwWCRTOfrdgH85ccCADzH/RoQBIiCgKtO6gQAOL5TMS4+rgMa4ESjxrQaUYI+IOBNqmRLatiDisnXoPK/V6B05t2a26gyi6ZdkMQJFnM0sxivr14uZ7Wkg2tR8cGvUTbjdjhXjknsxao72Rka4KZ1nkVfE4qWv2FsH6kEi95GlH5+N5w//gels+5n36AMUn2HxflOs22ZCdf8pyBVb4y5XVzKczuVqTSSpjjPDFxEiu5DUc+llkHQ8kYWsmPK7wapZkPG25AU5WBPqXzHBTyw/zQJ9o2fFnSw4lrwNEq/uB8Vk642Nv90NvD3pWAwWCTziRJqbpiJ2j6TUXdF29w6Q359Et69pTfG3XQGOhRbAQhxs4uCHDRlsAX71lmAV6N/mCpYTLwsMCnKcs5cCRbjBEm5HCyWRAwq5Pr6xZjb2td/iPKProd9/RQA6jvZloNr4PryL7Btmq67D8vupSiZ+ydYd8w33EZ1sBg63xIq703hQsp6YCXElrlMpfqdELx1Se/LMH9Tbly0BQOw7v5WNZdrJMFzGPaNn0BoOqS7TdJk430WxfrdKJt5N5xr3kHprHtTOqyg7JedlWBRwchIsPk2XoziRltW3mfFd4OlOk+CReVnI4VA27H2fZTOexSlX9wXqjIpUM51kwCErlmcq9/Jcmv05MD3PpmCwSKlh60Yvm7nA5I1vEgUBJzUpQQOq4QSe2j5QZTF3VXZjDtMaZLo05j/UHkhlUQfMk1x7qhlrAw16Idty0xYdy8xtn28UUBzuAxVaDY4TLevCaVzHoZ1zzKUznkkNF2L4iLLvvkzONe+h7JZ92pPgxIMoHzq/8KxbjLKPx0AobkG1qrFMQMRAKpSutYy1EQy2onM+6mi+H+m+460bfs8dBjXGxUTLwaaatN6rHhcX/0F5VP7oeK9S3UHrCqbfitKvxiM8o/6mh/gJjAaqn3Tp+HHlur1qR1X+d1i5Lsm3RkBI5UiyjLdfMtSZCFYVAaoOVmiKMuhvpQRf09VZU0KZaglEXP7lX6uXVFUaIqW/zt04zMXbspFyrX2UNIYLFJWlDlCA97UyiUZO6Zy5Enp4FrYt8+L3ibexb4e1Z3yGBc2wQCs+3+IPm6agkXnqnEom3k3yqf+LyxxBq8xIqdHQxXV/WI1N1MESKJ7f8wsgG3rLNUywVsPIeJv3GH82Sj/5EaUTbs5ZtZEnVls1FweSyr9eVT/96bqpPdlRNn0WyH6GmA5vA3iV8PSeqx4nD+F7sRLjXth3/CJegNvI6x7Q328LLWbIR2MPaJxLI41E1DyxWBIh9a1LczSPIvK88VYGXOaAzMD/3f1wDw53o8tQ5lFsa4K9vUfQfBoVAUob4Ik060izUF5yewH0eGdc1Ey6762hcrvRZNKeAt2gBWN7jOlcx6BbducLDVIR6G+/+0Qg0XKipJwsFicsWMK3ujMYumch1TbWHTuxMrKke6U+1b+KMf4vS377Fb1wjQFi67FQ9qOO/MeAxcC+VuGKovqEXe1N9S4aI91Aa2RbVWWjba+L9Z9K2CtWqi7K6l+Z/TrWjPZiWQLUyhDFRXllcrgMZ2EHV9n7FjxiM3qIFlZFprsxb5UuwUl858MDczyyU3hC3ZBGSDFzK6ZeMGeTGYxzQQjUwUFlNMamfzdE/Sj9PN7UPH+ZabcSFN9t6ajz6K/CRVTfoPSOQ+hZM7D0euCfhT9MDpqUULf17KMkln3o8PYU2FfN8WExqoJzbVwbPwYAODYPB1i/a7QclW3jBwolc5heje1SyMD8ByQ98G6HIRl3w+c2xgMFinLapC5zGLFB78O3c1s+VG3RN71j0dyxF6vKl/VvtgTGvfDptXHLR0XcIqLF7HpAFzzn4h5XDlesJjDZagwECyKDXtQ8cE1UcuEgCdOtkUjWIxRrhxZQhh17NqtKFoxUrGfZMpQk79oFt0Ho/flyeTACFksI1SNRKrxeTPpMxhZ+ic2HYBj7X9b2qAMFmNcSCnbm8JFlzJLk1LWJhiAc/m/Ubx4KKxVi+FYMyG5UmYD/x9VsG7yBZvjx4mwb54BS/V6lH06MPUdqkb0ND/gsW+dHb7hY982O+o8sW/4GI51k6PbkMB3hWXfCjg2TYPoqUXp3EfSkhVSBq+t/xdVxUUO35TMBZpZZeTg+5bnwWLprPtQMeValH/4u/wrgzcZg0XKilOPCE2vkcnMIgA4Nn0K27bEO73LltijtioHxhECXti2zIRl/6ro5ToXEIbutCdIa44t54//if7SS/QCLFd+jHxNcK4YCcfq8W0X+aI1ehuNL3fXwmfU2TSfO/adbK2sssZ8nK0sB9ZoLi9eMly1TPSE7hAnFISn8DcQmg5EH785g/0IY104+JvS+2OszARr/L3NGq5fWcFg3b8y9EDx/0vornsqnzvl/zWZIKal7bYtM+H65q8o+uEtlH9yI0rmP4mSL/+SRJuMZBaV5bPmfvfYt3wefqzZnz1B6uA2DdmxGGWmpXMfib99DMqqBykdg+Mog0KvzvdfludZFDx1kA6uzWobYhGT7S6TaSZ/p4v1u2FfPyUzo78GA7Bv/gwAYD2wGpa9eTINTZowWKSs6NmpGA9dfAw6deqS8WMnM7+c2FwT84dXmWkSPbWhvoJTfhv9o6N3oZaGzKJu5jSiraoLsDyZOsP543/g+vpFlCx4GvaN0wBolKFqZP8iLxBbCX53nGyLRmYxxqi5ellCS416CgSx6QAEz+HE+iyaWIYqpLnPYhSdCwf7uinoOPbU0N3bNF0kqt5frc+b8thJ3hUXFIFHuK90QlNnKALLFLLJqnM7mWCx5TUlC55RrbJvmZl4mwx836lGcTW7FMzsrIdqPss0nMuKG1fxysjD39eybODCPXrf1t3fJtq6uFRTRrW2XxlEZrEMVWiuQeW756Fy0pVwfv8vzW2Klo1AxX+vhG3zjAy3LkTwGBzMLetMHKQq4EX5R9ejdM4jKJ15V2rNMni8SGLTQZ0N2wcGi5Q1A885Cn1/frJq+cZgN93XBEr/J51Niqn8k5uAgC9UZqbMEugECIIcQOmcRyK20wkK0hAsinU7tJdHfOmpg794o6HmRrDoWvxC+HG476kiWBR9xu6+Cj53nDvwob+14K0PX9zEKkPVOxeCdu1pYiyH1qmnUokhlYBdWYaayT6LekrnPgLB3wzrvuWqMrpEWasWw7lyDARFxlT5N9HOLCqDquQ+k8rMYvhcSSFYjFkBEC/ANmPqjJZjyAYHkYrLSKCm/H+ZfqPK5Ey2qm9oW/uFpkMoXjw0NP9rEhfMjlVvo/yjvuEbY63iBotBP6TqDah4/1KUT74aYoy5KpU3OSz7VyfczniUv396Zaiq8z2DfcaKvvsHxJZgzPXty6r1UvUGFC99DZZDa1H2+T0Za1ekjEx5ZAbV+ADJ3wSw7l4CqSHUx9W2e0naq5xUNzZMm4M7PzFYpKySFRfQjXDgCu/fdLc/WHEWlnRNrX+JkOTdLeuepeg08hhUTrw4eiQ3xA4eLIfaMot6F/rpGA1VOfprq6jskir4izPlRyLzAWaass+Q11hpmeB3x7yAFgIeSDWbUTnhPHR4+0zYN3wM0b1ff3udElXZ4tRcLh1al2AZqs6FU8Cn25ellSqzmGywGPCGynJiBSqqAV3if+50S98MBBdS7RaUTbsJrkXPo3jx0Kh1qvdX62+k6tuX3AWqOlhs6ZequnAy3mdRsy0BD8o//B06jDsdtljZPRPKI8OfD6ODSCmp/u9GMovqMlShuQaurx5H8aIXtG9cyTIse78PjQoZ7xgmZxZV3+ER73PRd/9E0Q9vwbXoedg3RQd88Ug1m1Gy8BlY9yyFffvc6GMa+PyWfv4HWGo2wXrwR7gWqjPD4X0pfi/0fj9SotdnUa9MXJZROuNOdBz9MzhWjTO/PRq0KkCi1h+I7lqSjX55gif3y1AFbwOkxn3RC1OoHFEGyOm+0akKFs2aVi1PMVikrJId0cGi1VmGJ684Xnf7mZsbsbQqtS9KwWDGKRbH5ulRF4Vxv0haL/70MnMmBoti4z6UzLpP864oEB0wKC9C410g5/IXpmqQBIP9OgRfU+wfMX8zipb/G6KnFkLQh9LZD6B07h/196cTUIs6pUOWQz8lNsCNxt9IrNuBDm+fgQ7jz4a1anHbtp46uOY/Bdf8JyF4G1SlNMn+4JZ/ciMqPvwdyj4bpN9O1QjBGhdVygDSEj2QlOCpQ/kHv0HlO+fGHbGyaOlr4YDMuW5S9IW0MqOh0UdNPXl9ksGibhmq4mZGjMyiugRT/b3hXDkW1r3fQ/TWoWym/nxy6v9XEvMsBlszizrBYpyLQOUxY/3f2/apzi45V42D88f/oGjlaAhL3lC9xLL3+/B56fjxP3EOoMzeppipiJHBLVo1Nvy49IvBCe1Wa+qeVuHPb4zvj8jgR6sMv5XqJkcabgyqMovNsTOL1t3fwL51FoSAByULnzW9PZp8cf7fQnR2PS1BdRxiHmQWXfOfVC1LpbxY+VuV9i4UDBajMFikrAo6KqKeS1YHrv5ZZ6ySe2pu74YDwRRPW7O+ZAR322AhsfqwAYgYIjz9mcXib16CQ2dETiB2GWq8EsdcKFvUpQoWDWYWfe6YgYHr25cTKo8U/M2agZEyq9fKcmB1ygPclH4xGKLnMAS/G65Fz4eXO9a+B+ead+BcMwHFXw9TBXBaU0jEI9bthLUlcLPtnA9B5/+lvojSyCwqfoBlRbBYtPQ1WPevhNS4F+XTBsRul+LcrJx4cVvZsLIMVetGgio4Se7CxowyVFUfRY2/udXodA+qPouJB8Hhfo86waLgD91wsW2dDbF2q3oDZZbZyDyLGpne4mUjws+lL4cqX4KSr/6v7XHr5Ow+ncGTFIsEb4oX/THKUFNhqdmku671/BYb9qZ8HNVNjjSMfK36vWnS6bPY8lkU66IH3UloiqEkxb1xpwwW41RzpEM2jpkox4aP1AtTuM5RnuPpniNY+R0seKK7Nlh3L4FjzbuGrzPyHYNFyqqgsxKy1DbSqK/LGclg4eEAACAASURBVHBaJaw66VF8G/wZFgROjdq+UXagDKl9OB2bPkXFxF+mtA8AECODxTh3nSz7fwhtpxeMKS8sUqiPd6z/MOb64m+HQzrUMuG4sj3xMot6wWKGJhiXDq1Hic6deVUpk8ERDgW/2/w+MRoZZL33znJwbUI//lolsNaIQZssh9omk3d9/WL4sfPHdw23KSZllkjnzrpquVZGVPEDHPldAAC2iLK7eDdklAGg2FyDopYBKlRZZ40yLrMGVFEHiy3PlWWnscrXVDdx1G0xepdeldUzlFlUBnctxxd0+iz6m1G8ZDjKZtyOyvd/BbFREbwoR3s2MvqzRhlqPMqBP+wbP0XHsaeg4r1fQlBOG6OcVzNGJYLYsAeOVW9HTYuiOnaM9zlQFD2Qm9ZI1XqkGGWRrTdIJOX7nQRlsJyWaZKM9llsPbcVpfuRv7maTCgJVX3PxOk721oeadm/Eq75T8K6U3+eXbPkfJ9FnS4HKWUWFed4Mjc6DfM1wbpnqeJ4bb9VUs0mlH38e5TMfwLFEb+xhYzBImWXxYnGXzyOQEl3NJ18CxouCZVO/vKXv8YA/7N4zj8oavMm2HGUEOcHw8hhazenvA+xKTJYjH1XOjx8vu4AN20XLs4fRqHj6F4onX5rWqYTEJsOoPzj30Ns3Af7ps+i1tl2fQ3p4Fo41r4HcdbjwOGq6NfqBovGfgTEuh3JBWY+d2jS6Hl/gmPjJ5qbqMtQjQWL1l3fwLVYnaVIherudMAXVTp0aMDCcBZNCPpg3Wd8WG6rcghvRaAeWSoo613ct0gmU6wKqnT6z6huoGj8PVQD0aRw00ErM2Tdtzy0TplZ1LqRoMoMJRcsKktc9fssxsgsGsn4G71Lr/x/xPn8SbVb2r6vwsdv+ZtrTSOD0PtbtOLN0OOgD0VLR0SvV2UWDcyzqLhIj8yYhym+H5WZaeeqsRACHlhqt4SzjuFssyI4jPUdXjrzbpQsfAZlU2/Qf/9UfRbbtpPtpVGr9KoMtEhamdoWRgbcMkr1mUjDACK6ZajKG32tf3vliJQx+ooDMCXzqOxzrltW3vrcUx/6bfpiMJxrJqB05l2mZJtsm6ajfMp1cKyZoFqn16UBAIoXPpfysVOlO1prsoOGNdfC+dN/FcvSFCwGPKh8/9KoKoXQ8dp+K4sXDw3fbHLGLXcvDEn2VicyT9MZd6PpjOg+Nw6rhI7FNjTUR//4ByDiKCHOD0aGOH6aDH/XsxEs7hL3jmfrfIt6/UAiL8Bdi4cAAOzb58FatRi+oy40qcVtxOYadBh/lua6yklXtj1pPABc+nrosRxUlWK0EoI+yHBorgMA+Nwo/eJ+2LfNQaC0B6pvmqvqn9ZKOrgW1r3L4el5LWRHOewbPkbJl48hUNoDlur1uodQlVgaLFOx7fra0HaJEPxNUVVuYn100B0s7gJ/x5PDgZ9l3w8x97cmeDROEbeFtj2wBvA2ArbQHKUlcx6O2jZQdmzbcYo6qgcZiGxnwBMq07NqD76j+5oIoqcWWmGP6uLb06C6uFdmFlXzISZws0QrAAyXsakyixp35hPsv6vbDmVm0d8cCgyVmaxY/fZUZagabUklsyjLoWBA4zPo+vLP+sfSG/VZGQQo/66qPotGMosG/n+NBwC42p4r/j/Wvd+FH9u3zkLpjDth3zoLzSf9Xp2J9tZrnsfwuWFtqQyR3Ptg2b8K/iPOVm0WK7OovllhsOQ14FW/l5Ftbr2ANSGwU84Pa0pmMRiA2HQAweKuoX0qP98t39HqzGLofFf9jWJ8l2nuJwmqOZO9jZAjusso/3aitx7wuWE5vC303NcIx48TITYdhOe438Df5YzEGxH0o2zWvQBCN7w8x10L2VnZ1oYYv21Fq8ai8cLnEW8arHTSy/olm1l0RvT5DR8jyTJUsWE3gkWddUvq7Rs/haT4vQaiv9NilYYXKmYWKWfZLSIaoChDQRBvB67OUoui2bfPRcV7l0Lw1se949laSqQ7X1rrhaPibrrWl1ZMJg/vLK6dGn4seOr0JxKPc8ewaMWbsG+bAwCQ6rbrzuEluA+i/KPrUTL/cZS0XLSWzn4Agr85ZqAIQBUQRF4oZlrkRYt15yJ0mHhR+Lks2QGLE4GS7uFlse4UA8DaYA/UyaHPgiAHYIt4/+xbFYNWRFwkBJ0d47Y14XIeVQZXuyRKdQdeDmgEbcopLpK/2NO6my817gVkWX0jQSvLacbk9dAOWgW/W6PPon52TZ1p0SpDNZCFlWU4flL0t/U3o+zjfug45mQ41r4XChxb3h+xbkdoWHpVe1r6kOn064vbz0tV1qr9fSFVb0TpjDtD/WuNBECHoi/aZCnGDSuEAkYAcKybDElRCqqXDVLNr6Y3yE+MzLSq6sFgJjDWVBdAW5tTnf/W/tMk1SigKQdeQT8qJl+NDuPPRtF3/9Dcp9hcHRrBVjHCaOv5pgrM4vzOarY5keqc2p3qgVR8ygy0MpisUwX0rq+HomjFmyj77PboQN7bCOuO+eoMqCzDvv4jOH8YDXgbVX9358oxkCLmTY5bEZLlaR50uzfE6AcuNO6HY+37EOvU1zxa5d/JlKE6V4xEh3fORcV7l+hmoSWdz1xkFUwiZeSFgsEi5aze3cvQhOg+TAKAqQHzM231l6hHDm0+6fdxXyd660KDOjTG/hETmw6FLg51ftRFz2EUffdPVYZSlmxx2xC1nzh3XlMRs39bnMFAlKVUeplY55p3ILZcICQ62bfyQsG+ZSaKFw0JZZHkYEaHOI+8eC6bcUfUuqCzEhAEQ4FcKy8sWBw8Jfw8PEJiwKNxIRpxgaVTNhgp0VJUdcd/nf4zGhfEwg/R/SZF1XyIyV2gCp7DuiME2jdN1yhRjp9ZDH1mEy8D1wo6BF+j6vxzLR6i37dH1Zc4uv1S7Rb1zRCNz6B1x1eQ6rZHLbNvnwvb7iWhESa//AvKp1yLjmNOQdF3r6Ny4iXa/6mWwFmvH3C8kTNVga3OZ7Hkyz/DvnVW6ObShqma20Ttt7olWGzZv5xAhly1L53/m+q7Su/GmGK5VFeFki8Gw7XgafVnRPHZsOxZBseqcaqL4ng3C1vfd92bkAaVzntUve8Ug0X7xmnh/tPFS1qmw1KWVwf9cPz0vvrz2XIuiwlnFrWmxDH43sgypI/Vk72r+nIqKwc8dbpll2LTgVDA6A19/is+vA7lnw4ILYtgrVqI0jkPwbX4BRSteAOSYo7k4u//iYrJ10A8HPosxyvBjHfzMd10s356nx1ZRtn0W1Hy5Z9R/snvDY1EmsxAha19+C2Ht+mXj+rcJBQb90Joqkbp5/eobyymobtQrmEZKuWse87rgdnron+oBch4a8Av8OnKF/HbTU/HfP0H/osxMvBbFKMZvcTtWBvsATt86G+Zh/+VFoW3C4o2eDqfiZKI19bZumLAhkvwKQyMgikH49/xlAMQmmti/gAXLxmu3o+RIeZbBXxwrn1Pc1XDeU/C9c1LxvcVKegHREvMoEII+mPO0KgqJ1IMNtFKdXFk9Es44NUs6ytaOQpS3XZI1et15z9Mi4iLFmVZU9DRIfRvUSfDu/PBglmBc3CN1DIKaUuWVqufXuQPq5G+M1E3AXzuUAmts0PUNtadi1Dy1f/B3+EkNJ/UL2qd3oWJVqmd+NVLQM9b2rZRltipPh/G/v6u+U/prnP8OAHeo6+IblvAE/obRQygoSwjLF76Guwbp6HmhhmJlelqBYtedbAIANadC+DvdGqozC2ybEwZkCsC2eLF6kEVBH8TZMkataxk/hNx29vaP7F4ySu62wgBLxAM6GYQ4w7QJOuXaEa1JSIAVvab1CJ99gg64RHIohWNP38MEBO7uRbVJt3MomJuUp3vcOUFZPHSV/WPFfEZlWq3oHxqPwhyALJoxeHf/ge+7heEjh0ngxFuSzomKE9xn1qBrtZ751zxlvrFrWWoigA+3k1ZrWyR4G9W9WXVIqz7FEKVeoRhwdcAqXojnKvGwdftPHXFhLc+5m+jbecCOH98F97uF4WrY2xVC0M3DKxFACKCaQDF3/0D9SVHqdsR9KF42QjUX/7/4t7gC/3eHhFzGyPE+t0o/uYlBIs6ofH8pwzPs6oXzOqVoQruA7AeDJVBS3U7YN33A3xH/rxtvUaw6Ng0DYK3Hs0n3wzvsdcYalckqUZj3Ap/M5wrR2tv796P4iXDYd88Q71SWdLvb4aw/ivIR/YGUJZw23IRM4uUszqX2PHZH36O2i6hH85m2Yo93a9Fr64lOPaILnFeDayRj8FmuRtWycfhv4FfYZV8HJbJJ2FTsHvUdvUBC3434aeoZYMbBmG9u9hQOwV/U/yO9wiV0MQrF3KuHh+97xgj9AnuAyj75CaUffx7iA174Fr4DIqWq+ceAwBfV3UfG6Nayy9i/kDFGQxEdYdYWdrVulxxF99o3x6ppb+IFvvWWbAc3gbJnb6sq1KssrzWvieJBIsBiFGZRcm9H0Ljfs3zI/I9M/L+tf5dxboqdBh/NjqMPwu2rbOjtile+iqkuu2hrM+yf0StK/run5qBkG3HV+qDeRuj7i6rMovKDJXGzQKxrkr1/7ZUr1Nt17Zuo+ZFqvLYWneULTUbwwO3GCLLmhmq8g+vC2fMo5Z/OgAdxp2O8g9+E/W+qDOL0Z8v+7YvVPvSOudMG2I/4I05urDe51k69BNsW2aqMl/WPUtNHYFYCPrg+uavEFP4jDtXjAw9UParVX4n6X22E7ixF/m5tG2dHb7RJQR9sG9uG3QsbjeElrakWoaq2caU+/8p+swFfJr71BpsrjWzqLwZFq/0UCvDbXS+SGHLl9rLvQ0omftHOH98FyWzH1CV64reOt2+/K1cX7+o+v2JLF2VFTc5REVmsZVUtx0I+uNmDs363Bd/+1c4Nn6MopWj4Vj7vuHX6Q7gpFd+Xh89RYqkOCf0fsfsO75E2cy7UbT074ln9zSuWYq/Ha66Vomkl42MutEU9KNs2gBIH9wCafTFWS8JNguDRcppLrsFgStfQ/UZD+G7X7yJJ/ucDwDo2qFDnFcCnQTtL/CDiB6Zrhk21Cv6RgqQ4UPskSRblcx/wlApX/E3f0Xx0tcM7bOVVt+qVq5Fz8NWtRC2XV+j+OthMUflkm0u3XVx29DyAy14YmcWgVC/A8ueZaovbmXZn9h0MDRPpXKicuXw9gZ/9Crf/5Wh7dLJK7edL7GymK1zi8oJlKH6IeEAyuAV2+5edhx/pmYmWQh4wmV5WuePv+J4eLtd0LZ9y9/X9fXQ0IVP0I+yGYoyqciMz8HogTBETy0cP06MWmY5sBr2TdPVbZMD0VPOJNhn0f7TZHR49xeofOdciA17YNm/EoL7YMz3W2w6qHkzx7Z9Hpzf/yvcP0hvQBvrrsVtT3xu2DdO055LEAD8TZpZs1gXdwJkWA+sinq/Ep3/tPXYKolUJsRQPn0g7BtjzN2q+NzaN38Gx+rxqJh0Ncpm3q3Krhcv+RtKZj9kStsiWQ5p3zQItAywEvO1h7ei+Oth6DD2VJTMeSQU+HvrYdsRHUQIvgaUzrgTlePPQvGiIeFslnL01lgiL35VQ/Q3/X/2vjMwqjr9+tzpLcmk997oLbTQm/SqiAqIYsHe21p27Suru/ZVEbErKqCAIgK6CNJ7b4FAEhLS6/Tb3g93yq0zk6i7r/5zvkBuv3Pb7zzPec5TD03dMagbTkIt7jMo3g7128hQWZVWMo1gPO1qiaRuOouoNVdz15V2gxUZrBCkLfxspU/2LHasDfE9kHsPmHe+AG3FNpmlRWiSf6ZVria/wRHBMhI3asLdJg08ySDquwXC9XjrMGZh8Jvf/kiwjscucZCWPebfSIZq4EnB+dlPH7SVO2A88Lbku91egxt1i1Aqr6k/IVwvBOEy730ZurL/BF1GYrIlfl4pF0yH3w2+DQUYTq8EAKgbzyB6+RjoLnF134Sj4U/Th7FThtqJ/+/BRKYBQx9GIW8aYYhQXN4HFysvSapjrZLl7CKySEMF9jeOpehDvcxkIMkcsSz0JWugqT8maCFhKFkddDus1gRHrxtgOvJ+u49BX7oejpgCqJwBsujOGgfdxR2BQSBDgrDXIvqrSVA7auAqvAJt4wIZKPEL03B6FQynV4GM74Xm2d8CKo5oiSOMoSK2/wuwGpNsz79GRCIJoibwMuSHMbQ/s1jOJgIg0KBJRrInMKgxHfi37PIE5QCrNcsepzt3siAT66sv0YQh+1NCxJZH4epxbeC4dr0IwishpS3JAtMAlb0ajIWTSIWuWRQGHSL/cz+3nqcNsR8N4JbQGEKSTHHGHgg0cNdd3I6WGcuVa1V4tTERmx+GoWQ1GF0EGq/dIXBJBGRcQNsBQb1aCBmqHPz3HMv6Ja1BHVfbiYgtf1Het0wNcsTW4GUChnPfweZuhcpeDcvWx8FEpAVd/teATBkEtULLHT58WWTD6ZVwFcxExJbHJTWfuoqtfqMc0+F3wRqscPS/u11tAfjXSkwW9ee+l5e6yW7HJ0P9dVlAxhgj75pMuwGVKbA/Rx10FVvgSR8Jlv/+Ip2IXHe93xGUiu8pcTIm3K1hZyt9wRGJwY3EPdkDXcUvoKw5YKzZsllE37emecaXfnmv7D55ZJFVaf3ERmy+I4a68QzoyPbfuyp3i999l9ULpYrayp3yx0jaJS0dZJdrRx9GdeMZ6M5vhDt3ChhrtvKCYhfs1ouIWnMNCJaGtmoXWqd+FNi/U6nFVniZRU39ccHffBkqq9bLBs/UjaeArLGKhy/JTore97JKmDBh2fEcPOkjYF17jSCrynSZJnxO/sDozCx24g8JVhs8U+Zg9fic5l4c+fFmFMQHJKVisuiBFjTU2M10AQBcYmOwh+mquO1SJglfUqNk59Wx4evTW6zd4WalEV0+CI8Nli2PI+bjYuhL1kJfsgaRm+6EySeZChOs1gLHgPvg6Htru9YDuIiiurlUkJ050qxHGxWIHBMeO6xrr/FLbQynV0F3gddQXUHaoa07EogIMrQkItqRPoC/NxoW7ETj3J/9pM+HRjaQsVY3nYW2apckKwHwZajhZxb3MFyo5LQrvPuLIO2K0h0qsZ/AXMfX6yycup5g8DdNZllBOxLb8GdBxQRCPb5MnqZ6v9TEqAPSt18rl9Nd5JpoK9XR8T/+vqCMytMGw+lV0mMJI+qvjMDgWjLo5Z+jQgaLoFzQn16F2A/6IGLjnVyrm9+jsboM2tM3kA9N3VGYd/0DusqdMJxa8RsfVQCMQmaR0VtBR2bKzovccJuEKAKAqkUoEfSbTbXDPdf3bKqbzv6qd5w/sxhmxo4VS0NF25FM52+XZWD95gpE/ngvor69VqAKMZxc7ieKAJdZlmsxEbZcllbILIpIkGXb04hadx1ilo/l3itB7nfDqSD+A7Rb0FOYiuvu/7+25mDQQ9Vd2t0hosEPhEraESlIvn2lAKG3HSZZpD2I+nY+LLsWI2rddSEcmoXHqCv70R+M0pf9JKgBVMwsKgS9xM+UpuaQ4Nrz7yUyeYD8NkJJc8VGRaJjUcrmhovIH++WvAfZLtN+1Tb/f0InWezEHxLBZJW7mS4Y7n4VjV65aZRBg+emdEWEnkukl7LCgUMGwRGcWz334iFyEWa7nwQZJOkeRdhxgZUffOxgustOl8MP7p5oQnDSqyrdBOOxj6Buq0DkxtuhK/0h6PJKYLVmsIZo2Ic8ASYE0ZaD/vQqgXxwZ70Wbp7s0rxrsaS1he68t67KK+dSgq/eSdYQJYxa0P82WF0k6Og8uLpdI5jewAay3eZ9r8L6zWxErb9ZvDoYPResYIxxYEVupW3Dn5Xd51k2FQBgRJiRedKhKH8hk/oJspo+CSGr1ssuH64UTeOVZxGuRsHAgkwt9mcSAa81Oe1BpMxvo7u0GzEf9EPEhtu4DNl/y2WOdivW0KlcjZw5lXjgKkMMf438S2BMFCSzqFQ7aPnlb4j88R6onA0wlKxGzIfyg6rfAypn8D6zStDUHgpr8PtrweqtcPZYIJnOWFJAxfeQWUNaZ+2fLjpXTe0REI46fyY9HPiuta5iS9jryMIXVAiz/pOA/DOlJOPmy/9UbZXQeLPf2vpjgt6xYqKvqT0ElV3YgoDwBM8s8t+FhN99V1yzGHi+CEc9jMc+8i7vge7Cj4qOyAAXwDRvl3+/qlsr/NePJdSgYrsEzkVB2syHTiETGAwCVUUH69poUwJsxY/B2e0akIn9Att2t8Jw/FOY9r0mJI4sC/2pFYjYcDuM+9+Etuagv4WMprk0KMmU9BEVXcuYz0f6FQaKtaVKmUVRUIZgSGgrtvL2FXg3UvE95Y/PFYIsit6bktKYX+kkL3ufWEJ7a/xR0EkWO/GHBKuVN595mLwZV3ueQAPPgarW5kF2rAkrFvbHXcOz4RQ1j9cT3AusCZFYQY9CJYLLBqywoQXy+19PDwz7HOpcBByswgDdd2zOasHfVIW0B1pY4GWNxNK5cKCr3Ckgi3WsFRSPUOtk+iaqvDWOBGlX7s8IQFNzkMuCyDVV/x1bgYjhSRkc3oI+x0mRxI8Ks8bVJ7mFWgd3wSwAABnfC/U3HYer10LJ4suoSfCZRexiuoW1C4J0SAZadGQmbMOeAmuIFrid6s+tg+WnB6SSRW8kNhjR50PTeIY7LZ7klNWYOHLNI4sqezXUzaVQKwQC1I5aGM5+C03NAQD/nXYnhKslaMPouGU9EbtMOEiRW55voU/FFKJ5ZvjZMoFJjDjT0FYJ3bl1XNBGIRMlzoD8noZOnpTBcBUGXHGV3I1DIVy5pRxYIsznDQCjj4RtyBNw504WbkOtBWMMXf/Oh8TwBix0F8OoieOvQ9qhbjoHy7an2rWe5Fg8bVzdbntqFsVZa4bi6hNlwCcE4syST8quaquCtu6ocD2GgrZKKK8l3G1BaxYpvgmbr8+iuE0F5fBnHQ0iWTHhaVVsyeSD6dASWbKs5gU6mYg00LHKyqLfCvxgU8g+pQpw58+As9/tsI1+CVRc4NugP/M1In7+C8y7X4Lx0BLe9G8Q+dN9MJxdC8uuxdCfEZav+ANWpBO60uBBHL+ShAedl+AptrVQeMeKTYMABNQpDC24D8mE3rLbCCW9Fd9L4veo3Pn8WrCdZLETnfgfQ60DzSsKtw+4D2XjP0Fpykz0SrEiLy5A5iZ2TQAAxJp1WDAwHTN7JgmyQO3eNcGihZWSxUZE4kemn8wa8mj2qOBA+6R/Fk94EXzb0L+BsuYCANxZ4/01TGWNDjDtMC3wQVO9HxqeyUkdawXFBh+s+SJ9oV7ixhOfw7zjeRhOfimZ998kiy0zv/L/ZqzGFGJpAIyQyAxUhY5Acwi8dtvGvorGeVvRfMUaSd2KD/+grvb//0NqPBo1CSH3QJB2wceR0VvReO12OHtzfcTEPR6Np76UREZ9GZRwC/TVXrLIbyhNW5IBggBjSQks11oGdYuCQQx/e03nfrVxR7hEQOVuDpmdEUfWTQf+DXWdqLaGRxYZvZXLqoZ7DHzjH9Gg2njqS0T9cAsif7wHxkMdM2FQAhWd1+51WGMMWF7bEXHNUbgIpz2GHMjkgaBv2ASm7wKQcaHVHKw+EtCa0DbmZcF0OjpfIicPBbmMY+Smu9q1DYJ0QO81xfi1iFpztaIbrRzETceDEhU+WRQFn3yyQyX1h6T+3NMWNLNIJgW+nQRDgnA1QS0zgPd9T9RiV1JXU1hKFLm2DtqqQBCWTOitKHX8LcFXIXRULm4fEqgLZvWBMgg++TLvC3gHiOvS9WeFplW+axyx+UFErb9RukNe0Fdlk14bH+HiZxb5QR05qT/hbJCVsavaKrn5ovtTUQngbIDu7HfQVu1SyJ4L719NwylEbLwDhmMfAywrGGv8Zte/kyx2ohP/e7Rd9ibcuVPQOv4tOAY+AFP+aLw9pzfeu6YP3rqyJ4blxGB4Tgwu7yXsN/TI2Dws8tzv//uf5JXt2u+/yNlohZRMTHL9XZBtCwUXdPiZkY+S/Rq48mfA2WcRmq9Yjebpy9E6kYssrj1ajdkf7EOLLbx2FMzgO/z/J1haYP1fx0aFdIv1DZwJd+jMlOnQElmn2I7IUPn1ceHCkzoUIFRovnIdmqcvR9OV62SXa5nE68EkysT9wIT+wLAagzC7QRCgrTmBbKUIZ6KGwYPAvCZE4oGED2Ef9HDwHYkyi2LZdjj1kj7yQpDK1482BYirL7PIl5/55Kd8WZf+3Pey8lwxCMrRLqMGObRe9m+QCX3g6H0z6m49D0/GKPl9uZoVaxaDwbzvFcHffGmZj/yLibkSdBVbuUg/QwVteRLM9bi9cGeNg234M+1ejzHECmpc/1u1kXRkBlhCBWf3uUByHzBTXkXzVRuEz6UMfNeC1VnQNjrQ/9CdN7XdmcXfAgTpCN0WI0yoPG3tkvJGrZ4jHEyLJKgMT7XDD1pIBtve9gbhtjcKJkOlzUmCulJ1w0nELZOXG/pIljiLqHLUh8wsAlKyDAC6yoAyhkwdDCq2qyAY0hE4u80DoxAABEQ1ix3ILLqzxgVUKgAYXWSQpTlIWliJ3ahJO0C7JVlb/3xeNk5tl/6OKnsNQJMCIsyYecFNmXesXFYRANQ+sii6vxhzkmwwV1e5A1EbboX1m9mwrpoBy+aHuMCa916XUy4ZStYgYstjMBz7CGoe+eVLegF0yOsBAKAPfU3+KOh0Q+3EHxZkajHI1GLZedEmHV6ZJR+B0qhVYFMH4uqqJ5CAZnzPhC8d/ZIahY/oCcgipFG1Zm/9YStrQiQhdaEUww0t3qamY4JqH/JVlWEfQygwJi6axRqiQaYPx4UGB1YcKsNXh7jaBD2CZ1BYlQatE5fC3Hc6iH3vy37I6mCVreu0s3qYCW6AwXod0cKVMcpBLnoZDGR8T3iyxgnqJ9tGPA8QBEwHl8gaVtCGWNhGcLUsrM4CMn04wLKgorKh4WXA7EV3CZv/imRwcth88AAAIABJREFU71OTMFp1CDGE8KPUdMUaaBpPQ9VWCTJ9uN/gJhy4IXX0bXIzoKOygq6nL10PMm24/29WJ8ykh0Ngor+ehbrby4OSfSq+J9RlnJGRpvE0jAeX+KVIAI8sxskP/IIhlJtmKNj73wsyfRia0wMtKZSkiyp3i6JxTDDoRTXE/MwiawjUpgLCel4lR93ITXfCZrvUIeKqBCqmEO7cyTDvfUUyj0wbDiq+V7u3yRhj/nv1pF40z/gSZHJ/ELQHrC5CEK7z5EyCK286DGfXyq7LH7S7ul0NKiYfIFSgEvtCXyK/zq8FmdBbMXNKkHaB7K1t1GJE/KzsNvtbQm2vhsp+yZ/t59+HLAguQ+UdoAtkqKLG6MajH4K2pEKt0BNQDJXX+VYOZPoIsOrAu07DdwYWH7+3rYKELDrrJCYmssdhrwZ82SnaDfP256BpCLRqIFMGA2otPCmDoZcxKAsGFgRapn0CEGqQacPAmOIEmT0+DCe/gKPoLjARqUFb/yhBHOQIp7wkpFSTtPuDfnJQ2WsARz1oa45AQeKD2l4jcTBnTIl+gi4nd1bz9idwoW04CeuqmXD2vD4wn1ABaj1aJi+Dad+rAKGBjt/ayAttzQFoaw4AAGhrLjxZY4PeG+Zd/xAQaTKxr2A+q9aDis5XJLaKIOQNpf6I6MwsduL/JB4YnYs9bDesZYYEzQaupwPZoinuv+MRahFaYZY1pvEN7O8kA5Kk16mZitt2e1t2XOZ5EV1d7/vdWH8t+JE8F0njzlVH/UQRAMpZeRnjO/3W45HUz3BoyiZ4si/j5IMKGah6Nkq2Rm8/UxD4w1EPfcka2V6A4cLXr4iPYLVKTRPfQ0mL8AVNphbD1WOBpNeam9VgsOsN3Jf8CeiYAsE8EAQ82eOF+xXVyTr7LgKr4u6dVfQwHGezUex+E+WMsOaVSiqCq9tcOAY9xA1E2oFLOqmVeYuTEkZrZWA88TkiN97m/1tMLsPNdmnqjgVtUkx7Zbs+WHY8KzDtoM0cWWQiUsEa218r2xE4ei6Eo/dNcMpEgx397pBZg4vyK9VthQSPNAki6r7Moswz1Dr2Zck0Hyw7n+/YcSiAiusGx8AHZLMcrNYE1mAFbUkNug1xHz7WEA06St5F9PdA24jnubYHar0k8OED30RJDFaUdaGSikB5B4S/R2ax4fr9aJ79HdyZ8lb+2tpD0NYEiCRjTlZ0Zf09oKnlagx1pRsQ8/lo3gwjWDWvNCKIDBXg7lXj8U/C2qfu/AZBNtWdwe2X1ZhgH3AvWL1VaVUBojbcipjPRvjJgP/4wsws8kmO4dQKmI5+4P+bNcWCjs7njq/w8qDboaILJNPoqEyQGaO4gCNByL6D/MfLUIhePoYLMHWg9QlrFH1nwqizDFVSQJAOaET1p3zEfDkeMV+MRcynQ2SJv8peLWg1xKr1YA28945MEExX9rP//x5R6wtt9T5EbrozsD2tGSAIkOnD0TJrFezFoQMsll/+6j035XMXf+MoEVkkaDdYrTCbaRv2VMh9/5nQSRY78X8SBQkWfHFdf7x9pXJUvWdyBJ4mF+Adairu9tyB42yWf95FVtkEx5Y8HLd47sUj5M34dxCyaIfP3IaAEwZc43kCr3VbifqFh9p7OgLwG/x+feQSatqE9U9/JaUmKqWFt2PxjiZ8eY7ArBWXUGdz47Pd5TjaLM1sNagT4IBBVoZ6jA2QGx3rRuTGO4JblncAjqI7YRv8qOy8L442Y9VxYU2Kr82K+GU/xv0vVCMWa0/Ktztw8voGAsBXpSrc980xXGrlPuyMOQnNs1bhSPdH8QzJOS26ocMqeoR/nXBJGR9toxZzjnxR2fgxarZkfouLBJk0QLHQXw78urQPdpdj9ifHwlovesVkaOqVl2VMccouqkDAdIEgwKaEX8/bUTDGWNhHPAv7sKdkHZOp5AFomfIRbIOFg4zIn+6T7cUYDvjRen5U3S9DlSExZPpwtExcAqYDZlPtBR2ZIfiXD98zYRv+jD8IQ0Vlo+72cjTPXAFGawFjiEHLdGHAh9FHwZ03rd31fh2Ggkybj2CtX4LJARlRpp/ykoVfA8aUABCEoNesGPyMHm1Ogq34UTC6yKDHGg7aRi1G45zgslRfrVrU+hsFRk2s1gRoAs+zaf+bgeMlQ6tlaLNyjRbfBIeK7YrWSUvRMuEdNF25DkxkBjwKKqFwwclQQ5ct+MiiynZJks1lE7r7s0Hu7IlBtyNHVGhR/Syri0DbyMXKx0Laoa3a0yEZqjgIRcV18wcvxdBc2scZxYRQ+RCkHRpRHbYc1LZLsqZ1KnuNIDPJGKIFgSZCpN4g3K2CtiPObvNC7Fj4rVGq8xes0lrOGeiFWXvP6K2CGnuA67UrHj84eyxAywTlFmZMcfvqmP9/RydZ7MT/WWTHmtA/w4op3QJZmkGZVrwzpxdevbwHXpjWDdWIxWJqLtYywma+bJBHZ27/NGxgBuJLerSsjNCH06xw8MZAhU/PAKVOE26j7ldYKzSc+jh8sLscXx2sxL5yKRE6wBZgsucF1Exbgbpbz+HA5B8x5vAwwTKTl+zGM+tOop6Vau5fj+COTS4je4zJ6vBxhwuPNR+nshfiXWqKZN6S/Q2SXmI/XeA+xOLMIN/1lpWR1DFRWWi6ch3cmWNxJG46Xijvgm2ljXh72wX/MlRSEQ4lzkYLL9P8Lj0FZ1S5oLURaBv9kn86STN46aezeHjtCVS1uNDsJLF0Rxm+PyE08XF1n4+GhQfRNG8L7Ix0kNziosASKjRfIZTP2YY8oejoeopKAsuyuNTqwlvbLqCsyYntjLxMWwzz7pcU57Eag2JmhozvBU9OYMDFFskYJvzGCGlMRBDwZI2Fs+hOuLrM+U32qbIFsvZymUVXl6sEyzP6KLBaMzy5U9Cw8GDQgAIVFaRJdpjwZayYyHTJPN/v5cmZgKY562ErfhQtUz8GCBXI1GI0Xr8PDdfvB5nYR7QiC2hNkoBKy8QlcOUrB8g6Clal/B71LxOkxowNUjtEW3NBGjmSQ0ZmoXnWSrRM/Rju7AmSjGo4aBu52E84WIM1LPLHWJLgyZuKhpuOoelKqUNse5xfWV0E6OjcoMsYSlZDy+uF6l9XYwRL8FyuL+0G4TUfCac2kYoL753iyRwDaAzw5E0FHcORc9YU364AmBhqR40i6fKkDAosZ6uEuuE0or8cL1mOLeCVGWiNaL3sDdntNV2+WqKqAAB35hjJNFf3uUFrzNWtZR2UoYreGxoDqBh5dVL01zNh2fJYyP6LnEuvsgxVDs7u8/3/V7ddFChaGGMswCewosyipu6oX9HB6KO4jGwQiI2cwg2sqFsuhF1by1iSJPJRwtkgfb+odfDkTUXdbRfQPPUTuLMngDYlgNUYYRv6JJhhD4S1vz8KOsliJ/7P475RueiaaEFKpB53DM9GUboVQ7NjkGCRH6AsKs7EuIJ4PMHL0K2hhwAAnpxYgJF5cXhoTOBD8gE1QXY7F1npILHO5sGcD/dhPdVfZg0OFKvCcPcruNEj/zJaXcrirW0X8NJ/zuGXUnkL6xNMJt6vTAHUeizeJy+/oxkWDazwZVzZ92F8VM2RXJKVksUTbCYY9vfV6d/xow1rj1XDzgozCbTaCLtM2dmjG8tx4GIzWJ18uxMAsLnlHWKphN5onfoRZly82l+juf6kMHrd7BR+AJ0wYLzjWUzUfgBX1jj/9E/3XcRXh6qwuaQe7+4sw7s7yvDuzjI8uf40Dl0U9ohijTEAoYKbkpJYmmFh99CASo2mK9eBis6HJ204nD0WwF4sn3F9Zg+NTafrcJC3n0fIm3Eiu30EjhT1uKq3U7joke/b6eqxQDBQYPMngMnnyCOZ1B/1N58ELYrg/lq0x5Ti12Rw+AM1dVuALBK8FhK+2lQ6Jh91t1egeeoncOXPQOv4twK/i0oDJgiRsQ/9W9DjCIdEMV65KB0hQxZ50XI6rhuc/e4AYw0QVFZn4bJ6ot+V9i7jLrxCOD22a9jy1M+pMSA1nKTUlReieXUYmUVGJnPqR5Cso51WYTb1LO723IkbtC+BNcbCkzkGrZOXoX7RaTh6K5sx2YofF2TW7T0XojlfGISwD34k5LGzvgwtoZKV2bZHKsuq9UHP1wfDcWl5AKsx+q+tD+qWMhiOvB9Wm4+fqlRwG0M7QLoK5AMKHhmy5QMTpkxVDvy6XMPpVbCuuVq2BQ3bU3jt3AWz0DJpqcQYizEnyqoCBDXtPhAqOPrfrXhs6pYLEpLL6K2wDXsajFdq6hQFnABpaQEA0HHKUlR9yRqoZLJr/PMgSAfUTcr1opL9RaTBPughSb9gH6ikIsE7SuWoBVgGmtojMG1/FpEbbw9sKzITUGng7Co9VyWI5eVKUDeWBO3ByYdPmcUPOpPpwxXbtUGlAZk5Gq2Tl6Fx4QHU31ICZ5+b/1TmNkAnWexEJxBl1OLj+f2w+qaB6JoY+FATBIFRecKP9IIB6bh5SCZemNYVh+Jm4H1qIjbR/fAadTnMOjVG5nKDyCv7pGD5dUX4eH5ffGq8Fn8hb5LZM4E0qwGfL+iH7knSAcJKnpyRj7fo6ahgE/ETUyQ7/40DoeVCALBsVzlO1rRhj0z20Qe7qLXHXXsCxymWoTIgUMnGyzrFhsIUt7BOqx7yA4PTTBp2udLw8d6LsImOrZHiPkri5tg01Pj2WA02tWUp7r/OLm3RwM82yll5sCyLskYHGu3yZLuk0YM6GzePohm8xctIrjtegxW8OtI3f5FvJeGm5Elss5NjxVRCbzTN3Yym6Z/j08ONeKtE+oFqZY04w6bh8XWncKQq8MG8yMZjiXoe9haEcFblgRa1Wdhx6jxKnfIEzZM5CjY3hU/2VmDT6TquBvbKj9F4zWY0z1oJVheBxvnb0LBgD2hTeBbjjNIH2wtW2w6y2MFaNToygzNI8UJTfxyqVq5NAL9miuE5xYIgQGaORtv4f4PMGCnaonxwpXHuzyCTlYNGAODqfk3IDKlPfnpSI806tIdc24Y9zUXNc6ahLpIbfNPWHDh7XscdS9400NYcuHOEvQzdWdIMDgDsYwqwccQatEz+QOBQKnsOYQQV3LlT2u2E/NOZOox6YwcOt1mwlhmCXypJuEjeM6fWwT7sSbSOlZoDAQCV1A/NV6xB62Vv4sL1pzDp7HSMeXs3fjwduA9c3ebC0fc2uApnywYoKGuuIJMhJ59uT29cH3ltHfcqWI0BZGJf1N98Ci0Tl4DiEQxxzR/APT+O/vcKpkWvmo6IX+SDFuLMd6VTi+NuaT11Ixs4JzKhj2IfQyWy2DxrFRoW7kfjvK2oW1QCj+QZEuIHWuhM7S68QpAl9rUF4oO6bQ8gU1ftyZkER5FQUsiY4iUSSHfG6KAZbMG+YgM9EdUtFwSusw3zt6PhpmNw9r4RDQt2onHeVtjGSJ8Pfl9FH+iINMV9qkib5LzJuO7w8IzQVI4aQX/WUO9Id940sMZYSdDIB9uwJ0HFB6S5hhPLEfnDLYheMRnmQ0sELTN8wTX7sKfQNvLvaJm0DG4R+Za4Wau1AkduJUStvxHGox+FXA6A39ugedYq0JEZ8KQNg7P7vA6VlPyZ0EkWO9EJLwgZ56oHx+RhXlEa7h6RjaVX9cYdw7P886LNBjxDLcDN5IMoZVNwU3EmIgwa/7by4szomhiBz24aifvueRJLLQF5xoskFz1bcX1/5Mdb8PepXaFTC/f/GjULG+j++Inui1bWBBerxXPkPLxMBW/1YUN4A0CKYfHEuuC9ASMgJJ6H6Sz//8+zQsOYciIVJDRwBZHeelKHyE4vYYUfuVN0KihW+nqa73kUjPe1Je5RafNmGrfw2pG0sBxxbXR4cO/ZnviF7oE21oh7PLcL1q23CQnfykNVGPnGdjy05jgoWlqbQTMsHl57ArM/2IcP9yj3mKto4iLGZ+uDS2A8MvsINr3FKUyhbjxVh9e2lGLpHqlD3Z3k3XB6fys+WQSAH8/U4cojvXGAEZJApUyPR2TY4WqtR5tMcMCdMwmMOQnvbL+A17eex2PfncT2s/WASsPJznyZNbUOTEQKnP1uk2xDDo6BDwY3AlFp4CK5LOr5BmnQhKIZnG9wgGVZrm2CPkoiWw4FZ9ZlgpoW8+4XEftJMYwHlwgHWt4INc2EcA0VvXdYlQa24sdAWXPRBkvQ8yVju6FtzL/QeM1/UH/TCTTO3SJZhjEnYndZE67eFotaVhiEEdfhBIOz9404dOUBDDo7HxPe2Y2fS7gsqm3E86i/+RTaJrwNAKDjuwvkhI6+t3LZVBHsMKIBUZyZls4MR59b/PPc2RNAW1LA6KNgH/ggqCT5wBgfR6vtuNPyGlYPXoP6G4/6M1GuLvLvy+pWF/7y7UnJ9HqZ4A9fXswHo4sAFd8D7oKZWHemBeVNTpA0i0e/421XpYF9yONoG/cq2sa9LlifNiXCMVCkEFHrJHXA7QpseGsO3YWzUX/TcTRfsRaszgJP7hQBEZRzMWU1RtCxhX7zGSXQ5iS0TP4Azl7C+nc7DDjpEQ7ezzOJWOh5GM4uc+DsPh+t49+EEqiE3v5sGgA4et+Mlqkfg0wZBKj1XJshrVHRqAoAdjFd8SU9Sni8kekSwzIJorMUZ5FJRX4i5kkbzmVuVWq/ayajNcM2Srk2EQDaRr8EVq0HmTwQ9gG861AvvAcFz6TGwJ2znKsmzz12e2kj5n9yABurlOvHJcczajFaZnwp7M9YF6hPZzUGNCw8GLTm0vdusg1/RhIIsQ98EFDr4eo+3x/kU3laoS9dL7st3z3O6iLg6rEAnpwJaJ20FHW3lsKdMwlUdJ6EtAOAfchjHKlLH4mmy1fD0eeWkLLt1nGvonn652gdIzUa87VwoVIGonH+drTM+ALQGOEsusP/XDq7XRN0+39GdLbO6EQngiAxQo97R+XIzjPrhY/PsGx5swe1invRJw5ZiFfW1UJFMFhGT0L3pAho1BzxSYkyYFqPJKw6HBjsV7CJuIXk6gP18EALCrawsnbKg9+i9Chc3isZj3tJYnmTUP4yriAeP54JRB+/ZobjSnCtENbRA0HzsokvU1fCCT3Gqg6iERF4leKii5VsHJIIqcQHAJy9FsITlYMDRw8jgnCigKjAK9RsQS9BgJOA/I1aiL9rl/mnOVg96hCI/NpZISm2e0lyOZuIh8hFGK06hKXeusYd55sAqHAt+RjUoAXnAQQGiN+fqMHmknr8fJaLeP58tgFvb78gOY+jVa3+ZYKhvNmJ/hlW1LSFaFeiwCc8lDxZrGh2IdasQ7xFD7WKwN++D5D+n+i+GKs+CADYSXfDVh55LqkTkla7hwZA4EbPg/hR/xBiiTZ4Mkah7bI3YRA1bG66Yg0+q0rCHE0KEiguK7qWLsadmtWC5ZpnrfT3qfryYCB7+uLGM1iTJx+ddfa4Dj9vWY+paqn7rX+ZntfD2fN6qBtPwSjTAgUA4GjA/auPY295MwwaFb5a2B/JkRxRpmgGCz47iJI6O4rSo3DPyBy8ZV4Km9qDJ8flYMBaYSDDTphgZoWEc1nsI3jjQDc8FfU9xEI6y45nBX83IgrPrTmOHecbMaNnMh4emwc5MBFpQNNZ/98bpx5E71QrbvniMI5UteLJfk9hjnorPDkToT/3PYzHAhHyu/ZG4flCFnqvmy8tl3klVHhk7QmQ0GApNRmPawPyQ5/5U7j47EC1954BHlp7Ansf4NQP4mxY22VvwLTvdZCJfUGlDAQFwHV+g6B/WxuMaHMFsnj2QQ9C5WwAQdphG/60d9BGhG0//9fvT6GyxYUfzgDrC00g5vwATf1xeDJHyS6/64L8O6rW5kaaVfhuUfqd+OddKgpOtLkof/DQB0/WWDRP+xQqdyvXb1XBkITVRYBwBrJNjEnZUE2yLp9o8v5fZ3MjwaKceQICRCWYsywAuLpeBU/2ZdCdE/ajbWONaIXwHrzExuIwm4eLxdfCagohJyZUaB37Msx7X4YnYzQcA+Vr98nUIbAVPw5t9T6om876ez4CwMPkIiRAeG1ZrQW24c9Af06+fy6Z0BuEwrUAAKg0aLpyHbRVu0CmBxQ/LZOWwVCyGp60YWAigjsKu7pdw8lvNUaoGwMtGPgBJgCKEmJHvztgOvBv7v+9hUqll/5zFpUtLnxVr8as0Mp0AIA7fwZYXYRAXqm7uM3/fzoqByBUgEo5p0RHcvcTq4uAq/s8mA4EgkIebwkGq48CHdcdqkt7gh5PNWWGrG5ErUNrkD6q7sLZcBcGjOCo5P5wFN0F47FPYN79D8nyrEoDd+4UQGOEqkX6HeH3++S/exhzEppmfwtN/Qlhr+T/I+gki53oRAfRLMrupEcHz+ilxkXjbjog10iMEEYBJ3ZJEJBFH/4yLg+vbSmFjQwQh6wYIy40OvEoeSNe4BGqVbRygfjTkwoxIjcWGhUBvUYFt4iIXN0vFXcMy8Ke8ia0urg6vJ1MNzxLzkcmUYM3Rc6uLbBgMTUXizFXMP0DaiK6actQycbhKJuNWepAHyTGkoKj3Z/AggOcBEoFxp8p5MNAePA5PVZAFk2EUCoqlqHyJbMr6FFYIYou+yAmigDw5PrT2F7aiI2npfKkj/dKm2evORZe/8fyRo6M19mkMlc+fFyxts2N17eWgmWBh8bkwcW7RmoV4c9S/dVLDgsTLChKjxLIZJ+iFqCn6jw0oPAcFcJdzosmRGK25yn0JUrw2IR7Bc2eAaAtphfGfuNBo+McviXuxjOR38KSOQCHj+TBCOG5/eTMxwi1Dja3sJaztE4+u7r1XAP+8WMJasl78CZVjh/0UpfBt6lpUEXdjoMbzqFbQxaUKoColirsreVk1S6KwZqj1bh1aBYA4MilVj9Z3l/RggWfHvSupcJ7h23gC9fIpCIUVdyPU9rA77eMmoRnKznivbfZjJlBxr0sCCzeWuMPKKw4VIUbBmcgziwdydmGPIHo8i0gwOIlcg6WfX0cf5tYiMPeLPBTB/S47J6nodOooLJXC8jiloYIDHttG0bmxuLx8fnYVtqIgTm3oEfpEu43yJ0KD8X4Cd779CSMUh3GUPVxkPG9Qg5wxdhXIZSsNzo8iDFJz4m25qBt3KuCaVRsV4BHFivZOOE9ojFK1gG49j8GrfB+rGlzIyLS4A+2uUgalS2B9gO7y5oxpXsaPJHK5KjFJd/Lsk4msOMqmAHzrhcEsjmAV2sIIFb0OxypasXQHGkAkRRL6WTAGKwCMw85J1tFyLgTv7+rHG9vv4D+UXasDLKqTW3FxlO1mGxMCqpP8REMRiQft8GE04ywNrYBXOaqweGB1aRFZYsTsSad5Jr6QGaORnNm8MwmANj73oofT9dhyNG/IBsBsljBxqMC8TjDpKJAVQln1nhApQZjTkTdohJYv50L7aW9sPe/F6w+CtrKHXD0vxvyDVl452yMhSdXaKrGmhPg7LMo5LH64ZV909F5IOO6Q1svdR4VtC7hwdFnEdQNJwGWFWTYmp2k/96X80FQgu8aKtXikUlcwC9YT19+nbB94ANgCQ3UrWXwZE8EFR8wO6KjMqENQRa/K6UQfrVicLAGK1yFl8O092WB2y/AZa9914GJzABtToTazleECBVTfNBx3UB75b9n6+0oa3RgeE4sdJo/v0izkyx2ohMdREG8RRCd9mUQlZASKfyIixcvTBRGr/UaFZZd0wcF8WZ8tu8iKpoDg6GcWDMuNDqxnB6L9fRADFSdQiFRgc9p+b5eFr0ak7sFPuyj8+Pwg8ioZURuDAxaNV6c3g23fnXEO5XAMlo+ivbouDy88ONZyfTvmGL86O4HF3QYqjomIItNqhiU1Qci8HJEEQDcbGhDC7EM9RwTPBoeCnJEUQnfHa8JvRCAsibuXEORRSdJ46Wfzgr6YZIMK5Chdk+KkMhIT9facLpWaFpQwSZisPtNqMH4TXnCwXk2GefZZEyspZEfT+GMaRyGOn4EAPyTmoNGB/fRPc1m4KqWOwDvLfI2PR3D1Nyg5zt6MB5YfRzb7hmGM3XC43KSNA6UNyFbFCT52/en/GSmhE3FRTYOaYTQ9W4lPQLnvPfaVhRiniURsVQNTqRciW5VK/zLGQnhQP8o7/c6VaNsnb7hdD34t9MJmwUumsDlzFP4XPc83NAKAjGVbHBZIAEWRy4Jr9WlFpefLJI0g4vNLmTFGOGMKsAPvT7GT/sOYQvTGxQYLN9fKVj3SFUr+mdY4c6bCvLI+2BqTuAJaiF8KoIt5xqw5W2OyOhRjFeMJzE0zgF6wL1odAR+ExpqXEc+gveGa9C95wCAIFBnc+Op9afBggsoRRq02FvehNw4sz8r64NWLXxe39l+ASNz41CcHQ1ViAygs++t+M/ZRsTWbMc2pifK2CR/UEoJL/50FqsOV2FWr2T8ZRxXJ7rUawyVG2/Gmtu5bLBYOkorpep5EEu5fai1ufHVwSo02N2Y1z8NkQbO4Kdh/g7ELxXWRPIzizaP8FyOVLXIksVwQMcUQMPLNtNWeXWLHPjN7X111z51xIEWI2ijBmpW/ne/5WQP7DtxClQyheuC7cM32Bb1e3WzWhzjtZgCgHiCk/A2OUgsP1CJlzefQ4xJi6+u748oY+A9v/NCI1YcrIJaReDuEdz5Njo86JkSKXtvbThVi799fxoDiUH4Sr8RAOBJGwb2LHePTvc8h95EKR4fOhf+L4PWiOaZK0CQDr/80tlH2cBIDg12DzacqkWXRAv6pXXQdIcg4BhwL6LWC/fNqrSKZk6sMRatUz+WTD/HK3GoDvFeEh4D9zspSdFd3mwdmVIMd9Z46Mp/BquPEtQ9CmqJ1Xo4BsvXv4fTQ/SixwSWZUEQBErqbPjpTD3G5MehIKF96gcfmIhUNM9eC03dMZBJRTDtfxPq1jLY+KZhBAEybRjUp1fxjlVqBCY51mYn5n9yADTDYlavJDx2mbTn5p8NnWSxE53oIOb1T8XuVGHVAAAgAElEQVS3x6rR4iLx9CR5y2o+NKKBVmaM8CVtFEVaM6ONKPS+KOPMOgFZ7JJowX+8NUPNiMBGZgAOmIeiQcFsRez2+cCoXJyobvPLUCMNGvRN5WoOitKt+NuEAjyzQd5Ce1CmFSNyYzGrVzKW7CjzkwgfLiuMh1pF4IeTtdjHFKKWtSKBaEY5E49xH51DUUZgAJVg0aHWWy/4GjUL92i+AQAspriagOXUaFyj2QwA+JQSEmGbyA11LxP6GoiRHKnHpdbgRO7XYH9FM5wkjeq24Psob3JKJMGbS4SEqWdypIQsKoGBSpGIA0BxVjRcJI2DldLtLfqSaxaeiJm4VaPGBTYJH9Uqt3DYzvTAC+Q1yCSq8QbFNbLeeb4RFc1SO/h5y/bglZk9MCiLkxOzLOsnigBHZma6n0Wx6jjshBkLjb9gnbMbzrGBDJgDBgy1LUYGUYuS0lQcMG9GNM39VmcYYabscFUrlh+oxJaz9UHJIgCQif38ph8vNHLE8ABbgN7updCA9sucAU5aFwq1ojrYkno7eiRH4ER1G25bcQROkp/ZVwMI1OUdFRHNV34+h9uHZYNiGPSe8g2mvr1VsS2PGzrc7rwVKS16fBNTiIZqUcNpaHCEzUV3jRGrDldhMS/g89XBKtTbPfjueA0iDRp8cV0R4i0cud95oVEiY/7mSDW+OVKNh8bkYk7f4FnKahuFuy+OAjDKP02cfQY4ufDZeju2n2/0m0CtOnwJCwdlINakxbs7OenYuTo7fjheg5GZVkkvWSXTKT5aXPJk8fWtAbMpu4fGg2M4+TAjGlRLarRE79hNp+uw/XwTrEYNnp7UBbEyWWUlUNH54IdUgpHF5pkrYF3Nq8tUaVDaYMe9X3P1Z77jB7j3QrM+BbEuab3ie9Qk7GO5d+h31VZcF6T8zdeGgBGZixgJNyhoUMokIUfFqS98QZZGhwcvbz7n/T+J93eX475RnGt4m4vCI2tP+J+JskYnLjQ6wAJ4cHQuruonvbde38Jdpz1sF/yLnI07C21o6f8AcJYjMy7osZvtil3lNsyy8vKGKk3YRjRyeGLdSeyr4AjwdQPTcefwjrW3IZMHSabJOeGGwlneM0lCg71MAQaouG83Gd9T0N9SDiqX1OCOiu0aqBMmCLROeR+gXNBW7Yb1W55aJYTrLs2wWHX4EuIqjZKs4WkmDYWqgGqnkY1Ak5NEpF6D+745jpo2N9Yeq8bqGwcqZu4OXmxBg92D0flxUKsIuEiaU2B4gwtUfE9QXgfvtstel92GfcD9UNlroW48A0/2ZaDDMMnaXFLvV/l8c6Qai4ZkyapG/kzoJIud6EQHEWPSYe3NA+EgaVkplhxuGZKJJTvKEGnQ4GqZD+DCQen4YDdnmLJoSCAa1z/DKhjYD8mOwarDlwSDpMndEmQlkwBHBvmwmrT47Np+uO+bYzh6qQ13DM8WkNkp3RORmRiBD3eW4Rceabl+YDru4H0cHxmXj0fWnhBsu0dyBK7qm4q+aVEorbfjhapnkNnwM76jB4OBCnt57qvTeiRhdp8UTF2yC29RM1DBJqCSjcMxlhscvUDNRRRhhxY0XvcSER/ERjp7vQMdq1ErkQjLIc6sw8qFA/DGL+fxxYHKkMt/Mr8vHvn2JKp4cjcxtGoCJB3IajhJBm9sPY/vTwSyuBoVASqU6YkMxhTE4bP98te3vciKMSHKqJEliz7UIAZPU8HyCz4QWEILDXEeWnsCqVHSgQRJs1h9tNpPFuWkgPWIwrcMlzEq0QxCBS39vV3Q4wzLRYDnO+7Ht8YnQbPA46SwFYibYvwD1FBoGP0qrAdfx/raSOy6FHBrdEMHMdUPRRbdhgRAdNgvbCpBZbMLH+9VNkRSwpk6O+79hhv8qwmADmIi5UNVqxsnqtvQINNP5lydHW9vv4D3dwlJww8na/2BjVYXhWW7ynHDoAzEmLR4aM0JyXZ8eOk/59DgIHHDoAzoFQZ27++WEhQxYaMYFvd8fUzWobmkzoZagzDrcqyqBSMzrX7XYR9qbR7U2z2INWlBENzzphFJOVp4LW/4Em8+vjxY5SdbXxyoxD28eeLG3XZRZpEf3PvHT2fx4nSpe6USxO0rSFFmZjNbhM+o0ZgzvD/6phbDnT0B+vMbQCb0xrsnVXhnx37/sk+sExqoVOtzBWSRZglc7fkr9rKBQfI+tgCr6GEYYzoPcuTTILJHIX5JgHTuP1+NHZ4yXD9QmIVp9rqe3kXehX9ql6CSjcVab1spcVBxT1ngGp+rtwuCJ+cbA+qTf24+hxF5sbC5KeTFmf1GdIFsMoE36Msxd8Jwb/BBqBD5+6YSrD1WDZJmYXNTeH5qV1n38XBA0YyfKALAR3sqcPuwrJBZdTmwxhjQpkRBzaI7f3q7tyM2T7vXcwe+6F8KS+EYUElFqHxjJPqohO9AZ9er/f+nzUIpMRWVjZbJ70trhTUGkOkj4MqbBl3FL7ANeyrksb22pRTLD1SiN6HFVaLgwwf0RCxWvef/uxVm1La50eqi/OOaOpsHJ2va0DtV6iJ8uLLFH9hcOCgd3ZMi8Pi6U4gz6/DRvL6CrHUwMFGZaJmxXHbesUutWH2kGqML4jCU50khDgSuP1GDaweEzkj+kdFJFjvRiV8Bg1atWHshhxsHZ2BkXiySIw2w6KWP38JBGYjQaxBp0GBEbmBAOqdPKpbu5D7wWjWBlEgD5vRJwRu8lgtF6VZY9Bp8e6wac4vSEGnQ+I1s+BJU/rG/Pae37EBKRRAYWRAPD8X4yaJFr8YC0QtxTH4cvrlxAG764jAa7B7EW3SY3C0RahWBy3tx4p96ewau+jAJrRQl2gdnqBNn1uFfs3rg3q+PYSUttERvhRm3k0Irdx9K2RSUM/HIUNVhD9MFs4YOQKRRi1F5cdhZ1ogd55vQaPcIBp53Dc/2/2Z/GZcPnUaFe0bmSMji0OwYbD8v7FHZJTECi6d15dW6SfHyzO54+edSgRMnv0UGALwwtSs+2Xcx7Cyhf/8JFiye1lXWwbG9GJBhRbRJi3e2KxjF/Abg15AlRuj9A4CyJgcomsH2842i7JoU/AG3Eo6zWbglfjkOlNWhAR3vnXhJnQz1uFfx74/2A+AGYP0zrNgnQ1xaYUIba0QEId9M+3nItcpBh4iiGHQ74gx/+fakrNxSqeZWnAFfdfgSVh2+hHiLTlLjLMb7u8rR7CDx6GX5svO/OSLd5/kGBxiWhYdi4CRpfHGwSrGVz5lau2T8WuLNFotl3isOVWHFoSp0TbQgNcqAn882YGr3RDw+PiAX4xPV4TkxioZVboqBw0PhlZ9LkasdjKnqXQAgabSu1KsV4DIR5xscSIjQQUUQ2FfejKRIPfLj5SV2JK+dAWWIww1fl+E73nwj68CPdD/s3qnCpr4sWicugabuGJosBXjnnX2CbYmfsfX1cejOG0cvoyf7A20+sFDhAfJ2oAWYcCYez+Ub4MqfAUPJGjBQ4fHyvrhYVoYooxZzey6C9ei7OMckYyPDtXo5zmZjkkfoonmpVfgs86/ZxZbgTelnvrcHDAv8bUIBVASBchnVwtKdZZjWXb4Fz7FLgez6O9sv4I0resou5z9/lsXhylaoVQR6pnBZSIZlZRUiNW1uJEca8NXBKny8twJjC+Jw78gcEAQBm5uCiiBg0inUZ6YNhfrM1wCAMnUmbj07AU90sbVLeikmi5WIx+7UkRiZxNUvWgnh/JZJ7wlalLgLL4fpwL+htlfDPuB+rh7SK4WlGBa/nGtAjEnLETaC4FyPWTak8VRtmxvLvd/V42wWzjIpyFNVgVXr8ZZqHr52DcdibYAsNrIRqGnzSMYixy7Jk8VveaUgvgA7wH13lh+o9NeqA1zmetOZOqw7XoMYkxZ/nVDAyctlUG9zw6zXwKBR4bHvTuJSqxsbT9fiu0WDoCIIvPpzqeT96fuWsywXDN1f0Yw+mTG4kXcMf3R0ksVOdOK/CIIgFAcIACdFlYtQWU1avH5FD3x1sAqXFcYjwqDB/AFpsHkorDteg8IECwZmRmNIdgwWDgoUnasIApdaXbi8t3I9n/jlzMfIgnjM6JGEiy1O3DcqV+LuBwBpViO+vXkgqlvdSI4ySLYXZ9Zhw23FeHnzOQFxmt8/DXnxXHH90OwY7Ll/OE7W2NDqInHXqmOQQ7xFh1k9k/HuzjIwUOFa1Qv4bKQLSZnDsSAiQK4ndU3EpK6JKG2wY+5H+0GzHNm6dkAaRubFgmJY5MaZ/ec/IMPqz3j6pEUbT9X6ybZvENI1MQL3j87FK5vPgQXQKyUgDb17RDYGZ8Xgq+tjsLusCXeulJf/pFoNeH5KFyz49CCawsiA+s5bp1FhbEE80q3nZUnUncOzFfs1jsqLFQyGi7OioQpRYwt4s1ghyMmNgzOwbJc0a+SD1ajFP6Z3w/WfcSS7pM6O4le3KS7fEWwq8wA8otg/PUqQAQgHl1pdOFNnFwy+JnVJkCWLAIHTbDr6EwGp9g/0AAyZdD2OEF3w8Zrwalp/b4jlmR2FOHOnhK+PXMKhyhbcMiQTI/PiQtZxlzU5MejlX8La9pcHK5FgEaYnjlS2gGZYxfM8WWPDSS+hXH20Glf1TUVChA4WvUaQ1Z7aPREZ0UZZZcaw1wL36kvUHJBQo4RJw6SYYeBbYYhrFsWY86GQxKlVBD6c2we7y5rx0Z4KGLQqPDwmD6Py48CYE9E67nUYznyNt51jcazCLqipjfS2NGpzUxj8yi9Ydk0f9ErpgzMVyj1zfShhhYqW72mpHJKPDafq8OzkLrANfwZkfE/c/DPXoxUA3ttZhgFXPYhH9hWggk2QNQ/z4auDwqBZi4uC3UPB5qbx9A/yJQ8++JK+SqURABesOCGSXMth14Um2QApHxtP1eEJr4nYP2d0R63Njde2lMoGTMoaHYgz6/D6Vm7+5/sr8fn+SsRbdKizeaBWEbiqbwruGZmDI5Wt2Hy2HpO7JaIwwcI5ALsacNamx7VVs9BgZzHvkwNYOCgdxVkxSLMa/DJw+d+FFdQs+vDZ/kqM9DpPWyGU339l642PPjyEvDgz/j61K7T6KDTO3wbC0wbW67pb3eqCQavGN0cu+fsD90yOgEZFoE9aFG4dmuUvcmBZFufqHYiz6GDlZfOO8a4FBQ2me57Di0PUGNxvAD744AQ88OBtahpuUX+HDUx/nGHTUdboEATAAY6Iydm0nVUwTAO4/qldEyOQajUgJ9aEm788hHM8r4SsmIsChRTA1bc/t/EMShscsOjVeHVWD3+JipNkcKSqFadqbLKBtq3nGsCyLLaea8DfN3FOtxtO1SHOosOorPB7pP7/DIJlw6gE74Qs6upCv5j+m4iO5moqmprCa8reiU4Ew299P7Esi0/3XcTmkgaMK4zD1f1SFeU7G07W4vlNZ/xR8ZRIPYbmxOLyXslIjzbirpVHUNrgwJMTCzE8N7gkcMvZehy42IIr+6RILPF9uNDgwP2rj8GgVeP1y3sgzqIHzbB4d8cF1Nk8uH1YFuJ4H+3zDQ54KAa5cSZ8uu8iaJbF/P7pfgkezbCY+u5uifHGmPw4LJ7W1S+N81AMTta08QyFuNpEcc1az+RIvD+3DwDg0MUWPLjmuGCwW5wVjRsGZeBmryyHj75pUXhhalfM/Xg/Gh0k7hmZg/n9OZfITafr8Ji3J9zcolR8zjNW6ZYUgTeu6IF1J2qx43yjbKuBXimReO/q3vh030VcbHbh8l7JmP+psNn3ggHpXEb9je2S9cUozopGk4PEqVppfWG/tChM6pqAZbvKQ9aAvn1lLzy5/pRELuRDlwQL4iw61La5ccY76Li6X6ogw6xVE/jh1sEY+++dstt4XPMpbtZ87/87z/UxruyX6Y+m/1mRG2fC9B5JeG9nOdpkag75uLZ/Gqb3TMLKQ1WCNiq/JcYXxuOnM3XtyriOL4zHvopmvzTyvat7o3dqFGxuCld+sE+216IYCwakYcGAdJyps6FbUgSu/+wgLjQGz5CFg6v6pvgzG10SLbj362NgWOCCIeA6fZ5JxGjPK4L1Hr0sHxebnPhkX3CpehxasF1/N/QEiQZ1PAbYXwla3wwA3948EEmRBhyubMFNXwjfMf+Y1hWPdFDtML4wHmVNTolJ12+BGJMWD4zO9Qf8+PhwXl90TbTgfIPD68yqQnJCBNpcJD7ZfkEiXReXF/Bxdb9UzOyZhKs/2i8734er+qZg5aEq0CwXQF1zU6AWb8bS3aiSqZ3Xa1T44roi2e8Ww7J4cPVx/FLaKJkHAK/M6g4PxUDzw124Qs0FPOrZSPR3vyNYLjvGhFcu747UKG4fm0vq8cjaE9DJOKbzkRplwEszumFzST2W7iyHXsMFO6b35EIo//7lvKQH8ej8OLw4vRuGvbbNv20znIJ6cDHiLTqsWzQIZ2rt+OpQJQ5XtqKsKbznTKcm8Pep3fDgGqnr7D+mdcWIvDhoVASanSSmL90dVOly36gcvPJzqeJ8FQFEiIJQY7skYPGU9nsp/J6Ij++YBLuTLP4KdJLFTvyZ8b++n2iGhVpF+B3SxGBYtkO1IsGgtK+OYOeFRtzNy5DqNSpsu2eY7LJfeF0CkyL1ePXyHrjqQ+HAY3xhPJ6fGqijo2gGbW4Kd6w8iiYHicXTuqIwwYLhrwcI2Tc3DoCbYpAZY4LGW/zf5CQlDpebTteh2pt9Xr6/Ekt2lEFFAMuu6YMeyUIjiAa7B9d8tN+fEf3r+AL/4MCHI1WtuGvlUThIGmadGl9e3x+JEXoM+NfWoL/X4MxovHp5Dxy71CoZkALAptuKYTVx9agrD1WhqsWFg5UtuCiTZd185xC0uSks2VGGdSLn2uKsaLzulaH5nDXl4CPo/ON+ZnIhhmbH4PmNJThVcgqb9Q9AT5A4wWRisucFyTbm9EnBuhM1AhOf9uJfM7sjwaJDUoQBk9/dJRm0DsmO9vYRDZz76Dd3hL39jGgjmp2kwJk0yqDBjcWZsvWeI3Nj8c+Z3QEAlS1OvLujTFCT+0fEioX9keU1HKtudeGG5YfCzqYCXPChps0dtlKgI/iLZjlu1XC9T2/wPIj/MP06vK3LVPvwXP55vNg0HKtquef3kbF5SI82IjPaiGlLhW0OZvRMQrRRi73lzTguyt5N7Jrgd9YenBWNeUWpisqQ3wNdEy3+7DEf6VYDPpzXVzHYI8bowngcvtgSljmSGFf0TpZtexUM/5rZ3V9qsuDTA7LnAHDBGa1KhdIGO2b0TEZhghlvbbsgqQFVQirqsEL/NMxw4XrPIzjISmXiObEmXNUvFRadGp/svSgbrJPDsJwYHKhogYMMvN+WXtUbXZMicP838rXHYwvi8NOZesn0YLiqb0qHg01mnVrx/Xt1v1Q8MDoXv5zj+vP+1jDp1Pjx9mKJi/T/Eh0li+qnnnrqqd/2UH5/UBSF999/H08++SQWL16Md999F9u2bUNUVBRycsKzmD516hSeeeYZPPPMM3j11VexcuVKVFRUoEePHjAag/fL88HhaP9L5feE0SsBcCm4vHWiE+3B//p+8hFBJfL2W5G632ub6VYjRuTGYN3xGtAsZ27UN02+pq5HciSu6peCa4rSEG/RY+eFRkFWbGxhPIrSAzbtKhUBo1aNK3qnYF5RKpK8PeeSIvQob3JgblEaRubFIcak8/+OGrUKETJ1srlxZvROjYJOrUKv1Ch0S4rAvP5p6J4kdQw06dSINeuwu6wJPZMjcNfIHImcKzFCj0ldE5BmNWDRkExkeIMO55ocOF+vHHi4ZWgWChIsSIo0IDlSjy3nArJZnZrA7cOyQBAEDFo1+qVbMTIvDr1TIyW1cHePyMaAjGhE6DUYlReH9GgDNpcEtjU0OwZDvGYF3ZIisOFUnWyG7LXLeyDGrENihA67LjShW1IE7h2ZA6NOg3EFcfjieBt2uDLQzFrwEnUVGiH9ve4blYObizNxsdkpyDqpvL3mWXAZ3cQIg6SpO8CRtgdG5yE5ygCDVo0DFS2CWtAvrivC3KI01NvdKK23Y+GgDAzJjgFBcL0kAXgDLtzyj47LwzZeJiIpQo/VNw3EqZo2wf7nFaVi4aAMjMmPQ02bW+DUOzQnBsVZ3O8XadBidH4c+mdEhd1Oxgc1AYQTqV5z00CcrbcHNZYCOGfje0bkYHR+HGb3Scbj4wswrUciatrcITN+i4oz/bXnFr0GuXEmrD8pJcDX9EsV1L/5UG/3CHqifjK/L67tn47R+XHt/l2UcJjJhZPVYR0zGBeTxmNQVmzQQf2i4kzU2T1ocVHonhQBvUblDwiUsil4r6E7St2RfmOfOX1TUJwVA4teA62aEBiRna614VBlqyyB5su2p3RLxKRuiVi+vxIkzzCoa6IlrGxtuHhoTC5uH5qNLokW3Dk8G3vKmiXbT4404JqiNBypEj4zSrjQ4ICT7FhQR4noBUNFkxO9UiJxsdkVVMbf5CBRb/eAZoET1W3Yek6+1ntCl3iB1NKHNpjxIT0BS+mpqES8/D6cJLaVNuI/JfXtuk7lTU7BdQa4WsL3d5cr/ubnRe+5jGijYs9TH8QBCj6K0qNw5/Bsvzu8GEoZYYCrh+ybFonSBgd2lUmVM6FgNWpBMSyU/OpImsX0Hkmy5Tv/K5jNQWyOg+APSRbvvfdefPzxxygqKsINN9yAwYMH4/Dhw/jggw8QFxeHnj2DFy8fPnwY8+fPR319Pa6//nrMnDkTUVFR+Pzzz7Fx40bMmjULOl1ot7lOstiJPzM676dfjziLHuMK4jGmIA4TuyYEJaN6jdpPvKKNOn/fxzizDo+NL1A0SeBvszDRgjleJ9qOQEUQyIwxBa2TyY+34NoB6ZjRM1mx7sei16B7cqSgXUCfrBiUNzlRnGnF36d2xeHKFv/AJNqoxePjC/w1boUJFrAsiwMXOcIzf0A6BmVKaz/iLXrUtrn9MrYbBmfgxsFC58isGBN2XmjyD3RvGJzhb1ujVauQE2PC9yJiMKNHEmZ6DZq6/L/27jssinP9G/iXXkVEioACERkUEATFEjEFjxxjL4CgIooaS4ye+CbHxJpEPTHJMf5ilKNRg4qIYhQVYjeWWGKJDSViV0CKBWEpS1nm/YPsxnWWogEB8/1cl5cXzzw7+8xwszv3zFNsmmBEx5YY4mULHe2KO8RaWlowMdDF+ht6OFLeQWOi6GJlggndnWBqoIsezs2xKzkbBSUKaGsB83q7YmSnVvBp2RTB3nboYG+GLFkxsmTFqosv5TqrNk+tS2lhoqdKYtrZmKqOtYdzc4R3dkDnP86Rp50ZHJoZYaiXLWb2EtDCzABDvewQ0NYKp+8+QZasGPo6Wvh//s5wsTKFU3NjxF/KgIiKLncL+rSFsb4uLEz04dDMCAmXM1WJ3TBve9VYYyVbM0P0cbNGeq5csgSMJqtDvDAzQIBTM2PVRd4/21rhI/82iOjigK0XM1AuVjyFGOxpi37uNigXRZxPkybASl/0a4d/uFrD1doULc2NoKutBTNDPQS0tUZzEz2cvP1YY3KqfIr6dC8Fa1MDbLlwX7XO6WsWxvjsHVf092iBuPP3q7wABYCILg6wNzeClak+fr72UDU780f+zvBr3RxaWoCdmSEKShRqSWZVSqCH02I7yC3bIzK4A3oKVhjduRU2nE2VdMFtZW6Iub1dMczbHn6tLRDeuRUGe9ri1zs5asnA0zPAjvJtqfp79W7ZFEWliueehCvUpyVaW5rgxoMC3PwjKTDS08b6kT6IrmSm7qdFdGmFXm2tcfF+LkoqOceGutr4pJcAh2ZGaGfTBAa6OsjIk+PCMzM7e9mZoZerFbo6NYOtmSFG+bbE3qvZlV7YV8dAVxvT33JGSnY+rEz10aqZUaXd3GviYUEJfryYgZ2VTDb1PMZ1dcCk7q/h3dcdsfl8uiQ+xWqWUqpLjs2M4G7bpNLJyvZP7ob8YoXGmzDV8XUwx1cD3OHWogm8W5rhbGpulb04TPR1JOfmp+TsF0oU32rTHCuHeWH8646487hQLQnW0daCrrYW3nK1wgD3FrXeA+qveNFksdF1Qz1w4ADee+899OvXD4sXL1aVy+VyDBgwANnZ2fj5559hYVH5YriDBg3C9evXsWPHDrRp8+d00HFxcZgzZw4iIiIwY8aMatvCbqj0KmM81a/tlzJw/UEBhneyV40nacyejafcolJ8nJCMaw8KMCtAgL+LpeQ1DwtKIIpilcmrvFSB/x2/gzKFiEl+ThpnGS4qVWBXchaaGOiil6uVJGnfdvE+vnhqvcF/92yDoA52z+5GjaJcxGd7UnD05iOY6OuoXTi+/lozfDXAXW0ZiYw8OU7eyUHHlk0la6wqiaKIXcnZeFRQgqEdbGGiLz2WmLNpuJIpw9iuDqpJmp5HUakC59Jy4WptqrY22KHrD7ErOQuD2ttKFpNPzpRhe1IGLIz1Ma6rg2TN2MreZ9Dq02rd5VysTDCzl4uqe7Moioi/lIFceRmGedurboicT8tFcqYMfdys0eyPZYmKShWYtu0y7vwxVtnW0gSJSRm4ej8Pfq0tMLxjyyrbk5pThLOpT3D23hPVjRgA+Mi/DYK9pb/rozcfYd3pVPT4I9lSxsyJ248RfykDb7WxhJG+jmTpIKCiK7AyDovLynE29QnMDHThYdtELfZKFRXb7Jsa4dL9XMzfe02SzAz1skWojz1O3X2CzDw5wnxbqs4JAEzackltEqbpbzsjyMtW4++ooKQMX+y/jr1X1ZeXaGVuiC1jfNUmJLqXU4Txmy5Iujvq62hheaAnZiQkq20zN9JD/FhfmBro4mF+MVaeuIs8eRmGeNqii1MzJN3Pw/tbkyCKwNKhHtj9e7aq6+ZrFsbYGN5RdfNJJi/DtQf5KCsX8cX+68jIk+MN54pZxN9wbo5ODuZqbcopLEHw2t9USbmejhZ+CO2AtjbqXe6e/jt3sTJBfnGZxnV2nSyM8A+hYl7Dx/UAACAASURBVL3glScquqkHdbDDv3u2gaJc/KNngBb2Xc3Gwn3X1bph/t9gD3RxNMfRm49wJTMfV7Nkqu6YXRzNUar48yaYJlV1m3xWU0Nd7JnUTe2m3d7fs/H9ybtwsTJB77bW2HE5E2fvPVG7KWFlqo/WzY1x6m7VEyIZ6WlLnmKO8m0pmQhKC6h0jON/B7rD16HifBy9+Qj7n/rba2akh32Tu0EURZy+9wT5xWUoLivH2y6WuJadj3c3X5T8PfxDsISvgzksjPXx1jPfGfJSBebuTsGFtFy0MDOQPPFVfq5/d/RWpcuMNTHQhU/Lpmo9W561sG9bBLT9c43R3KJSTN9+BZfu56FFEwNEj/RByxZNoKej3eCun/42YxYnTpyIQ4cOYevWrfDw8FDbtmbNGnz11VeYNWsWRo0apfH1V65cwZAhQ/D2229jxQr1gb5lZWXo1q0bdHR0cOLECWhrV/2FyGSRXmWMJ6pNmuKpNseI/lUbzqZh2dFbaG6ij03hnWrcdUh5DKIoYn/KA+TKyzDAo0Wl6w3+nWTmyTFvdwr0dbSxoG/bGq99VhXl+f4rn0/n03Kx72o22rVogv7uNn8pBpccvqk2MZS1qT4S/phm/3kpykUkZ8rw3o+XoKOthVUhHdCmmhsCyZkyzPrpd6Q9kaOzgzm+C2xf5XuLoogfTt1D1KlU1cX9zF4uGOwpnTE7I0+O8KdmbW5ioIv/9GuLrk4WSM8twp7fs5EnL0MrcyO87WKp1pNAE3mpAmXlIkwNdFEuijh5JwdZsmK87tQMLcwqX+C9uKy82r+ni+m5WP7LbRjo6WBcVweNyy1okppThP87cgtt7czQ3r4pCgtL8Hab5qqYuJyRh7Qncvi7WGpcHD7tSRE+35OCJ0VlGOTZAqE+9pJ4KixRqG6EFJeV44df72L9mTTJervWpvrYNrYzvv75BnYkZcLaVB8D27fA6M4O+HxviiTJ/3qAmyRh0qRcFKEoF7H65F0kZ+ZjQndHeNiaoaCkDD9fewhnSxPYmhkgKOqsqktoP3cbzOvtijx5KcZsvIB7OUUY7NkCM3sJOHT9IWYm/v7H71IHC/q0g0MzI8zfm6K2dm+nVk0RGeSpdj5+S32CBfuuIe2JHOO7OeDd150qbff2Sxn46ucbKFWI8GnZFP8L9nyuv6syRTnGb76oemq5KbwjnC1NIC9VYMPZNOz5PVsyWc7KYZ7waWmOq1ky/Gf/dViZGmDC6444m/oEThbG6ObUrNI5FK5nF8DevGJZtIZ6/fS3SRa7du2KwsJCXLhwQZLMnT9/HiEhIejTpw+WLFmi8fUxMTH4/PPPMX36dEyYMEGyfezYsTh27Bh27doFZ2fnKtvCZJFeZYwnqk2NIZ4eFZSgqZFeldPqU8PQUOKpuKwca0/dw+VMGQx0tBHa0V5tfPGLkJcqoKWlVeMbDuWiiEcFJbA00a9x4pstK8bWi/fR3EQfQR3sKn3dg/xiHLr+CN2cmmlcGulV8bLjSVEuIuFyJrJkxXhYUILfs/IxtqsD3q4k+ZOXKrD+TCqyZMV4s40lerS2qPUbbXcfF6q6uYf62Ktu7hSWKHA/Tw7n5saq9ywpK4eejpbGNuxPeYDbjwowvGNLjT09RFFEblEZzI2rv3n0uLAEaU/kEKxMnmtNa6X84jLEX8qAs6WJaqz60+04n56LZUdvIylDBldrU6wd4V0rMd5QPp+e9aLJYsMZdVkD+fn5yMnJgaOjo8anfnZ2FV1J7t2rfLBwamrFVL62tprXnVOWp6amVpssKoOhodD5o9tJQ2sXNU6MJ6pNjSGeGnLbSF1DiqeP+7nVdxPQ3OL5uiQ3a2aMmQ7VrwHXrJkxhFavxlpxVamPeBrzZtXXmM+a0bdu46xZM2N0cJYmq80A2NvUPMkIfmbcuCaVDxSTtsnZvvp6lb4ewFQNk7Up9bQwgb+HLTJy5bBuYlCjLvY10ZA+n2pDo0oWCwoqZt2qbLZSZXl+fuUzUyn3YWys+RdYk30QEREREVHjpqWlBbtK1mCmCo0qWazukXtNetTWxj6UGtrj5Yb62JsaJ8YT1SbGE9UmxhPVJsYT1aaGGk8v2g21UY3ANzU1BQAUFmo++cqnhk2aVH4yTExM1Oq+yD6IiIiIiIhedY0qWTQ2NoaVlRUyMzOhUEinFk5Lq5gK97XXXqt0H46OFX2p79+/r3F7TfZBRERERET0qmtUySIA+Pj4oKSkBBcvXpRsO336NADA19e30td37NgRAHDmzBnJNrlcjqSkJNjY2KBVq1a11GIiIiIiIqLGp9EliyEhIQAq1lR8mkwmQ1xcHMzNzdGnTx9V2c2bN/H48WNVPRcXF/j4+ODkyZO4cuWK2j5iYmJQVFSEkJCQBrP2FxERERERUX3Q+fTTTz+t70Y8j1atWiEzMxOJiYlITk5GaWkpzp07h08//RTp6elYtGgR3Nwqphf+6aefEBERAVEU4efnp9qHp6cnEhMTkZCQgPLycty/fx9xcXH4/vvv0b59eyxcuBA6OtWv51JYWFJnx/kijP5YE0cuL63nltCrgPFEtYnxRLWJ8US1ifFEtamhxpOJicELva5RzYaqNH/+fLi5uSEuLg7z5s2Dvr4+vLy8MHfuXHTu3Lna1wuCgLi4OCxbtgxRUVGQyWSws7PDuHHjMGHCBOjr67+EoyAiIiIiImq4tMTnWSuC1Dx4IKvvJqhpqFP1UuPEeKLaxHii2sR4otrEeKLa1FDj6W+xdAYRERERERG9HEwWiYiIiIiISILJIhEREREREUkwWSQiIiIiIiIJJotEREREREQkwWSRiIiIiIiIJJgsEhERERERkQSTRSIiIiIiIpJgskhEREREREQSTBaJiIiIiIhIgskiERERERERSTBZJCIiIiIiIgkmi0RERERERCTBZJGIiIiIiIgktERRFOu7EURERERERNSw8MkiERERERERSTBZJCIiIiIiIgkmi0RERERERCTBZJGIiIiIiIgkmCwSERERERGRBJNFIiIiIiIikmCySERERERERBJMFomIiIiIiEhCt74bQH9dWVkZ1q5dix07duDu3bvQ0dGBu7s7xowZg549e9Z386geyWQyrF69Grt27UJGRgb09PQgCAICAwMRGBgILS0ttfpXr15FZGQkzpw5A5lMBmtra/j7+2Py5MmwsLCQ7P/AgQNYu3YtkpOTUVpaCicnJwwaNAijR4+Gjo7OyzpMqkfHjx9HREQEACAlJUVtW2pqKpYvX47jx48jJycH5ubm8PPzw5QpU9CyZUvJvs6cOYOVK1fi0qVLKCwshL29PXr37o0JEybA2Nj4pRwPvXznz5/HihUrcP78eZSUlKBly5YYOHAgxo4dC21t9XvajCmqTnp6OlasWIHjx48jOzsb+vr6cHV1xZAhQyTfe4wneta2bduwcOFC5Ofn4+DBgxrjoK7jZsuWLdi8eTNu3LgBAHB2dkZoaCgCAwNr/4BrQEsURbFe3plqzdSpU7F3714EBATA398fxcXF2LJlCy5fvoxPP/0UoaGh9d1EqgdZWVkICQlBdnY2Bg4ciE6dOiEvLw+bN2/GrVu3EBERgRkzZqjqX7x4EeHh4TAxMUF4eDhsbW2RnJyM6Oho2NvbY+vWrTA1NVXV37BhA+bPnw93d3cMHToUJiYmOHToEPbs2YM+ffpgyZIl9XHY9BLl5+ejf//+uH//PgD1ZDE1NRXBwcEoLi5GeHg4Wrdujbt37yIqKgqGhoaIi4uDvb29qv6BAwcwdepU2NvbY8SIEbCwsMDZs2exZcsWeHt7Y/369dDV5f3NV83+/fsxbdo0ODg4YPjw4TAxMUFiYiJOnDiBQYMG4csvv1TVZUxRde7cuYNhw4ZBLpcjODgYbm5uyMvLQ0JCApKSkhASEoLPPvsMAOOJ1D169Ahz587FwYMHYWRkhMLCQo3JYl3HzZdffokffvgBXbp0Qf/+/aGtra36TBw/fjw+/PDDl3ZOVERq1Pbv3y8KgiBOnz5drbyoqEjs1auX6OXlJT569KieWkf1ac6cOaIgCOK6devUynNzc8Vu3bqJ7dq1Ex8+fKgqHzhwoOjm5iZev35drf7mzZtFQRDERYsWqcqys7PF9u3bi7169RILCwvV6k+fPl0UBEE8dOhQ7R8UNShz5swRO3ToIPbu3VsUBEFt26RJk0RBEMRjx46plR87dkwUBEF8//33VWXFxcXi66+/Lvr6+ooPHjxQq//NN9+IgiCIGzZsqLsDoXqRk5Mj+vr6igEBAaJMJlOVKxQKceTIkWK/fv3E7OxsVTljiqozY8YMURAEcdOmTWrlxcXFor+/vygIgnjv3j1RFBlPpO6tt94Su3fvLh49elQcOXKkKAiCmJqaKqlXl3Fz5coV0dXVVQwNDRUVCoWqXKFQiMOHDxfbtm0rXr16tbYOucY4ZrGR+/HHHwEAY8aMUSs3NDTEsGHDUFRUhMTExPpoGtUza2tr/POf/5R0WzAzM4OPjw8UCgWuXbsGALhy5Qp+//139OjRA23atFGrP2TIEJiZmSE+Ph7l5eUAgMTERBQXFyMkJARGRkZq9UePHg3gz9ikV9PJkycRFxeHiRMnwtLSUm3bo0ePcPjwYQiCgO7du6tt6969O1xcXHDw4EHk5OQAAA4fPoyHDx+if//+kn2Fh4dDS0uL8fQK2r59O3JzczFp0iS1Xgva2tqIjo5GQkICrKysADCmqGbu3bsHAOjUqZNaub6+Ptq3bw8ASEtLYzyRRIcOHbBz50706NGj0jp1HTfbtm2DKIoIDw9X64Kvra2NsLAwlJeXY9u2bbVxuM+FyWIjd+HCBRgYGMDNzU2yzcfHB0DFeBD6+5kyZQqWLl2qsT+8TCYDANUF2oULFwAA3t7ekrq6urrw9PRETk4Obt++DeDPmNJU393dHQYGBoy7V1hBQQFmzZoFNzc3jB07VrI9KSkJCoVCY3wAFZ9NZWVlSEpKAlB1PFlYWMDR0RFXr15FYWFhLR4F1bdjx44BAN544w1VmVwu11iXMUU1IQgCAKi+q56WlpYGHR0dtG7dmvFEEkuWLNE4N8PT6jpuqqpfn9f0TBYbsfz8fOTk5KBFixaSSQAAwM7ODsCfd9qIgIpxZWfOnIGLiwvc3d0BVPTBBwBbW1uNr1GWK+ulpaUB+DPGnqatrY0WLVrg4cOH/OJ8Rf33v/9FdnY2/vOf/2gco/Oi8VRZfTs7O5SXlyM9Pf0vt50ajhs3bsDMzAxFRUWYOnUqvLy84OXlhS5dumDBggUoKChQ1WVMUU28++67sLa2xsKFC3Ho0CE8evQI9+7dw5IlS5CUlITRo0fDxsaG8UQvpK7jJi0tDXp6eqoeFU+zsrKCnp5evVzTcyRuI6b8In22G6CSsjw/P/+ltYkatoyMDLz33nvQ1tbGp59+qrrJoIylymZzezaWnif2OEPcq+XUqVOIjY3FpEmT0LZtW411nvez6Xnjj14NT548gb6+PkaNGoXu3bvjm2++QX5+PuLj4xEdHY3Lly8jJiYGOjo6jCmqETs7O2zZsgUfffQRJk6cqCo3MDDAxx9/rBqyw3iiF1HXcVNQUABDQ0PJTPUAoKWlBUNDw3qJMSaLjZimYHqayIlu6SkXL17Ee++9hydPnmDx4sVqYzpqO5YYe6+moqIizJo1Cy4uLpg0aVKl9aqLp+etz3h6NZWUlKCoqAijRo3ClClTVOUDBgxAaGgozp8/j71796JPnz6MKaqR1NRUTJ48GZmZmZg2bRratWuH0tJSHDhwAIsWLUJ6ejpmz57NeKIXUt9xU19xxmSxEVOON6usq5/yjkaTJk1eWpuoYdq5cydmz54NIyMjrFmzBl26dFHbbmJiAgBq3b6e9mwsPR17ZmZm1danV8PixYtx//59bNq0Cfr6+pXWq+6zSXlnVFnveeOPXg0mJibIy8vD0KFD1cq1tLQQGBiI8+fP49SpU+jTpw9jimpk5syZuHHjBrZs2QIPDw9VeUBAAPT09BAdHY2uXbsynuiF1HXcmJqaIj8/H6IoShLN8vJyyOVyjddcdY1jFhsxY2NjWFlZITMzEwqFQrJd2Vf6tddee9lNowZkzZo1+Oijj+Do6Igff/xRkigCgKOjIwCo1st71rOxpKyvaXxGWVkZsrKy0KJFi0q7alDjc/bsWWzYsAFBQUGwtrZGZmam6l9JSQkAqH52cHAAUHk8KeOmdevWAGoWf7q6umjVqlWtHhPVL+Xvs6ysTLJNOWZHefHFmKLqFBYW4syZM3BwcFBLFJV69uwJADh+/DjjiV5IXceNo6MjSktLkZ2dLambkZGBsrKyermmZ7LYyPn4+KCkpAQXL16UbDt9+jQAwNfX92U3ixqImJgYfPXVV+jatStiY2Mr/SLr2LEjAODMmTOSbXK5HElJSbCxsVG9vqr658+fR2lpqWTqcmrcTp48CVEUsWnTJrz55ptq/5Sz6Sp/9vT0hJ6ensb4ACrixsDAQDWVfVXxdP/+faSnp6N9+/YwMDCoo6Oj+qD8vV+5ckWyTXlxZWNjAwCMKaqWXC6HKIooLi6udLvyf8YTvYi6jhvljKfK6/dn9w3UzzU9k8VGLiQkBEDF06OnyWQyxMXFwdzcHH369KmPplE9O3fuHBYuXAhvb2+sXLlSbR2zZ7m4uMDHxwcnT56UXLjFxMSgqKgIISEhqm4Rffv2hampKTZv3iwZbK2MxdDQ0Fo+IqpP/fr1w4oVKzT+U05Xr/y5adOm6N27N+7cuYMDBw6o7WfPnj1ITU1F//79VTHp5+cHe3t7JCYmIjMzU63+6tWrATCeXkWBgYHQ1tbGypUrUVRUpCovKSnBxo0bAfz5NIgxRdWxsLCAk5MTMjIycOrUKcl25ZrTnTp1YjzRC6nruAkMDISuri7Wrl2r1uOitLQU69atg56enmTt7JdBS+So3EZv1qxZ+PHHH+Hv74+AgAAUFhYiNjYWt27dwjfffIPevXvXdxOpHgwdOhSXL1/GBx98ACcnJ4112rRpgzZt2gAArl27hhEjRkBHRwcRERGwtbXFhQsXEBsbC3d3d8TExKiNU9u+fTs+/vhjCIKAkJAQGBkZYffu3Thy5AjCwsIwe/bsl3GY1ACEhYXh9OnTSElJUZVlZ2cjODgYT548wejRo+Hs7IwbN25g7dq1sLa2xubNm9XWtDp58iTeffddWFlZYdSoUWjWrBmOHTuGnTt3omfPnli+fPlzTy5ADd93332HZcuWwd3dHaGhoSgqKkJ8fDySk5MRHByM+fPnq+oypqg6R48exeTJk6Gjo4MRI0bAzc0NRUVF2L17N44fPw5vb2+sX78e+vr6jCdSSU9PV62NCFR8Lt24cQPz5s1TxYC9vT3at29f53ETGRmJb7/9Fp06dcKgQYMAAFu3bsX58+fxySefYPTo0S/npDyFyeIroLy8HLGxsYiLi8Pt27ehr68PLy8vTJgwAZ07d67v5lE9cXV1rbbOlClT8P7776t+vn37NpYtW4YTJ05AJpPBzs4OvXv3xoQJE1QDtZ92/PhxfP/996qFap2dnRESEoKgoCB+af6NaEoWASArKwvLly/H4cOH8fjxY1haWsLf3x/vvfcemjdvLtnPpUuXEBkZiXPnzqGoqAiOjo4YOHAgRo8eDT09vZd1OPSS7dq1C+vXr0dKSgrKy8ur/BxhTFF1rl69ilWrVuHMmTN4/Pgx9PT04OTkhHfeeQfh4eFqXUUZTwQA27ZtwyeffFJlncGDB2PRokUA6j5uEhMTER0djZSUFGhpaaFdu3YYPXo0AgICaueAnxOTRSIiIiIiIpLgmEUiIiIiIiKSYLJIREREREREEkwWiYiIiIiISILJIhEREREREUkwWSQiIiIiIiIJJotEREREREQkwWSRiIiIiIiIJJgsEhERERERkQSTRSIiIiIiIpJgskhEREREREQSTBaJiIiIiIhIgskiERH9bWzbtg2urq747rvv6rspL0QURXz99dfo0qUL3N3dsWrVqvpuUq1zdXVF796967sZREQEJotERPQXnDp1Cq6urnB1dcWRI0eqrddYk7SG4ujRo1i9ejWaNWuGBQsWwM/Pr76bRERErzAmi0REVCvmzZuH/Pz8+m7GKy0lJQUAEBYWhsGDB6Ndu3b13CIiInqVMVkkIqK/zM/PDxkZGfj666/ruymvtOLiYgCAkZFRPbeEiIj+DpgsEhHRX9a3b1+8+eab2Lx5M86cOVOj11Q1fnDDhg2SbWFhYXB1dcXjx4/x5ZdfokePHvD09ET//v1x8OBBAEBCQgIGDhwILy8v+Pv7Y8GCBSgtLdX4/r/88gtCQkLg7e0Nb29vjBkzBleuXJHUe/DgAebPn4+ePXvCw8MDvr6+CAsLw08//aRWLy0tDa6urpg8eTKOHDmCf/zjH/Dw8Kj2PBQWFmLp0qXo27cvvLy80KFDB/Tv3x+RkZGq5BCoGMu3bNkyAMAnn3xSo269oihi8+bNCAoKgre3Nzw9PdG7d28sXrwYeXl5anWV5/fu3btYsmQJ/P394eHhgTfeeAOLFi1CYWGhZP8HDx5EeHg4fH19VXU//PBD3Lx5U1K3uLgYy5YtQ9++feHp6YnOnTtj2rRpuH79usa2FxQUYP78+ejRowc8PDzg7++PyMhIiKKoVu/w4cOIiIiAn58fPDw80KNHD0yZMgUXLlyo8twQEVH1dOu7AURE9Gr47LPP0LdvX8yePRs7d+6EgYFBnbzPggULUFRUhGnTpiE9PR2rV6/GtGnTMH36dGzatAkjRoyAgYEB1q1bh+joaLRo0QLjxo1T28elS5ewefNmBAYGIjg4GFevXsXGjRsxatQo7NixAy1btgQAZGVlISgoCIWFhQgJCYGLiwtycnKwfft2TJ8+Hbdu3cL777+vtm+ZTIa5c+dizJgxMDc3r/JYSkpKMGrUKCQlJaFv374ICwuDKIo4fvw4vv32W5w6dQpRUVHQ1tbGt99+i927d2PPnj0YMWIEOnfujDZt2lS5/5kzZ2Lbtm3o2bMngoODAQBnz57FmjVrcOjQIcTFxcHY2FjtNZ9//jnkcjkiIiJgYmKCnTt3IioqCrdv38bKlStV9aKiorBo0SK0adMG48ePh7W1NW7evImYmBj8/PPP2LhxI9q2bQsAKC0tRXh4OC5duoTQ0FBMmDABmZmZWLt2LYKDgxEbG6uqC1QkuZMmTYKlpSWmTZuG4uJirFq1Ct9++y3MzMwwcuRIAMDu3bvxr3/9Cx4eHpg4cSLMzc2Rnp6O2NhYhIWFYePGjWjfvn2V54iIiKogEhERvaBff/1VFARB3Lp1qyiKohgTEyMKgiB+9dVXGustXbpUVbZ161ZJmVJ0dLRk28iRI0VBEMSxY8eq1Z0zZ44oCILYoUMH8cGDB6ryc+fOiYIgiMOHD5e8p5ubm5iSkqK2nx9++EEUBEGcP3++quxf//qX6ObmJl66dEmtbnFxsdi/f3+xXbt2Ynp6uiiKopiamioKgiC6urqKCQkJVZ+4Kt5TaerUqaIgCGJiYqKqbOnSpWrnuypHjhwRBUEQFy5cKNm2cuVKURAE8X//+5+qTHl+Bw0aJJaWlqrKy8rKxAEDBoiCIKjOQ3Z2tuju7i6+8cYbokwmU9v34cOHRUEQxIiICFWZMi4iIyPV6v7222+iIAji+PHjVWWCIIiCIIhLlixRq3v69GlREAQxPDxcVTZx4kRREATx4cOHanXv3r0rjho1SoyPj6/uNBERURXYDZWIiGpNaGgoOnXqhKioKI1dOmtDUFCQ2s/KSV78/f1haWmpKndzcwNQ0Y30WZ07d4YgCGplffv2BVAxcysAyOVy7N+/H+3atYOjoyPy8vJU/+RyOQICAqBQKPDLL7+o7cfQ0BABAQE1Opa9e/cCqOgC+qyQkBAAwIEDB2q0r2clJCQAAPr376/W9ry8PFX7Dh8+LHldUFAQdHX/7Hiko6ODd955BwDw22+/AQB+/vlnlJaWYtCgQTA1NVV7/ZtvvglbW1ucPHlS1XVV2WV3yJAhanV9fHywceNGzJgxQ61cS0tL8jRY+fvMyspSlenp6QH483em5ODggHXr1mHQoEEazw0REdUMu6ESEVGt0dLSwoIFCzBw4EDMnDkTW7duVUs8aoO9vb3az8rurpWVl5WVSfbh4uIiKbO2toaBgQHS0tIAAHfu3EFpaSmSkpLg6+tbaXuU9ZVsbGygr69fgyMBbty4AX19fTg6Okq2OTs7AwBu3bpVo309SzkWMDAwsNI6z7YdgCSJBoAWLVoA+DPxvnHjBgDN5xGoaHtGRgbu3r2Ldu3aISUlBQYGBrCxsZHU7dixo6TM0tJSkoSamJgAgNo4znHjxuHYsWP44IMPEBUVBT8/P3Tt2hUdO3as9bgjIvo74icpERHVqtdeew1TpkzB4sWLsWrVKkyaNKlW919ZIqZ8ylQTysTjWYaGhqrlP5T/d+jQAdOnT690X7a2tjXatyaFhYWSpEhJOeNpUVFRjff3tIKCAgDA8uXL0aRJE411NCVUmtqjLJPJZACgemJY2ayshoaGavUKCgoqPU5Nappse3p6Yvv27YiKisKBAwcQGRmJyMhImJubIyIiAu+++y60tLRq/L5ERKSOySIREdW6iIgI7N69G5GRkTXukvk0uVxeB62qfv9yuVyVACmTG4VCgS5dutRJO0xMTFBYWAhRFCVJjTLRep7k82nK9js5OVU7Ec7TNJ0bZZLYtGlTtTZpmiH16XJlPVNTU8hkMigUCujo6NS4LTXh4OCAefPmYd68ebh27RqOHj2K2NhYfPPNNygvL6/1mxVERH8nHLNIRES1TldXFwsXLkR5eTlmz56N8vJyjXUAzQnHnTt36rR9mpZ2yMzMRHFxMRwcHABUPCHV09PD9evXkZubK6mfm5ursYvr83BxsFiHsAAABKpJREFUcUFpaSlu374t2ZaSkgLgz+6oz0vZnVTTUiaiKOLx48caX6fp3Ny9exdARVddZbsB4Nq1axr3ff36dejq6sLJyQlAxTEoy5+VkJCA+Pj4GhxR9QRBwLhx47Blyxbo6empxoQSEdGLYbJIRER1ws3NDRERETh37hw2btwo2a4cv5acnKxWnpWVJVnDsLadOHFCkqDt3LkTANC9e3cAFWMeAwICIJfLsW7dOrW6ZWVlmDp1Kvz8/CpNumpCOalOdHS0WrkoioiJiQEA1eQyz6tfv34AgPXr10ueFm7btg1+fn7YsmWL5HVbtmyBQqFQ/VxWVoY9e/YAqJgYCAB69uwJQ0NDxMfHq546Ku3ZswcPHjzA22+/reqO2qdPHwBAbGysWt2UlBR8+OGHqsl4nkdRURGCgoLw0UcfSbYZGhpCW1u7xt1ZiYhIM3ZDJSKiOjNlyhTs27cP+/btk2zz9vaGjY0Nfv31V8ydOxc+Pj7Izs5GdHQ0evfujW3bttVZu7p27YrRo0cjKCgIdnZ2SE5ORmxsLMzNzTFq1ChVvRkzZuDs2bOIjIzE/fv30a1bN8hkMuzYsQOXLl3C+PHjYWFh8cLtGDZsGHbt2oWNGzciLy8PXbt2RUlJCQ4dOoRffvkF77zzDnr27PlC++7RowcGDx6M+Ph4DBs2DMHBwTA2NsZvv/2G+Ph4ODk5oVevXpLXmZiYIDw8HAEBATA1NcXOnTtx+/ZtvPPOO3B1dQUAWFhY4JNPPsG8efMQEhKCwMBAmJubIyUlBbGxsWjevDk+/vhj1T5DQkKQmJiITZs2obi4GN26dUNWVhbWr18PQ0NDyWyoNWFkZIT27dsjJiYGjx8/hr+/P8zNzfHo0SNs374dJSUlGmeZJSKimmOySEREdcbAwAALFy7EyJEjIYqi2jZ9fX2sXbsWX3zxBRISErBz5044Oztj3rx50NHRqdNk0c/PD+Hh4Vi2bBlSUlKgpaWF119/Hf/+979VXS2BiqefW7duxYoVK3Do0CEkJiZCT08Prq6u+PLLL//y0gy6urpYs2YNVq1ahV27dmHfvn3Q0dFB69atMXv2bAwfPvwv7f+LL75Ahw4dsHXrVvz3v/9FaWkpbG1tERYWhgkTJsDc3Fzymg8//BAHDx5EdHQ0MjIyYGFhgXHjxmHq1Klq9UJCQmBra4s1a9Zg+fLlkMvlsLKywsCBAzF58mTVDKpAxe86KioK33//PXbv3o3ExEQYGRmha9eu+OCDD9C6desXOr45c+bAxcUF27dvx9KlS1FQUABra2u4uLhg9erV8PPze6H9EhFRBS3x2W9vIiIi+tsJCwvD6dOnkZCQoHH5DCIi+vvhmEUiIiIiIiKSYLJIREREREREEkwWiYiIiIiISIJjFomIiIiIiEiCTxaJiIiIiIhIgskiERERERERSTBZJCIiIiIiIgkmi0RERERERCTBZJGIiIiIiIgkmCwSERERERGRBJNFIiIiIiIikmCySERERERERBJMFomIiIiIiEiCySIRERERERFJMFkkIiIiIiIiCSaLREREREREJMFkkYiIiIiIiCSYLBIREREREZHE/we1+d2qcLHFOAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1050x750 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1050x750 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1350x1050 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Angry       1.00      0.99      1.00       104\n",
            "     Boredom       0.99      0.96      0.97        69\n",
            "     Disgust       1.00      1.00      1.00        26\n",
            "        Fear       0.95      0.97      0.96        63\n",
            "       Happy       0.95      1.00      0.97        55\n",
            "     Neutral       1.00      0.98      0.99        62\n",
            "     Sadness       1.00      1.00      1.00        49\n",
            "\n",
            "    accuracy                           0.98       428\n",
            "   macro avg       0.98      0.99      0.98       428\n",
            "weighted avg       0.98      0.98      0.98       428\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}